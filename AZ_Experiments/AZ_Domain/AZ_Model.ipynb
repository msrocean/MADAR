{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time, random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from ember_utils import *\n",
    "from ember_model import *\n",
    "from ember_pjr_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = '/home/mr6564/continual_research/AZ_Data/Domain/'\n",
    "train_file = raw_path + 'All_Domain_AZ_Train.npz'\n",
    "test_file = raw_path + 'All_Domain_AZ_Test.npz'\n",
    "\n",
    "\n",
    "train_data = np.load(train_file, allow_pickle=True)\n",
    "test_data = np.load(test_file, allow_pickle=True)\n",
    "\n",
    "X_train, Y_train, Y_tr_family_year = train_data['X_train'], train_data['Y_train'], train_data['Y_tr_family']\n",
    "X_test, Y_test, Y_te_family_year = test_data['X_test'], test_data['Y_test'], test_data['Y_te_family']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 2.0.1 CUDA 11.8\n",
      "Model has 3.720193m parameters\n",
      "X_train (682598, 2959) Y_train (682598,)\n",
      "X_test (75848, 2959) Y_test (75848,)\n",
      "Epoch 1 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1333/1333 [00:14<00:00, 94.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 149/149 [00:01<00:00, 112.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6893, Train Acc: 0.5271\n",
      "Val Loss: 0.6989, Val Acc: 0.5849\n",
      "Validation loss decreased (inf --> 0.698858).  Saving model ...\n",
      "../az_model/model/best_model_epoch_1.pt\n",
      "../az_model/opt/best_optimizer_epoch_1.pt\n",
      "Epoch 2 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1333/1333 [00:14<00:00, 94.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 149/149 [00:01<00:00, 92.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6668, Train Acc: 0.5739\n",
      "Val Loss: 0.6650, Val Acc: 0.5801\n",
      "Validation loss decreased (0.698858 --> 0.664996).  Saving model ...\n",
      "../az_model/model/best_model_epoch_2.pt\n",
      "../az_model/opt/best_optimizer_epoch_2.pt\n",
      "Epoch 3 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1333/1333 [00:13<00:00, 98.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 149/149 [00:01<00:00, 97.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6084, Train Acc: 0.6352\n",
      "Val Loss: 0.6769, Val Acc: 0.6048\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 4 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1333/1333 [00:13<00:00, 98.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 149/149 [00:01<00:00, 112.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5541, Train Acc: 0.6759\n",
      "Val Loss: 0.7139, Val Acc: 0.5854\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 5 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1333/1333 [00:13<00:00, 97.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 149/149 [00:01<00:00, 108.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5151, Train Acc: 0.7024\n",
      "Val Loss: 0.7294, Val Acc: 0.6515\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 6 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1333/1333 [00:13<00:00, 96.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 149/149 [00:01<00:00, 135.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4871, Train Acc: 0.7216\n",
      "Val Loss: 0.7850, Val Acc: 0.6066\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 7 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1333/1333 [00:15<00:00, 86.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 149/149 [00:01<00:00, 119.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4664, Train Acc: 0.7342\n",
      "Val Loss: 0.7730, Val Acc: 0.6409\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Training time: 1.800 minutes\n",
      "Elapsed time 1.8717517852783203 mins.\n",
      "loading best model ../az_model/model/best_model_epoch_2.pt\n",
      "loading best optimizer ../az_model/opt/best_optimizer_epoch_2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 149/149 [00:01<00:00, 88.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.5050845334193851 and ROC-AUC 0.5054501448809074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Ember_MLP_Net(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(Ember_MLP_Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_features, 1024)\n",
    "        #self.fc1_bn = nn.BatchNorm1d(1024)\n",
    "        self.act1 = nn.ReLU()\n",
    "        #self.fc1_drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        #self.fc2_bn = nn.BatchNorm1d(512)\n",
    "        self.act2 = nn.ReLU()\n",
    "        #self.fc2_drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        #self.fc3_bn = nn.BatchNorm1d(256)\n",
    "        self.act3 = nn.ReLU()\n",
    "        #self.fc3_drop = nn.Dropout(p=0.5)        \n",
    "        \n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        #self.fc4_bn = nn.BatchNorm1d(128)\n",
    "        self.act4 = nn.ReLU()\n",
    "        #self.fc4_drop = nn.Dropout(p=0.5)  \n",
    "        \n",
    "        self.fc_last = nn.Linear(128, 1) \n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "        #self.activate = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        #x = self.fc1_bn(x)\n",
    "        x = self.act1(x) \n",
    "        #x = self.fc1_drop(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        #x = self.fc2_bn(x)\n",
    "        x = self.act2(x) \n",
    "        #x = self.fc2_drop(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        #x = self.fc3_bn(x)\n",
    "        x = self.act3(x) \n",
    "        #x = self.fc3_drop(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        #x = self.fc4_bn(x)\n",
    "        x = self.act4(x)\n",
    "        #x = self.fc4_drop(x)\n",
    "        \n",
    "        x = self.fc_last(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exp_seeds = [random.randint(1, 99999) for i in range(1)]\n",
    "\n",
    "\n",
    "accs_all = []\n",
    "rocauc_all = []\n",
    "\n",
    "num_epoch = 500\n",
    "batch_size = 512\n",
    "patience = 5\n",
    "\n",
    "\n",
    "input_features = X_train.shape[1]\n",
    "\n",
    "replay_type, current_task = 'azdomain', 'azdomain'\n",
    "\n",
    "for exp in exp_seeds:\n",
    "\n",
    "    start_time = time.time()\n",
    "    use_cuda = True\n",
    "    print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "    use_cuda = use_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    torch.manual_seed(exp)\n",
    "\n",
    "    model = Ember_MLP_Net(input_features)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.000001)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "       \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(f'Model has {count_parameters(model)/1000000}m parameters')    \n",
    "    criterion = nn.BCELoss()    \n",
    "\n",
    "    \n",
    "#     standardization = StandardScaler()\n",
    "#     standard_scaler = standardization.fit(X_train)\n",
    "\n",
    "#     X_train = standard_scaler.transform(X_train)\n",
    "#     X_test = standard_scaler.transform(X_test)\n",
    "    \n",
    "    X_train, Y_train = np.array(X_train, np.float32), np.array(Y_train, np.int32)\n",
    "    X_test, Y_test = np.array(X_test, np.float32), np.array(Y_test, np.int32)  \n",
    "\n",
    "    \n",
    "    model_save_dir = '../az_model/model/'\n",
    "    create_parent_folder(model_save_dir)\n",
    "\n",
    "    opt_save_path = '../az_model/opt/'\n",
    "    create_parent_folder(opt_save_path)\n",
    "\n",
    "    results_save_dir =  '../az_model/res/' \n",
    "    create_parent_folder(results_save_dir)\n",
    "\n",
    "    print(f'X_train {X_train.shape} Y_train {Y_train.shape}')\n",
    "    print(f'X_test {X_test.shape} Y_test {Y_test.shape}')\n",
    "    \n",
    "    \n",
    "    task_training_time, epoch_ran, training_loss, validation_loss  = training_early_stopping(\\\n",
    "                                 model, model_save_dir, opt_save_path, X_train, Y_train,\\\n",
    "                                 X_test, Y_test, patience, batch_size, device, optimizer, num_epoch,\\\n",
    "                                 criterion, replay_type, current_task, exp, earlystopping=True)\n",
    "\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f'Elapsed time {(end_time - start_time)/60} mins.') \n",
    "    \n",
    "    \n",
    "    \n",
    "    best_model_path = model_save_dir + os.listdir(model_save_dir)[0]\n",
    "    print(f'loading best model {best_model_path}')\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.000001)\n",
    "    best_optimizer = opt_save_path + os.listdir(opt_save_path)[0]\n",
    "    print(f'loading best optimizer {best_optimizer}')\n",
    "    optimizer.load_state_dict(torch.load(best_optimizer))\n",
    "\n",
    "\n",
    "    acc, precision, recall, f1score = testing_aucscore(model, X_test, Y_test, batch_size, device)\n",
    "    print()\n",
    "    del model_save_dir\n",
    "    del opt_save_path\n",
    "    del results_save_dir\n",
    "    \n",
    "#     accs_all.append(acc)\n",
    "#     rocauc_all.append(rocauc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
