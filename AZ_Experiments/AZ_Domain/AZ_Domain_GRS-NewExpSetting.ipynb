{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "            Year-Train         Year-Test\n",
    "            \n",
    "       1         2008            2009-2016 ==> 8\n",
    "       2         2009            2010-2016 ==> 7\n",
    "       3         2010            2011-2016 ==> 6\n",
    "       4         2011            2012-2016 ==> 5\n",
    "       5         2012            2013-2016 ==> 4\n",
    "       6         2013            2014-2016 ==> 3\n",
    "       7         2014            2015-2016 ==> 2\n",
    "       8         2015            2016      ==> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CountV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import scipy\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time, random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from ember_utils import *\n",
    "from ember_model import *\n",
    "from ember_pjr_utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ember_MLP_Net(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(Ember_MLP_Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_features, 1024)\n",
    "        self.fc1_bn = nn.BatchNorm1d(1024)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc1_drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc2_bn = nn.BatchNorm1d(512)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.fc2_drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc3_bn = nn.BatchNorm1d(256)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.fc3_drop = nn.Dropout(p=0.5)        \n",
    "        \n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc4_bn = nn.BatchNorm1d(128)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.fc4_drop = nn.Dropout(p=0.5)  \n",
    "        \n",
    "        self.fc_last = nn.Linear(128, 1) \n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "        #self.activate = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_bn(x)\n",
    "        x = self.act1(x) \n",
    "        x = self.fc1_drop(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_bn(x)\n",
    "        x = self.act2(x) \n",
    "        x = self.fc2_drop(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.fc3_bn(x)\n",
    "        x = self.act3(x) \n",
    "        x = self.fc3_drop(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.fc4_bn(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc4_drop(x)\n",
    "        \n",
    "        x = self.fc_last(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "def testing_aucscore(model, X_test, Y_test, batch_size, device):\n",
    "    #X_te = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "    #y_te = torch.from_numpy(Y_test).type(torch.FloatTensor) \n",
    "    \n",
    "    testloader = get_dataloader(X_test, Y_test, batch_size, train_data=False)   \n",
    "    \n",
    "    model.eval()\n",
    "    y_pred_list = []\n",
    "    y_true_list = []\n",
    "    test_acc = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(testloader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_test_pred = model(x_batch)\n",
    "            tmp_test_acc = binary_acc(y_test_pred, y_batch)\n",
    "            test_acc.append(tmp_test_acc.item())\n",
    "            \n",
    "            y_pred_tag = torch.round(y_test_pred).squeeze(1)\n",
    "            y_pred_list += list(y_pred_tag.cpu().numpy())\n",
    "            y_true_list += list(y_batch.cpu().numpy())\n",
    "        \n",
    "            \n",
    "    #correct_test_results = (np.array(y_pred_list) == np.array(y_true_list)).sum()\n",
    "    #acc = correct_test_results/len(y_true_list)\n",
    "    \n",
    "    from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "    \n",
    "    correct_labels, predicted_labels = np.array(y_true_list), np.array(y_pred_list)\n",
    "    \n",
    "    roc_auc = roc_auc_score(correct_labels, predicted_labels)\n",
    "    precision = precision_score(correct_labels, predicted_labels, average='micro')\n",
    "    recall = recall_score(correct_labels, predicted_labels, average='micro')\n",
    "    f1score = f1_score(correct_labels, predicted_labels, average='macro')\n",
    "    \n",
    "    print(f'test accuracy {np.mean(test_acc)} and ROC-AUC {roc_auc}')\n",
    "\n",
    "    #wrong_good, wrong_mal, top_k_mistaken_families = \\\n",
    "    #            get_mistaken_stats(np.array(y_true_list), np.array(np.round(y_pred_list)), Y_test_family, top_k)\n",
    "    \n",
    "    return np.mean(test_acc), roc_auc, precision, recall, f1score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_year_data(data_dir, year, train=True):\n",
    "    \n",
    "    if train:\n",
    "        data_dir = data_dir + '/'\n",
    "        XY_train = np.load(data_dir + str(year) + '_Domain_AZ_Train_Transformed.npz', allow_pickle=True)\n",
    "        X_tr, Y_tr = XY_train['X_train'], XY_train['Y_train']\n",
    "        \n",
    "        return X_tr, Y_tr\n",
    "    else:\n",
    "        data_dir = data_dir + '/'\n",
    "        XY_test = np.load(data_dir + str(year) + '_Domain_AZ_Test_Transformed.npz', allow_pickle=True)\n",
    "        X_test, Y_test = XY_test['X_test'], XY_test['Y_test']\n",
    "\n",
    "        return X_test, Y_test \n",
    "\n",
    "\n",
    "def get_MemoryData(X, Y, memory_budget):\n",
    "    indx = [i for i in range(len(Y))]\n",
    "    random.shuffle(indx)\n",
    "    \n",
    "    replay_index = indx[:memory_budget]\n",
    "    X_train = X[replay_index]\n",
    "    Y_train = Y[replay_index]\n",
    "    \n",
    "    return X_train, Y_train\n",
    "\n",
    "\n",
    "\n",
    "def get_GRS_data(data_dir, task_years, memory_budget, train=True, joint=True):\n",
    "    \n",
    "    if train:\n",
    "        X_tr, Y_tr = get_year_data(data_dir, task_years[-1])\n",
    "        print(f'Current Task Year {task_years[-1]} data X {X_tr.shape} Y {Y_tr.shape}')\n",
    "        \n",
    "        if len(task_years) != 1:\n",
    "            previous_Xs, previous_Ys = [], []\n",
    "            for year in task_years[:-1]:\n",
    "                pre_X_tr, pre_Y_tr = get_year_data(data_dir, year)\n",
    "\n",
    "\n",
    "                pre_X_tr, pre_Y_tr = np.array(pre_X_tr), np.array(pre_Y_tr)\n",
    "                #print(f'pre_X_tr {pre_X_tr.shape}  pre_Y_tr {pre_Y_tr.shape}')\n",
    "\n",
    "                for idx, prevSample in enumerate(pre_X_tr):\n",
    "                    previous_Xs.append(prevSample)\n",
    "                    previous_Ys.append(pre_Y_tr[idx])\n",
    "\n",
    "\n",
    "            previous_Xs, previous_Ys = np.array(previous_Xs), np.array(previous_Ys)  \n",
    "\n",
    "            #print(f'Y_tr {Y_tr.shape}  previous_Ys {previous_Ys.shape}')\n",
    "            if joint:\n",
    "                X_tr, Y_tr = np.concatenate((X_tr, previous_Xs)), np.concatenate((Y_tr, previous_Ys))\n",
    "            else:\n",
    "                if memory_budget >= len(previous_Ys):\n",
    "                    X_tr, Y_tr = np.concatenate((X_tr, previous_Xs)), np.concatenate((Y_tr, previous_Ys))\n",
    "                else:\n",
    "                    previous_Xs, previous_Ys = get_MemoryData(previous_Xs, previous_Ys, memory_budget)\n",
    "                    X_tr, Y_tr = np.concatenate((X_tr, previous_Xs)), np.concatenate((Y_tr, previous_Ys))\n",
    "                    #print(f'memory_budget {memory_budget}  Y_tr {previous_Ys.shape} ')\n",
    "                    assert memory_budget == len(previous_Ys)\n",
    "            \n",
    "\n",
    "        X_train, Y_train  = X_tr, Y_tr\n",
    "        print(f'X_train {X_train.shape} Y_train {Y_train.shape}\\n')\n",
    "        return X_train, Y_train\n",
    "    else:\n",
    "        X_te, Y_te = get_year_data(data_dir, task_years[-1], train=False)\n",
    "        for year in task_years[:-1]:\n",
    "            pre_X_te, pre_Y_te = get_year_data(data_dir, year, train=False)\n",
    "            \n",
    "            X_te, Y_te = np.concatenate((X_te, pre_X_te)), np.concatenate((Y_te, pre_Y_te))\n",
    "\n",
    "        X_test, Y_test  = X_te, Y_te\n",
    "        print(f'X_test {X_test.shape} Y_test {Y_test.shape}')\n",
    "        return X_test, Y_test\n",
    "\n",
    "\n",
    "\n",
    "data_dir = '/home/mr6564/continual_research/AZ_Data/Domain_Transformed/' #args.data_dir\n",
    "num_exps = 1 #args.num_exps\n",
    "num_epoch = 100 #args.num_epoch\n",
    "batch_size = 512 #args.batch_size\n",
    "memory_budget = 'none' #args.memory_budget\n",
    "patience = 5\n",
    "\n",
    "exp_seeds = [random.randint(1, 99999) for i in range(1)]\n",
    "\n",
    "all_task_years = ['2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016']\n",
    "\n",
    "\n",
    "if args.grs_joint:\n",
    "    memory_budget = 'joint'\n",
    "\n",
    "input_features = 1789\n",
    "\n",
    "replay_type, current_task = 'azdomain', 'azdomain'\n",
    "\n",
    "\n",
    "cnt =  1    \n",
    "for exp in exp_seeds:\n",
    "    start_time = time.time()\n",
    "    use_cuda = True\n",
    "    print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "    use_cuda = use_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    torch.manual_seed(exp)\n",
    "\n",
    "    model = Ember_MLP_Net(input_features)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.000001)\n",
    "       \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(f'Model has {count_parameters(model)/1000000}m parameters')    \n",
    "    criterion = nn.BCELoss()    \n",
    "    \n",
    "    \n",
    "#     standardization = StandardScaler()\n",
    "#     standard_scaler = None\n",
    "    for task_year in range(len(all_task_years)):\n",
    "                \n",
    "        print(f'\\n{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Round {cnt} ...')\n",
    "        task_start = time.time()\n",
    "        current_task = all_task_years[task_year]\n",
    "        task_years = all_task_years[:task_year+1]\n",
    "        print(f'Current Task {current_task} with Budget {memory_budget}')\n",
    "\n",
    "\n",
    "        model_save_dir = '../az_model/GRS_SavedModel' + '/GRSModel_' + str(memory_budget) + '/' + str(current_task) + '/'\n",
    "        create_parent_folder(model_save_dir)\n",
    "        \n",
    "        opt_save_path = '../az_model/GRS_SavedModel' + '/GRSOpt_' + str(memory_budget) + '/' + str(current_task) + '/'\n",
    "        create_parent_folder(opt_save_path)\n",
    "        \n",
    "        results_save_dir =  '../az_model/GRS_SavedResults_' +'/GRS_' + str(memory_budget) + '/' \n",
    "        create_parent_folder(results_save_dir)\n",
    "        \n",
    "        \n",
    "        if args.grs_joint:\n",
    "            X_train, Y_train = get_GRS_data(data_dir, task_years, memory_budget, train=True, joint=True)\n",
    "            X_test, Y_test = get_GRS_data(data_dir, task_years, memory_budget, train=False, joint=True)\n",
    "        else:\n",
    "            X_train, Y_train = get_GRS_data(data_dir, task_years, memory_budget, train=True, joint=False)\n",
    "            X_test, Y_test = get_GRS_data(data_dir, task_years, memory_budget, train=False, joint=False)\n",
    "        \n",
    "        \n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Standardizing ...')\n",
    "        \n",
    "#         if args.grs_joint:\n",
    "#                 standardization = StandardScaler()\n",
    "#                 standard_scaler = None\n",
    "#                 standard_scaler = standardization.fit(X_train)\n",
    "#         else:        \n",
    "#                 standard_scaler = standardization.partial_fit(X_train)\n",
    "\n",
    "#         X_train = standard_scaler.transform(X_train)\n",
    "#         X_test = standard_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "        X_train, Y_train = np.array(X_train, np.float32), np.array(Y_train, np.int32)\n",
    "        X_test, Y_test = np.array(X_test, np.float32), np.array(Y_test, np.int32)        \n",
    "        \n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Training ...')\n",
    "        \n",
    "        \n",
    "        \n",
    "        task_training_time, epoch_ran, training_loss, validation_loss  = training_early_stopping(\\\n",
    "                                     model, model_save_dir, opt_save_path, X_train, Y_train,\\\n",
    "                                     X_test, Y_test, patience, batch_size, device, optimizer, num_epoch,\\\n",
    "                                     criterion, replay_type, current_task, exp, earlystopping=True)\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f'Elapsed time {(end_time - start_time)/60} mins.') \n",
    "\n",
    "\n",
    "        best_model_path = model_save_dir + os.listdir(model_save_dir)[0]\n",
    "        print(f'loading best model {best_model_path}')\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "        #optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.000001)\n",
    "        best_optimizer = opt_save_path + os.listdir(opt_save_path)[0]\n",
    "        print(f'loading best optimizer {best_optimizer}')\n",
    "        optimizer.load_state_dict(torch.load(best_optimizer))\n",
    "\n",
    "\n",
    "        acc, rocauc, precision, recall, f1score = testing_aucscore(model, X_test, Y_test, batch_size, device)\n",
    "        end_time = time.time()\n",
    "        print(f'Elapsed time {(end_time - start_time)/60} mins.')    \n",
    "        \n",
    "       \n",
    "        results_f = open(os.path.join('./Submission_Domain/' + 'grs_' + str(memory_budget) + '_results.txt'), 'a')\n",
    "        result_string = '{}\\t{}\\t{}\\t{}\\t{}\\t\\n'.format(current_task, acc, precision, recall, f1score)\n",
    "        \n",
    "        results_f.write(result_string)\n",
    "        results_f.flush()\n",
    "        results_f.close()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    cnt += 1\n",
    "    print(f'Elapsed time {(end_time - start_time)/60} mins.')\n",
    "    \n",
    "    del model_save_dir\n",
    "    del opt_save_path\n",
    "    del results_save_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
