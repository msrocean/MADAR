Current date and time 
##### START task 10000 grs #####
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.9894319682959049]
 precisions [0.9903126376045794]
 recalls [0.9907529722589168]
 f1scores [0.9885538194588557]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.995 Precision 0.995 Recall 0.995 F1 0.995 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9951563188022897, 1.0]
 precisions [0.9960369881109643, 1.0]
 recalls [0.9951563188022897, 1.0]
 f1scores [0.9951211773342621, 1.0]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.997 


accs [0.9740202553940995, 1.0, 0.9976019184652278]
 precisions [0.9669749009247027, 0.9951690821256038, 0.9976019184652278]
 recalls [0.9682959048877147, 1.0, 0.9952038369304557]
 f1scores [0.9669056400941859, 0.9966831140350877, 1.0]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.970 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.964 


accs [0.973139586085425, 0.9887278582930756, 0.9712230215827338, 0.9628252788104089]
 precisions [0.9744605900484368, 0.9790660225442834, 0.9688249400479616, 0.9671623296158612]
 recalls [0.9704975781594012, 0.9806763285024155, 0.9664268585131894, 0.9609665427509294]
 f1scores [0.9728162370313367, 0.9773263845836946, 0.9702670083023162, 0.9566356776008623]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.934 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.930 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.936 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.894 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.872 


accs [0.9339498018494056, 0.92914653784219, 0.935251798561151, 0.90272614622057, 0.8815301170425349]
 precisions [0.9299867899603699, 0.9307568438003221, 0.9424460431654677, 0.8866171003717472, 0.8838138738224379]
 recalls [0.9264641127256715, 0.9565217391304348, 0.9448441247002398, 0.8866171003717472, 0.8895232657721953]
 f1scores [0.9280080242399267, 0.9326478148743632, 0.9494729172575681, 0.8716426633745737, 0.8735593588088127]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.907 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.846 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.830 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.9053280493174812, 0.964573268921095, 0.9376498800959233, 0.8494423791821561, 0.8544105052811876, 0.9977426636568849]
 precisions [0.9031263760457948, 0.9629629629629629, 0.9136690647482014, 0.8543990086741016, 0.8461318869540394, 1.0]
 recalls [0.9035667107001321, 0.961352657004831, 0.9136690647482014, 0.8568773234200744, 0.8538395660862118, 1.0]
 f1scores [0.911494269733546, 0.9691458520194821, 0.9101597263461908, 0.84409737027523, 0.8252404797930373, 0.997632804566306]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.929 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.938 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.896 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.834 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.825 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.949 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.884 


accs [0.9304271246147072, 0.9339774557165862, 0.8992805755395683, 0.8370508054522925, 0.842706251784185, 0.945823927765237, 0.8864883401920439]
 precisions [0.9185380889476001, 0.9355877616747182, 0.8920863309352518, 0.8469640644361834, 0.8535540964887239, 0.9480812641083521, 0.8796296296296297]
 recalls [0.9339498018494056, 0.9371980676328503, 0.9088729016786571, 0.8370508054522925, 0.8532686268912361, 0.9322799097065463, 0.8885459533607681]
 f1scores [0.9203441135844311, 0.9332271346736899, 0.9123459456265446, 0.8254311422659019, 0.8295900709439991, 0.9425321041958566, 0.8873978245027114]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.862 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.882 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.835 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.812 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.815 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.877 
=> Acc: 0.800 Precision 0.800 Recall 0.800 F1 0.800 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.981 


accs [0.8621752531924263, 0.8808373590982287, 0.841726618705036, 0.8228004956629492, 0.8375677990294034, 0.8781038374717833, 0.8000685871056241, 0.9818875119161106]
 precisions [0.8837516512549538, 0.9146537842190016, 0.8321342925659473, 0.8159851301115242, 0.8270054239223523, 0.8690744920993227, 0.8082990397805213, 0.9714013346043852]
 recalls [0.8736239542051959, 0.8808373590982287, 0.8273381294964028, 0.8246592317224287, 0.8375677990294034, 0.8668171557562077, 0.815843621399177, 0.9714013346043852]
 f1scores [0.8705146823768155, 0.9109783778680012, 0.8209275813446139, 0.8274130828931708, 0.8045001537284531, 0.8660147714045662, 0.8159701757934353, 0.9661556173648677]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.903 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.922 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.857 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.819 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.834 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.906 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.883 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.925 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.956 


accs [0.9053280493174812, 0.9227053140096618, 0.8561151079136691, 0.8265179677819083, 0.8521267485012846, 0.9029345372460497, 0.8837448559670782, 0.9275500476644424, 0.9554030874785592]
 precisions [0.9145750770585646, 0.92914653784219, 0.8585131894484412, 0.8240396530359355, 0.8678275763631174, 0.9029345372460497, 0.8700274348422496, 0.9199237368922784, 0.9531160663236135]
 recalls [0.9088507265521797, 0.9178743961352657, 0.8393285371702638, 0.832094175960347, 0.857836140451042, 0.9051918735891648, 0.8762002743484225, 0.9361296472831268, 0.9605488850771869]
 f1scores [0.8989011635798848, 0.9102729271822158, 0.830801381183116, 0.810346096271424, 0.843744066760897, 0.9183131349893852, 0.873763278898615, 0.939346421633425, 0.9507147598404394]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.888 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.923 
=> Acc: 0.508 Precision 0.508 Recall 0.508 F1 0.482 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.807 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.833 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.847 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.815 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.885 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.934 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.928 


accs [0.888595332452664, 0.9194847020933977, 0.5083932853717026, 0.8104089219330854, 0.8455609477590637, 0.8465011286681715, 0.8168724279835391, 0.8875119161105816, 0.9331046312178388, 0.9291754756871036]
 precisions [0.8921180096873624, 0.9146537842190016, 0.5851318944844125, 0.8228004956629492, 0.8612617756208963, 0.837471783295711, 0.8096707818930041, 0.892278360343184, 0.9262435677530018, 0.9323467230443975]
 recalls [0.8903566710700133, 0.9210950080515298, 0.5611510791366906, 0.8438661710037175, 0.8455609477590637, 0.8148984198645598, 0.8041838134430727, 0.8989513822688274, 0.9302458547741567, 0.936046511627907]
 f1scores [0.8868777026817407, 0.9331643528053014, 0.5006697865596988, 0.8278773191208357, 0.8239428604820072, 0.8163461580662394, 0.8155404804578534, 0.8853305558077235, 0.924441159249956, 0.938006595406689]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.906 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.906 
=> Acc: 0.590 Precision 0.590 Recall 0.590 F1 0.546 
=> Acc: 0.744 Precision 0.744 Recall 0.744 F1 0.715 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.817 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.901 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.810 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.854 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.848 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.841 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.964 


accs [0.9101717305151915, 0.9033816425120773, 0.5899280575539568, 0.7441140024783147, 0.8421353125892093, 0.9029345372460497, 0.8093278463648834, 0.8741658722592945, 0.855917667238422, 0.8551797040169133, 0.9658469945355191]
 precisions [0.9141347424042272, 0.8985507246376812, 0.6354916067146283, 0.7304832713754646, 0.8472737653439909, 0.8893905191873589, 0.8106995884773662, 0.8474737845567207, 0.8593481989708405, 0.8488372093023255, 0.9754098360655737]
 recalls [0.9189784236019375, 0.9210950080515298, 0.60431654676259, 0.7311028500619579, 0.8409934341992578, 0.8803611738148984, 0.8096707818930041, 0.8398474737845567, 0.8473413379073756, 0.8631078224101479, 0.9781420765027322]
 f1scores [0.9085699443476889, 0.9204336190201285, 0.5593908600528529, 0.7078737828377026, 0.8119687247711121, 0.9143247080330488, 0.818517101547274, 0.8360543230936214, 0.8348670695844271, 0.8504257256284691, 0.971914572187368]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.901 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.657 Precision 0.657 Recall 0.657 F1 0.649 
=> Acc: 0.727 Precision 0.727 Recall 0.727 F1 0.706 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.866 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.901 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.846 
=> Acc: 0.668 Precision 0.668 Recall 0.668 F1 0.646 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.845 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.889 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.817 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.993 


accs [0.9000440334654337, 0.9259259259259259, 0.657074340527578, 0.7273853779429987, 0.8741079075078504, 0.9006772009029346, 0.8491083676268861, 0.6682554814108675, 0.8542024013722127, 0.8916490486257929, 0.819672131147541, 0.9923954372623575]
 precisions [0.89740202553941, 0.8921095008051529, 0.6594724220623501, 0.7311028500619579, 0.864401941193263, 0.8939051918735892, 0.8401920438957476, 0.663489037178265, 0.8502001143510578, 0.8979915433403806, 0.8401639344262295, 0.9961977186311787]
 recalls [0.8996036988110965, 0.9114331723027376, 0.6738609112709832, 0.7298636926889716, 0.8683985155580931, 0.9006772009029346, 0.8347050754458162, 0.674928503336511, 0.8427672955974843, 0.895877378435518, 0.8278688524590164, 0.9954372623574145]
 f1scores [0.8916217694495862, 0.9434051223157166, 0.6552812389470798, 0.7227499750944208, 0.8497655752036035, 0.9116024554203351, 0.8491571526270448, 0.6434781518524707, 0.8324629235895042, 0.8789382656261807, 0.8197603729964967, 0.9916428157625198]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.832 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.935 
=> Acc: 0.525 Precision 0.525 Recall 0.525 F1 0.507 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.743 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.868 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.880 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.852 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.796 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.869 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.803 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.804 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.947 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 


accs [0.836635843240863, 0.9339774557165862, 0.5251798561151079, 0.7620817843866171, 0.8801027690550957, 0.8803611738148984, 0.8545953360768176, 0.8083889418493804, 0.8724985706117782, 0.8113107822410148, 0.8169398907103825, 0.9505703422053232, 0.9799307958477509]
 precisions [0.8507265521796565, 0.9227053140096618, 0.5059952038369304, 0.7726146220570013, 0.8666856979731659, 0.8848758465011287, 0.850480109739369, 0.8274547187797903, 0.8656375071469411, 0.8134249471458774, 0.7882513661202186, 0.9574144486692016, 0.9854671280276817]
 recalls [0.8489652135623074, 0.9404186795491143, 0.5731414868105515, 0.765179677819083, 0.88352840422495, 0.8939051918735892, 0.8566529492455418, 0.8169685414680649, 0.8530588907947398, 0.8372093023255814, 0.8306010928961749, 0.9551330798479087, 0.9820069204152249]
 f1scores [0.8479468669168027, 0.9180696816084242, 0.5248590967148583, 0.7358107338879524, 0.8729053023737897, 0.8758374063212772, 0.8484192386055293, 0.8031126581859926, 0.856649392746829, 0.8146967410681855, 0.8277156071331409, 0.9551165759999327, 0.9910006629611298]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.894 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.899 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.813 
=> Acc: 0.734 Precision 0.734 Recall 0.734 F1 0.708 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.811 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.902 
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.785 
=> Acc: 0.667 Precision 0.667 Recall 0.667 F1 0.626 
=> Acc: 0.751 Precision 0.751 Recall 0.751 F1 0.738 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.865 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.871 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.948 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.966 


accs [0.8947600176133862, 0.895330112721417, 0.8225419664268585, 0.7342007434944238, 0.8369968598344276, 0.9029345372460497, 0.7866941015089163, 0.667302192564347, 0.7507146941109205, 0.8673361522198731, 0.8770491803278688, 0.9330798479087452, 0.9487889273356401, 0.968609865470852]
 precisions [0.8872743284896522, 0.9210950080515298, 0.8321342925659473, 0.7422552664188352, 0.8278618327148158, 0.9413092550790068, 0.8007544581618655, 0.684461391801716, 0.743281875357347, 0.8668076109936576, 0.8674863387978142, 0.932319391634981, 0.9460207612456747, 0.9820627802690582]
 recalls [0.8859533245266402, 0.9162640901771336, 0.7961630695443646, 0.7211895910780669, 0.8349985726520126, 0.927765237020316, 0.8000685871056241, 0.678741658722593, 0.7570040022870211, 0.8789640591966174, 0.8579234972677595, 0.9338403041825095, 0.9515570934256056, 0.9775784753363229]
 f1scores [0.8761048733611064, 0.9121762230109335, 0.8081204618642854, 0.69926922084039, 0.8104932032085337, 0.9230449068705102, 0.8050202599328964, 0.6256552423311807, 0.729667038390126, 0.8682123539874208, 0.8574249684681577, 0.9319982417755224, 0.953872470383198, 0.9645342312008978]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.880 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.938 
=> Acc: 0.739 Precision 0.739 Recall 0.739 F1 0.725 
=> Acc: 0.730 Precision 0.730 Recall 0.730 F1 0.693 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.846 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.904 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.839 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.855 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.757 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.815 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.880 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.912 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.869 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.8859533245266402, 0.9371980676328503, 0.7386091127098321, 0.7304832713754646, 0.86211818441336, 0.9051918735891648, 0.8415637860082305, 0.8636796949475691, 0.7764436821040595, 0.8160676532769556, 0.8825136612021858, 0.9186311787072243, 0.9737024221453288, 0.8789237668161435, 1.0]
 precisions [0.8837516512549538, 0.9371980676328503, 0.6954436450839329, 0.7410161090458488, 0.857836140451042, 0.9006772009029346, 0.8405349794238683, 0.8703527168732126, 0.7747284162378502, 0.8261099365750528, 0.8811475409836066, 0.9269961977186312, 0.9612456747404844, 0.9147982062780269, 1.0]
 recalls [0.892998678996037, 0.9307568438003221, 0.697841726618705, 0.7342007434944238, 0.8484156437339423, 0.891647855530474, 0.8326474622770919, 0.8646329837940896, 0.7695826186392224, 0.828752642706131, 0.8934426229508197, 0.9155893536121673, 0.9577854671280277, 0.9192825112107623, 0.9987684729064039]
 f1scores [0.880967864985533, 0.9348925346612489, 0.6970631783258787, 0.6987943899417779, 0.8384951583469947, 0.8712760947889187, 0.8389451091240547, 0.8651502219163841, 0.7486026197002285, 0.8183671389341152, 0.87713148420181, 0.9214252274205664, 0.9676250911201517, 0.8852044653349, 0.9986808890034696]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.882 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.935 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.766 
=> Acc: 0.708 Precision 0.708 Recall 0.708 F1 0.689 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.848 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.831 
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.781 
=> Acc: 0.660 Precision 0.660 Recall 0.660 F1 0.619 
=> Acc: 0.764 Precision 0.764 Recall 0.764 F1 0.753 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.878 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.906 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.867 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.889 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.987 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.940 


accs [0.892998678996037, 0.9371980676328503, 0.7721822541966427, 0.70817843866171, 0.8624036540108478, 0.8306997742663657, 0.7746913580246914, 0.6596758817921831, 0.7644368210405946, 0.8874207188160677, 0.9057377049180327, 0.8737642585551331, 0.9245674740484429, 0.8834080717488789, 0.9864532019704434, 0.9411764705882353]
 precisions [0.8903566710700133, 0.9082125603864735, 0.8105515587529976, 0.7162329615861215, 0.8526976876962603, 0.8555304740406321, 0.7781207133058985, 0.6472831267874166, 0.769010863350486, 0.9006342494714588, 0.9057377049180327, 0.8836501901140684, 0.9245674740484429, 0.8834080717488789, 0.9778325123152709, 0.9443684450524396]
 recalls [0.8863936591809776, 0.9098228663446055, 0.8513189448441247, 0.7075588599752168, 0.8509848701113332, 0.8284424379232506, 0.7788065843621399, 0.6310772163965681, 0.7610062893081762, 0.888477801268499, 0.9043715846994536, 0.8775665399239544, 0.9307958477508651, 0.9237668161434978, 0.9778325123152709, 0.9471044231646146]
 f1scores [0.8868485957466865, 0.9082122589067527, 0.8111571552127271, 0.6728130583005415, 0.8449840535285247, 0.8509907510560437, 0.7760916114550568, 0.610290030691292, 0.7399902512363296, 0.8689683312661479, 0.912712208128732, 0.9054716347056406, 0.9309663713317404, 0.8947941650555805, 0.9751472635509888, 0.9327045499278105]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.894 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.810 
=> Acc: 0.752 Precision 0.752 Recall 0.752 F1 0.733 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.824 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.823 
=> Acc: 0.757 Precision 0.757 Recall 0.757 F1 0.752 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.878 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.773 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.836 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.862 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.849 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.949 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.972 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.928 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 


accs [0.8956406869220608, 0.9371980676328503, 0.829736211031175, 0.751548946716233, 0.8509848701113332, 0.8284424379232506, 0.7565157750342936, 0.8856053384175405, 0.7838765008576329, 0.8430232558139535, 0.8620218579234973, 0.8585551330798479, 0.9391003460207612, 0.9506726457399103, 0.9729064039408867, 0.9270405836753306, 0.9817724701445631]
 precisions [0.9000440334654337, 0.9452495974235104, 0.8345323741007195, 0.7503097893432465, 0.8381387382243791, 0.8442437923250564, 0.752400548696845, 0.8779790276453765, 0.7987421383647799, 0.8366807610993657, 0.8770491803278688, 0.864638783269962, 0.9231833910034603, 0.9417040358744395, 0.9753694581280788, 0.9316005471956225, 0.9880578252671276]
 recalls [0.9110523998238661, 0.9355877616747182, 0.8273381294964028, 0.7577447335811648, 0.8455609477590637, 0.8600451467268623, 0.7623456790123457, 0.8741658722592945, 0.7913093196112064, 0.8340380549682875, 0.8715846994535519, 0.8798479087452471, 0.9294117647058824, 0.9551569506726457, 0.9642857142857143, 0.9302325581395349, 0.983029541169076]
 f1scores [0.9005977189709844, 0.9400556033991216, 0.8270781163241976, 0.7377957906658651, 0.8313903737911291, 0.854338887476373, 0.7535595116345357, 0.8787085899932062, 0.7970341454830485, 0.8578253658452798, 0.8945904173607321, 0.8771679756269913, 0.9332404424184787, 0.9576781479390174, 0.9763202247317333, 0.9404623060709177, 0.9842229294087247]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.871 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.934 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.885 
=> Acc: 0.737 Precision 0.737 Recall 0.737 F1 0.716 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.797 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.851 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.769 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.837 
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.737 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.847 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.912 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.868 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.933 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.719 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.882 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 


accs [0.8731836195508587, 0.9307568438003221, 0.8872901678657075, 0.7372986369268897, 0.82329431915501, 0.8487584650112867, 0.7716049382716049, 0.8446139180171592, 0.7535734705546027, 0.8520084566596194, 0.9139344262295082, 0.8745247148288974, 0.9349480968858132, 0.7488789237668162, 0.9852216748768473, 0.8828089375284998, 0.9748585795097423, 0.9683959451401312]
 precisions [0.8656979304271246, 0.9323671497584541, 0.8729016786570744, 0.7540272614622057, 0.8284327719097916, 0.8487584650112867, 0.757201646090535, 0.8379408960915157, 0.7570040022870211, 0.8641649048625792, 0.9057377049180327, 0.8859315589353612, 0.9294117647058824, 0.695067264573991, 0.9827586206896551, 0.8891928864569083, 0.9773727215587681, 0.9636255217650567]
 recalls [0.8872743284896522, 0.92914653784219, 0.8657074340527577, 0.7410161090458488, 0.842706251784185, 0.8487584650112867, 0.7678326474622771, 0.8408007626310772, 0.7650085763293311, 0.8557082452431289, 0.9098360655737705, 0.8692015209125475, 0.9266435986159169, 0.7488789237668162, 0.979064039408867, 0.8723210214318285, 0.9742300439974858, 0.9666070363744782]
 f1scores [0.8714883678065, 0.9506138363567865, 0.8834664381591149, 0.7186078388512669, 0.8091798233567692, 0.8580270082971915, 0.7765985022246775, 0.8344960736140585, 0.7446830469249361, 0.8300606735134372, 0.9030709875989578, 0.8708196756303656, 0.9334664963560122, 0.7116410627532973, 0.9901340526648262, 0.8813821748531485, 0.9752541099042313, 0.9668617157975229]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.846 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.845 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.772 
=> Acc: 0.673 Precision 0.673 Recall 0.673 F1 0.643 
=> Acc: 0.781 Precision 0.781 Recall 0.781 F1 0.743 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.814 
=> Acc: 0.710 Precision 0.710 Recall 0.710 F1 0.711 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.805 
=> Acc: 0.598 Precision 0.598 Recall 0.598 F1 0.558 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.865 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.908 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.896 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.806 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.955 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.818 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.939 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.905 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 


accs [0.845442536327609, 0.8421900161030595, 0.762589928057554, 0.6728624535315985, 0.7810448187268056, 0.8126410835214447, 0.7102194787379973, 0.8055290753098189, 0.5980560320182962, 0.8694503171247357, 0.9316939890710383, 0.9102661596958175, 0.8961937716262975, 0.8026905829596412, 0.9544334975369458, 0.8253533971728226, 0.9409176618478944, 0.9028026237328562, 0.9703287890938251]
 precisions [0.8463232056362836, 0.8679549114331723, 0.7961630695443646, 0.6728624535315985, 0.7721952612046817, 0.8532731376975169, 0.7287379972565158, 0.8083889418493804, 0.5860491709548313, 0.8847780126849895, 0.9153005464480874, 0.911787072243346, 0.8913494809688581, 0.8340807174887892, 0.9445812807881774, 0.8253533971728226, 0.9478315524827152, 0.9123434704830053, 0.9711307137129109]
 recalls [0.8489652135623074, 0.8615136876006442, 0.7769784172661871, 0.6697645600991325, 0.7764773051669998, 0.8284424379232506, 0.7256515775034293, 0.8331744518589133, 0.6043453401943968, 0.888477801268499, 0.9453551912568307, 0.9140684410646388, 0.8768166089965398, 0.852017937219731, 0.9692118226600985, 0.8326493388052896, 0.9428032683846638, 0.9117471675611211, 0.9727345629510826]
 f1scores [0.8573137602665536, 0.8600873550075446, 0.774547996493677, 0.630258619731056, 0.7403037739407606, 0.8293025263523914, 0.7267358923900801, 0.7861124482878978, 0.5687587798089527, 0.8929536467747564, 0.9311269767285193, 0.910726369834879, 0.8909464754639818, 0.827678450624683, 0.9500172351592315, 0.8220401120903645, 0.9416388081832942, 0.902931249106828, 0.9710198028820753]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.846 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.954 
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.748 
=> Acc: 0.680 Precision 0.680 Recall 0.680 F1 0.639 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.822 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.801 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.812 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.775 
=> Acc: 0.671 Precision 0.671 Recall 0.671 F1 0.641 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.910 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.914 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.877 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.903 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.773 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.863 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.927 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.966 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.931 


accs [0.8428005284015853, 0.9549114331723028, 0.7529976019184652, 0.6796778190830235, 0.840422495004282, 0.8148984198645598, 0.8144718792866941, 0.8017159199237369, 0.6712407089765581, 0.912262156448203, 0.9180327868852459, 0.8806083650190114, 0.9065743944636678, 0.7847533632286996, 0.9852216748768473, 0.8686730506155951, 0.972972972972973, 0.9272510435301133, 0.9647153167602245, 0.934040047114252]
 precisions [0.8361955085865258, 0.9597423510466989, 0.7314148681055156, 0.6716232961586122, 0.8472737653439909, 0.835214446952596, 0.8199588477366255, 0.7912297426120114, 0.6998284734133791, 0.8916490486257929, 0.9139344262295082, 0.8965779467680608, 0.8920415224913495, 0.8385650224215246, 0.9852216748768473, 0.8682170542635659, 0.9717159019484601, 0.9272510435301133, 0.97514033680834, 0.9199057714958775]
 recalls [0.8353148392778512, 0.9597423510466989, 0.7266187050359713, 0.7118959107806692, 0.838424207821867, 0.8284424379232506, 0.8192729766803841, 0.8074356530028599, 0.6861063464837049, 0.8916490486257929, 0.894808743169399, 0.8927756653992396, 0.9114186851211072, 0.8385650224215246, 0.9889162561576355, 0.8499772001823985, 0.9742300439974858, 0.9373881932021467, 0.9607056936647955, 0.9540636042402827]
 f1scores [0.8475468619716293, 0.9639334090002318, 0.7364303511953513, 0.6571613447026148, 0.8283943135178566, 0.8437366913623517, 0.8211698016780247, 0.7901810234742118, 0.664827257014051, 0.8991783008976955, 0.8949602874460559, 0.8873449670893372, 0.9082356931324437, 0.8208533828323933, 0.9939060544907768, 0.8629808006925268, 0.9712587187766886, 0.9320638761831976, 0.9549531077278239, 0.9288005281746468]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.9980694980694981]
 precisions [0.9996138996138996]
 recalls [0.9992277992277993]
 f1scores [0.9992343469906828]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.947 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 


accs [0.9478764478764479, 0.9808808467053602]
 precisions [0.9540540540540541, 0.9829293274155002]
 recalls [0.9602316602316602, 0.9805394332536702]
 f1scores [0.9493886113415415, 0.9766101678732895]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.967 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.972 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9683397683397683, 0.9716626835097303, 1.0]
 precisions [0.9702702702702702, 0.9709798566063503, 1.0]
 recalls [0.9745173745173745, 0.9689313758962103, 1.0]
 f1scores [0.9662415864542038, 0.9680407218284763, 1.0]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.950 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.954 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.9521235521235522, 0.9539091840218504, 0.9908045977011494, 0.9915730337078652]
 precisions [0.9555984555984556, 0.9535677705701605, 0.9827586206896551, 0.9915730337078652]
 recalls [0.9478764478764479, 0.9566404916353705, 0.9873563218390805, 0.9915730337078652]
 f1scores [0.9433635303996754, 0.9561966448305069, 0.9887358106166797, 0.9897586431833008]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.923 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.987 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 


accs [0.9250965250965251, 0.9317173096620007, 0.993103448275862, 0.9859550561797753, 0.9909801563439568]
 precisions [0.922007722007722, 0.9446910208262206, 0.996551724137931, 0.9803370786516854, 0.9849669272399278]
 recalls [0.9471042471042471, 0.9286445885967907, 0.993103448275862, 0.9943820224719101, 0.9807576668671076]
 f1scores [0.919503034186947, 0.9340915643774828, 0.993167701863354, 0.9797975201911046, 0.9902554673397918]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.905 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.920 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 


accs [0.9123552123552123, 0.9197678388528508, 0.9712643678160919, 0.9831460674157303, 0.9729404690318701, 0.9955555555555555]
 precisions [0.9084942084942085, 0.9112325025606008, 0.9839080459770115, 0.9719101123595506, 0.9783523752254961, 0.997037037037037]
 recalls [0.9081081081081082, 0.9211334926596108, 0.9793103448275862, 0.9831460674157303, 0.9693325315694528, 0.9903703703703703]
 f1scores [0.8988465380438454, 0.9245383556302202, 0.9751518324418258, 0.9807016049512356, 0.9809253062557112, 0.9921629909124998]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.895 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.887 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.980 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.943 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 


accs [0.9034749034749034, 0.8876749743939911, 0.9873563218390805, 0.9775280898876404, 0.9807576668671076, 0.9407407407407408, 0.9647577092511013]
 precisions [0.9077220077220077, 0.898941618299761, 0.9850574712643678, 0.9887640449438202, 0.9807576668671076, 0.9585185185185185, 0.9676945668135095]
 recalls [0.9158301158301159, 0.898600204848071, 0.9862068965517241, 0.9831460674157303, 0.9825616355983163, 0.9555555555555556, 0.9647577092511013]
 f1scores [0.8947952789515117, 0.8991944721700857, 0.9885509899595796, 0.9798357892107891, 0.9828434746579042, 0.9589735214912951, 0.9655283243828254]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.904 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.889 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.989 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.968 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.885 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.941 


accs [0.9123552123552123, 0.8921133492659611, 0.9896551724137931, 0.9691011235955056, 0.9801563439567047, 0.8881481481481481, 0.9581497797356828, 0.9428571428571428]
 precisions [0.9123552123552123, 0.9037214066234209, 0.9908045977011494, 0.9775280898876404, 0.9825616355983163, 0.8977777777777778, 0.9588839941262849, 0.9396825396825397]
 recalls [0.911969111969112, 0.9067941276886309, 0.9908045977011494, 0.9859550561797753, 0.9795550210463019, 0.8918518518518519, 0.9566813509544787, 0.943764172335601]
 f1scores [0.9103632716116126, 0.8867261949086629, 0.9893371463959942, 0.9755015457509206, 0.9743749010602569, 0.8695614879401404, 0.9521367646633211, 0.9456968196703585]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.950 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.904 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.958 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.949 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.970 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.897 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.944 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.886 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.908 


accs [0.9521235521235522, 0.9081597814953909, 0.9586206896551724, 0.9466292134831461, 0.9705351773902585, 0.9007407407407407, 0.9456681350954479, 0.8970521541950114, 0.9187542315504401]
 precisions [0.9505791505791505, 0.9057698873335609, 0.9586206896551724, 0.9606741573033708, 0.9657245941070355, 0.8918518518518519, 0.9427312775330396, 0.9065759637188209, 0.9038591740013541]
 recalls [0.9590733590733591, 0.902355752816661, 0.9563218390804598, 0.9662921348314607, 0.9663259170174384, 0.8874074074074074, 0.9530102790014684, 0.8997732426303855, 0.9214624238320921]
 f1scores [0.947788687877161, 0.9086938237605159, 0.9602641985431202, 0.9600420604857514, 0.9715509873856764, 0.8849468157111614, 0.939837296865137, 0.8785702364124491, 0.9074898006352832]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.925 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.919 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.943 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.863 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.870 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.887 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.962 


accs [0.9301158301158301, 0.9197678388528508, 0.9632183908045977, 0.9578651685393258, 0.94167167769092, 0.8696296296296296, 0.9508076358296622, 0.8802721088435375, 0.8991198375084631, 0.9646017699115044]
 precisions [0.9258687258687258, 0.9201092523045408, 0.9735632183908046, 0.9662921348314607, 0.9512928442573662, 0.8733333333333333, 0.9537444933920705, 0.8929705215419501, 0.8984427894380501, 0.9557522123893806]
 recalls [0.9250965250965251, 0.9156708774325708, 0.9528735632183908, 0.9691011235955056, 0.9512928442573662, 0.8777777777777778, 0.9515418502202643, 0.8970521541950114, 0.8903182125930941, 0.9424778761061947]
 f1scores [0.9186959052335519, 0.9220190957858041, 0.9588932437786539, 0.970795541084291, 0.9398264501107783, 0.8783707966165997, 0.9552762348327881, 0.8788993579041786, 0.8770533776118308, 0.9468665252875781]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.897 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.850 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.967 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.979 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.858 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.872 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.876 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.922 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.939 


accs [0.9011583011583012, 0.8583134175486514, 0.9701149425287356, 0.9662921348314607, 0.9789536981358989, 0.8614814814814815, 0.9698972099853157, 0.8752834467120182, 0.8835477318889641, 0.9247787610619469, 0.9399869536855838]
 precisions [0.8945945945945946, 0.8538750426766815, 0.957471264367816, 0.9606741573033708, 0.9789536981358989, 0.8740740740740741, 0.9757709251101322, 0.8575963718820862, 0.8970886932972241, 0.9336283185840708, 0.9556425309849967]
 recalls [0.9023166023166023, 0.8528508023216115, 0.9517241379310345, 0.9662921348314607, 0.9819603126879134, 0.8681481481481481, 0.9559471365638766, 0.8820861678004536, 0.8991198375084631, 0.911504424778761, 0.9419439008480104]
 f1scores [0.8981689923945503, 0.8554246595540835, 0.943453533257854, 0.944448602035901, 0.9770704843100292, 0.8722016971995912, 0.9680306801673619, 0.8609115951497426, 0.8809537329220809, 0.9277137091838652, 0.9494002262734224]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.928 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.932 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.947 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.932 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.853 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.914 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.800 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.797 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.961 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.876 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.935 


accs [0.9308880308880308, 0.9337657903721407, 0.9816091954022989, 0.949438202247191, 0.930847865303668, 0.8585185185185186, 0.9155653450807636, 0.817687074829932, 0.8165199729180772, 0.9601769911504425, 0.8767123287671232, 0.9342465753424658]
 precisions [0.9281853281853282, 0.9443496073745306, 0.9712643678160919, 0.9747191011235955, 0.9272399278412508, 0.8651851851851852, 0.9287812041116006, 0.8285714285714286, 0.8334461746784022, 0.9778761061946902, 0.8864970645792564, 0.9488584474885845]
 recalls [0.9293436293436294, 0.9351314441789006, 0.9712643678160919, 0.9466292134831461, 0.9488875526157546, 0.8674074074074074, 0.9273127753303965, 0.8058956916099773, 0.8226134055517942, 0.9380530973451328, 0.9015003261578604, 0.9452054794520548]
 f1scores [0.9263439116523615, 0.934434696228341, 0.9758485728149925, 0.9772729788729789, 0.932959909502786, 0.8615457821685186, 0.9299078518442065, 0.7985996432528868, 0.8067550667635356, 0.929016885778417, 0.8708006566854118, 0.9404347939015544]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.913 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.901 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.970 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.976 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.935 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.780 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.728 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.885 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.935 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.913 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.882 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 


accs [0.916988416988417, 0.904062820075111, 0.9689655172413794, 0.9775280898876404, 0.9344558027660854, 0.7911111111111111, 0.9684287812041116, 0.7551020408163265, 0.8943805010155721, 0.9424778761061947, 0.913894324853229, 0.8840182648401826, 0.9758389261744966]
 precisions [0.9274131274131274, 0.9091840218504609, 0.9689655172413794, 0.9803370786516854, 0.9212266987372218, 0.7925925925925926, 0.9691629955947136, 0.7437641723356009, 0.8652674339878131, 0.9292035398230089, 0.8969341161121983, 0.8936073059360731, 0.9791946308724833]
 recalls [0.927027027027027, 0.9125981563673609, 0.960919540229885, 0.9831460674157303, 0.9242333132892363, 0.802962962962963, 0.9647577092511013, 0.7428571428571429, 0.8774542992552471, 0.911504424778761, 0.903457273320287, 0.8831050228310502, 0.9798657718120806]
 f1scores [0.9187609206998306, 0.9029465123102662, 0.9591377940731437, 0.9644932918236462, 0.9257842423596021, 0.7889546220218412, 0.9705028809465084, 0.7177011777619389, 0.8733171907529733, 0.9012063991607657, 0.9038479605859454, 0.8828060257329874, 0.9788341433362195]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.920 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.872 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.930 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.796 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.751 Precision 0.751 Recall 0.751 F1 0.721 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.875 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.922 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.911 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.877 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.883 


accs [0.922007722007722, 0.8784568111983612, 0.9747126436781609, 0.9297752808988764, 0.9332531569452797, 0.8140740740740741, 0.9713656387665198, 0.7514739229024944, 0.8869329722410291, 0.9203539823008849, 0.9119373776908023, 0.8776255707762557, 0.9583892617449664, 0.8887530562347188]
 precisions [0.9158301158301159, 0.8876749743939911, 0.9701149425287356, 0.9297752808988764, 0.9326518340348767, 0.8192592592592592, 0.9676945668135095, 0.7523809523809524, 0.8950575490859851, 0.9070796460176991, 0.9106327462491846, 0.8872146118721461, 0.9429530201342282, 0.8924205378973105]
 recalls [0.918918918918919, 0.8791396381017412, 0.960919540229885, 0.9466292134831461, 0.9428743235117258, 0.7955555555555556, 0.9662261380323054, 0.7396825396825397, 0.8754231550440081, 0.9469026548672567, 0.9067188519243313, 0.8968036529680365, 0.9416107382550336, 0.8777506112469438]
 f1scores [0.9120231899212005, 0.868074373834362, 0.9647934564683849, 0.9438742904179536, 0.942779620746715, 0.7918142327773188, 0.9718128802092894, 0.6962804158023962, 0.8640745875148814, 0.9030255395500942, 0.9002571192445842, 0.8920681522514519, 0.9491501046580293, 0.8805997470563751]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.882 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.913 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.966 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.911 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.915 
=> Acc: 0.757 Precision 0.757 Recall 0.757 F1 0.744 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.938 
=> Acc: 0.716 Precision 0.716 Recall 0.716 F1 0.687 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.792 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.856 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.887 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.863 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.765 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.880 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 


accs [0.8934362934362934, 0.9143052236258109, 0.9666666666666667, 0.9129213483146067, 0.9140108238123873, 0.7570370370370371, 0.9397944199706314, 0.7156462585034014, 0.8083953960731212, 0.8716814159292036, 0.8917155903457273, 0.8616438356164383, 0.77248322147651, 0.8887530562347188, 0.9678414096916299]
 precisions [0.8787644787644787, 0.9163537043359509, 0.957471264367816, 0.9213483146067416, 0.9224293445580276, 0.7592592592592593, 0.9295154185022027, 0.7210884353741497, 0.8226134055517942, 0.8495575221238938, 0.8910632746249184, 0.869406392694064, 0.7677852348993288, 0.8899755501222494, 0.9546255506607929]
 recalls [0.9, 0.9132809832707409, 0.9505747126436782, 0.9073033707865169, 0.9200240529164161, 0.7592592592592593, 0.9390602055800293, 0.7065759637188208, 0.7975626269465133, 0.8805309734513275, 0.8936725375081539, 0.8748858447488584, 0.7845637583892617, 0.8655256723716381, 0.9524229074889868]
 f1scores [0.8882731897909022, 0.913326000518383, 0.9568169356250819, 0.897569039591833, 0.9188437835718494, 0.7456490100909139, 0.9353968752731516, 0.7089878812074004, 0.7827634743980836, 0.8692292425648211, 0.8843548762591216, 0.8683622607323007, 0.7725113052937402, 0.8824488753708127, 0.9577838317453088]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.867 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.892 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.935 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.717 Precision 0.717 Recall 0.717 F1 0.701 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.691 Precision 0.691 Recall 0.691 F1 0.656 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.836 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.961 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.887 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.828 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.922 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.834 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.869 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 


accs [0.8810810810810811, 0.892796176169341, 0.9701149425287356, 0.9382022471910112, 0.9332531569452797, 0.717037037037037, 0.9251101321585903, 0.691156462585034, 0.8551117129316181, 0.9646017699115044, 0.8851924331376386, 0.8365296803652968, 0.9221476510067114, 0.8410757946210269, 0.873568281938326, 0.967741935483871]
 precisions [0.8768339768339768, 0.893820416524411, 0.9471264367816092, 0.9101123595505618, 0.926037282020445, 0.7385185185185185, 0.9302496328928047, 0.7011337868480726, 0.8672985781990521, 0.9247787610619469, 0.8858447488584474, 0.8351598173515982, 0.9154362416107382, 0.8484107579462102, 0.8775330396475771, 0.9637096774193549]
 recalls [0.877992277992278, 0.893820416524411, 0.9517241379310345, 0.9382022471910112, 0.9200240529164161, 0.7422222222222222, 0.9353891336270191, 0.7197278911564626, 0.8686526743398781, 0.9292035398230089, 0.8845401174168297, 0.8470319634703196, 0.9174496644295302, 0.8643031784841075, 0.8814977973568282, 0.9657258064516129]
 f1scores [0.8715625005414622, 0.8754765808625381, 0.9552860847712141, 0.9224737729754452, 0.9285147388889137, 0.7012809218951082, 0.9307958807829598, 0.6696473430645045, 0.8349822233518587, 0.94564382846565, 0.894687281202741, 0.842859561675424, 0.9204683449639373, 0.8311509127102272, 0.8711679272789654, 0.9738183213450959]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.907 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.903 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.847 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.798 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.937 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.700 
=> Acc: 0.693 Precision 0.693 Recall 0.693 F1 0.642 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.910 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.895 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.857 
=> Acc: 0.723 Precision 0.723 Recall 0.723 F1 0.704 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.876 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.857 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 


accs [0.9142857142857143, 0.9067941276886309, 0.9689655172413794, 0.8567415730337079, 0.9368610944076969, 0.8037037037037037, 0.9361233480176211, 0.7401360544217687, 0.6932972241029113, 0.911504424778761, 0.8962818003913894, 0.8547945205479452, 0.7228187919463087, 0.8838630806845966, 0.8599118942731278, 0.9576612903225806, 0.9741379310344828]
 precisions [0.9077220077220077, 0.902697166268351, 0.967816091954023, 0.8286516853932584, 0.9398677089597114, 0.8088888888888889, 0.9295154185022027, 0.744671201814059, 0.7054840893703453, 0.911504424778761, 0.9015003261578604, 0.8470319634703196, 0.7120805369127516, 0.9083129584352079, 0.8757709251101321, 0.9737903225806451, 0.9798850574712644]
 recalls [0.9104247104247104, 0.8934790030727211, 0.9735632183908046, 0.8651685393258427, 0.9302465423932652, 0.8237037037037037, 0.9295154185022027, 0.7401360544217687, 0.7048070412999323, 0.8893805309734514, 0.8891063274624919, 0.8552511415525114, 0.7134228187919464, 0.8887530562347188, 0.8559471365638767, 0.9637096774193549, 0.9813218390804598]
 f1scores [0.8992150249360616, 0.8860786482602864, 0.9716601415696713, 0.8460739829610441, 0.9275120618398788, 0.8192696012320211, 0.9231505153199329, 0.7044404068336675, 0.6517210400681647, 0.937736162253678, 0.8983212466416862, 0.8425671652045665, 0.7099566869510683, 0.8855000620556568, 0.8587678603831671, 0.9685279034690799, 0.9911072841601731]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.905 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.869 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.936 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.967 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.939 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.770 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.939 
=> Acc: 0.711 Precision 0.711 Recall 0.711 F1 0.662 
=> Acc: 0.770 Precision 0.770 Recall 0.770 F1 0.749 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.930 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.890 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.873 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.879 
=> Acc: 0.707 Precision 0.707 Recall 0.707 F1 0.703 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.785 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.926 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.934 


accs [0.911969111969112, 0.8729941959713212, 0.9390804597701149, 0.9691011235955056, 0.9410703547805171, 0.7903703703703704, 0.9397944199706314, 0.7106575963718821, 0.7704807041299933, 0.9292035398230089, 0.8884540117416829, 0.8735159817351598, 0.8812080536912752, 0.706601466992665, 0.8088105726872247, 0.8971774193548387, 0.9267241379310345, 0.9362154500354358]
 precisions [0.9057915057915058, 0.8777739842949812, 0.9367816091954023, 0.9831460674157303, 0.9380637402285027, 0.7881481481481482, 0.9478707782672541, 0.7015873015873015, 0.7867298578199052, 0.9292035398230089, 0.8806262230919765, 0.8808219178082192, 0.8624161073825504, 0.7469437652811736, 0.8233480176211454, 0.8850806451612904, 0.9295977011494253, 0.9390503189227498]
 recalls [0.9131274131274131, 0.8794810515534313, 0.9436781609195403, 0.9747191011235955, 0.9512928442573662, 0.7755555555555556, 0.9500734214390602, 0.6952380952380952, 0.7569397427217333, 0.911504424778761, 0.8864970645792564, 0.871689497716895, 0.8684563758389262, 0.7090464547677262, 0.8123348017621146, 0.8951612903225806, 0.9238505747126436, 0.9319631467044649]
 f1scores [0.9054016660641329, 0.872804802114492, 0.923693317008088, 0.9678378820546865, 0.9535355918335343, 0.7761395093347823, 0.9528113004638454, 0.6571545707774084, 0.7693491548259536, 0.9269405387745244, 0.8790612946657346, 0.8792165064001608, 0.8738547909885366, 0.6960235368524337, 0.7746104774074951, 0.8785994505358861, 0.9329202125170888, 0.9337311148307247]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.893 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.838 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.969 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.949 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.938 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.818 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.926 
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.728 
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.726 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.839 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.823 
=> Acc: 0.777 Precision 0.777 Recall 0.777 F1 0.776 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.778 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.844 
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.777 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.889 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.906 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.949 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.896 


accs [0.8992277992277993, 0.8385114373506316, 0.9712643678160919, 0.9466292134831461, 0.9398677089597114, 0.8274074074074074, 0.9251101321585903, 0.7528344671201814, 0.7433987813134733, 0.8495575221238938, 0.8258317025440313, 0.7771689497716895, 0.785234899328859, 0.8508557457212714, 0.7929515418502202, 0.8971774193548387, 0.9080459770114943, 0.9482636428065202, 0.8977505112474438]
 precisions [0.8787644787644787, 0.8391942642540116, 0.960919540229885, 0.9691011235955056, 0.9266386049308478, 0.8496296296296296, 0.922173274596182, 0.7374149659863946, 0.7752200406228842, 0.8938053097345132, 0.7971298108284409, 0.7817351598173516, 0.7503355704697987, 0.8643031784841075, 0.809251101321586, 0.9133064516129032, 0.9152298850574713, 0.9567682494684621, 0.9004771642808452]
 recalls [0.8795366795366796, 0.8371457835438716, 0.9666666666666667, 0.9438202247191011, 0.9344558027660854, 0.8103703703703704, 0.9449339207048458, 0.7573696145124716, 0.7549085985104943, 0.8451327433628318, 0.8297455968688845, 0.7840182648401827, 0.7778523489932886, 0.8765281173594132, 0.7991189427312775, 0.905241935483871, 0.9339080459770115, 0.9397590361445783, 0.9175187457396047]
 f1scores [0.8757295678789989, 0.8266976651150426, 0.9618672163335648, 0.955497520684235, 0.9488613447933003, 0.8219970271961362, 0.9528514192569018, 0.7332808202817296, 0.7572687700432206, 0.8743426825244388, 0.8113853579614076, 0.7976837786715371, 0.7703746492082528, 0.8619890859438103, 0.7916459283423045, 0.9126824460304999, 0.9089534628677203, 0.94731430719358, 0.9048309151066395]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.859 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.821 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.940 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.863 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.781 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.757 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.894 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.824 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.836 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.778 
=> Acc: 0.713 Precision 0.713 Recall 0.713 F1 0.698 
=> Acc: 0.751 Precision 0.751 Recall 0.751 F1 0.717 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.821 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.887 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.836 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 


accs [0.8667953667953668, 0.8255377261864117, 0.9597701149425287, 0.9438202247191011, 0.9693325315694528, 0.8681481481481481, 0.973568281938326, 0.7977324263038549, 0.7691266079891672, 0.9070796460176991, 0.822570123939987, 0.8374429223744292, 0.8161073825503355, 0.7127139364303179, 0.751101321585903, 0.8225806451612904, 0.9367816091954023, 0.8830616583982991, 0.841854124062713, 0.9637931034482758]
 precisions [0.8718146718146718, 0.8282690337999317, 0.9597701149425287, 0.9578651685393258, 0.968129885748647, 0.8681481481481481, 0.9787077826725403, 0.7941043083900227, 0.7806364251861883, 0.8982300884955752, 0.8232224396607958, 0.8342465753424657, 0.8147651006711409, 0.7090464547677262, 0.7590308370044053, 0.8245967741935484, 0.9181034482758621, 0.8880226789510985, 0.8275391956373551, 0.9577586206896552]
 recalls [0.8683397683397683, 0.8303175145100717, 0.9712643678160919, 0.9606741573033708, 0.9675285628382442, 0.8555555555555555, 0.9853157121879589, 0.799546485260771, 0.7894380501015572, 0.8805309734513275, 0.8140900195694716, 0.8269406392694064, 0.7939597315436242, 0.7090464547677262, 0.7427312775330397, 0.8225806451612904, 0.9238505747126436, 0.8858965272856131, 0.8425357873210634, 0.9577586206896552]
 f1scores [0.8661010325441882, 0.8359757842013067, 0.9637970965677922, 0.9479327435849175, 0.9695764917416716, 0.8640541770520805, 0.9836245010479366, 0.7830567309816033, 0.763967609832548, 0.8793494232846809, 0.8254206673348822, 0.8357369662343682, 0.787272613864133, 0.6763370181867006, 0.7158442369586833, 0.8401756877148404, 0.9192131887792024, 0.8858546085511136, 0.8328446743925213, 0.9551980554815378]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 


accs [0.9990757855822551]
 precisions [1.0]
 recalls [1.0]
 f1scores [1.0]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.926 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 


accs [0.9269870609981515, 0.9777411376751854]
 precisions [0.9214417744916821, 0.9752679307502061]
 recalls [0.9297597042513863, 0.9719703215169002]
 f1scores [0.9232115167229988, 0.9777650035235068]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.936 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.945 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 


accs [0.9343807763401109, 0.9472382522671063, 0.97803738317757]
 precisions [0.949630314232902, 0.9604286892003298, 0.983177570093458]
 recalls [0.9440850277264325, 0.9563066776586975, 0.9845794392523365]
 f1scores [0.9341969896774925, 0.9505941169611754, 0.9826524896501823]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.954 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.905 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.973 
=> Acc: 0.995 Precision 0.995 Recall 0.995 F1 0.995 


accs [0.955637707948244, 0.9084913437757626, 0.9724299065420561, 0.9947089947089947]
 precisions [0.9500924214417745, 0.9043693322341303, 0.97803738317757, 0.9929453262786596]
 recalls [0.9519408502772643, 0.9126133553173948, 0.9700934579439252, 0.9911816578483245]
 f1scores [0.9528744666535169, 0.9030218560476705, 0.9654540778117857, 0.9857883810682786]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.842 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.946 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 


accs [0.9847504621072088, 0.8466611706512778, 0.9509345794392523, 0.9470899470899471, 0.9962756052141527]
 precisions [0.987985212569316, 0.8293487221764221, 0.9598130841121495, 0.9400352733686067, 0.9962756052141527]
 recalls [0.9875231053604436, 0.832646331409728, 0.9542056074766355, 0.9259259259259259, 0.9986033519553073]
 f1scores [0.986383133878261, 0.8245755043500387, 0.9495630656924485, 0.9363564638335914, 0.9948329192336587]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.778 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.953 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.803 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.838 


accs [0.9713493530499075, 0.7881286067600989, 0.9663551401869159, 0.9523809523809523, 0.8310055865921788, 0.8451882845188284]
 precisions [0.9671903881700554, 0.7798845836768343, 0.9738317757009346, 0.9576719576719577, 0.8207635009310987, 0.8870292887029289]
 recalls [0.9690388170055453, 0.7807089859851608, 0.9686915887850467, 0.9541446208112875, 0.8445065176908753, 0.8744769874476988]
 f1scores [0.96388686643718, 0.7690066271042597, 0.9721006608605528, 0.9425491381352552, 0.814503952059108, 0.8674551594110446]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.877 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.858 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.901 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.946 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.882 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.822 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.969 


accs [0.8821626617375231, 0.8639736191261336, 0.9014018691588785, 0.9470899470899471, 0.888733705772812, 0.8242677824267782, 0.9701492537313433]
 precisions [0.8863216266173752, 0.8499587798845837, 0.9214953271028037, 0.9400352733686067, 0.909217877094972, 0.8200836820083682, 0.9623312011371713]
 recalls [0.884011090573013, 0.854080791426216, 0.9200934579439253, 0.9523809523809523, 0.8985102420856611, 0.799163179916318, 0.9637526652452025]
 f1scores [0.8783308819854406, 0.8236648409553435, 0.9079736836393701, 0.9488145705566617, 0.8900529880879103, 0.8910066083065118, 0.9614924125493378]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.928 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.871 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.927 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.922 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.916 
=> Acc: 0.757 Precision 0.757 Recall 0.757 F1 0.745 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.933 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 


accs [0.9292975970425139, 0.8788128606760099, 0.927570093457944, 0.9223985890652557, 0.9180633147113594, 0.7573221757322176, 0.9339019189765458, 0.9704209328782708]
 precisions [0.9371534195933456, 0.9068425391591096, 0.9214953271028037, 0.9488536155202821, 0.9194599627560521, 0.7824267782426778, 0.9402985074626866, 0.9755403868031854]
 recalls [0.9362292051756007, 0.8730420445177246, 0.922429906542056, 0.9241622574955908, 0.9264432029795159, 0.7866108786610879, 0.9282160625444208, 0.9681456200227532]
 f1scores [0.9442321636192814, 0.8941085135702866, 0.9273917311002592, 0.9244385485066117, 0.9183358485512801, 0.765518217106085, 0.9248731797477634, 0.9727857749965709]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.923 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.856 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.963 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.946 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.872 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.823 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.927 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.879 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.987 


accs [0.9251386321626618, 0.8590272052761748, 0.9640186915887851, 0.9435626102292769, 0.8836126629422719, 0.8535564853556485, 0.9289267945984364, 0.8748577929465301, 0.9875141884222475]
 precisions [0.9232902033271719, 0.8746908491343776, 0.9602803738317757, 0.9259259259259259, 0.8933891992551211, 0.8326359832635983, 0.9317697228144989, 0.8777019340159272, 0.9897843359818388]
 recalls [0.9232902033271719, 0.8557295960428689, 0.9626168224299065, 0.9153439153439153, 0.8994413407821229, 0.7949790794979079, 0.9246624022743426, 0.8708759954493743, 0.9875141884222475]
 f1scores [0.9228843923604997, 0.8737804418259832, 0.964829873325795, 0.929202278613209, 0.88412914482267, 0.8364459547395517, 0.9237975483475818, 0.8737509697887349, 0.9882266602439639]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.895 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.838 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.893 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.915 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.918 
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.761 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.913 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.824 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.987 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.956 


accs [0.8964879852125693, 0.843363561417972, 0.8948598130841121, 0.9171075837742504, 0.9194599627560521, 0.7866108786610879, 0.9154228855721394, 0.820250284414107, 0.9875141884222475, 0.9565587734241908]
 precisions [0.9043438077634011, 0.8549051937345424, 0.902803738317757, 0.9047619047619048, 0.9324953445065177, 0.7949790794979079, 0.9168443496801706, 0.8321956769055745, 0.9858115777525539, 0.9420783645655877]
 recalls [0.9024953789279113, 0.854080791426216, 0.9018691588785047, 0.8871252204585538, 0.9259776536312849, 0.799163179916318, 0.9040511727078892, 0.8350398179749715, 0.9886492622020431, 0.9378194207836457]
 f1scores [0.9042835079735119, 0.8362199982503136, 0.9024082536694001, 0.9007350935269359, 0.9127317947832957, 0.7677961935762447, 0.9016006148440479, 0.8313269637025889, 0.9901423393730026, 0.9484619921621926]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.903 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.896 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.925 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.924 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.971 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.785 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.874 
=> Acc: 0.760 Precision 0.760 Recall 0.760 F1 0.760 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.897 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.958 


accs [0.9075785582255084, 0.9051937345424568, 0.9242990654205607, 0.9259259259259259, 0.9716014897579144, 0.7907949790794979, 0.8777540867093105, 0.7599544937428896, 0.9370034052213394, 0.8986371379897785, 0.9594460929772503]
 precisions [0.8918669131238447, 0.8969497114591921, 0.9112149532710281, 0.8994708994708994, 0.9720670391061452, 0.8075313807531381, 0.8621179815209666, 0.7514220705346986, 0.9392735527809307, 0.8756388415672913, 0.9614243323442137]
 recalls [0.9061922365988909, 0.9043693322341303, 0.9135514018691588, 0.908289241622575, 0.9688081936685289, 0.7866108786610879, 0.8649609097370291, 0.7411831626848692, 0.9432463110102156, 0.8909710391822828, 0.9624134520276953]
 f1scores [0.8946502720527507, 0.8888906018556518, 0.9247865251934881, 0.9050651313702914, 0.9714075726624383, 0.7358420280538661, 0.8503805098735597, 0.7538015101818661, 0.9460764141672346, 0.8818631219146607, 0.9556957302144615]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.894 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.857 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.899 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.894 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.924 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.730 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.889 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.754 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.836 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.797 Precision 0.797 Recall 0.797 F1 0.798 


accs [0.8969500924214417, 0.8623248145094806, 0.9, 0.8959435626102292, 0.9259776536312849, 0.7824267782426778, 0.8919687277896233, 0.7554038680318543, 0.9670828603859251, 0.8321976149914821, 0.9322453016815034, 0.7966909702748177]
 precisions [0.9043438077634011, 0.8565539983511954, 0.9018691588785047, 0.892416225749559, 0.925512104283054, 0.7489539748953975, 0.8813077469793887, 0.7872582480091013, 0.9676503972758229, 0.82793867120954, 0.9099901088031652, 0.8053841839596186]
 recalls [0.9140480591497228, 0.8656224237427865, 0.8953271028037383, 0.8888888888888888, 0.9189944134078212, 0.7112970711297071, 0.8877043354655295, 0.7554038680318543, 0.9642451759364359, 0.823679727427598, 0.923837784371909, 0.7989343802579921]
 f1scores [0.8986881903802638, 0.8537092693320594, 0.9192065342697475, 0.858498256381151, 0.9276377453634724, 0.706989639284833, 0.8747607113362428, 0.7600880400987439, 0.9623967703305263, 0.8303426538638942, 0.9037471087353385, 0.8024443896080232]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.720 Precision 0.720 Recall 0.720 F1 0.670 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.865 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.899 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.916 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.823 
=> Acc: 0.745 Precision 0.745 Recall 0.745 F1 0.717 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.888 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.827 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.813 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.882 
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.745 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 


accs [0.7204251386321626, 0.8713932399010718, 0.8995327102803738, 0.9171075837742504, 0.845903165735568, 0.7447698744769874, 0.8955223880597015, 0.8282138794084186, 0.9551645856980704, 0.8091993185689949, 0.8911968348170128, 0.7473359506449804, 0.9582651391162029]
 precisions [0.7185767097966729, 0.887881286067601, 0.9214953271028037, 0.9135802469135802, 0.8431098696461825, 0.7280334728033473, 0.9154228855721394, 0.8373151308304891, 0.9574347332576617, 0.8151618398637138, 0.8961424332344213, 0.7535053280987101, 0.9599018003273322]
 recalls [0.7282809611829945, 0.8722176422093982, 0.9168224299065421, 0.9259259259259259, 0.8440409683426443, 0.7196652719665272, 0.898365316275764, 0.835608646188851, 0.9614074914869466, 0.82793867120954, 0.8793273986152325, 0.7703309029725183, 0.9566284779050737]
 f1scores [0.6852157212968057, 0.8770221838569554, 0.9007875574310867, 0.9272719116656404, 0.8167104491696602, 0.6760620076721772, 0.8837322775764797, 0.8386705087949075, 0.9485319604275881, 0.7964529899695649, 0.8807870469534498, 0.7607045043409345, 0.9672495871089885]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.883 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.841 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.895 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.893 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.753 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.730 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.836 
=> Acc: 0.638 Precision 0.638 Recall 0.638 F1 0.639 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.927 
=> Acc: 0.761 Precision 0.761 Recall 0.761 F1 0.766 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.910 
=> Acc: 0.697 Precision 0.697 Recall 0.697 F1 0.707 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.900 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.990 


accs [0.8826247689463955, 0.8656224237427865, 0.8953271028037383, 0.8941798941798942, 0.7737430167597765, 0.7489539748953975, 0.851457000710732, 0.6376564277588168, 0.9307604994324631, 0.7614991482112436, 0.9154302670623146, 0.6974200785193494, 0.9009819967266776, 0.9893899204244032]
 precisions [0.8821626617375231, 0.8746908491343776, 0.8869158878504673, 0.8747795414462081, 0.7807262569832403, 0.7364016736401674, 0.8315565031982942, 0.6353811149032992, 0.9137343927355278, 0.7938671209540034, 0.9188921859545005, 0.7016264722378015, 0.9083469721767594, 0.9893899204244032]
 recalls [0.8886321626617375, 0.8598516075845012, 0.902803738317757, 0.8694885361552028, 0.7774674115456238, 0.7364016736401674, 0.8450604122245914, 0.6518771331058021, 0.9114642451759364, 0.7844974446337308, 0.913946587537092, 0.7066741446999439, 0.911620294599018, 0.9946949602122016]
 f1scores [0.886723401429679, 0.8312602001019702, 0.8739502424566113, 0.8785780683744366, 0.7692590200731891, 0.7193521310963409, 0.8347941160008586, 0.6301435948921927, 0.9131404338389159, 0.7766212791780871, 0.9054332641883992, 0.6938556704415206, 0.9227804777631634, 0.9972570569724297]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.860 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.889 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.879 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.917 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.717 
=> Acc: 0.770 Precision 0.770 Recall 0.770 F1 0.771 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.865 
=> Acc: 0.650 Precision 0.650 Recall 0.650 F1 0.618 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.961 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.834 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.689 Precision 0.689 Recall 0.689 F1 0.685 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.899 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.889 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 


accs [0.8664510166358595, 0.8944765045342127, 0.8803738317757009, 0.9171075837742504, 0.7420856610800745, 0.7698744769874477, 0.8749111584932481, 0.6496018202502845, 0.9619750283768445, 0.8330494037478705, 0.9520276953511375, 0.6887268648345485, 0.8993453355155483, 0.8859416445623343, 0.9804772234273319]
 precisions [0.8687615526802218, 0.9117889530090684, 0.8719626168224299, 0.8871252204585538, 0.7360335195530726, 0.8117154811715481, 0.8628287135749823, 0.6439135381114903, 0.9631101021566402, 0.8143100511073254, 0.9455984174085065, 0.6901289960740326, 0.9140752864157119, 0.8912466843501327, 0.9768618944323934]
 recalls [0.8632162661737524, 0.8928276999175597, 0.8799065420560748, 0.9047619047619048, 0.723463687150838, 0.7782426778242678, 0.8706467661691543, 0.6331058020477816, 0.9642451759364359, 0.8006814310051107, 0.933728981206726, 0.6744251261918116, 0.9067103109656302, 0.8806366047745358, 0.982646420824295]
 f1scores [0.8381080892527513, 0.888264890716072, 0.8758501739333516, 0.9156155097948326, 0.6967830385690075, 0.8058810955993712, 0.8569953385640575, 0.6096756357761122, 0.9573661583056658, 0.8259430093536707, 0.946257604752358, 0.6788538959902402, 0.9037374795605657, 0.849017024245887, 0.9761851801023524]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.777 Precision 0.777 Recall 0.777 F1 0.748 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.830 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.914 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.912 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.775 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.678 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.801 
=> Acc: 0.700 Precision 0.700 Recall 0.700 F1 0.705 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.690 Precision 0.690 Recall 0.690 F1 0.699 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.938 
=> Acc: 0.660 Precision 0.660 Recall 0.660 F1 0.648 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.885 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.797 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.933 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.887 


accs [0.777264325323475, 0.8375927452596867, 0.9149532710280374, 0.9135802469135802, 0.7886405959031657, 0.698744769874477, 0.8130774697938877, 0.6996587030716723, 0.960272417707151, 0.6899488926746167, 0.940158259149357, 0.6601233875490746, 0.886252045826514, 0.8249336870026526, 0.9342010122921186, 0.8987517337031901]
 precisions [0.782347504621072, 0.8425391591096455, 0.8906542056074767, 0.890652557319224, 0.7867783985102421, 0.7280334728033473, 0.8095238095238095, 0.7064846416382252, 0.9551645856980704, 0.6626916524701874, 0.9357072205736894, 0.6430173864273696, 0.8747954173486089, 0.8673740053050398, 0.9421547360809833, 0.8987517337031901]
 recalls [0.7860443622920518, 0.8408903544929925, 0.8953271028037383, 0.8677248677248677, 0.7839851024208566, 0.7196652719665272, 0.8116560056858564, 0.717292377701934, 0.9608399545970489, 0.6933560477001703, 0.9431256181998022, 0.6430173864273696, 0.9050736497545008, 0.8488063660477454, 0.9269703543022415, 0.8966712898751734]
 f1scores [0.7395497703547398, 0.8230422711981236, 0.9032599322154432, 0.8823420585612087, 0.7853124123405857, 0.6317816568732755, 0.7957768868992136, 0.7315988898228211, 0.9563857963226919, 0.6614794169616062, 0.9433394676038503, 0.6276313181254298, 0.8780603716642279, 0.8228774994494632, 0.9448448752611789, 0.8944794709595179]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.748 Precision 0.748 Recall 0.748 F1 0.691 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.873 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.916 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.871 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.920 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.676 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.806 
=> Acc: 0.601 Precision 0.601 Recall 0.601 F1 0.604 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.673 Precision 0.673 Recall 0.673 F1 0.637 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.894 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.683 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.862 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.740 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.890 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.804 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.940 


accs [0.7481515711645101, 0.8779884583676835, 0.9186915887850468, 0.8677248677248677, 0.9241154562383612, 0.698744769874477, 0.8166311300639659, 0.6012514220705347, 0.9812712826333712, 0.6729131175468483, 0.8986152324431256, 0.699383062254627, 0.8649754500818331, 0.7692307692307693, 0.8922631959508315, 0.8321775312066574, 0.9417249417249417]
 precisions [0.7421441774491682, 0.875515251442704, 0.9093457943925234, 0.8483245149911817, 0.9273743016759777, 0.7531380753138075, 0.8336886993603412, 0.5967007963594995, 0.9767309875141884, 0.6899488926746167, 0.917408506429278, 0.6999439147504206, 0.855973813420622, 0.7692307692307693, 0.9023861171366594, 0.8453536754507628, 0.9463869463869464]
 recalls [0.7370609981515711, 0.9002473206924979, 0.9168224299065421, 0.8712522045855379, 0.9152700186219739, 0.6485355648535565, 0.8130774697938877, 0.5910125142207053, 0.9795686719636776, 0.6729131175468483, 0.9149357072205737, 0.7142456533931576, 0.8608837970540099, 0.7559681697612732, 0.9038322487346349, 0.8377253814147018, 0.9393939393939394]
 f1scores [0.6828683985598272, 0.8795144277688083, 0.9143588644242158, 0.8868238449874036, 0.9327126042563336, 0.6437768101919045, 0.8062071118702387, 0.5981339256406627, 0.9778750537718464, 0.6487763770618723, 0.9102427004023312, 0.6857744598403589, 0.8624511612384455, 0.7473742609059835, 0.882503552118122, 0.8173601650825113, 0.9448817364783751]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48
 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.748 Precision 0.748 Recall 0.748 F1 0.703 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.830 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.869 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.840 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.887 
=> Acc: 0.695 Precision 0.695 Recall 0.695 F1 0.649 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.743 
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.777 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.875 
=> Acc: 0.687 Precision 0.687 Recall 0.687 F1 0.687 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.731 Precision 0.731 Recall 0.731 F1 0.734 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.892 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.817 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.844 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.874 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.854 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.865 


accs [0.7481515711645101, 0.8450123660346249, 0.8724299065420561, 0.8395061728395061, 0.8873370577281192, 0.694560669456067, 0.7661691542288557, 0.7787258248009101, 0.8779795686719637, 0.6873935264054515, 0.9322453016815034, 0.730790802019069, 0.8936170212765957, 0.8196286472148541, 0.8510484454085322, 0.8869625520110958, 0.8648018648018648, 0.8687089715536105]
 precisions [0.7426062846580407, 0.830997526793075, 0.8742990654205608, 0.8447971781305115, 0.8929236499068901, 0.698744769874477, 0.7654584221748401, 0.7929465301478953, 0.8654937570942112, 0.7189097103918228, 0.9297725024727992, 0.7181716208637129, 0.8739770867430442, 0.8116710875331565, 0.8604483007953724, 0.8904299583911235, 0.8344988344988346, 0.899343544857768]
 recalls [0.7416820702402958, 0.8458367683429514, 0.8771028037383177, 0.8430335097001763, 0.8933891992551211, 0.7322175732217573, 0.7555081734186212, 0.7912400455062572, 0.8751418842224744, 0.7010221465076661, 0.9183976261127597, 0.7218171620863713, 0.8903436988543372, 0.8037135278514589, 0.8568329718004338, 0.8848821081830791, 0.8205128205128205, 0.9080962800875274]
 f1scores [0.7099590888049077, 0.8124443599928467, 0.858510313941205, 0.8421738215637463, 0.8880842954742505, 0.6569516222720105, 0.7343430119552379, 0.7761219791487728, 0.868764546894093, 0.7137877424817198, 0.9273260799137455, 0.7324363046715625, 0.891509650682007, 0.8349174318382406, 0.8463625540618501, 0.8771860019560158, 0.8323494159594477, 0.8761452121148988]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.718 Precision 0.718 Recall 0.718 F1 0.656 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.833 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.932 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.832 
=> Acc: 0.735 Precision 0.735 Recall 0.735 F1 0.683 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.771 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.776 
=> Acc: 0.704 Precision 0.704 Recall 0.704 F1 0.707 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.935 
=> Acc: 0.648 Precision 0.648 Recall 0.648 F1 0.639 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.966 
=> Acc: 0.599 Precision 0.599 Recall 0.599 F1 0.593 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.850 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.774 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.782 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.830 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.865 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.781 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.939 


accs [0.717652495378928, 0.8474855729596042, 0.930373831775701, 0.8324514991181657, 0.7351024208566108, 0.7949790794979079, 0.7903340440653873, 0.7036405005688282, 0.934733257661748, 0.6482112436115843, 0.9673590504451038, 0.5992708917554683, 0.8518821603927987, 0.7851458885941645, 0.7924801156905278, 0.8502080443828016, 0.8717948717948718, 0.8183807439824945, 0.936495791889824]
 precisions [0.7264325323475046, 0.8598516075845012, 0.927570093457944, 0.8042328042328042, 0.7239292364990689, 0.7322175732217573, 0.7818052594171997, 0.7127417519908987, 0.9324631101021567, 0.6678023850085179, 0.9648862512363996, 0.6043185642176108, 0.8576104746317512, 0.7745358090185677, 0.7736804049168474, 0.8744798890429958, 0.8508158508158508, 0.7571115973741794, 0.9479724560061209]
 recalls [0.7259704251386322, 0.843363561417972, 0.927570093457944, 0.7954144620811288, 0.7239292364990689, 0.7364016736401674, 0.8031272210376688, 0.7059158134243458, 0.9358683314415437, 0.6499148211243612, 0.9708209693372898, 0.592540661805945, 0.8412438625204582, 0.7984084880636605, 0.7874186550976139, 0.8592233009708737, 0.8554778554778555, 0.8030634573304157, 0.9441469013006886]
 f1scores [0.6592595175298196, 0.8150695705239736, 0.9308465852938687, 0.790146891985498, 0.6789957637309797, 0.7256970914885742, 0.7759011478600311, 0.7133350577940796, 0.9375529523547923, 0.6415445087637351, 0.9708432722506221, 0.594732613855706, 0.8622372060776871, 0.7754181660971188, 0.7930840446563586, 0.8587258505791068, 0.8616217571927913, 0.7434713217105244, 0.9436623987022686]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.854 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.880 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.889 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.819 
=> Acc: 0.741 Precision 0.741 Recall 0.741 F1 0.693 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.703 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.858 
=> Acc: 0.738 Precision 0.738 Recall 0.738 F1 0.730 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 
=> Acc: 0.695 Precision 0.695 Recall 0.695 F1 0.690 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.936 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.736 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.857 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.823 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.842 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.793 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.878 
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.771 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.920 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 


accs [0.8558225508317929, 0.8903544929925804, 0.8897196261682243, 0.8201058201058201, 0.7406890130353817, 0.7615062761506276, 0.8685145700071073, 0.7377701934015927, 0.9597048808172531, 0.6950596252129472, 0.9391691394658753, 0.729388670779585, 0.8600654664484452, 0.8275862068965517, 0.8496023138105567, 0.8287101248266296, 0.8834498834498834, 0.7789934354485777, 0.918133129303749, 0.9107744107744108]
 precisions [0.8535120147874307, 0.8837592745259687, 0.8939252336448598, 0.8395061728395061, 0.7490689013035382, 0.7656903765690377, 0.8642501776830135, 0.726962457337884, 0.9483541430192962, 0.702725724020443, 0.9441147378832839, 0.7223780145821649, 0.8797054009819967, 0.843501326259947, 0.8532176428054953, 0.8335644937586685, 0.8927738927738927, 0.811816192560175, 0.9135424636572304, 0.9102132435465768]
 recalls [0.8562846580406654, 0.8705688375927453, 0.8780373831775701, 0.8377425044091711, 0.75512104283054, 0.7112970711297071, 0.8670931058990761, 0.7445961319681457, 0.9557321225879682, 0.6976149914821125, 0.9307616221562809, 0.7097588334268088, 0.8617021276595744, 0.8673740053050398, 0.8394793926247288, 0.8363384188626907, 0.8811188811188811, 0.7986870897155361, 0.9334353481254782, 0.9062850729517397]
 f1scores [0.859214260678173, 0.8698457100523787, 0.8848002528117245, 0.8109968959442856, 0.690742446899305, 0.7120574166332057, 0.8490130474874787, 0.7164031906741656, 0.947992589942474, 0.6790020009173933, 0.9309332712879174, 0.7284976943150923, 0.8715672165479772, 0.82065156755849, 0.8018665178791103, 0.7758504447930546, 0.8841746856205577, 0.7584569011584303, 0.9395735895871427, 0.89859970436199]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 


accs [0.9990909090909091]
 precisions [0.9981818181818182]
 recalls [1.0]
 f1scores [0.9981836905954358]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.954 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9545454545454546, 1.0]
 precisions [0.9527272727272728, 1.0]
 recalls [0.9518181818181818, 0.9992125984251968]
 f1scores [0.9496421775796142, 1.0]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.863 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 


accs [0.8627272727272727, 0.9905511811023622, 0.9731735159817352]
 precisions [0.8663636363636363, 0.9944881889763779, 0.9691780821917808]
 recalls [0.8781818181818182, 0.9921259842519685, 0.9765981735159818]
 f1scores [0.8693514682887209, 0.9874508491733789, 0.9712510432442588]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.824 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.937 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.930 


accs [0.8318181818181818, 0.9960629921259843, 0.9394977168949772, 0.9307692307692308]
 precisions [0.8572727272727273, 0.9960629921259843, 0.9309360730593608, 0.9487179487179487]
 recalls [0.8272727272727273, 0.9944881889763779, 0.930365296803653, 0.9384615384615385]
 f1scores [0.8346543734915022, 0.9958953142731378, 0.9400497513162762, 0.9276460608169834]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.845 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.974 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.906 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.960 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.857 


accs [0.8472727272727273, 0.9748031496062992, 0.908675799086758, 0.958974358974359, 0.8786549707602339]
 precisions [0.8481818181818181, 0.9708661417322835, 0.896689497716895, 0.9538461538461539, 0.8910818713450293]
 recalls [0.8545454545454545, 0.968503937007874, 0.9052511415525114, 0.9641025641025641, 0.8925438596491229]
 f1scores [0.8562549727914355, 0.9709796716415054, 0.8993061684269751, 0.9391162303664922, 0.8806554917658531]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.858 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.985 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.891 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.822 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 


accs [0.8581818181818182, 0.984251968503937, 0.910958904109589, 0.8948717948717949, 0.8421052631578947, 0.9961389961389961]
 precisions [0.860909090909091, 0.9803149606299213, 0.9178082191780822, 0.9358974358974359, 0.8603801169590644, 0.9961389961389961]
 recalls [0.8781818181818182, 0.9850393700787402, 0.9212328767123288, 0.9307692307692308, 0.8603801169590644, 1.0]
 f1scores [0.8629659595598443, 0.9797974888982873, 0.915516072328658, 0.9090920532621581, 0.8473190444254719, 0.9925683473499631]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.858 
=> Acc: 0.821 Precision 0.821 Recall 0.821 F1 0.811 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.900 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.885 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.858 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.963 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.897 


accs [0.8581818181818182, 0.8212598425196851, 0.9006849315068494, 0.8871794871794871, 0.8676900584795322, 0.9652509652509652, 0.898682417083144]
 precisions [0.87, 0.8220472440944881, 0.9029680365296804, 0.8948717948717949, 0.8764619883040936, 0.972972972972973, 0.8984552476147206]
 recalls [0.8636363636363636, 0.8165354330708662, 0.8949771689497716, 0.8666666666666667, 0.8801169590643275, 0.9575289575289575, 0.8964107223989096]
 f1scores [0.8740218529045759, 0.8147565104658099, 0.9034642831603124, 0.8754292084726867, 0.8524339601326174, 0.9608943052632373, 0.8997484224898367]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.838 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.903 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.852 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.848 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.935 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.870 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.916 


accs [0.8372727272727273, 0.925984251968504, 0.906392694063927, 0.8641025641025641, 0.8603801169590644, 0.9343629343629344, 0.8755111313039527, 0.9187105816398038]
 precisions [0.8345454545454546, 0.9165354330708662, 0.8858447488584474, 0.841025641025641, 0.8369883040935673, 0.9652509652509652, 0.8820990458882326, 0.918009810791871]
 recalls [0.8390909090909091, 0.9220472440944882, 0.8898401826484018, 0.8461538461538461, 0.8457602339181286, 0.9498069498069498, 0.8834620626987733, 0.9099509460406447]
 f1scores [0.8342792008536956, 0.9171836829980041, 0.8986973377093985, 0.8411868028393451, 0.836956329191049, 0.9737294916312136, 0.8715158924109385, 0.9224300062647955]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.822 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.935 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.918 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.837 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.882 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.937 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.880 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.870 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.907 


accs [0.8254545454545454, 0.9362204724409449, 0.9200913242009132, 0.8564102564102564, 0.8940058479532164, 0.9382239382239382, 0.8875511131303953, 0.873510861948143, 0.9115281501340483]
 precisions [0.8281818181818181, 0.9236220472440945, 0.8881278538812786, 0.8692307692307693, 0.881578947368421, 0.9498069498069498, 0.8693775556565198, 0.877365101611773, 0.9276139410187667]
 recalls [0.8272727272727273, 0.937007874015748, 0.9029680365296804, 0.9025641025641026, 0.8640350877192983, 0.918918918918919, 0.8741481144934121, 0.8714085494043448, 0.9195710455764075]
 f1scores [0.8301773503832148, 0.92166036653856, 0.8959781204719128, 0.8789844593105531, 0.8614328156770625, 0.9551965499532068, 0.8612423645283291, 0.8751813569898639, 0.9126366059402866]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.868 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.942 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.905 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.811 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.835 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.926 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.867 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.846 
=> Acc: 0.606 Precision 0.606 Recall 0.606 F1 0.530 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.87, 0.9425196850393701, 0.906392694063927, 0.823076923076923, 0.8508771929824561, 0.9266409266409267, 0.8771013175829169, 0.8486334968465312, 0.6058981233243967, 1.0]
 precisions [0.8790909090909091, 0.9433070866141732, 0.9075342465753424, 0.8307692307692308, 0.8654970760233918, 0.9305019305019305, 0.8870967741935484, 0.8710581639803784, 0.6246648793565683, 1.0]
 recalls [0.8481818181818181, 0.9464566929133859, 0.9218036529680366, 0.8487179487179487, 0.8728070175438597, 0.918918918918919, 0.8777828259881872, 0.854239663629993, 0.5764075067024129, 1.0]
 f1scores [0.8587294784138416, 0.9250250900200253, 0.9082939893589209, 0.7637992660949469, 0.8308656863028577, 0.9419287572668444, 0.8702317556476903, 0.8447554972565605, 0.5087472766884531, 1.0]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.854 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.911 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.775 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.839 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.935 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.875 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.867 
=> Acc: 0.638 Precision 0.638 Recall 0.638 F1 0.551 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.962 


accs [0.8554545454545455, 0.9456692913385827, 0.910958904109589, 0.8025641025641026, 0.8589181286549707, 0.9382239382239382, 0.8825533848250795, 0.8728100911002102, 0.6380697050938338, 0.9629629629629629, 0.9641873278236914]
 precisions [0.8336363636363636, 0.9503937007874016, 0.9309360730593608, 0.8128205128205128, 0.8406432748538012, 0.9613899613899614, 0.8698318945933666, 0.861948142957253, 0.6595174262734584, 0.9696969696969697, 0.9889807162534435]
 recalls [0.83, 0.9488188976377953, 0.9235159817351598, 0.8128205128205128, 0.8508771929824561, 0.9305019305019305, 0.8784643343934575, 0.849334267694464, 0.5951742627345844, 0.9696969696969697, 0.9862258953168044]
 f1scores [0.8256118355971411, 0.9409247735964467, 0.9210382757249784, 0.7902097103457435, 0.8175463854650173, 0.9382022716265336, 0.8629927411014233, 0.857896073493577, 0.5409323064900659, 0.9705050249602273, 0.9854792672402424]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.799 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.934 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.885 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.827 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.825 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.966 
=> Acc: 0.807 Precision 0.807 Recall 0.807 F1 0.796 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.846 
=> Acc: 0.582 Precision 0.582 Recall 0.582 F1 0.558 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 


accs [0.8081818181818182, 0.9346456692913386, 0.889269406392694, 0.8487179487179487, 0.8391812865497076, 0.9652509652509652, 0.8073602907769196, 0.855290819901892, 0.5817694369973191, 0.98989898989899, 0.9752066115702479, 0.9780805687203792]
 precisions [0.8127272727272727, 0.9354330708661417, 0.872716894977169, 0.8666666666666667, 0.8355263157894737, 0.9227799227799228, 0.8148568832348932, 0.8612473721093202, 0.6193029490616622, 0.9932659932659933, 0.953168044077135, 0.9816350710900474]
 recalls [0.8409090909090909, 0.9480314960629921, 0.8715753424657534, 0.841025641025641, 0.8260233918128655, 0.9266409266409267, 0.815765561108587, 0.8601962158374211, 0.646112600536193, 0.98989898989899, 0.9586776859504132, 0.9798578199052133]
 f1scores [0.8083644822573438, 0.9275563056766449, 0.8887428809536434, 0.8326167516509713, 0.8045516679201828, 0.9243882228362079, 0.7998682950566903, 0.851118453561748, 0.589033887298585, 0.9786323898323899, 0.9612549488549048, 0.9778727555707375]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.861 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.886 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.699 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.848 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.932 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.876 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.843 
=> Acc: 0.641 Precision 0.641 Recall 0.641 F1 0.520 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.917 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.8636363636363636, 0.9496062992125984, 0.889269406392694, 0.7487179487179487, 0.8574561403508771, 0.9305019305019305, 0.8852794184461609, 0.8475823405746321, 0.6407506702412868, 0.9259259259259259, 0.9641873278236914, 0.955568720379147, 0.9917231000752446]
 precisions [0.8645454545454545, 0.9401574803149606, 0.8767123287671232, 0.7564102564102564, 0.868421052631579, 0.915057915057915, 0.8764198091776465, 0.8412754029432375, 0.6112600536193029, 0.9090909090909091, 0.9752066115702479, 0.9626777251184834, 0.9864559819413092]
 recalls [0.8854545454545455, 0.9582677165354331, 0.8755707762557078, 0.7410256410256411, 0.8669590643274854, 0.8957528957528957, 0.8798273512039981, 0.8353188507358094, 0.5898123324396782, 0.9158249158249159, 0.9559228650137741, 0.95260663507109, 0.9887133182844243]
 f1scores [0.8514378338682311, 0.942084947511843, 0.8720760268660085, 0.7414628159667006, 0.8618133772348197, 0.9079240839705358, 0.8735646085028851, 0.8312100989957534, 0.5050855468792346, 0.9089481080050952, 0.9551583852887463, 0.9514684160965554, 0.989436180838899]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.779 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.887 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.772 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.843 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.827 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.868 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.775 
=> Acc: 0.582 Precision 0.582 Recall 0.582 F1 0.531 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.926 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.968 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 


accs [0.7918181818181819, 0.9503937007874016, 0.8932648401826484, 0.7923076923076923, 0.85453216374269, 0.8301158301158301, 0.8773284870513403, 0.7894183601962158, 0.5817694369973191, 0.9292929292929293, 0.9669421487603306, 0.9253554502369669, 0.944319036869827, 0.9797033567525371]
 precisions [0.7736363636363637, 0.9496062992125984, 0.8681506849315068, 0.7564102564102564, 0.8552631578947368, 0.806949806949807, 0.8696047251249432, 0.7876664330763841, 0.6005361930294906, 0.9494949494949495, 0.9834710743801653, 0.9247630331753555, 0.9435665914221218, 0.9687743950039032]
 recalls [0.7727272727272727, 0.9417322834645669, 0.872716894977169, 0.7410256410256411, 0.8720760233918129, 0.9034749034749034, 0.878691503861881, 0.7904695164681149, 0.6246648793565683, 0.9393939393939394, 0.9752066115702479, 0.9262440758293838, 0.9307750188111362, 0.9765807962529274]
 f1scores [0.742007785004351, 0.9515032459691344, 0.8756031988043007, 0.7462531784299082, 0.862184676655479, 0.8709320659175604, 0.8603924385936617, 0.765260475567594, 0.5134833882795766, 0.929663058377681, 0.9749000992166813, 0.9187153072511134, 0.9320499156415953, 0.9754687279663111]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.779 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.914 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.832 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.762 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.860 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.887 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.819 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.797 
=> Acc: 0.576 Precision 0.576 Recall 0.576 F1 0.477 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.921 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.938 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.922 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 


accs [0.7963636363636364, 0.9173228346456693, 0.8424657534246576, 0.782051282051282, 0.8698830409356725, 0.8841698841698842, 0.8400726942298955, 0.810791871058164, 0.5764075067024129, 0.9259259259259259, 0.9366391184573003, 0.9333530805687204, 0.9382994732881866, 0.9211553473848556, 0.9782608695652174]
 precisions [0.7863636363636364, 0.9133858267716536, 0.829337899543379, 0.7897435897435897, 0.881578947368421, 0.8416988416988417, 0.8512039981826443, 0.8163980378416258, 0.5254691689008043, 0.9292929292929293, 0.9586776859504132, 0.9306872037914692, 0.9322799097065463, 0.9305230288836847, 0.9707646176911544]
 recalls [0.7881818181818182, 0.9062992125984252, 0.8441780821917808, 0.7846153846153846, 0.8801169590643275, 0.8185328185328186, 0.8350749659245797, 0.819551506657323, 0.517426273458445, 0.9461279461279462, 0.9504132231404959, 0.9292061611374408, 0.9247554552294959, 0.9188134270101483, 0.9767616191904048]
 f1scores [0.7738461353993131, 0.897411563085635, 0.8161897568938532, 0.7565764267002306, 0.8736325761801632, 0.8333273280183245, 0.8094201181179594, 0.7925326037053209, 0.5021478178544652, 0.9416681624469154, 0.9372601961158015, 0.9295044138443396, 0.9133167792398661, 0.92970324184021, 0.968669022121135]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.781 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.908 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.901 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.745 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.813 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.853 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.826 
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.790 
=> Acc: 0.592 Precision 0.592 Recall 0.592 F1 0.478 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.883 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.875 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.954 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.885 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.917 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.947 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 


accs [0.7881818181818182, 0.9110236220472441, 0.9029680365296804, 0.7743589743589744, 0.8318713450292398, 0.8648648648648649, 0.8389368468877783, 0.799229152067274, 0.5924932975871313, 0.8821548821548821, 0.8815426997245179, 0.9537914691943128, 0.8848758465011287, 0.9164715066354411, 0.9490254872563718, 0.989851150202977]
 precisions [0.8172727272727273, 0.905511811023622, 0.9075342465753424, 0.7974358974358975, 0.8552631578947368, 0.8494208494208494, 0.8507496592457974, 0.8002803083391731, 0.6005361930294906, 0.898989898989899, 0.9035812672176309, 0.9505331753554502, 0.8901429646350639, 0.9250585480093677, 0.9422788605697151, 0.9817320703653586]
 recalls [0.8336363636363636, 0.9125984251968504, 0.91324200913242, 0.8128205128205128, 0.8267543859649122, 0.8841698841698842, 0.8568832348932304, 0.7932725998598459, 0.5924932975871313, 0.9461279461279462, 0.8870523415977961, 0.9493483412322274, 0.8698269375470279, 0.9094457455113193, 0.9355322338830585, 0.986468200270636]
 f1scores [0.8006262725045324, 0.9107766051725026, 0.900675072509238, 0.7439534424871548, 0.8221741900499235, 0.8631424588281231, 0.8281441260916633, 0.7691121916995155, 0.5093646746570807, 0.895007334170948, 0.8640945450779464, 0.9487921767277138, 0.874887689711098, 0.9190848357074, 0.9414552416059774, 0.9840659207477543]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.783 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.913 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.870 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.766 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.794 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.864 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.822 
=> Acc: 0.744 Precision 0.744 Recall 0.744 F1 0.728 
=> Acc: 0.536 Precision 0.536 Recall 0.536 F1 0.475 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.864 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.884 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.961 


accs [0.8018181818181818, 0.915748031496063, 0.872716894977169, 0.7846153846153846, 0.8157894736842105, 0.8687258687258688, 0.841890049977283, 0.7435178696566223, 0.5361930294906166, 0.9461279461279462, 0.8650137741046832, 0.9256516587677726, 0.9510910458991723, 0.8899297423887588, 0.9505247376311844, 0.9682002706359946, 0.9603436880370125]
 precisions [0.78, 0.9102362204724409, 0.8744292237442922, 0.7923076923076923, 0.8442982456140351, 0.888030888030888, 0.8298500681508405, 0.7302032235459005, 0.5120643431635389, 0.9393939393939394, 0.8760330578512396, 0.9297985781990521, 0.9533483822422875, 0.8844652615144418, 0.9557721139430285, 0.9634641407307172, 0.9576999339061467]
 recalls [0.7918181818181819, 0.8992125984251969, 0.872716894977169, 0.8, 0.8252923976608187, 0.8996138996138996, 0.8293957292139936, 0.7459705676243868, 0.546916890080429, 0.9494949494949495, 0.8567493112947658, 0.9345379146919431, 0.9473288186606471, 0.8969555035128806, 0.9460269865067467, 0.959404600811908, 0.9656311962987442]
 f1scores [0.7882831517827815, 0.9025316721785808, 0.864069390425605, 0.7754881784450334, 0.8106319276965858, 0.9035612330647531, 0.8156222464421292, 0.7314469247691976, 0.47338820899682865, 0.9557907480449369, 0.8133228884489203, 0.9271203577275472, 0.9538039275565332, 0.8734698111858951, 0.955753683260839, 0.9630869805932505, 0.9769081792250527]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.862 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.852 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.843 
=> Acc: 0.764 Precision 0.764 Recall 0.764 F1 0.718 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.814 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.769 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.877 
=> Acc: 0.715 Precision 0.715 Recall 0.715 F1 0.704 
=> Acc: 0.576 Precision 0.576 Recall 0.576 F1 0.460 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.940 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.891 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.875 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.908 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.885 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.943 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.915 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.916 


accs [0.8690909090909091, 0.852755905511811, 0.8447488584474886, 0.764102564102564, 0.8326023391812866, 0.7760617760617761, 0.8895956383462063, 0.7147862648913805, 0.5764075067024129, 0.936026936026936, 0.9008264462809917, 0.8794431279620853, 0.909706546275395, 0.8875878220140515, 0.9437781109445277, 0.9167794316644113, 0.9616655651024455, 0.9187582562747688]
 precisions [0.85, 0.8598425196850393, 0.8281963470319634, 0.7589743589743589, 0.810672514619883, 0.8494208494208494, 0.8789186733303044, 0.7368605466012614, 0.5227882037533512, 0.9225589225589226, 0.8815426997245179, 0.8809241706161137, 0.9021820917983446, 0.9008587041373927, 0.9430284857571214, 0.918809201623816, 0.9596827495042961, 0.9233817701453104]
 recalls [0.8672727272727273, 0.8409448818897638, 0.8213470319634704, 0.7717948717948718, 0.8201754385964912, 0.8146718146718147, 0.8734666060881418, 0.7274001401541695, 0.5656836461126006, 0.9023569023569024, 0.8760330578512396, 0.8717417061611374, 0.9134687735139202, 0.8813427010148321, 0.9377811094452774, 0.9133964817320703, 0.9524124256444151, 0.9121532364597094]
 f1scores [0.8617002666853425, 0.8428667378896254, 0.8084398027811863, 0.7175448165246859, 0.781050726250706, 0.8480533291424379, 0.859742610975883, 0.7038269403824403, 0.46847160232250484, 0.9024024787643775, 0.8572384731811326, 0.8755626604149015, 0.9093770619399691, 0.8933656875389252, 0.935925006526601, 0.9152624388896111, 0.9562940074468415, 0.926205464415429]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72
 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.731 Precision 0.731 Recall 0.731 F1 0.715 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.873 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.838 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.883 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.780 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.864 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.820 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.782 
=> Acc: 0.536 Precision 0.536 Recall 0.536 F1 0.466 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.898 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.916 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.871 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.884 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.917 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.916 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.891 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.834 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.842 


accs [0.730909090909091, 0.8763779527559055, 0.843607305936073, 0.8897435897435897, 0.804093567251462, 0.8725868725868726, 0.8400726942298955, 0.7887175893482831, 0.5361930294906166, 0.9326599326599326, 0.8980716253443526, 0.917654028436019, 0.8743416102332581, 0.8844652615144418, 0.9182908545727136, 0.9167794316644113, 0.8896232650363516, 0.8500660501981506, 0.8421052631578947]
 precisions [0.7663636363636364, 0.8803149606299212, 0.8401826484018264, 0.8692307692307693, 0.7945906432748538, 0.8532818532818532, 0.8432530667878237, 0.7862648913805186, 0.5737265415549598, 0.9225589225589226, 0.928374655647383, 0.9309834123222749, 0.8871331828442438, 0.8930523028883685, 0.9115442278860569, 0.9174560216508796, 0.900198281559815, 0.8632760898282695, 0.8436308161708619]
 recalls [0.76, 0.8543307086614174, 0.8447488584474886, 0.8743589743589744, 0.7931286549707602, 0.8648648648648649, 0.8396183552930486, 0.7904695164681149, 0.5683646112600537, 0.936026936026936, 0.9118457300275482, 0.9253554502369669, 0.8758465011286681, 0.8961748633879781, 0.9205397301349325, 0.915426251691475, 0.8856576338400529, 0.8375165125495376, 0.8489702517162472]
 f1scores [0.711774865579262, 0.8375845586300331, 0.8353918487571198, 0.874277835128104, 0.78160975734079, 0.8739054584857102, 0.823131733437022, 0.7803242407076967, 0.5028693904834487, 0.9268797945276415, 0.9128627262461849, 0.922726467805575, 0.8650562962931364, 0.8683652121416557, 0.9032380199113075, 0.9309852016884477, 0.8885294981301157, 0.8438542875636509, 0.8541812955886409]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.717 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.867 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.818 
=> Acc: 0.738 Precision 0.738 Recall 0.738 F1 0.711 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.836 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.802 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.854 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.760 
=> Acc: 0.595 Precision 0.595 Recall 0.595 F1 0.551 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.930 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.862 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.848 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.846 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.873 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.931 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.893 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.900 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.819 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.804 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.917 


accs [0.7427272727272727, 0.8708661417322835, 0.8253424657534246, 0.7384615384615385, 0.8384502923976608, 0.803088803088803, 0.8675601999091322, 0.7687456201822004, 0.5951742627345844, 0.9292929292929293, 0.8622589531680441, 0.8575236966824644, 0.8547780285929271, 0.8758782201405152, 0.9347826086956522, 0.8964817320703654, 0.9008592200925314, 0.8256274768824307, 0.8192219679633868, 0.9185929648241206]
 precisions [0.7627272727272727, 0.8472440944881889, 0.8184931506849316, 0.7589743589743589, 0.841374269005848, 0.8223938223938224, 0.8741481144934121, 0.7708479327259986, 0.5683646112600537, 0.9427609427609428, 0.8815426997245179, 0.8438981042654028, 0.8382242287434161, 0.8719750195160031, 0.9325337331334332, 0.9046008119079838, 0.8889623265036352, 0.8229854689564069, 0.8108314263920672, 0.9185929648241206]
 recalls [0.7454545454545455, 0.8519685039370078, 0.817351598173516, 0.7615384615384615, 0.841374269005848, 0.7799227799227799, 0.8657428441617446, 0.7582340574632095, 0.5442359249329759, 0.936026936026936, 0.8650137741046832, 0.8450829383886256, 0.8487584650112867, 0.8961748633879781, 0.9205397301349325, 0.9093369418132612, 0.88433575677462, 0.8309114927344782, 0.8253241800152555, 0.9195979899497487]
 f1scores [0.7472128174817498, 0.8427169496236481, 0.8100783021956393, 0.7522789952613856, 0.8237344866012402, 0.7483176283030344, 0.8556323839021728, 0.7566590297748361, 0.5311246056080813, 0.9289840075393233, 0.8272784894564168, 0.8381643708117821, 0.8449742919172403, 0.8837909030592155, 0.9279213517078695, 0.9109327976891624, 0.9058654417375843, 0.8184333237197514, 0.797999254752925, 0.9214604771677812]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.959 


accs [0.9573643410852714]
 precisions [0.9767441860465116]
 recalls [0.9612403100775194]
 f1scores [0.9734563832124807]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.958 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9573643410852714, 1.0]
 precisions [0.9573643410852714, 0.998003992015968]
 recalls [0.9806201550387597, 0.9940119760479041]
 f1scores [0.9652490911545162, 0.9903723271606164]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 


accs [0.9534883720930233, 0.9840319361277445, 0.9900990099009901]
 precisions [0.9767441860465116, 0.9860279441117764, 0.9929278642149929]
 recalls [0.9534883720930233, 0.9960079840319361, 0.9952852428099953]
 f1scores [0.9544416499865871, 0.9918916284082482, 0.9943395696511393]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.888 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.926 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.9031007751937985, 0.9281437125748503, 0.9811409712399811, 0.9887920298879203]
 precisions [0.9108527131782945, 0.9441117764471058, 0.9820839226779821, 0.9925280199252802]
 recalls [0.875968992248062, 0.9161676646706587, 0.9844413012729845, 0.9869240348692403]
 f1scores [0.8996792443564099, 0.8965921005598931, 0.9851121582251764, 0.9889147575463081]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.854 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.902 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.900 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 


accs [0.8682170542635659, 0.9041916167664671, 0.9844413012729845, 0.900373599003736, 0.968299711815562]
 precisions [0.8488372093023255, 0.8942115768463074, 0.9839698255539839, 0.8953922789539228, 0.9750240153698367]
 recalls [0.8565891472868217, 0.8802395209580839, 0.9844413012729845, 0.8966376089663761, 0.9615754082612872]
 f1scores [0.8457101879414253, 0.9156773055088772, 0.9880611376641113, 0.8981362371645293, 0.973339958291084]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.785 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.798 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.845 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.960 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.934 


accs [0.8023255813953488, 0.8063872255489022, 0.975011786892975, 0.8567870485678705, 0.9615754082612872, 0.9345217689406925]
 precisions [0.7674418604651163, 0.7764471057884231, 0.9726544082979727, 0.8349937733499377, 0.9634966378482228, 0.9413781282139184]
 recalls [0.7751937984496124, 0.7884231536926147, 0.9698255539839699, 0.8511830635118306, 0.9716618635926993, 0.9403496743229345]
 f1scores [0.7332316992316993, 0.8013034378556766, 0.9726111238621467, 0.8325826599537607, 0.9631129820341592, 0.9331784120325775]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.777 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.843 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.929 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.843 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.932 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.986 


accs [0.7984496124031008, 0.8423153692614771, 0.9292786421499293, 0.8493150684931506, 0.9341978866474544, 0.9331504970860474, 0.9865319865319865]
 precisions [0.8062015503875969, 0.8622754491017964, 0.9231494578029231, 0.8331257783312578, 0.9418828049951969, 0.9300651354130957, 0.9831649831649831]
 recalls [0.7868217054263565, 0.8802395209580839, 0.9226779820839227, 0.8499377334993773, 0.9380403458213257, 0.9300651354130957, 0.9831649831649831]
 f1scores [0.8050989742490943, 0.8757348553506509, 0.9304587151241346, 0.8514233325780015, 0.9336456456803367, 0.9261452777903356, 0.9784496640568605]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.806 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.843 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.845 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.895 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.870 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.974 


accs [0.813953488372093, 0.8502994011976048, 0.9514380009429514, 0.8437110834371109, 0.9005763688760807, 0.8711004456633528, 0.9259259259259259, 0.9748603351955307]
 precisions [0.7984496124031008, 0.8283433133732535, 0.9467232437529467, 0.8574097135740971, 0.9101825168107589, 0.865615358244772, 0.9326599326599326, 0.9832402234636871]
 recalls [0.8410852713178295, 0.8662674650698603, 0.9354078264969354, 0.8599003735990037, 0.8957732949087416, 0.8765855330819335, 0.9292929292929293, 0.9720670391061452]
 f1scores [0.7795414167891233, 0.8312448083231854, 0.9530011312798223, 0.8633751180381857, 0.891214057207027, 0.8870408670030387, 0.9069794471914046, 0.9706050439187728]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.756 Precision 0.756 Recall 0.756 F1 0.728 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.787 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.778 Precision 0.778 Recall 0.778 F1 0.773 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.934 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.872 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.861 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.947 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 


accs [0.7558139534883721, 0.8083832335329342, 0.9368222536539368, 0.7783312577833126, 0.93611911623439, 0.8711004456633528, 0.8585858585858586, 0.946927374301676, 0.9901234567901235]
 precisions [0.7790697674418605, 0.8023952095808383, 0.9273927392739274, 0.7858032378580324, 0.9404418828049952, 0.8680150839904011, 0.8888888888888888, 0.9692737430167597, 0.9925925925925926]
 recalls [0.7558139534883721, 0.7784431137724551, 0.9316360207449317, 0.7814445828144458, 0.9322766570605188, 0.8676722660267397, 0.8518518518518519, 0.952513966480447, 0.9876543209876543]
 f1scores [0.7182982019356043, 0.7778582722725587, 0.9287193729958055, 0.7739200103325178, 0.9331952021464124, 0.8661754089886843, 0.8781061319192078, 0.9350283032095452, 0.9925888710586139]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.772 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.806 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.930 
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.733 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.953 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.768 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.846 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.924 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.995 Precision 0.995 Recall 0.995 F1 0.995 


accs [0.7984496124031008, 0.8183632734530938, 0.9306930693069307, 0.7540473225404732, 0.9538904899135446, 0.7737401439835447, 0.8720538720538721, 0.9385474860335196, 0.9530864197530864, 0.9946460440214159]
 precisions [0.810077519379845, 0.7924151696606786, 0.9236209335219236, 0.7627646326276464, 0.9447646493756003, 0.7730545080562221, 0.8282828282828283, 0.9134078212290503, 0.9432098765432099, 0.9934562760261749]
 recalls [0.8372093023255814, 0.7984031936127745, 0.9207920792079208, 0.7409713574097135, 0.94716618635927, 0.7816249571477546, 0.8047138047138047, 0.9581005586592178, 0.9506172839506173, 0.9970255800118977]
 f1scores [0.8137422253200665, 0.8365917117237747, 0.9253091755444031, 0.7384962247379231, 0.9473616688359805, 0.7680444472665368, 0.8022141518361264, 0.9231473283947231, 0.9567350638431262, 0.9940239084870592]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.703 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.804 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.919 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.779 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.903 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.762 
=> Acc: 0.781 Precision 0.781 Recall 0.781 F1 0.778 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.883 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.925 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.945 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.884 


accs [0.7403100775193798, 0.812375249500998, 0.918906176331919, 0.790161892901619, 0.9082612872238233, 0.7881384984573192, 0.7811447811447811, 0.8938547486033519, 0.9259259259259259, 0.9458655562165378, 0.8848857644991213]
 precisions [0.7209302325581395, 0.8223552894211577, 0.917020273455917, 0.7677459526774595, 0.9169068203650336, 0.7850531367843675, 0.8114478114478114, 0.88268156424581, 0.9358024691358025, 0.9512195121951219, 0.8774165202108963]
 recalls [0.7248062015503876, 0.8602794411177644, 0.9302215935879302, 0.7963885429638854, 0.9116234390009607, 0.7747685978745287, 0.8013468013468014, 0.88268156424581, 0.9308641975308642, 0.9464604402141582, 0.8796133567662566]
 f1scores [0.7052560564932409, 0.828341549556882, 0.9224351465284913, 0.7681029238503518, 0.9008530143193854, 0.7573793868047739, 0.8197851363068753, 0.884318231274753, 0.9541222695974941, 0.9525312439761698, 0.8775107838665421]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.755 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.772 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.899 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.684 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.895 
=> Acc: 0.706 Precision 0.706 Recall 0.706 F1 0.698 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.732 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.868 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.885 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.938 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.835 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.7790697674418605, 0.7944111776447106, 0.8995756718528995, 0.7285180572851806, 0.904418828049952, 0.7062050051422695, 0.7878787878787878, 0.8659217877094972, 0.8962962962962963, 0.9387269482450922, 0.8312829525483304, 1.0]
 precisions [0.7868217054263565, 0.7724550898203593, 0.9075907590759076, 0.736612702366127, 0.9169068203650336, 0.7003770997600274, 0.7508417508417509, 0.8910614525139665, 0.9259259259259259, 0.9434860202260559, 0.8246924428822495, 1.0]
 recalls [0.7751937984496124, 0.7684630738522954, 0.8958038661008958, 0.7496886674968867, 0.9111431316042267, 0.7123757284881728, 0.7845117845117845, 0.8854748603351955, 0.8716049382716049, 0.9244497323022011, 0.8233743409490334, 1.0]
 f1scores [0.7481770357574327, 0.7728092017996914, 0.8991741316866317, 0.6988552299872618, 0.9081850402465971, 0.7010360738486028, 0.7880674940542235, 0.873379690405854, 0.9085330241367826, 0.9266442532595663, 0.8332071956195284, 1.0]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.721 
=> Acc: 0.739 Precision 0.739 Recall 0.739 F1 0.711 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.943 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.720 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.889 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.738 
=> Acc: 0.667 Precision 0.667 Recall 0.667 F1 0.624 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.894 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.819 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.903 
=> Acc: 0.800 Precision 0.800 Recall 0.800 F1 0.800 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.847 
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.763 


accs [0.7403100775193798, 0.7385229540918163, 0.942008486562942, 0.7285180572851806, 0.8996157540826129, 0.7418580733630442, 0.6666666666666666, 0.8966480446927374, 0.8345679012345679, 0.9071980963712076, 0.7996485061511424, 0.8531073446327684, 0.7752715121136173]
 precisions [0.7945736434108527, 0.7465069860279441, 0.9410655351249411, 0.775840597758406, 0.909702209414025, 0.7435721631813507, 0.6161616161616161, 0.8687150837988827, 0.8197530864197531, 0.8964901844140393, 0.8075571177504394, 0.8870056497175142, 0.7898913951545531]
 recalls [0.7868217054263565, 0.7564870259481038, 0.9462517680339463, 0.74906600249066, 0.9020172910662824, 0.743914981145012, 0.6902356902356902, 0.8854748603351955, 0.8320987654320988, 0.8899464604402142, 0.8071177504393673, 0.8870056497175142, 0.7949039264828739]
 f1scores [0.7359761657491753, 0.7112982116446027, 0.9424900961339902, 0.7286155090719395, 0.9044793846100774, 0.7442892973531788, 0.6215804037393242, 0.8857252459525871, 0.806397215281773, 0.8805621204195896, 0.8090355807790429, 0.896807250324651, 0.7789063149737052]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.757 
=> Acc: 0.717 Precision 0.717 Recall 0.717 F1 0.696 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.940 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.777 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.901 
=> Acc: 0.756 Precision 0.756 Recall 0.756 F1 0.739 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.792 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.877 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.878 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.846 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.824 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.892 
=> Acc: 0.783 Precision 0.783 Recall 0.783 F1 0.770 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.989 


accs [0.7751937984496124, 0.716566866267465, 0.9391796322489392, 0.8026151930261519, 0.9048991354466859, 0.7559136098731574, 0.8080808080808081, 0.8770949720670391, 0.8864197530864197, 0.8494943486020226, 0.8189806678383128, 0.8983050847457628, 0.7827903091060986, 0.9879518072289156]
 precisions [0.7945736434108527, 0.7764471057884231, 0.9405940594059405, 0.7945205479452054, 0.9173871277617676, 0.7658553308193349, 0.8148148148148148, 0.888268156424581, 0.891358024691358, 0.8322427126710291, 0.8163444639718805, 0.8926553672316384, 0.7593984962406015, 0.9879518072289156]
 recalls [0.7403100775193798, 0.7624750499001997, 0.9377652050919377, 0.8138231631382317, 0.909221902017291, 0.7589989715461091, 0.797979797979798, 0.8435754189944135, 0.891358024691358, 0.8328375966686496, 0.8260105448154658, 0.8926553672316384, 0.7694235588972431, 0.9879518072289156]
 f1scores [0.7509277250923363, 0.7346711766989122, 0.9434564851188677, 0.7901826025401253, 0.9081416301258873, 0.7472196885719136, 0.7895644437730022, 0.8655800347078525, 0.8896122316867789, 0.8402368979459561, 0.821353700090732, 0.91999869326498, 0.7537151853099346, 0.9955033472274852]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.752 Precision 0.752 Recall 0.752 F1 0.704 
=> Acc: 0.673 Precision 0.673 Recall 0.673 F1 0.632 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.906 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.666 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.899 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.739 
=> Acc: 0.667 Precision 0.667 Recall 0.667 F1 0.614 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.859 
=> Acc: 0.681 Precision 0.681 Recall 0.681 F1 0.649 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.900 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.823 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.809 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.764 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.934 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.974 


accs [0.751937984496124, 0.6726546906187625, 0.9061763319189062, 0.7285180572851806, 0.9020172910662824, 0.7404868015083991, 0.6666666666666666, 0.8687150837988827, 0.6814814814814815, 0.9018441403926234, 0.8185413005272407, 0.8305084745762712, 0.772765246449457, 0.9397590361445783, 0.9730872741253364]
 precisions [0.7209302325581395, 0.7065868263473054, 0.892975011786893, 0.7478206724782067, 0.9053794428434198, 0.7219746314706891, 0.6430976430976431, 0.8603351955307262, 0.6839506172839506, 0.8917311124330756, 0.81195079086116, 0.7627118644067796, 0.7852965747702589, 0.8835341365461847, 0.9757785467128027]
 recalls [0.7558139534883721, 0.7465069860279441, 0.8873173031588873, 0.7291407222914073, 0.8996157540826129, 0.7504285224545766, 0.6632996632996633, 0.7905027932960894, 0.671604938271605, 0.900059488399762, 0.819859402460457, 0.8361581920903954, 0.7811194653299917, 0.891566265060241, 0.98000768935025]
 f1scores [0.6643698893436543, 0.7075942084041255, 0.8987483882287949, 0.6684001465537082, 0.8938748408512979, 0.7489279013500326, 0.6141187200406188, 0.8314919434936922, 0.6331267666197776, 0.8972195944918611, 0.8146699302478408, 0.7836778731763399, 0.7719150113160782, 0.9208924005872341, 0.9766894901113957]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.721 Precision 0.721 Recall 0.721 F1 0.721 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.813 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.903 
=> Acc: 0.778 Precision 0.778 Recall 0.778 F1 0.768 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.840 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.790 
=> Acc: 0.737 Precision 0.737 Recall 0.737 F1 0.737 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.869 
=> Acc: 0.738 Precision 0.738 Recall 0.738 F1 0.732 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.783 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.780 
=> Acc: 0.746 Precision 0.746 Recall 0.746 F1 0.706 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.790 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.778 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.913 


accs [0.7209302325581395, 0.8303393213572854, 0.900990099009901, 0.7777085927770859, 0.8515850144092219, 0.8097360301679808, 0.7373737373737373, 0.8798882681564246, 0.7382716049382716, 0.7804878048780488, 0.7851493848857645, 0.7457627118644068, 0.7936507936507936, 0.7951807228915663, 0.9500192233756247, 0.9135514018691588]
 precisions [0.7131782945736435, 0.8203592814371258, 0.901933050447902, 0.7714819427148194, 0.8539865513928915, 0.7980802194034967, 0.7811447811447811, 0.8575418994413407, 0.7135802469135802, 0.7953599048185603, 0.7987697715289982, 0.7627118644067796, 0.8007518796992481, 0.7911646586345381, 0.9519415609381008, 0.9205607476635514]
 recalls [0.751937984496124, 0.7864271457085829, 0.8943894389438944, 0.7839352428393525, 0.8376560999039385, 0.8035653068220775, 0.8013468013468014, 0.888268156424581, 0.7333333333333333, 0.7763236168947055, 0.7833919156414763, 0.751412429378531, 0.7928153717627402, 0.8152610441767069, 0.9554017685505575, 0.9182242990654206]
 f1scores [0.733948861407638, 0.8366475602586714, 0.8999571821840794, 0.750470742519733, 0.8465959840148887, 0.7829754492435815, 0.7888323039966787, 0.8649257742243337, 0.7126928951622628, 0.8128181068746707, 0.7891765201556185, 0.7484719207523397, 0.8005386766489861, 0.7898822793857571, 0.9539104581091589, 0.9319064829458353]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.840 
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.716 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.812 
=> Acc: 0.719 Precision 0.719 Recall 0.719 F1 0.674 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.900 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.788 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.821 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.905 
=> Acc: 0.691 Precision 0.691 Recall 0.691 F1 0.688 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.891 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.826 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.831 
=> Acc: 0.756 Precision 0.756 Recall 0.756 F1 0.739 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.840 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.906 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.909 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.961 


accs [0.8488372093023255, 0.7465069860279441, 0.8217821782178217, 0.7185554171855542, 0.9087415946205571, 0.7922523140212547, 0.8282828282828283, 0.9134078212290503, 0.691358024691358, 0.8929208804283165, 0.8194200351493849, 0.8418079096045198, 0.7560568086883876, 0.8353413654618473, 0.9065743944636678, 0.9135514018691588, 0.9621552277100706]
 precisions [0.8062015503875969, 0.7524950099800399, 0.8279113625648279, 0.7235367372353674, 0.9053794428434198, 0.7603702434007542, 0.7811447811447811, 0.9189944134078212, 0.6691358024691358, 0.9149315883402737, 0.8343585237258347, 0.8587570621468926, 0.7598162071846283, 0.8835341365461847, 0.8931180315263361, 0.9088785046728972, 0.9595894804361771]
 recalls [0.8217054263565892, 0.7564870259481038, 0.8316831683168316, 0.7359900373599004, 0.9058597502401537, 0.792595131984916, 0.8148148148148148, 0.8938547486033519, 0.7012345679012346, 0.8982748364069006, 0.8150263620386643, 0.768361581920904, 0.7765246449456976, 0.8674698795180723, 0.8873510188389081, 0.9252336448598131, 0.9621552277100706]
 f1scores [0.8203692487407684, 0.7248735797261522, 0.8080258503016609, 0.6689235046561872, 0.9098158872510032, 0.7671755047837916, 0.8231475759489871, 0.8803357505260818, 0.7018661003828626, 0.8978019828586115, 0.8284906191594776, 0.8804035364790185, 0.742894298328457, 0.8260420803620043, 0.9053561910495318, 0.9110996581337731, 0.9660360077730715]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.855 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.807 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.868 
=> Acc: 0.721 Precision 0.721 Recall 0.721 F1 0.647 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.818 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.781 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.851 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.843 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.826 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.845 
=> Acc: 0.695 Precision 0.695 Recall 0.695 F1 0.672 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.762 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.908 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.923 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.876 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.890 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.956 


accs [0.8604651162790697, 0.8163672654690619, 0.8736445073078737, 0.7210460772104608, 0.9106628242074928, 0.823791566678094, 0.7845117845117845, 0.8575418994413407, 0.8641975308641975, 0.8316478286734087, 0.8413884007029877, 0.6949152542372882, 0.7802840434419381, 0.9076305220883534, 0.9254133025759324, 0.8808411214953271, 0.8922386144964721, 0.9577393075356415]
 precisions [0.8527131782945736, 0.7764471057884231, 0.8807166430928807, 0.7004981320049813, 0.8996157540826129, 0.8344189235515941, 0.7878787878787878, 0.8798882681564246, 0.8246913580246914, 0.8494943486020226, 0.8194200351493849, 0.7175141242937854, 0.7702589807852965, 0.8514056224899599, 0.9284890426758939, 0.9158878504672897, 0.8877485567671585, 0.9516293279022403]
 recalls [0.8527131782945736, 0.782435129740519, 0.8873173031588873, 0.7061021170610212, 0.9121037463976945, 0.8248200205690778, 0.797979797979798, 0.840782122905028, 0.8024691358024691, 0.8590124925639501, 0.8268892794376098, 0.751412429378531, 0.7798663324979115, 0.891566265060241, 0.9265667051134179, 0.8925233644859814, 0.8871071199486851, 0.9536659877800407]
 f1scores [0.8713140199696264, 0.8072842953682408, 0.8787506501946684, 0.6393712620147316, 0.8992056952540309, 0.8237189049975153, 0.7469367849891814, 0.859912085600383, 0.8125469613614248, 0.8369347763878505, 0.8295530813209187, 0.7545726434606399, 0.765734620086181, 0.8662890978753047, 0.913378186463256, 0.8941743684550231, 0.891480363632221, 0.9558066584252698]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.862 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.751 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.878 
=> Acc: 0.733 Precision 0.733 Recall 0.733 F1 0.703 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.903 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.829 
=> Acc: 0.734 Precision 0.734 Recall 0.734 F1 0.740 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.804 
=> Acc: 0.758 Precision 0.758 Recall 0.758 F1 0.763 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.829 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.815 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.764 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.751 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.826 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.908 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.865 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.832 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.921 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.868 


accs [0.8643410852713178, 0.7724550898203593, 0.8793022159358793, 0.7328767123287672, 0.9082612872238233, 0.8351045594789167, 0.734006734006734, 0.8156424581005587, 0.7580246913580246, 0.8334324806662701, 0.8145869947275922, 0.7853107344632768, 0.766499582289056, 0.8273092369477911, 0.910803537101115, 0.866822429906542, 0.8396407953816549, 0.9220977596741344, 0.8715102589976454]
 precisions [0.8565891472868217, 0.7485029940119761, 0.8731730315888732, 0.727895392278954, 0.9020172910662824, 0.8344189235515941, 0.7609427609427609, 0.8491620111731844, 0.725925925925926, 0.8488994646044021, 0.8413884007029877, 0.7570621468926554, 0.7481203007518797, 0.7871485943775101, 0.9058054594386774, 0.8785046728971962, 0.8531109685695959, 0.9210794297352343, 0.8523377060208543]
 recalls [0.810077519379845, 0.780439121756487, 0.8708156529938709, 0.7403486924034869, 0.9063400576368876, 0.8152211175865616, 0.7441077441077442, 0.8100558659217877, 0.7061728395061728, 0.8221296847114813, 0.8268892794376098, 0.847457627118644, 0.7568922305764411, 0.8072289156626506, 0.9054209919261822, 0.8948598130841121, 0.8409236690186017, 0.9317718940936863, 0.8610830810628994]
 f1scores [0.8534963858502964, 0.6986725173124937, 0.8513713643758305, 0.7164986637181274, 0.8990107851033884, 0.8203156101024278, 0.7228702212801228, 0.817212950388994, 0.7361692065160274, 0.834264188232764, 0.8250798868287671, 0.814299853773538, 0.7528387153588654, 0.7591279485091367, 0.9095410855641642, 0.8808492786527105, 0.8231437325329388, 0.9246419285050271, 0.8558037925822581]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.717 Precision 0.717 Recall 0.717 F1 0.702 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.753 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.886 
=> Acc: 0.752 Precision 0.752 Recall 0.752 F1 0.726 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.880 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.832 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.817 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.856 
=> Acc: 0.701 Precision 0.701 Recall 0.701 F1 0.690 
=> Acc: 0.750 Precision 0.750 Recall 0.750 F1 0.716 
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.781 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.762 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.706 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.801 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.877 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.837 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.850 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.918 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.870 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.907 


accs [0.7170542635658915, 0.7744510978043913, 0.8844884488448845, 0.7515566625155666, 0.8895292987512008, 0.8361330133699005, 0.835016835016835, 0.8631284916201117, 0.7012345679012346, 0.7501487209994051, 0.7873462214411248, 0.7740112994350282, 0.7255639097744361, 0.8232931726907631, 0.8835063437139562, 0.8504672897196262, 0.8595253367543297, 0.9175152749490835, 0.8694920955264043, 0.9094626168224299]
 precisions [0.7364341085271318, 0.8183632734530938, 0.8811881188118812, 0.7440846824408468, 0.8818443804034583, 0.8419609187521426, 0.8451178451178452, 0.840782122905028, 0.6666666666666666, 0.7513384889946461, 0.7776801405975395, 0.7740112994350282, 0.7410192147034252, 0.8112449799196787, 0.8965782391387928, 0.8364485981308412, 0.8492623476587556, 0.9134419551934827, 0.8634376051126808, 0.8901869158878505]
 recalls [0.7248062015503876, 0.7664670658682635, 0.8958038661008958, 0.7515566625155666, 0.8832853025936599, 0.8474460061707233, 0.8249158249158249, 0.8743016759776536, 0.6888888888888889, 0.7144556811421773, 0.7930579964850615, 0.8022598870056498, 0.7234753550543024, 0.8393574297188755, 0.8715878508266052, 0.8434579439252337, 0.8563181526619628, 0.9144602851323829, 0.8718466195761857, 0.9117990654205608]
 f1scores [0.7224488074799812, 0.7907542437429887, 0.8762701167387033, 0.7312023607932644, 0.8738602762512666, 0.8306663966253105, 0.8168123968792503, 0.8528747189839878, 0.7105967526292836, 0.6940088882875162, 0.7702294309780499, 0.8041687598928977, 0.7225581218963136, 0.8273118686764741, 0.8752832953461203, 0.8555613588690608, 0.8314842939397185, 0.9150303011960762, 0.8582025777615163, 0.9250960121881778]
done w/ time
All done
