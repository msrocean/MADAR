Current date and time 
##### START task 10000 aws #####
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.9918578830495929]
 precisions [0.993338267949667]
 recalls [0.993338267949667]
 f1scores [0.9897676797676798]
task 2 =>> taskLabels [5, 6, 7, 8, 9]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 


accs [0.9955156950672646]
 precisions [0.9932735426008968]
 recalls [0.9977578475336323]
 f1scores [0.9976044468352161]
task 2 =>> taskLabels [5, 6, 7, 8, 9]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.99848828420257]
 precisions [1.0]
 recalls [0.9977324263038548]
 f1scores [1.0]
task 2 =>> taskLabels [5, 6, 7, 8, 9]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 


accs [0.9550084889643463]
 precisions [0.9579796264855688]
 recalls [0.9571307300509337]
 f1scores [0.9590667242272112]
task 2 =>> taskLabels [5, 6, 7, 8, 9]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 


accs [0.9928263988522238]
 precisions [0.9903156384505022]
 recalls [0.992467718794835]
 f1scores [0.992887619503127]
task 2 =>> taskLabels [5, 6, 7, 8, 9]
done w/ time
All done
