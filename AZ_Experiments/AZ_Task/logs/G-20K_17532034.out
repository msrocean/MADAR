Current date and time 
##### START task 10000 grs #####
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [1.0]
 recalls [1.0]
 f1scores [0.9969924812030075]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.986 


accs [0.9990147783251232, 0.9870362092087618]
 precisions [0.9970443349753695, 0.9830129637907913]
 recalls [0.9960591133004926, 0.9892713455520786]
 f1scores [0.999026740943777, 0.9833216282284832]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.9802955665024631, 0.9624497094322754, 0.9981447124304267]
 precisions [0.9733990147783251, 0.9615556548949485, 0.9958256029684601]
 recalls [0.9753694581280788, 0.957532409476978, 0.9939703153988868]
 f1scores [0.9825174316777371, 0.9505766439054236, 0.9938917202751023]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.951 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.943 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9527093596059113, 0.9472507822977202, 0.9981447124304267, 1.0]
 precisions [0.9625615763546798, 0.9369691551184622, 0.9990723562152134, 1.0]
 recalls [0.954679802955665, 0.9356280733124721, 0.9990723562152134, 1.0]
 f1scores [0.9639544519503763, 0.9360499294757538, 0.9962560453254727, 1.0]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.977 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.921 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.979 


accs [0.9763546798029556, 0.9275815824765311, 0.987012987012987, 0.9911634756995582, 0.9787810383747179]
 precisions [0.9822660098522168, 0.9226642825212338, 0.9902597402597403, 0.9926362297496318, 0.981038374717833]
 recalls [0.9783251231527094, 0.9137237371479661, 0.9879406307977736, 0.9926362297496318, 0.98058690744921]
 f1scores [0.9810899233240462, 0.9168896658083142, 0.9855991026592041, 0.9970721044287998, 0.98396942740186]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.707 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.918 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.954 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.7527093596059113, 0.9231113097898972, 0.9962894248608535, 1.0, 0.9544018058690745, 1.0]
 precisions [0.7477832512315271, 0.9190880643719267, 0.9948979591836735, 1.0, 0.9525959367945824, 0.9931506849315068]
 recalls [0.7477832512315271, 0.9248994188645507, 0.9972170686456401, 1.0, 0.9503386004514672, 0.9954337899543378]
 f1scores [0.7071983774086394, 0.9152124709247605, 0.994475648895507, 0.9985159020276283, 0.9466443710368176, 0.9913692318453616]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.694 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.883 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.993 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.964 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 


accs [0.7467980295566502, 0.8922664282521234, 0.9935064935064936, 0.9911634756995582, 0.963431151241535, 0.9817351598173516, 0.9803006739243131]
 precisions [0.7517241379310344, 0.9092534644613322, 0.9865491651205937, 0.9941089837997055, 0.9652370203160271, 0.9726027397260274, 0.9761534473820632]
 recalls [0.7458128078817734, 0.9088064371926687, 0.9851576994434137, 0.9882179675994109, 0.9656884875846501, 0.9794520547945206, 0.9673405909797823]
 f1scores [0.693301603488413, 0.895589749554407, 0.9874782474177648, 0.9910632434432044, 0.9619346337674461, 0.9889554427114021, 0.9743307271766503]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.921 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.896 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.986 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.930 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.983 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.963 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 


accs [0.9251231527093596, 0.9092534644613322, 0.9879406307977736, 0.9867452135493373, 0.9282167042889391, 0.9840182648401826, 0.9637117677553136, 0.9692631578947368]
 precisions [0.9123152709359605, 0.8994188645507376, 0.9888682745825603, 0.9955817378497791, 0.9367945823927766, 0.9863013698630136, 0.968895800933126, 0.9692631578947368]
 recalls [0.9133004926108375, 0.8842199374161824, 0.987012987012987, 0.9926362297496318, 0.9345372460496614, 0.9863013698630136, 0.966822187662001, 0.9629473684210527]
 f1scores [0.8925540153867553, 0.8743581440434965, 0.9909641537325872, 0.9970235312904323, 0.9413693659338757, 0.9811432594914116, 0.9561459179726362, 0.9623227545045399]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.884 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.892 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.986 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.957 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 


accs [0.8857142857142857, 0.9025480554313813, 0.9823747680890538, 0.9646539027982327, 0.9404063205417608, 0.9863013698630136, 0.9502332814930016, 0.9574736842105264, 0.9592096876991715]
 precisions [0.8926108374384236, 0.9043361645060348, 0.9846938775510204, 0.946980854197349, 0.9363431151241535, 0.9908675799086758, 0.9559357179885951, 0.9612631578947368, 0.9649458253664754]
 recalls [0.8985221674876848, 0.9038891372373715, 0.9828385899814471, 0.9808541973490427, 0.9322799097065463, 0.9794520547945206, 0.9548989113530326, 0.9562105263157895, 0.9668578712555768]
 f1scores [0.9042273070844498, 0.8853379495216227, 0.9872316075854309, 0.9511188366054657, 0.9334086774529979, 0.9859577542606995, 0.9530602507154231, 0.9615674795666006, 0.9566026893306401]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.944 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.903 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.992 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.938 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.842 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 


accs [0.9458128078817734, 0.9110415735359857, 0.9842300556586271, 0.9926362297496318, 0.9399548532731377, 0.860730593607306, 0.9606013478486263, 0.9402105263157895, 0.9592096876991715, 0.9554227941176471]
 precisions [0.9280788177339901, 0.9038891372373715, 0.987012987012987, 0.9837997054491899, 0.9358916478555305, 0.8127853881278538, 0.9595645412130638, 0.9414736842105264, 0.9598470363288719, 0.9577205882352942]
 recalls [0.9458128078817734, 0.9141707644166294, 0.9865491651205937, 0.9955817378497791, 0.9300225733634312, 0.8447488584474886, 0.9616381544841887, 0.9381052631578948, 0.9566602931803697, 0.9549632352941176]
 f1scores [0.9310003927422935, 0.8942308228970047, 0.9847417660770714, 0.9868591233517282, 0.939315502785591, 0.8120181999659671, 0.9513682281335797, 0.9412436994639238, 0.9594444994485277, 0.9570117231870116]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.760 Precision 0.760 Recall 0.760 F1 0.699 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.900 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.975 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.939 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.972 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.882 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.950 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.914 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.903 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.904 


accs [0.7596059113300493, 0.9101475189986589, 0.9819109461966605, 0.9764359351988218, 0.9376975169300226, 0.9726027397260274, 0.8859512700881286, 0.9494736842105264, 0.9145952836201402, 0.9076286764705882, 0.9065300896286812]
 precisions [0.7477832512315271, 0.8927134555207867, 0.9842300556586271, 0.9499263622974963, 0.9363431151241535, 0.9863013698630136, 0.8761016070502852, 0.9423157894736842, 0.89993626513703, 0.8952205882352942, 0.9257362355953905]
 recalls [0.741871921182266, 0.9012069736253912, 0.9823747680890538, 0.9617083946980854, 0.9413092550790068, 0.9771689497716894, 0.8771384136858476, 0.9473684210526315, 0.9094964945825367, 0.9140625, 0.9270166453265045]
 f1scores [0.6964672870135613, 0.8931609427284716, 0.9879231147990717, 0.9644508557911337, 0.9446640947777345, 0.9907853733066128, 0.8761436064646867, 0.9432233195466779, 0.8959301396363941, 0.9030269641324017, 0.9257178981937603]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.952 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.887 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.966 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.925 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.912 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.904 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.926 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.907 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.947 


accs [0.9536945812807882, 0.8967367009387572, 0.9735621521335807, 0.9631811487481591, 0.9367945823927766, 0.9703196347031964, 0.9274235355106273, 0.9136842105263158, 0.9082217973231358, 0.9283088235294118, 0.912932138284251, 0.9474474474474475]
 precisions [0.9625615763546798, 0.9043361645060348, 0.9730983302411874, 0.9484536082474226, 0.9422121896162529, 0.9817351598173516, 0.9279419388284085, 0.9153684210526316, 0.8986615678776291, 0.9250919117647058, 0.8950064020486556, 0.9421921921921922]
 recalls [0.9477832512315271, 0.9012069736253912, 0.9717068645640075, 0.9631811487481591, 0.9431151241534989, 0.9817351598173516, 0.9263867288750648, 0.9098947368421053, 0.9005736137667304, 0.9287683823529411, 0.9193341869398207, 0.9459459459459459]
 f1scores [0.9444125144997321, 0.8962956359425925, 0.9680111839212102, 0.9398484247077168, 0.9480225908702418, 0.9681197969523844, 0.9361280874260516, 0.9043734205188555, 0.9059721582310523, 0.9142578325933235, 0.9223735291391432, 0.9367820239887811]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.952 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.894 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.908 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.771 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.876 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.874 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.886 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.928 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.945 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.946 


accs [0.9527093596059113, 0.9101475189986589, 0.9888682745825603, 0.9837997054491899, 0.9060948081264109, 0.821917808219178, 0.9595645412130638, 0.8736842105263158, 0.8769917144678139, 0.8915441176470589, 0.9282970550576184, 0.9474474474474475, 0.946776611694153]
 precisions [0.961576354679803, 0.8962896736700938, 0.9846938775510204, 0.9779086892488954, 0.8997742663656885, 0.8264840182648402, 0.9663037843442198, 0.8791578947368421, 0.8655194391332058, 0.8874080882352942, 0.9052496798975672, 0.9504504504504504, 0.952023988005997]
 recalls [0.9684729064039409, 0.9110415735359857, 0.9865491651205937, 0.9808541973490427, 0.8961625282167043, 0.819634703196347, 0.9580093312597201, 0.8665263157894737, 0.8616953473550032, 0.8901654411764706, 0.9218950064020487, 0.948948948948949, 0.9640179910044977]
 f1scores [0.9476233826777115, 0.8832498685778429, 0.983999593762728, 0.9861494124938561, 0.9025584614262991, 0.8053644941782803, 0.9564225448359835, 0.868672150238325, 0.8655776471361787, 0.8948419962918471, 0.9261922964529632, 0.9647699952023275, 0.9522075116259676]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.897 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.970 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.973 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.869 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.832 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.969 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.875 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.877 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.844 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.915 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.939 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.931 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.985 


accs [0.9635467980295567, 0.9056772463120251, 0.9693877551020408, 0.9720176730486009, 0.8668171557562077, 0.8424657534246576, 0.9683773976153447, 0.8741052631578947, 0.8763543658381134, 0.8543198529411765, 0.9180537772087067, 0.9436936936936937, 0.9287856071964018, 0.9880597014925373]
 precisions [0.9586206896551724, 0.9038891372373715, 0.9772727272727273, 0.9631811487481591, 0.8749435665914221, 0.8287671232876712, 0.9652669777086573, 0.8677894736842106, 0.8718929254302104, 0.8478860294117647, 0.9154929577464789, 0.9414414414414415, 0.9310344827586207, 0.9970149253731343]
 recalls [0.967487684729064, 0.899865891819401, 0.9726345083487941, 0.9705449189985272, 0.8821670428893905, 0.817351598173516, 0.9704510108864697, 0.8505263157894737, 0.8553218610579987, 0.8556985294117647, 0.9308578745198464, 0.9512012012012012, 0.9295352323838081, 0.9880597014925373]
 f1scores [0.9641419962507095, 0.8881387528216538, 0.9740442930567077, 0.978898485919531, 0.8775143463531586, 0.7934439885609856, 0.9718668819251732, 0.8693510860469569, 0.8843734363587636, 0.8584052668879254, 0.9149367624229224, 0.9524193560729014, 0.9452884507900812, 0.9972789115646259]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.926 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.892 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.940 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.947 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.934 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.772 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.911 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.885 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.904 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.838 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.885 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.942 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.883 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.968 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.850 


accs [0.9310344827586207, 0.9043361645060348, 0.9420222634508348, 0.946980854197349, 0.9336343115124154, 0.7922374429223744, 0.9139450492483152, 0.8896842105263157, 0.9050350541746335, 0.8455882352941176, 0.8860435339308579, 0.9429429429429429, 0.8830584707646177, 0.9701492537313433, 0.855929323819232]
 precisions [0.929064039408867, 0.9061242735806885, 0.9406307977736549, 0.9425625920471281, 0.9331828442437923, 0.8013698630136986, 0.9217210990150337, 0.8846315789473684, 0.9037603569152326, 0.8506433823529411, 0.8886043533930857, 0.9211711711711712, 0.8665667166416792, 0.9791044776119403, 0.8525314305130819]
 recalls [0.9231527093596059, 0.8971837282074206, 0.9397031539888683, 0.9587628865979382, 0.9354401805869075, 0.7899543378995434, 0.909279419388284, 0.8821052631578947, 0.9069471000637349, 0.8570772058823529, 0.910371318822023, 0.9414414414414415, 0.8935532233883059, 0.9611940298507463, 0.853550798504927]
 f1scores [0.9304336733734427, 0.8863348402583764, 0.9395706158842512, 0.9571661962332147, 0.940637717854478, 0.7810007574475359, 0.9033140128881808, 0.8753724909105971, 0.9060028839598602, 0.8424827234541628, 0.9140721616319093, 0.9348155223424179, 0.8810664579402175, 0.9680548012924929, 0.8424080132596725]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.947 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.875 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.928 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.920 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.903 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.952 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.857 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.752 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.843 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.876 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.868 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.897 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.989 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.776 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.910 


accs [0.9477832512315271, 0.8895842646401431, 0.9281076066790352, 0.9234167893961709, 0.9020316027088036, 0.952054794520548, 0.9398652151373769, 0.8568421052631578, 0.7616316124920331, 0.8543198529411765, 0.8796414852752881, 0.8753753753753754, 0.8988005997001499, 0.9880597014925373, 0.7835541963982331, 0.919526627218935]
 precisions [0.9428571428571428, 0.894054537326777, 0.9308905380333952, 0.9278350515463918, 0.8957110609480813, 0.958904109589041, 0.9486780715396579, 0.8593684210526316, 0.7737412364563416, 0.8653492647058824, 0.8988476312419974, 0.8776276276276276, 0.9205397301349325, 0.9850746268656716, 0.7913693510023785, 0.9189349112426035]
 recalls [0.9586206896551724, 0.8936075100581136, 0.9225417439703154, 0.8954344624447718, 0.9029345372460497, 0.9703196347031964, 0.9460860549507517, 0.8568421052631578, 0.794136392606756, 0.8607536764705882, 0.8783610755441741, 0.8911411411411412, 0.9160419790104948, 0.9970149253731343, 0.7954468229697588, 0.9189349112426035]
 f1scores [0.956519440102055, 0.8661491754688472, 0.9290088587282938, 0.9080288650776295, 0.8979987492522096, 0.9629014261700808, 0.9432757726271825, 0.8477589669445145, 0.7800215603583047, 0.8511692969259759, 0.8571131928859653, 0.8708819935250205, 0.9118775730068824, 0.9796222674498306, 0.7758405339123129, 0.9127977657038728]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.918 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.842 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.970 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.810 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.746 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.929 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.824 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.824 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.821 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.854 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.870 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.912 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.983 
=> Acc: 0.681 Precision 0.681 Recall 0.681 F1 0.668 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.875 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.872 


accs [0.9172413793103448, 0.867679928475637, 0.9475881261595547, 0.9690721649484536, 0.8117381489841986, 0.773972602739726, 0.9284603421461898, 0.8374736842105264, 0.8317399617590823, 0.8322610294117647, 0.8604353393085787, 0.8746246246246246, 0.9145427286356822, 0.982089552238806, 0.6812776078831124, 0.8840236686390532, 0.8740157480314961]
 precisions [0.9310344827586207, 0.8927134555207867, 0.9424860853432282, 0.96759941089838, 0.8112866817155756, 0.8082191780821918, 0.9320891653706583, 0.8463157894736842, 0.8183556405353728, 0.8336397058823529, 0.8745198463508322, 0.8843843843843844, 0.9167916041979011, 0.991044776119403, 0.6785592932381923, 0.9094674556213018, 0.8732658417697787]
 recalls [0.9241379310344827, 0.8864550737594993, 0.9387755102040817, 0.9661266568483063, 0.8045146726862302, 0.8287671232876712, 0.9284603421461898, 0.8341052631578947, 0.8221797323135756, 0.8432904411764706, 0.8514724711907811, 0.8678678678678678, 0.9220389805097451, 0.9791044776119403, 0.6809378185524975, 0.9011834319526627, 0.8623922009748781]
 f1scores [0.9156769743114838, 0.8668891275445365, 0.9328673218817707, 0.9555994185161311, 0.8044189555341076, 0.7535923295674768, 0.9325125949612865, 0.8162621097177187, 0.8315930329435929, 0.84033142082196, 0.8473902317341067, 0.876084438696018, 0.9052689637112936, 0.9971392081736911, 0.6754593912302537, 0.8768417835735262, 0.8688502424217124]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.885 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.921 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.949 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.864 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.939 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.922 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.871 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.825 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.909 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.889 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.911 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.924 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.979 
=> Acc: 0.778 Precision 0.778 Recall 0.778 F1 0.761 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.886 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.851 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.952 


accs [0.9517241379310345, 0.9012069736253912, 0.9216141001855288, 0.9484536082474226, 0.8654627539503386, 0.9406392694063926, 0.9206842923794712, 0.8745263157894737, 0.8247291268323773, 0.9145220588235294, 0.8924455825864277, 0.9144144144144144, 0.9257871064467766, 0.9791044776119403, 0.7781175671083927, 0.8946745562130177, 0.8511436070491188, 0.9522058823529411]
 precisions [0.9458128078817734, 0.9029950827000447, 0.9128014842300557, 0.9602356406480118, 0.8613995485327314, 0.954337899543379, 0.9061689994815967, 0.863578947368421, 0.8304652644996813, 0.9053308823529411, 0.8937259923175416, 0.9151651651651652, 0.9062968515742129, 0.9611940298507463, 0.763846415222562, 0.9053254437869822, 0.8507686539182602, 0.9558823529411765]
 recalls [0.9576354679802955, 0.8953956191327671, 0.9216141001855288, 0.9484536082474226, 0.8604966139954854, 0.9611872146118722, 0.9170554691550026, 0.8698947368421053, 0.8266411727214786, 0.9113051470588235, 0.882202304737516, 0.8986486486486487, 0.9205397301349325, 0.9641791044776119, 0.7628270472307169, 0.9011834319526627, 0.8661417322834646, 0.9375]
 f1scores [0.9464049556392193, 0.8853500275230886, 0.9042561038688529, 0.9514993656802467, 0.8626636586795131, 0.9471415876106726, 0.922143323726752, 0.8489804908711511, 0.8252933234327587, 0.9021122195983071, 0.9061845374655224, 0.9115503745444619, 0.9119390409331185, 0.9822130037738024, 0.7550352676486567, 0.8850514282466634, 0.8558644668497866, 0.9641633118492079]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.924 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.853 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.911 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.884 
=> Acc: 0.797 Precision 0.797 Recall 0.797 F1 0.797 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.739 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.887 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.730 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.741 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.852 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.863 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.909 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.890 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.989 
=> Acc: 0.698 Precision 0.698 Recall 0.698 F1 0.686 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.902 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.881 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.874 


accs [0.9251231527093596, 0.8748323647742512, 0.9151205936920223, 0.8762886597938144, 0.7968397291196389, 0.771689497716895, 0.8849144634525661, 0.7545263157894737, 0.7622689611217336, 0.8575367647058824, 0.8693982074263764, 0.9114114114114115, 0.8913043478260869, 0.9880597014925373, 0.6975874957526333, 0.9100591715976332, 0.8807649043869517, 0.8823529411764706, 0.8680851063829788]
 precisions [0.9083743842364532, 0.8806437192668752, 0.9160482374768089, 0.8733431516936672, 0.7914221218961626, 0.7625570776255708, 0.880248833592535, 0.768, 0.7635436583811345, 0.8465073529411765, 0.8732394366197183, 0.9114114114114115, 0.8860569715142429, 0.991044776119403, 0.7003058103975535, 0.9071005917159763, 0.8702662167229096, 0.8676470588235294, 0.902127659574468]
 recalls [0.9073891625615763, 0.8712561466249441, 0.9132653061224489, 0.8630338733431517, 0.8076749435665914, 0.771689497716895, 0.8776568170036289, 0.7545263157894737, 0.7463352453792225, 0.8690257352941176, 0.8770806658130602, 0.8986486486486487, 0.8823088455772113, 0.9880597014925373, 0.7064220183486238, 0.8792899408284024, 0.8833895763029621, 0.8566176470588235, 0.8936170212765957]
 f1scores [0.904021479760751, 0.8374944771598264, 0.9122377468739817, 0.8772530196763064, 0.8071504787443275, 0.751329820516005, 0.8823258935482159, 0.7186914461675874, 0.7487871962418351, 0.8539315606796141, 0.8746085461279298, 0.896635530354474, 0.9028993769126382, 1.0, 0.6865031126431482, 0.8768511698271972, 0.8898379014610303, 0.8860044285095448, 0.8993893765395692]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.950 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.876 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.918 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.832 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.795 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.798 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.813 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.893 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.918 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.887 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.980 
=> Acc: 0.712 Precision 0.712 Recall 0.712 F1 0.692 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.906 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.873 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.864 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.788 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.899 


accs [0.9507389162561576, 0.8895842646401431, 0.9174397031539888, 0.9705449189985272, 0.8279909706546276, 0.9429223744292238, 0.8144116122343183, 0.8134736842105263, 0.8119821542383684, 0.9443933823529411, 0.8962868117797695, 0.9204204204204204, 0.8853073463268366, 0.982089552238806, 0.7121984369690791, 0.9112426035502958, 0.8728908886389202, 0.8639705882352942, 0.8170212765957446, 0.9226519337016574]
 precisions [0.9655172413793104, 0.8712561466249441, 0.9359925788497218, 0.9572901325478645, 0.8316027088036118, 0.9246575342465754, 0.8320373250388803, 0.8058947368421052, 0.8177182919056724, 0.9434742647058824, 0.8988476312419974, 0.9309309309309309, 0.8883058470764618, 0.982089552238806, 0.7060822290180089, 0.9005917159763314, 0.8680164979377578, 0.8676470588235294, 0.8425531914893617, 0.8950276243093923]
 recalls [0.9665024630541872, 0.8855610192221726, 0.9271799628942486, 0.9513991163475699, 0.8401805869074492, 0.9246575342465754, 0.8201140487299119, 0.8143157894736842, 0.8406628425748884, 0.9434742647058824, 0.9014084507042254, 0.9181681681681682, 0.8958020989505248, 0.9850746268656716, 0.72646958885491, 0.8970414201183432, 0.8597675290588677, 0.8529411764705882, 0.8468085106382979, 0.9337016574585635]
 f1scores [0.9566614720027464, 0.8777366225100065, 0.9229818125855085, 0.9565606993876543, 0.8338002587805272, 0.951927928402492, 0.8052140538511006, 0.7936757128475411, 0.8256465355880115, 0.9458244031464617, 0.8844669353662352, 0.918037938345676, 0.8974872824655076, 0.9754654159693011, 0.6894744684461453, 0.904297676321163, 0.872255112134324, 0.8293023099474712, 0.8029368281126799, 0.929899033550719]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [1.0]
 recalls [1.0]
 f1scores [1.0]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9989583333333333, 1.0]
 precisions [0.996875, 1.0]
 recalls [0.9979166666666667, 0.9969183359013868]
 f1scores [0.9989322306325189, 1.0]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.968 


accs [0.9916666666666667, 0.9984591679506933, 0.969225449515906]
 precisions [0.9875, 0.9984591679506933, 0.9681881051175657]
 recalls [0.9895833333333334, 0.9953775038520801, 0.9761410788381742]
 f1scores [0.9876269028412598, 0.996861240572753, 0.9620166822916184]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.966 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.9770833333333333, 0.9922958397534669, 0.9671507607192255, 0.9918330308529946]
 precisions [0.975, 0.987673343605547, 0.9654218533886584, 0.9931941923774955]
 recalls [0.9822916666666667, 0.9922958397534669, 0.9688796680497925, 0.9945553539019963]
 f1scores [0.9759947248322364, 0.9935479674796749, 0.9648281773931462, 0.9920578973998101]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.895 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.970 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.8875, 0.9691833590138675, 0.9754495159059474, 0.9646098003629764, 0.9919354838709677]
 precisions [0.903125, 0.9799691833590138, 0.9744121715076072, 0.9696007259528131, 0.9959677419354839]
 recalls [0.9135416666666667, 0.9815100154083205, 0.9706085753803596, 0.9646098003629764, 0.9879032258064516]
 f1scores [0.908770932625718, 0.9787230358002919, 0.975146331534418, 0.9765110299280796, 0.9752340425531916]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.873 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.976 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.760 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.870 


accs [0.8729166666666667, 0.975346687211094, 0.9664591977869986, 0.7931034482758621, 0.9798387096774194, 0.8726953467954346]
 precisions [0.8635416666666667, 0.9784283513097073, 0.9699170124481328, 0.7881125226860254, 0.9879032258064516, 0.9012291483757682]
 recalls [0.878125, 0.9799691833590138, 0.9681881051175657, 0.779491833030853, 0.9838709677419355, 0.8959613696224759]
 f1scores [0.8708141441638639, 0.9772815772368059, 0.9686029001373104, 0.7610942994126095, 0.96301422715798, 0.8836091370403143]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.855 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.773 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.870 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.908 


accs [0.8572916666666667, 0.9738058551617874, 0.9674965421853389, 0.7958257713248639, 0.9798387096774194, 0.874451273046532, 0.9107215654300856]
 precisions [0.8385416666666666, 0.9722650231124808, 0.9688796680497925, 0.8171506352087115, 0.9919354838709677, 0.8691834942932397, 0.9188748471259682]
 recalls [0.8552083333333333, 0.9799691833590138, 0.9664591977869986, 0.8185117967332124, 0.9838709677419355, 0.8788410886742757, 0.9078679168365267]
 f1scores [0.8549877408926866, 0.9782784102482855, 0.9682786628204463, 0.77290712643192, 0.9756880316608288, 0.8718675773929163, 0.9037731332226627]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.844 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.972 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.953 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.807 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.878 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.896 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 


accs [0.8458333333333333, 0.975346687211094, 0.9540110650069157, 0.8339382940108893, 0.9758064516129032, 0.8819139596136962, 0.9017529555646148, 0.9880287310454908]
 precisions [0.8645833333333334, 0.9722650231124808, 0.9505532503457814, 0.8144283121597096, 0.9596774193548387, 0.892449517120281, 0.8846310640032613, 0.9904229848363927]
 recalls [0.8833333333333333, 0.9707241910631741, 0.9491701244813278, 0.8284936479128857, 0.9798387096774194, 0.8902546093064091, 0.8972686506318793, 0.990023942537909]
 f1scores [0.8582271860093769, 0.9616031632991247, 0.9489155542826582, 0.8035719186351867, 0.9759738912850814, 0.8810257398899951, 0.88522906888535, 0.9856265558344657]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.841 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.887 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.955 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.913 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.815 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.899 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.881 


accs [0.8604166666666667, 0.8936825885978429, 0.9560857538035962, 0.9659709618874773, 0.9153225806451613, 0.8274802458296752, 0.9017529555646148, 0.961292897047087, 0.8888888888888888]
 precisions [0.8760416666666667, 0.8875192604006163, 0.9457123098201936, 0.9582577132486388, 0.9395161290322581, 0.8353819139596137, 0.8980839788014676, 0.9640861931364725, 0.8858024691358025]
 recalls [0.875, 0.8859784283513097, 0.9571230982019364, 0.9718693284936479, 0.9314516129032258, 0.8327480245829675, 0.9013452914798207, 0.9553072625698324, 0.8966049382716049]
 f1scores [0.8335556428556241, 0.8930765530007434, 0.944725926469839, 0.9684616892563842, 0.9191368855234401, 0.8180825013302325, 0.8981464056710007, 0.9630490220296315, 0.8876029451430348]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.826 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.879 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.953 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.699 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.839 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.832 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.907 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.979 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.823 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.922 


accs [0.8385416666666666, 0.884437596302003, 0.9543568464730291, 0.7259528130671506, 0.8467741935483871, 0.839332748024583, 0.9082755809213209, 0.9792498004788508, 0.8341049382716049, 0.9220462850182704]
 precisions [0.8322916666666667, 0.8782742681047766, 0.9564315352697096, 0.7046279491833031, 0.842741935483871, 0.8323090430201932, 0.9196901752955564, 0.9816440542697525, 0.8464506172839507, 0.9488428745432399]
 recalls [0.815625, 0.9029275808936826, 0.9619640387275242, 0.7268602540834845, 0.8467741935483871, 0.8274802458296752, 0.9123522217692621, 0.9800478850758181, 0.8472222222222222, 0.9500609013398295]
 f1scores [0.818299858264343, 0.8538638012365081, 0.9513022608496182, 0.6983607135340221, 0.812841218534809, 0.8196610088668368, 0.9145051886593573, 0.978337327958636, 0.8155555162351906, 0.9364687570391]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.894 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.912 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.881 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.798 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.816 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.835 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.874 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.847 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 


accs [0.8979166666666667, 0.9060092449922958, 0.8886583679114799, 0.8189655172413793, 0.8346774193548387, 0.840649692712906, 0.9368120668569099, 0.9732641660015962, 0.8850308641975309, 0.8574908647990256, 0.9517184942716858]
 precisions [0.9052083333333333, 0.926040061633282, 0.8858921161825726, 0.8058076225045372, 0.842741935483871, 0.8204565408252853, 0.9351814105177334, 0.970071827613727, 0.8919753086419753, 0.8587088915956151, 0.955810147299509]
 recalls [0.8895833333333333, 0.9306625577812019, 0.8962655601659751, 0.808076225045372, 0.8266129032258065, 0.8187006145741879, 0.933958418263351, 0.9672785315243416, 0.878858024691358, 0.8623629719853837, 0.9607201309328969]
 f1scores [0.8906645057704949, 0.9174494054796044, 0.8855532282230362, 0.8114970939196919, 0.849728569844965, 0.8098251845603549, 0.9395741401647877, 0.9703476635429042, 0.861755221420168, 0.8381869557866084, 0.9424045267633858]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.834 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.830 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.716 Precision 0.716 Recall 0.716 F1 0.687 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.805 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.806 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.925 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.862 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.892 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.843 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 


accs [0.840625, 0.8459167950693375, 0.9374135546334716, 0.7159709618874773, 0.8024193548387096, 0.8165057067603161, 0.9274357929066449, 0.966879489225858, 0.8703703703703703, 0.8940316686967114, 0.8445171849427169, 0.9652777777777778]
 precisions [0.8854166666666666, 0.8212634822804314, 0.9377593360995851, 0.7209618874773139, 0.8467741935483871, 0.7827041264266901, 0.9392580513656746, 0.966879489225858, 0.8634259259259259, 0.8635809987819733, 0.8404255319148937, 0.9694444444444444]
 recalls [0.8822916666666667, 0.810477657935285, 0.9387966804979253, 0.7254990925589837, 0.8064516129032258, 0.8024582967515365, 0.9286587851610273, 0.965682362330407, 0.8858024691358025, 0.8696711327649208, 0.8420621931260229, 0.9625]
 f1scores [0.8442356778520363, 0.7872493815605675, 0.9384270704070292, 0.686389860306246, 0.7469585869532848, 0.7969508286477632, 0.9378875726409234, 0.964280453233193, 0.8724908203654523, 0.8595148677623007, 0.8629075402299579, 0.9744241741604375]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.942 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.848 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.909 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.805 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.854 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.755 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.937 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.877 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.874 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.895 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.972 


accs [0.9427083333333334, 0.8505392912172574, 0.9100968188105117, 0.8130671506352087, 0.8629032258064516, 0.7655838454784899, 0.9380350591112923, 0.9648842777334398, 0.8873456790123457, 0.879415347137637, 0.8952536824877251, 0.9333333333333333, 0.971830985915493]
 precisions [0.9364583333333333, 0.8459167950693375, 0.9163208852005532, 0.8212341197822142, 0.8145161290322581, 0.7611940298507462, 0.9335507541785568, 0.9736632083000798, 0.9050925925925926, 0.8928136419001218, 0.9034369885433715, 0.9583333333333334, 0.9873239436619718]
 recalls [0.953125, 0.8952234206471494, 0.9159751037344398, 0.823502722323049, 0.8225806451612904, 0.7712906057945567, 0.9258051365674684, 0.9708699122106943, 0.8919753086419753, 0.8891595615103532, 0.8927986906710311, 0.9569444444444445, 0.9633802816901409]
 f1scores [0.9435631744250511, 0.8515349903753364, 0.92417676908803, 0.8255816077799285, 0.8139399897374933, 0.7600229310415585, 0.9292369848898906, 0.9664143309851468, 0.9003484362885696, 0.9069528404542215, 0.8826003898635477, 0.9485703475585077, 0.9730436093251044]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.905 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.860 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.719 Precision 0.719 Recall 0.719 F1 0.687 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.766 
=> Acc: 0.781 Precision 0.781 Recall 0.781 F1 0.768 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.926 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.962 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.900 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.868 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.894 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.924 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.962 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.955 


accs [0.9052083333333333, 0.8613251155624037, 0.931881051175657, 0.7186932849364791, 0.7741935483870968, 0.7805092186128183, 0.9278434569914391, 0.9628890662410216, 0.9074074074074074, 0.8745432399512789, 0.8936170212765957, 0.9222222222222223, 0.9605633802816902, 0.9539316918189039]
 precisions [0.9114583333333334, 0.8443759630200308, 0.9270401106500692, 0.691016333938294, 0.7540322580645161, 0.7967515364354697, 0.9359967386873217, 0.9648842777334398, 0.9066358024691358, 0.8903775883069428, 0.8797054009819967, 0.9291666666666667, 0.9422535211267605, 0.9571088165210484]
 recalls [0.896875, 0.8412942989214176, 0.9270401106500692, 0.7114337568058077, 0.7741935483870968, 0.8002633889376646, 0.9286587851610273, 0.9720670391061452, 0.9104938271604939, 0.8428745432399513, 0.8780687397708674, 0.9097222222222222, 0.9591549295774648, 0.9571088165210484]
 f1scores [0.9085850429700262, 0.8308177234551068, 0.9195243350327879, 0.6565539943457745, 0.7672292697882916, 0.7690477459612213, 0.9247793577587476, 0.9633486155078218, 0.8988352414263104, 0.8360263030217336, 0.8768475784649207, 0.9162329228680657, 0.9582525308341008, 0.9605661569943168]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.908 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.807 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.916 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.810 
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.770 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.768 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.894 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.866 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.892 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.834 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.961 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.899 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 


accs [0.9072916666666667, 0.8197226502311248, 0.9166666666666666, 0.822141560798548, 0.7983870967741935, 0.7822651448639157, 0.9001222992254383, 0.9521149241819633, 0.8757716049382716, 0.8940316686967114, 0.881342062193126, 0.8361111111111111, 0.9619718309859155, 0.8983320095313742, 0.9673154608887257]
 precisions [0.8864583333333333, 0.8412942989214176, 0.9024896265560166, 0.8212341197822142, 0.7903225806451613, 0.7642669007901668, 0.8968609865470852, 0.9437350359138069, 0.8981481481481481, 0.8976857490864799, 0.8739770867430442, 0.8375, 0.967605633802817, 0.8792692613185068, 0.9669482188762395]
 recalls [0.9072916666666667, 0.8289676425269645, 0.9066390041493776, 0.8262250453720508, 0.7943548387096774, 0.7726075504828798, 0.9005299633102324, 0.942537909018356, 0.8858024691358025, 0.8842874543239951, 0.8895253682487725, 0.8430555555555556, 0.9633802816901409, 0.886417791898332, 0.9706206390011017]
 f1scores [0.8924363536136461, 0.7765517830155414, 0.8971292948107571, 0.8110630717514568, 0.7680426563905665, 0.7373450841323244, 0.8852522678216221, 0.9467166391975205, 0.8848215371588839, 0.8905125760143768, 0.8911694427887606, 0.820332789911632, 0.9662388658778523, 0.8867720311162284, 0.9678284889324381]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.917 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.825 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.719 Precision 0.719 Recall 0.719 F1 0.677 
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.795 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.781 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.896 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.851 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.838 
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.776 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.945 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.984 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.927 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 


accs [0.9166666666666666, 0.8443759630200308, 0.9370677731673582, 0.719147005444646, 0.7983870967741935, 0.7954345917471466, 0.8980839788014676, 0.952513966480447, 0.8703703703703703, 0.8514007308160779, 0.779050736497545, 0.9458333333333333, 0.9830985915492958, 0.9269261318506752, 0.9478516342269555, 0.9776536312849162]
 precisions [0.909375, 0.8335901386748844, 0.9353388658367912, 0.7141560798548094, 0.9032258064516129, 0.7963125548726954, 0.9025682837342031, 0.9505187549880287, 0.8626543209876543, 0.8380024360535931, 0.779050736497545, 0.9208333333333333, 0.9746478873239437, 0.9301032565528197, 0.940506793977231, 0.9664804469273743]
 recalls [0.9364583333333333, 0.8335901386748844, 0.941908713692946, 0.7096188747731398, 0.8588709677419355, 0.8064091308165057, 0.9017529555646148, 0.9473264166001596, 0.8858024691358025, 0.8721071863580999, 0.7839607201309329, 0.9361111111111111, 0.9802816901408451, 0.9046862589356632, 0.9412412780022035, 0.9664804469273743]
 f1scores [0.9272609157727987, 0.8114685914376144, 0.9322100739365343, 0.6674852460423665, 0.8710729237414517, 0.7847502406327083, 0.902708208074326, 0.950614972513414, 0.8623586369255399, 0.8099456537827529, 0.7734589154122273, 0.9302668304451188, 0.9820778407890843, 0.9322835113664304, 0.9304537394135173, 0.9761102991793724]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.889 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.811 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.912 
=> Acc: 0.731 Precision 0.731 Recall 0.731 F1 0.701 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.836 
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.772 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.908 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.881 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.896 
=> Acc: 0.660 Precision 0.660 Recall 0.660 F1 0.631 
=> Acc: 0.807 Precision 0.807 Recall 0.807 F1 0.806 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.962 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.882 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.947 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.778 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.922 


accs [0.8895833333333333, 0.827426810477658, 0.9125172890733056, 0.7309437386569873, 0.8508064516129032, 0.7870939420544337, 0.9099062372604974, 0.960095770151636, 0.8881172839506173, 0.8989037758830695, 0.6595744680851063, 0.8069444444444445, 0.9605633802816902, 0.8824463860206513, 0.9485861182519281, 0.8100558659217877, 0.9230769230769231]
 precisions [0.9135416666666667, 0.8366718027734977, 0.9014522821576764, 0.735934664246824, 0.8387096774193549, 0.7761194029850746, 0.8952303302079087, 0.9628890662410216, 0.8981481481481481, 0.8964677222898904, 0.6882160392798691, 0.825, 0.952112676056338, 0.8911834789515488, 0.9471171502019831, 0.7988826815642458, 0.9161882893226176]
 recalls [0.8697916666666666, 0.8197226502311248, 0.9090594744121715, 0.7445553539019963, 0.8387096774193549, 0.792361720807726, 0.9139828781084387, 0.9545091779728652, 0.9158950617283951, 0.8964677222898904, 0.6677577741407529, 0.8402777777777778, 0.9549295774647887, 0.8848292295472597, 0.9504223283143591, 0.8128491620111732, 0.9196326061997704]
 f1scores [0.8755391958610321, 0.812059430736336, 0.9080854578391421, 0.7126771805153137, 0.8595609985719396, 0.7911373989231336, 0.9196617918022316, 0.951560026416962, 0.8922099105666005, 0.8995188963973637, 0.6313536210855101, 0.8179522078029213, 0.9534130380258039, 0.8836013070762359, 0.9494868993769492, 0.7904171466785327, 0.9178475881956603]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.821 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.882 
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.773 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.746 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.757 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.918 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.950 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.892 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.844 
=> Acc: 0.720 Precision 0.720 Recall 0.720 F1 0.657 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.813 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.953 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.921 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.923 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.761 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.866 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 


accs [0.9333333333333333, 0.827426810477658, 0.8852005532503457, 0.7980943738656987, 0.7661290322580645, 0.7625109745390694, 0.9188748471259682, 0.9517158818834797, 0.8981481481481481, 0.853836784409257, 0.7201309328968903, 0.8152777777777778, 0.9535211267605633, 0.9237490071485306, 0.9265515975027543, 0.7821229050279329, 0.870264064293915, 0.9663394109396914]
 precisions [0.9302083333333333, 0.8335901386748844, 0.896957123098202, 0.808983666061706, 0.7298387096774194, 0.7589991220368745, 0.924582144313086, 0.9545091779728652, 0.9266975308641975, 0.8112058465286236, 0.7340425531914894, 0.8138888888888889, 0.9535211267605633, 0.9078633836378078, 0.9254498714652957, 0.8016759776536313, 0.8748564867967853, 0.9696119682094436]
 recalls [0.94375, 0.8305084745762712, 0.8921161825726142, 0.8176043557168784, 0.7983870967741935, 0.753731343283582, 0.924582144313086, 0.9517158818834797, 0.9050925925925926, 0.8282582216808769, 0.7152209492635024, 0.8375, 0.9380281690140845, 0.9158061953931692, 0.9269188395152406, 0.7597765363128491, 0.8587830080367393, 0.9686769518466574]
 f1scores [0.9279845559970751, 0.8312734431520985, 0.8936424826507666, 0.7814354260333041, 0.6819490509309569, 0.7612788144142485, 0.9216143005803973, 0.9575245419150635, 0.9156070184973043, 0.8156843777891947, 0.6462686063260182, 0.8285388161972642, 0.9555887975043869, 0.9113414410288385, 0.9328866511210295, 0.7405742908360057, 0.8859807055354325, 0.9680134392006166]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.930 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.900 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.935 
=> Acc: 0.694 Precision 0.694 Recall 0.694 F1 0.646 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.853 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.813 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.897 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.878 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.872 
=> Acc: 0.660 Precision 0.660 Recall 0.660 F1 0.613 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.756 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.942 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.899 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.826 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.904 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.957 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.947 


accs [0.93125, 0.8998459167950693, 0.9384508990318119, 0.6941923774954628, 0.8588709677419355, 0.8204565408252853, 0.8984916428862617, 0.9740622505985634, 0.8881172839506173, 0.8781973203410475, 0.6595744680851063, 0.7652777777777777, 0.9422535211267605, 0.937251787132645, 0.9041498347410943, 0.8268156424581006, 0.9081515499425947, 0.9574567554932212, 0.95]
 precisions [0.9166666666666666, 0.9106317411402157, 0.9405255878284924, 0.6964609800362976, 0.8548387096774194, 0.8125548726953468, 0.8997146351406441, 0.9740622505985634, 0.8587962962962963, 0.879415347137637, 0.6006546644844517, 0.7444444444444445, 0.9492957746478873, 0.9356632247815727, 0.9166360631656262, 0.8910614525139665, 0.9115958668197475, 0.9471715755025713, 0.9066666666666666]
 recalls [0.925, 0.9152542372881356, 0.9384508990318119, 0.7041742286751361, 0.8266129032258065, 0.8380158033362599, 0.9017529555646148, 0.9688747007182761, 0.8641975308641975, 0.9013398294762485, 0.6432078559738135, 0.7708333333333334, 0.9507042253521126, 0.937251787132645, 0.9063532868160118, 0.8659217877094972, 0.9024110218140069, 0.9513791491351099, 0.94]
 f1scores [0.9247743459367674, 0.8963911346026399, 0.9306244750763615, 0.6376732849162344, 0.8240869858111235, 0.8009743931163162, 0.893324287856695, 0.9672254988237758, 0.8664459159761975, 0.881734699966696, 0.6143600050228868, 0.7630038296884912, 0.9470013287611885, 0.9306771309463719, 0.9019796774263822, 0.8572629085129329, 0.8927197186608169, 0.951316890941446, 0.9085143816825102]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.928 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.828 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.853 
=> Acc: 0.709 Precision 0.709 Recall 0.709 F1 0.686 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.680 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.720 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.890 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.827 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.855 
=> Acc: 0.688 Precision 0.688 Recall 0.688 F1 0.635 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.839 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.942 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.891 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.867 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.905 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.851 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.942 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.837 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.892 


accs [0.928125, 0.8305084745762712, 0.8582295988934993, 0.7087114337568058, 0.7419354838709677, 0.7423178226514486, 0.8911536893599674, 0.9684756584197926, 0.8495370370370371, 0.8647990255785627, 0.6882160392798691, 0.8416666666666667, 0.9422535211267605, 0.8911834789515488, 0.877708409842086, 0.9078212290502793, 0.8530424799081515, 0.9420289855072463, 0.8633333333333333, 0.8943589743589744]
 precisions [0.940625, 0.8197226502311248, 0.8692946058091287, 0.7146098003629764, 0.7016129032258065, 0.7361720807726075, 0.8927843456991439, 0.9712689545091779, 0.8402777777777778, 0.8745432399512789, 0.690671031096563, 0.8583333333333333, 0.9253521126760563, 0.8816521048451151, 0.884318766066838, 0.9078212290502793, 0.8668197474167624, 0.9513791491351099, 0.87, 0.9117948717948718]
 recalls [0.9479166666666666, 0.8320493066255779, 0.8634163208852006, 0.7382032667876588, 0.7540322580645161, 0.7401229148375769, 0.8944150020383205, 0.9728651237031125, 0.8649691358024691, 0.856272838002436, 0.6808510638297872, 0.8361111111111111, 0.9084507042253521, 0.8856235107227959, 0.897172236503856, 0.8938547486033519, 0.8404133180252583, 0.9504441327723235, 0.8833333333333333, 0.8907692307692308]
 f1scores [0.9295416311202824, 0.8238456757870546, 0.8549047235759915, 0.6876018224279102, 0.7121263813298238, 0.730530453177691, 0.896140087349161, 0.9710170228575322, 0.8256517645992629, 0.8727119053188641, 0.6394564635632621, 0.8512930113000101, 0.9294140128184111, 0.8965101523167791, 0.8782542397857128, 0.8961780959455379, 0.8541412820400172, 0.9482171128147184, 0.8044659405002218, 0.8902086943500628]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [1.0]
 recalls [1.0]
 f1scores [0.9968656259565349]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 


accs [1.0, 0.9829855537720706]
 precisions [1.0, 0.9836276083467095]
 recalls [1.0, 0.9861958266452648]
 f1scores [1.0, 0.9848312892013208]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.956 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 


accs [0.9761194029850746, 0.9573033707865168, 0.9824070371851259]
 precisions [0.9850746268656716, 0.9534510433386838, 0.9840063974410236]
 recalls [0.9940298507462687, 0.9560192616372392, 0.9800079968012795]
 f1scores [0.9913153605015674, 0.9551393039535572, 0.9801300368243566]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.938 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.963 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 


accs [0.9940298507462687, 0.9406099518459069, 0.9640143942423031, 0.9768076398362893]
 precisions [1.0, 0.9486356340288925, 0.9672131147540983, 0.9771487039563438]
 recalls [0.991044776119403, 0.9377207062600321, 0.9596161535385845, 0.9819236016371078]
 f1scores [0.9903990001178045, 0.9433655613017141, 0.9650979544160687, 0.9789835581282874]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.934 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.992 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.989 


accs [0.9850746268656716, 0.9666131621187801, 0.9332267093162735, 0.9914733969986358, 0.9883597883597883]
 precisions [0.982089552238806, 0.9653290529695024, 0.9360255897640943, 0.9887448840381992, 0.982010582010582]
 recalls [0.9791044776119403, 0.9656500802568219, 0.9368252698920432, 0.9894270122783083, 0.982010582010582]
 f1scores [0.9814802264992017, 0.9687879908851089, 0.9237640061276297, 0.9897505204603121, 0.9883322137632481]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.984 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.960 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.914 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.952 
=> Acc: 0.995 Precision 0.995 Recall 0.995 F1 0.995 


accs [0.9850746268656716, 0.9614767255216693, 0.9148340663734507, 0.982605729877217, 0.9523809523809523, 0.9951690821256038]
 precisions [1.0, 0.9579454253611557, 0.9244302279088364, 0.980218281036835, 0.9587301587301588, 0.998792270531401]
 recalls [0.9850746268656716, 0.9691813804173355, 0.9232307077169132, 0.9798772169167803, 0.9661375661375662, 0.9975845410628019]
 f1scores [0.9854422207454963, 0.9592762862915345, 0.9167021945985312, 0.9817008220124505, 0.9674655481403118, 0.9988016990833891]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.904 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.959 


accs [0.9671641791044776, 0.9521669341894061, 0.9072371051579369, 0.9751023192360164, 0.9798941798941799, 0.982487922705314, 0.9611780455153949]
 precisions [0.9701492537313433, 0.9393258426966292, 0.9184326269492203, 0.977830832196453, 0.9703703703703703, 0.9722222222222222, 0.9491298527443106]
 recalls [0.9671641791044776, 0.9463884430176565, 0.9136345461815274, 0.9747612551159618, 0.9862433862433863, 0.9806763285024155, 0.9451137884872824]
 f1scores [0.9614478974321488, 0.9373826481682312, 0.8966572118691462, 0.9734694160905878, 0.9842922003040409, 0.9848385040591976, 0.9444534656022704]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.932 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.902 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.948 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 


accs [0.982089552238806, 0.9348314606741573, 0.9036385445821671, 0.9652114597544338, 0.9492063492063492, 0.9704106280193237, 0.9598393574297188, 0.9944547134935305]
 precisions [0.982089552238806, 0.9335473515248797, 0.9148340663734507, 0.9655525238744884, 0.964021164021164, 0.9619565217391305, 0.9491298527443106, 1.0]
 recalls [0.9701492537313433, 0.9373996789727127, 0.9004398240703718, 0.9590723055934516, 0.9534391534391534, 0.9643719806763285, 0.9665327978580991, 0.9981515711645101]
 f1scores [0.9770338811117874, 0.936514149241685, 0.8964127230487497, 0.9545428717443324, 0.9592139138312759, 0.9642411294608788, 0.9436253201814886, 0.9980287912994926]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.912 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.903 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.931 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.954 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.963 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.968 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.986 


accs [0.9791044776119403, 0.9146067415730337, 0.9048380647740903, 0.9328103683492497, 0.9566137566137566, 0.961352657004831, 0.963855421686747, 0.9704251386321626, 0.9874651810584958]
 precisions [0.9522388059701492, 0.9280898876404494, 0.9148340663734507, 0.9358799454297408, 0.9608465608465608, 0.9631642512077294, 0.9437751004016064, 0.9741219963031423, 0.979108635097493]
 recalls [0.9761194029850746, 0.9226324237560193, 0.90843662534986, 0.9409959072305594, 0.9619047619047619, 0.964975845410628, 0.9558232931726908, 0.9648798521256932, 0.9721448467966574]
 f1scores [0.9794168945398134, 0.9140960890889142, 0.9081385083379429, 0.9406930995628322, 0.9613365970120198, 0.9751776488654091, 0.9627317136999523, 0.9703502939825039, 0.9744418823468959]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.922 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.902 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.905 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.951 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.974 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.895 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.952 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.934 


accs [0.9253731343283582, 0.9017656500802568, 0.9088364654138344, 0.9866984993178718, 0.9534391534391534, 0.9746376811594203, 0.8969210174029452, 0.9944547134935305, 0.9512534818941504, 0.9345422379478107]
 precisions [0.9223880597014925, 0.8956661316211878, 0.8884446221511395, 0.9894270122783083, 0.9714285714285714, 0.964975845410628, 0.891566265060241, 0.9944547134935305, 0.9401114206128134, 0.9336576735957541]
 recalls [0.9373134328358209, 0.9062600321027288, 0.8884446221511395, 0.992837653478854, 0.9629629629629629, 0.9788647342995169, 0.8995983935742972, 0.9870609981515711, 0.9415041782729805, 0.9327731092436975]
 f1scores [0.9373882227331924, 0.8863387594364609, 0.8913064527781291, 0.9889559455386625, 0.9689937264804206, 0.9661167141443121, 0.8894309725235271, 0.9884453619915717, 0.957862331075597, 0.9320605526760339]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.969 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.904 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.948 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.927 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.941 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.908 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.890 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.947 


accs [0.9701492537313433, 0.9104333868378812, 0.9432227109156337, 0.9505457025920873, 0.9555555555555556, 0.9257246376811594, 0.92904953145917, 0.9426987060998152, 0.9066852367688022, 0.8920831490490934, 0.9485396383866481]
 precisions [0.9611940298507463, 0.9040128410914928, 0.9412235105957617, 0.9457708049113234, 0.9587301587301588, 0.928743961352657, 0.9397590361445783, 0.9593345656192237, 0.9178272980501393, 0.8863334807607254, 0.9582753824756607]
 recalls [0.991044776119403, 0.9059390048154093, 0.9380247900839664, 0.9529331514324693, 0.964021164021164, 0.9208937198067633, 0.9410977242302544, 0.9537892791127541, 0.9373259052924791, 0.8867757629367536, 0.9534075104311543]
 f1scores [0.9717631071986881, 0.9046217879678757, 0.9402174249387725, 0.9497070125176552, 0.9662880340854014, 0.93595072682558, 0.9298563540331859, 0.9429627843445483, 0.9225037732240363, 0.8834319240973549, 0.9531805948680594]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.876 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.867 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.964 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.937 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.973 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.945 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.898 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.821 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 


accs [0.9582089552238806, 0.8869983948635634, 0.8740503798480608, 0.9631650750341064, 0.9523809523809523, 0.964975845410628, 0.9384203480589023, 0.9722735674676525, 0.9456824512534819, 0.9000442282176029, 0.8261474269819193, 0.981301421091997]
 precisions [0.9462686567164179, 0.8998394863563403, 0.8892443022790884, 0.968281036834925, 0.9365079365079365, 0.9577294685990339, 0.9437751004016064, 0.9630314232902033, 0.915041782729805, 0.9093321539141973, 0.8435326842837274, 0.9865370231862378]
 recalls [0.9283582089552239, 0.898876404494382, 0.8804478208716513, 0.9618008185538881, 0.9386243386243386, 0.9595410628019324, 0.9464524765729585, 0.977818853974122, 0.9303621169916435, 0.9026979212737727, 0.8463143254520167, 0.9827973074046372]
 f1scores [0.9639248043773556, 0.8882634137233879, 0.8773930559081234, 0.9641303574486789, 0.9263480459507427, 0.9620690577656561, 0.9596930936915857, 0.9648688564127557, 0.9138518538711091, 0.907944935150029, 0.844917032769317, 0.9839621447305408]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.966 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.919 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.883 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.947 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.925 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.866 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.857 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.868 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 


accs [0.9671641791044776, 0.9232744783306581, 0.8872451019592164, 0.9911323328785812, 0.9587301587301588, 0.9468599033816425, 0.927710843373494, 0.9630314232902033, 0.958217270194986, 0.8690844758956214, 0.8539638386648123, 0.8698578908002992, 0.9490494296577947]
 precisions [0.9402985074626866, 0.9088282504012841, 0.8852459016393442, 0.9901091405184175, 0.9714285714285714, 0.946256038647343, 0.9103078982597055, 0.9630314232902033, 0.9540389972144847, 0.8761609907120743, 0.8831710709318498, 0.8833208676140614, 0.9467680608365019]
 recalls [0.9611940298507463, 0.9165329052969502, 0.890843662534986, 0.9901091405184175, 0.9608465608465608, 0.9426328502415459, 0.9156626506024096, 0.9519408502772643, 0.9568245125348189, 0.8721804511278195, 0.8581363004172462, 0.8773373223635004, 0.9338403041825095]
 f1scores [0.9689845455222595, 0.9108647783517057, 0.8711127479640008, 0.9903924204694462, 0.9549739141196938, 0.9442665831861451, 0.9144826226172589, 0.9730449041709381, 0.9418319682270037, 0.8703801918246474, 0.8619094611093487, 0.87033115032903, 0.9487770166816176]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.901 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.958 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.941 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.880 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.955 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.879 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.831 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.911 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.931 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.891 


accs [0.9373134328358209, 0.9370786516853933, 0.9024390243902439, 0.9822646657571623, 0.9587301587301588, 0.9426328502415459, 0.8808567603748326, 0.9741219963031423, 0.9526462395543176, 0.8850066342326405, 0.8407510431154381, 0.912490650710546, 0.9307984790874525, 0.888243831640058]
 precisions [0.9641791044776119, 0.9168539325842696, 0.9024390243902439, 0.9863574351978172, 0.944973544973545, 0.9468599033816425, 0.8741633199464525, 0.9870609981515711, 0.9735376044568245, 0.8584697036709421, 0.8219749652294854, 0.9020194465220643, 0.9216730038022813, 0.918722786647315]
 recalls [0.9402985074626866, 0.9242375601926164, 0.9000399840063974, 0.9860163710777626, 0.944973544973545, 0.9601449275362319, 0.8634538152610441, 0.9704251386321626, 0.9623955431754875, 0.8872180451127819, 0.8247566063977747, 0.9169783096484667, 0.9269961977186312, 0.8998548621190131]
 f1scores [0.9641453237512352, 0.9225657073804825, 0.9029591879080104, 0.9851697883629124, 0.9486079120724792, 0.9462479374627775, 0.8884069242676438, 0.9767114447266858, 0.9665294763573227, 0.8703751079410725, 0.8269063510210748, 0.9188036421741282, 0.9243206004110522, 0.8922003129727303]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.972 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.926 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.921 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.878 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.952 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.936 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.835 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.920 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.848 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.898 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.929 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.910 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.902 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.917 


accs [0.9731343283582089, 0.9300160513643659, 0.9244302279088364, 0.8823328785811733, 0.9534391534391534, 0.9353864734299517, 0.8406961178045516, 0.9796672828096118, 0.9206128133704735, 0.8518354710305175, 0.8977746870653686, 0.9296933433059088, 0.9095057034220533, 0.9027576197387518, 0.9223946784922394]
 precisions [0.9522388059701492, 0.9300160513643659, 0.9204318272690923, 0.8884720327421555, 0.9650793650793651, 0.9239130434782609, 0.8232931726907631, 0.9648798521256932, 0.915041782729805, 0.8544891640866873, 0.9033379694019471, 0.9169783096484667, 0.9095057034220533, 0.9129172714078374, 0.9068736141906873]
 recalls [0.9611940298507463, 0.9203852327447833, 0.9172331067572971, 0.8847203274215553, 0.9492063492063492, 0.9239130434782609, 0.8125836680053548, 0.9704251386321626, 0.9317548746518106, 0.8345864661654135, 0.8838664812239221, 0.9244577412116679, 0.9011406844106464, 0.9100145137880987, 0.9090909090909091]
 f1scores [0.9810642582449471, 0.9231025251439468, 0.9185726167076712, 0.8900296697074402, 0.9490102696228048, 0.925307868554766, 0.8393218935358115, 0.9833588999742993, 0.9300971898057531, 0.842728827029131, 0.8956877086444237, 0.9308533182629478, 0.9068377005035405, 0.9121908376717492, 0.9192214768743836]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.965 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.895 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.923 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.912 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.835 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.983 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.950 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.889 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.813 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.935 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.896 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.776 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.861 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.933 


accs [0.9611940298507463, 0.9008025682182985, 0.924030387844862, 0.9590723055934516, 0.9333333333333333, 0.9130434782608695, 0.8380187416331994, 0.9815157116451017, 0.9526462395543176, 0.8907563025210085, 0.8171070931849791, 0.9349289454001496, 0.8950570342205323, 0.8055152394775036, 0.8603104212860311, 0.9336071184120466]
 precisions [0.9552238805970149, 0.9004815409309791, 0.9208316673330668, 0.9570259208731241, 0.9238095238095239, 0.9045893719806763, 0.8179384203480589, 0.9722735674676525, 0.9498607242339833, 0.8779301194161875, 0.7899860917941586, 0.9409124906507106, 0.9072243346007605, 0.8026124818577649, 0.8625277161862528, 0.9582477754962354]
 recalls [0.9701492537313433, 0.8853932584269663, 0.9316273490603758, 0.9662346521145976, 0.9185185185185185, 0.9160628019323671, 0.8701472556894244, 0.988909426987061, 0.9568245125348189, 0.8788146837682441, 0.8018080667593881, 0.943904263275991, 0.870722433460076, 0.818577648766328, 0.844789356984479, 0.945242984257358]
 f1scores [0.9780963752807675, 0.8898143808918058, 0.9242300159237873, 0.9532503184848766, 0.9143832489815551, 0.912354237620163, 0.8586380391595002, 0.9721557115859017, 0.9503022347442786, 0.8770884317648961, 0.8124789453864671, 0.9431325443219393, 0.8991452556118272, 0.7935267259164921, 0.8744682977467001, 0.9306174371332798]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.898 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.889 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.895 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.873 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.897 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.858 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.822 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.806 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.928 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.805 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.919 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.908 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.916 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.835 


accs [0.9044776119402985, 0.8847512038523274, 0.8948420631747301, 0.9525920873124147, 0.8740740740740741, 0.9021739130434783, 0.8634538152610441, 0.966728280961183, 0.9484679665738162, 0.8297213622291022, 0.8136300417246175, 0.9296933433059088, 0.8114068441064639, 0.9158200290275762, 0.9046563192904656, 0.91854893908282, 0.8554886521537749]
 precisions [0.9194029850746268, 0.8821829855537721, 0.9016393442622951, 0.9560027285129604, 0.8931216931216931, 0.8931159420289855, 0.8955823293172691, 0.9500924214417745, 0.947075208913649, 0.8460858027421495, 0.8094575799721836, 0.9416604338070307, 0.8433460076045627, 0.9346879535558781, 0.8758314855875832, 0.9164955509924709, 0.8480778138026864]
 recalls [0.9432835820895522, 0.8818619582664526, 0.9020391843262695, 0.9577080491132333, 0.891005291005291, 0.8967391304347826, 0.8741633199464525, 0.9537892791127541, 0.9554317548746518, 0.8297213622291022, 0.8184979137691237, 0.9304412864622289, 0.8425855513307985, 0.8911465892597968, 0.88470066518847, 0.9130732375085557, 0.857341361741547]
 f1scores [0.9101723946686832, 0.8861668686463885, 0.8936996075262387, 0.9506507934770294, 0.8850126046301409, 0.896295918182178, 0.8657047621400281, 0.9255546024954647, 0.9384910260906457, 0.8241146148187702, 0.7933098574245435, 0.9290772187836023, 0.8308745071400988, 0.9091678787449606, 0.8791767717870362, 0.8894333068030871, 0.845288194000229]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.912 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.902 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.929 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.788 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.839 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.869 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.926 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.873 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.814 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.799 
=> Acc: 0.821 Precision 0.821 Recall 0.821 F1 0.812 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.855 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.807 Precision 0.807 Recall 0.807 F1 0.805 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.840 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.854 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 


accs [0.9373134328358209, 0.9155698234349919, 0.899640143942423, 0.9287175989085948, 0.7957671957671958, 0.857487922705314, 0.8741633199464525, 0.9242144177449169, 0.8774373259052924, 0.8230871295886776, 0.8150208623087621, 0.8212415856394913, 0.8524714828897338, 0.9738751814223512, 0.8070953436807096, 0.8507871321013005, 0.8587308939323761, 0.932633903920486]
 precisions [0.9343283582089552, 0.9097913322632424, 0.9012395041983207, 0.930081855388813, 0.7978835978835979, 0.8725845410628019, 0.856760374832664, 0.9205175600739371, 0.8760445682451253, 0.8040689960194605, 0.8191933240611962, 0.8175018698578908, 0.8387832699619772, 0.9680696661828737, 0.8337028824833703, 0.8576317590691307, 0.8587308939323761, 0.9282164549972391]
 recalls [0.9582089552238806, 0.8959871589085072, 0.9052379048380648, 0.9389495225102319, 0.8359788359788359, 0.8695652173913043, 0.8621151271753681, 0.922365988909427, 0.8816155988857939, 0.7983193277310925, 0.8108484005563282, 0.8354525056095736, 0.8562737642585552, 0.969521044992743, 0.8337028824833703, 0.8494182067077344, 0.8476146364057434, 0.9431253451131971]
 f1scores [0.9611035541554918, 0.9079125079287239, 0.8984105581647462, 0.9397912377230991, 0.7800121054642428, 0.859159512120392, 0.8772117899320119, 0.9274236903991925, 0.8607404017489749, 0.7912555863294233, 0.806677904963695, 0.8115950666688233, 0.8522889527733992, 0.9786914621209732, 0.8062879070340354, 0.8406073334307488, 0.8416120336775916, 0.9306690730043978]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.911 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.830 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.831 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.912 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.903 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.789 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.937 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.797 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.859 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.843 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.843 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.923 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.800 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.907 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.867 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.831 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.846 


accs [0.9223880597014925, 0.9367576243980739, 0.83046781287485, 0.8274215552523875, 0.9121693121693122, 0.9051932367149759, 0.8032128514056225, 0.933456561922366, 0.9387186629526463, 0.8031844316674038, 0.8616133518776078, 0.8489154824233358, 0.8463878326996198, 0.9245283018867925, 0.8048780487804879, 0.9089664613278576, 0.8786475220009263, 0.8404196576477084, 0.8530092592592593]
 precisions [0.8925373134328358, 0.9325842696629213, 0.8380647740903638, 0.8195770804911323, 0.9259259259259259, 0.9057971014492754, 0.7911646586345381, 0.9186691312384473, 0.9512534818941504, 0.8027421494913755, 0.8532684283727399, 0.8481675392670157, 0.8418250950570342, 0.9114658925979681, 0.8226164079822617, 0.8966461327857632, 0.8865215377489578, 0.8310325786858089, 0.8564814814814815]
 recalls [0.9104477611940298, 0.9306581059390048, 0.8356657337065174, 0.834924965893588, 0.8931216931216931, 0.8979468599033816, 0.8072289156626506, 0.9242144177449169, 0.9484679665738162, 0.8120300751879699, 0.8789986091794159, 0.8369483919222139, 0.823574144486692, 0.9361393323657474, 0.7804878048780488, 0.9041752224503764, 0.8791106993978693, 0.8310325786858089, 0.8535879629629629]
 f1scores [0.8992488067887747, 0.927588361665873, 0.8347138537427593, 0.8395417078811398, 0.9146708782284797, 0.9225521138973456, 0.8334898621491856, 0.9057877138376622, 0.9470796396681574, 0.7912727775115327, 0.8337154046816929, 0.8441299563326247, 0.8374715836539884, 0.935011854373071, 0.8122662548070897, 0.8994487780961071, 0.8686984776624561, 0.808125009148073, 0.8589277831788864]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.923 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.867 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.898 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.845 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.922 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.851 
=> Acc: 0.768 Precision 0.768 Recall 0.768 F1 0.762 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.913 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.920 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.805 
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.783 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.823 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.810 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.944 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.799 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.870 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.868 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.824 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.830 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.952 


accs [0.9253731343283582, 0.8686998394863563, 0.8980407836865254, 0.8414051841746248, 0.9259259259259259, 0.8671497584541062, 0.7684069611780455, 0.9149722735674677, 0.9206128133704735, 0.8177797434763379, 0.7934631432545202, 0.8257292445774121, 0.8144486692015209, 0.9448476052249637, 0.8093126385809313, 0.8754277891854894, 0.8786475220009263, 0.8343456653782441, 0.8362268518518519, 0.9522673031026253]
 precisions [0.9194029850746268, 0.8648475120385233, 0.8916433426629349, 0.8332196452933152, 0.928042328042328, 0.8665458937198067, 0.7536813922356091, 0.9316081330868762, 0.9080779944289693, 0.8270676691729323, 0.8004172461752433, 0.8279730740463724, 0.8220532319391635, 0.9579100145137881, 0.8093126385809313, 0.8781656399726215, 0.8754052802223251, 0.8282716731087797, 0.8165509259259259, 0.964200477326969]
 recalls [0.9074626865671642, 0.8780096308186196, 0.8852459016393442, 0.8485675306957708, 0.946031746031746, 0.8586956521739131, 0.7751004016064257, 0.9260628465804066, 0.9233983286908078, 0.816452896948253, 0.8184979137691237, 0.8421839940164547, 0.84106463878327, 0.9375907111756169, 0.844789356984479, 0.867214236824093, 0.8661417322834646, 0.8282716731087797, 0.8269675925925926, 0.9785202863961814]
 f1scores [0.9122122449221122, 0.877065391414859, 0.8877181701400157, 0.8551811649506691, 0.9137767731300226, 0.843993265445409, 0.7704586990135185, 0.9431694405265733, 0.9155631776458677, 0.8049586752798537, 0.8006606327713885, 0.8360568237930543, 0.8218033023624629, 0.953314150517176, 0.7783248359145067, 0.8654871161928852, 0.8550302440639854, 0.8251284752604782, 0.8273500119659432, 0.9717627935644122]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [0.9960505529225908]
 recalls [0.9992101105845181]
 f1scores [0.9974872480934772]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 


accs [0.9865718799368088, 0.9774193548387097]
 precisions [0.9842022116903634, 0.9774193548387097]
 recalls [0.9849921011058452, 0.9903225806451613]
 f1scores [0.9955087058161263, 0.9725090693132058]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.945 


accs [0.9921011058451816, 0.9870967741935484, 0.9411764705882353]
 precisions [0.9865718799368088, 0.9913978494623656, 0.9634888438133874]
 recalls [0.9881516587677726, 0.9838709677419355, 0.9371196754563894]
 f1scores [0.987592262232986, 0.9814993819433331, 0.9492090718505812]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.904 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.880 


accs [0.9052132701421801, 0.978494623655914, 0.9513184584178499, 0.8841187863137508]
 precisions [0.9012638230647709, 0.9731182795698925, 0.9614604462474645, 0.8666881859264042]
 recalls [0.909952606635071, 0.964516129032258, 0.9614604462474645, 0.8886378308586185]
 f1scores [0.9070995729624911, 0.9702672300646299, 0.9615934627170581, 0.8739571989908953]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.838 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.911 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.892 
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 


accs [0.8412322274881516, 0.9795698924731183, 0.9168356997971603, 0.894770819883796, 0.9991755976916735]
 precisions [0.839652448657188, 0.9849462365591398, 0.9148073022312373, 0.8983214977404778, 0.9967023907666942]
 recalls [0.8641390205371248, 0.9731182795698925, 0.9046653144016227, 0.894770819883796, 0.998351195383347]
 f1scores [0.8567883940955277, 0.9688537823251491, 0.9002052152023422, 0.8939755370512694, 0.9982718894009217]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.723 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.955 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.865 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.883 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.934 


accs [0.7290679304897314, 0.9559139784946237, 0.8722109533468559, 0.8857327307940607, 0.9826875515251443, 0.933186490455213]
 precisions [0.7401263823064771, 0.9483870967741935, 0.8884381338742393, 0.8863783085861846, 0.9835119538334708, 0.9416299559471366]
 recalls [0.7440758293838863, 0.9505376344086022, 0.8600405679513184, 0.8873466752743706, 0.9851607584501236, 0.9456681350954479]
 f1scores [0.7389036892286647, 0.9628858262144331, 0.8556845479709982, 0.874629389314163, 0.9909795722182168, 0.9406752244177776]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.860 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.855 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.870 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.986 


accs [0.8601895734597157, 0.9688172043010753, 0.8722109533468559, 0.8702388637830859, 0.9777411376751854, 0.9394273127753304, 0.9859017987360233]
 precisions [0.8672985781990521, 0.9763440860215054, 0.8701825557809331, 0.8747579083279535, 0.9810387469084914, 0.9390602055800293, 0.9927078269324259]
 recalls [0.8720379146919431, 0.9698924731182795, 0.8519269776876268, 0.8737895416397676, 0.9670239076669415, 0.9390602055800293, 0.9941662615459407]
 f1scores [0.8742549768693573, 0.9623883440500819, 0.8521158875909208, 0.8624876027835022, 0.9801037590607816, 0.9334058468471269, 0.9902372694252863]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.730 Precision 0.730 Recall 0.730 F1 0.720 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.960 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.813 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.839 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.948 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.863 


accs [0.7298578199052133, 0.9612903225806452, 0.8154158215010142, 0.8450613298902517, 0.9744435284418796, 0.9618208516886931, 0.9474963539134662, 0.8835057158410452]
 precisions [0.7259083728278041, 0.9666666666666667, 0.8133874239350912, 0.8479664299548095, 0.9694971145919209, 0.9610866372980911, 0.9455517744287798, 0.8780620577027762]
 recalls [0.7440758293838863, 0.953763440860215, 0.8640973630831643, 0.8521626856036152, 0.9727947238252267, 0.9625550660792952, 0.9416626154594069, 0.8720740337506805]
 f1scores [0.6948306691359052, 0.9583384742635032, 0.8127609491145897, 0.8381999864744424, 0.9699637935608723, 0.9643238446873894, 0.945525532993778, 0.859673789749482]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.812 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.907 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.788 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.803 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.954 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.872 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.938 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.909 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.943 


accs [0.8127962085308057, 0.9010752688172043, 0.8133874239350912, 0.8102001291155584, 0.9563066776586975, 0.8803230543318649, 0.9406903257170637, 0.914534567229178, 0.9457831325301205]
 precisions [0.8199052132701422, 0.9419354838709677, 0.8296146044624746, 0.8085861846352486, 0.9464138499587799, 0.881791483113069, 0.9314535731648032, 0.9205225911812738, 0.9268502581755593]
 recalls [0.8096366508688784, 0.9236559139784947, 0.8356997971602435, 0.8121368624919303, 0.9472382522671063, 0.881424375917768, 0.9402041808458921, 0.9324986390854655, 0.9363166953528399]
 f1scores [0.8090867489916297, 0.9307399442036501, 0.7735487738289171, 0.8111000134380293, 0.9340702946101919, 0.8697661041147493, 0.9420099501443382, 0.9120019229051384, 0.9328611362538398]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.809 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.901 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.802 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.811 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.908 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.907 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.898 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.882 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.906 


accs [0.8096366508688784, 0.8978494623655914, 0.8235294117647058, 0.8169786959328599, 0.9703215169002474, 0.9111600587371512, 0.9081186193485659, 0.9058247142079477, 0.8864027538726333, 0.9081779053084649]
 precisions [0.80173775671406, 0.9150537634408602, 0.8194726166328601, 0.8118140735958683, 0.9719703215169002, 0.9177679882525698, 0.9168692270296548, 0.8998366902558519, 0.8855421686746988, 0.9081779053084649]
 recalls [0.7788309636650869, 0.9053763440860215, 0.8275862068965517, 0.8192382182052937, 0.9703215169002474, 0.9118942731277533, 0.9017987360233349, 0.9101796407185628, 0.8889845094664371, 0.9053084648493543]
 f1scores [0.8156512425459145, 0.9027171815558059, 0.7886484392364929, 0.814277672831228, 0.9633886983569966, 0.9153019824406959, 0.9150813061977809, 0.8920389696040928, 0.9053769128474987, 0.9050158859658328]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.737 Precision 0.737 Recall 0.737 F1 0.727 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.934 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.729 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.827 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.959 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.884 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.897 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.905 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.892 
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.786 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.966 


accs [0.7369668246445498, 0.9333333333333333, 0.768762677484787, 0.8337637185280826, 0.9579554822753503, 0.8880323054331865, 0.9017987360233349, 0.9156232988568318, 0.8984509466437177, 0.793400286944046, 0.9654036243822076]
 precisions [0.7266982622432859, 0.9311827956989247, 0.7768762677484787, 0.8321497740477728, 0.957131079967024, 0.882525697503671, 0.904229460379193, 0.9031028851388133, 0.887263339070568, 0.8020086083213773, 0.9802306425041186]
 recalls [0.721958925750395, 0.921505376344086, 0.7789046653144016, 0.8492575855390575, 0.9711459192085737, 0.895007342143906, 0.8964511424404472, 0.9031028851388133, 0.8864027538726333, 0.8077474892395983, 0.9818780889621087]
 f1scores [0.7312637987509952, 0.9299969869019818, 0.7359202087141498, 0.8329843374821537, 0.9630598423419603, 0.8822786285200749, 0.8895221056753438, 0.8942686705476566, 0.8935976386097881, 0.763639849432841, 0.9817516531603699]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.705 Precision 0.705 Recall 0.705 F1 0.686 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.894 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.809 
=> Acc: 0.751 Precision 0.751 Recall 0.751 F1 0.739 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.974 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.944 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.844 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.901 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.903 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.797 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.919 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.992 


accs [0.7045813586097947, 0.8946236559139785, 0.8194726166328601, 0.7511297611362169, 0.9727947238252267, 0.9453010279001468, 0.8585318424890618, 0.9101796407185628, 0.9087779690189329, 0.8163558106169297, 0.9242174629324547, 0.9928057553956835]
 precisions [0.6974723538704581, 0.8591397849462366, 0.795131845841785, 0.7527437056165268, 0.9637262984336357, 0.9511747430249633, 0.8624210014584346, 0.9052803483941209, 0.9001721170395869, 0.8335724533715926, 0.9093904448105437, 0.9748201438848921]
 recalls [0.6729857819905213, 0.8806451612903226, 0.8275862068965517, 0.7462879276952873, 0.9604286892003298, 0.9515418502202643, 0.8672824501701507, 0.904735982580294, 0.891566265060241, 0.8421807747489239, 0.9159802306425041, 0.9784172661870504]
 f1scores [0.6956432074798715, 0.8839094660468296, 0.8171100049325661, 0.7527053482278184, 0.9753177639305329, 0.9462544175549533, 0.8465268722270307, 0.9093173592388789, 0.8933226737754698, 0.7810715638303731, 0.9297721124357539, 0.9744602519344745]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.881 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.832 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.826 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.789 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.884 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.945 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.892 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.908 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.819 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.923 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.857 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.915 


accs [0.8815165876777251, 0.8268817204301075, 0.8519269776876268, 0.8079406068431246, 0.9563066776586975, 0.8872980910425844, 0.9474963539134662, 0.9025585193249864, 0.9130808950086059, 0.8393113342898135, 0.9225700164744646, 0.8597122302158273, 0.9151785714285714]
 precisions [0.9210110584518167, 0.8258064516129032, 0.8275862068965517, 0.8043899289864429, 0.966199505358615, 0.8876651982378855, 0.9504132231404959, 0.8960261295590637, 0.9139414802065404, 0.8249641319942611, 0.942339373970346, 0.9028776978417267, 0.9357142857142857]
 recalls [0.8941548183254344, 0.8451612903225807, 0.7971602434077079, 0.8111684958037444, 0.9521846661170651, 0.8858296622613803, 0.95770539620807, 0.9129014697876974, 0.9148020654044751, 0.8378766140602583, 0.9341021416803954, 0.8812949640287769, 0.9232142857142858]
 f1scores [0.8969781809044018, 0.8551890954002032, 0.7516981896091945, 0.7878915440742398, 0.9612918091684841, 0.8834849937529368, 0.951673554847518, 0.908447803876426, 0.9149250294100133, 0.7998430369407197, 0.9271197253645888, 0.8426384754823453, 0.9219147261997118]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.744 Precision 0.744 Recall 0.744 F1 0.730 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.924 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.810 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.761 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.941 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.908 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.864 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.888 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.868 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.908 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.880 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.878 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.923 


accs [0.7440758293838863, 0.9247311827956989, 0.821501014198783, 0.7798579728857328, 0.9464138499587799, 0.9416299559471366, 0.912980068060282, 0.8786064235166031, 0.8993115318416524, 0.8766140602582496, 0.9110378912685337, 0.8776978417266187, 0.88125, 0.9253187613843351]
 precisions [0.7330173775671406, 0.9268817204301075, 0.8093306288032455, 0.7708198837959974, 0.9596042868920033, 0.9390602055800293, 0.9100631988332523, 0.8775176918889493, 0.8889845094664371, 0.8593974175035868, 0.9225700164744646, 0.8669064748201439, 0.8767857142857143, 0.912568306010929]
 recalls [0.7306477093206951, 0.9365591397849462, 0.845841784989858, 0.7821174951581665, 0.9587798845836768, 0.9397944199706314, 0.9115216334467672, 0.8769733260751225, 0.9036144578313253, 0.860832137733142, 0.9077429983525536, 0.8633093525179856, 0.8678571428571429, 0.9275045537340619]
 f1scores [0.7281640791945899, 0.9340534182251069, 0.8129311800269468, 0.7708432327410867, 0.953930558216916, 0.9220304003050188, 0.9065603369554008, 0.8616629985150486, 0.8711253935935647, 0.8481245008082358, 0.9245716699713935, 0.8287775475438316, 0.8651450940604747, 0.9216575056082599]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.669 Precision 0.669 Recall 0.669 F1 0.627 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.921 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.811 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.808 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.956 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.892 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.906 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.813 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.789 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.841 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.875 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.873 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.897 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.923 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.957 


accs [0.6690363349131122, 0.9193548387096774, 0.8316430020283976, 0.8131052291801162, 0.9579554822753503, 0.8909691629955947, 0.9081186193485659, 0.8285247686445292, 0.8244406196213425, 0.8550932568149211, 0.8747940691927513, 0.8776978417266187, 0.8991071428571429, 0.9256830601092896, 0.9574565416285453]
 precisions [0.6461295418641391, 0.921505376344086, 0.821501014198783, 0.8166559070367979, 0.9497114591920858, 0.8920704845814978, 0.8867282450170151, 0.8279804028307022, 0.8528399311531841, 0.860832137733142, 0.8698517298187809, 0.8741007194244604, 0.88125, 0.9162112932604736, 0.9419030192131748]
 recalls [0.6421800947867299, 0.9258064516129032, 0.8356997971602435, 0.8214977404777276, 0.9546578730420445, 0.9071218795888399, 0.9095770539620807, 0.8410451823625477, 0.8450946643717728, 0.8680057388809183, 0.8451400329489291, 0.8884892086330936, 0.8830357142857143, 0.9296903460837888, 0.9414455626715462]
 f1scores [0.5904815361890364, 0.9241704080826928, 0.8137254149204385, 0.8077852826712271, 0.9545641432765712, 0.8999488900368309, 0.8864348626475198, 0.8138062543916856, 0.8152813208284042, 0.8327172892643959, 0.874507502359199, 0.9107475361871199, 0.8781765207937993, 0.9301600593087519, 0.941088840350193]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.637 Precision 0.637 Recall 0.637 F1 0.598 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.910 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.783 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.793 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.945 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.788 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.919 
=> Acc: 0.800 Precision 0.800 Recall 0.800 F1 0.779 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.841 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.865 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.930 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.920 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.929 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.901 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.943 


accs [0.636650868878357, 0.9129032258064517, 0.8133874239350912, 0.7943834732085217, 0.9488870568837593, 0.7944199706314243, 0.9192999513855129, 0.7996733805117039, 0.8640275387263339, 0.8651362984218077, 0.9308072487644151, 0.9244604316546763, 0.93125, 0.9402550091074682, 0.9016468435498628, 0.9448853615520282]
 precisions [0.6500789889415481, 0.9064516129032258, 0.8194726166328601, 0.7879276952872821, 0.9563066776586975, 0.7922173274596183, 0.9134662129314536, 0.8285247686445292, 0.8588640275387264, 0.8479196556671449, 0.943986820428336, 0.9064748201438849, 0.9125, 0.9340619307832423, 0.9011893870082343, 0.9435626102292769]
 recalls [0.6611374407582938, 0.9129032258064517, 0.8133874239350912, 0.7963202065848934, 0.9505358615004122, 0.7914831130690162, 0.9056878949927079, 0.8132825258573761, 0.8683304647160068, 0.8637015781922525, 0.9489291598023064, 0.9280575539568345, 0.9035714285714286, 0.9438979963570128, 0.9057639524245197, 0.9422398589065256]
 f1scores [0.6171562442651454, 0.9167866312757298, 0.8136894188454112, 0.7910822366338627, 0.9596655227115386, 0.7862227148606588, 0.9119285187171966, 0.7973038852979171, 0.827285356605001, 0.8395542027709115, 0.9621844588545901, 0.9156181278433186, 0.9129756550978835, 0.9370364502766251, 0.91632369172327, 0.9387750747460217]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.559 Precision 0.559 Recall 0.559 F1 0.529 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.917 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.786 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.816 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.823 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.766 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.932 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.823 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.858 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.884 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.780 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.891 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.825 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.914 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.929 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.917 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 


accs [0.5592417061611374, 0.9161290322580645, 0.8052738336713996, 0.8179470626210459, 0.8483099752679307, 0.7797356828193832, 0.9314535731648032, 0.8464888405008165, 0.882960413080895, 0.8880918220946915, 0.8023064250411862, 0.8920863309352518, 0.8366071428571429, 0.917304189435337, 0.9290942360475755, 0.9188712522045855, 0.9598997493734336]
 precisions [0.5458135860979463, 0.921505376344086, 0.8073022312373225, 0.8337637185280826, 0.8260511129431163, 0.7712922173274597, 0.9299951385512882, 0.8415895481763745, 0.8795180722891566, 0.8880918220946915, 0.7940691927512356, 0.89568345323741, 0.8508928571428571, 0.9122040072859745, 0.934583714547118, 0.9096119929453262, 0.9655388471177945]
 recalls [0.5592417061611374, 0.9172043010752688, 0.8093306288032455, 0.8431245965138799, 0.8392415498763397, 0.7944199706314243, 0.9324258629071464, 0.8448557430593359, 0.8485370051635112, 0.8751793400286944, 0.8171334431630972, 0.8597122302158273, 0.8366071428571429, 0.9012750455373406, 0.934583714547118, 0.9197530864197531, 0.956766917293233]
 f1scores [0.49347368984066503, 0.9227787687235187, 0.7664473952195909, 0.8245363593092675, 0.8219419388550842, 0.7652000649510823, 0.934342690541062, 0.8538117931104626, 0.8461996991445722, 0.8948156794614684, 0.7686045573432514, 0.9185484846220968, 0.8569919670853594, 0.9025586627125252, 0.9395169671036758, 0.9069775156212216, 0.9600120153575089]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.678 Precision 0.678 Recall 0.678 F1 0.659 
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.754 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.730 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.785 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.848 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.805 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.904 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.836 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.855 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.886 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.735 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.827 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.835 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.899 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.917 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.890 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 


accs [0.6777251184834123, 0.7537634408602151, 0.7626774847870182, 0.7863137508069722, 0.8598516075845012, 0.815712187958884, 0.9052017501215363, 0.8481219379422972, 0.8683304647160068, 0.890961262553802, 0.7693574958813838, 0.8381294964028777, 0.84375, 0.902367941712204, 0.9181152790484904, 0.8959435626102292, 0.943609022556391, 0.9767441860465116]
 precisions [0.7069510268562401, 0.7709677419354839, 0.8073022312373225, 0.7717882504841833, 0.8697444352844188, 0.7900146842878121, 0.9061740398638795, 0.8454001088731627, 0.8975903614457831, 0.8737446197991392, 0.7742998352553542, 0.8489208633093526, 0.8473214285714286, 0.9092896174863389, 0.9098810612991766, 0.876984126984127, 0.9404761904761905, 0.9629164047768699]
 recalls [0.6864139020537124, 0.7569892473118279, 0.8093306288032455, 0.7666236281471918, 0.8722176422093982, 0.8032305433186491, 0.9188138065143413, 0.8508437670114317, 0.8803786574870912, 0.8723098995695839, 0.7545304777594728, 0.8705035971223022, 0.8232142857142857, 0.9012750455373406, 0.9112534309240622, 0.9029982363315696, 0.9291979949874687, 0.9660590823381521]
 f1scores [0.651144967609688, 0.7692384292423133, 0.7379371112133316, 0.7697636776360276, 0.8511467672781949, 0.7893386965779021, 0.909079832219598, 0.8387118807421665, 0.8570392928176578, 0.9004637130774406, 0.7283193559990864, 0.8674692155829197, 0.8377996544579794, 0.901520696649191, 0.9108743869034681, 0.8866262322549702, 0.9456386964099858, 0.9703825712945966]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.600 Precision 0.600 Recall 0.600 F1 0.568 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.866 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.804 
=> Acc: 0.737 Precision 0.737 Recall 0.737 F1 0.733 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.871 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.837 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.914 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.819 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.818 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.857 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.769 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.809 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.861 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.901 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.922 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.925 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.928 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.948 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.986 


accs [0.6003159557661928, 0.8655913978494624, 0.8377281947261663, 0.73692704970949, 0.8804616652926628, 0.8447136563876652, 0.9163830821584832, 0.833968426782798, 0.8493975903614458, 0.8637015781922525, 0.7907742998352554, 0.8345323741007195, 0.8651785714285715, 0.9045537340619307, 0.923604757548033, 0.9259259259259259, 0.9285714285714286, 0.9472030169704588, 0.9866310160427807]
 precisions [0.5932069510268563, 0.8559139784946237, 0.8539553752535497, 0.7420916720464816, 0.8977741137675186, 0.8564610866372981, 0.9095770539620807, 0.8383233532934131, 0.8545611015490534, 0.8680057388809183, 0.8385502471169687, 0.7841726618705036, 0.8955357142857143, 0.9063752276867031, 0.9153705397987191, 0.9254850088183422, 0.9235588972431078, 0.9440603394091767, 0.9759358288770054]
 recalls [0.5695102685624013, 0.8763440860215054, 0.8722109533468559, 0.7479018721755971, 0.8730420445177246, 0.855359765051395, 0.9183276616431697, 0.8328796951551443, 0.8605851979345955, 0.8794835007173601, 0.8220757825370676, 0.8561151079136691, 0.8883928571428571, 0.9041894353369763, 0.918572735590119, 0.9281305114638448, 0.918546365914787, 0.9484600879949717, 0.9786096256684492]
 f1scores [0.5651194084012781, 0.8284419889163042, 0.8129855456583417, 0.7271520577651212, 0.8705761076894177, 0.8370265580049863, 0.9093097089411847, 0.8210993078345407, 0.8401431864802605, 0.8568151766381005, 0.8159284276008952, 0.785273069882535, 0.8735596414822409, 0.906330748291224, 0.9091164775134143, 0.920632098230695, 0.9183796854010902, 0.9470263516749157, 0.974964795862739]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.591 Precision 0.591 Recall 0.591 F1 0.577 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.912 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.798 
=> Acc: 0.539 Precision 0.539 Recall 0.539 F1 0.520 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.838 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.909 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.847 
=> Acc: 0.821 Precision 0.821 Recall 0.821 F1 0.798 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.837 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.862 
=> Acc: 0.768 Precision 0.768 Recall 0.768 F1 0.737 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.868 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.878 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.906 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.928 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.911 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.928 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.929 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.838 


accs [0.5908372827804107, 0.9096774193548387, 0.8113590263691683, 0.538734667527437, 0.8565539983511954, 0.9085903083700441, 0.8502673796791443, 0.8214480130647795, 0.8614457831325302, 0.8708751793400287, 0.7677100494233937, 0.8669064748201439, 0.8785714285714286, 0.9085610200364299, 0.9268069533394327, 0.9122574955908289, 0.9279448621553885, 0.9283469516027656, 0.9545454545454546, 0.8517350157728707]
 precisions [0.5868878357030016, 0.8741935483870967, 0.7971602434077079, 0.5429309231762427, 0.86479802143446, 0.907856093979442, 0.8332523091881381, 0.8219923788786064, 0.8605851979345955, 0.8751793400286944, 0.7644151565074135, 0.8776978417266187, 0.8901785714285714, 0.8990892531876138, 0.9281793229643184, 0.9241622574955908, 0.9210526315789473, 0.9346323067253299, 0.93048128342246, 0.8675078864353313]
 recalls [0.584518167456556, 0.8924731182795699, 0.8194726166328601, 0.5480955455132344, 0.8738664468260511, 0.895741556534508, 0.8434613514827418, 0.809471965160588, 0.8709122203098106, 0.896700143472023, 0.7726523887973641, 0.8741007194244604, 0.8830357142857143, 0.9009107468123861, 0.9286367795059469, 0.9175485008818343, 0.9235588972431078, 0.9472030169704588, 0.9625668449197861, 0.8454258675078864]
 f1scores [0.5820018690818983, 0.8846363636687066, 0.7969816986560649, 0.5354918300959681, 0.8389691892714435, 0.9069416583553538, 0.8440487606681103, 0.7963616962808351, 0.8406525859000787, 0.8556575374596733, 0.7324860298270702, 0.8302343255828875, 0.9027226265072951, 0.8914521234591921, 0.9260251286565865, 0.9207992152218661, 0.9201896999339301, 0.9321095911927643, 0.948726469015277, 0.8292893613640795]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 


accs [0.9992019154030327]
 precisions [1.0]
 recalls [1.0]
 f1scores [1.0]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.991 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 


accs [0.9904229848363927, 0.967989756722151]
 precisions [0.99122106943336, 0.9571062740076824]
 recalls [0.9936153232242618, 0.9641485275288092]
 f1scores [0.9874370475840599, 0.9690181355853502]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.947 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.948 


accs [0.9776536312849162, 0.9519846350832266, 0.9509251810136766]
 precisions [0.9816440542697525, 0.9430217669654289, 0.9420756234915527]
 recalls [0.9808459696727854, 0.9494238156209988, 0.9404666130329847]
 f1scores [0.9852504471143213, 0.9439519812967333, 0.9412096702535292]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.972 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.885 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.938 


accs [0.9720670391061452, 0.9020486555697823, 0.9895414320193081, 0.9414519906323185]
 precisions [0.9704708699122107, 0.9071702944942381, 0.9911504424778761, 0.9402810304449649]
 recalls [0.9744612928970471, 0.8956466069142125, 0.9879324215607401, 0.9414519906323185]
 f1scores [0.9647718331158794, 0.891142684030814, 0.9870300040147238, 0.9327275285240761]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.976 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.889 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.893 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.961 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 


accs [0.9768555466879489, 0.8975672215108835, 0.8954143201930812, 0.9601873536299765, 0.9928853754940712]
 precisions [0.965682362330407, 0.8975672215108835, 0.8833467417538214, 0.9625292740046838, 0.9920948616600791]
 recalls [0.9776536312849162, 0.9001280409731114, 0.8793242156074015, 0.9601873536299765, 0.991304347826087]
 f1scores [0.9714000426425853, 0.891001795300099, 0.8844302588453192, 0.967856456433758, 0.990100269550761]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.943 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.915 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.912 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.989 


accs [0.945730247406225, 0.9225352112676056, 0.914722445695897, 0.9590163934426229, 0.9889328063241106, 0.9884892086330935]
 precisions [0.9505187549880287, 0.9148527528809219, 0.9372485921158488, 0.9578454332552693, 0.9849802371541502, 0.9856115107913669]
 recalls [0.9409417398244214, 0.9020486555697823, 0.9380530973451328, 0.9707259953161592, 0.9849802371541502, 0.99568345323741]
 f1scores [0.9482821134926528, 0.8995378843217992, 0.9343071560459053, 0.9620621608999554, 0.9856244981129739, 0.9916339869281046]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.966 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.908 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.917 


accs [0.9672785315243416, 0.9148527528809219, 0.9324215607401448, 0.9742388758782201, 0.9881422924901185, 0.9942446043165467, 0.9223404255319149]
 precisions [0.9760574620909817, 0.9090909090909091, 0.9388576025744167, 0.9718969555035128, 0.9881422924901185, 0.9827338129496402, 0.9329787234042554]
 recalls [0.9792498004788508, 0.8975672215108835, 0.9308125502815768, 0.9765807962529274, 0.9897233201581027, 0.9884892086330935, 0.9340425531914893]
 f1scores [0.9765095808515121, 0.8954889152822856, 0.9347538492701158, 0.9662771004354795, 0.9872808067820603, 0.9894969528248488, 0.9410567585600569]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.901 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.896 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.885 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.935 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.948 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.961 


accs [0.9050279329608939, 0.9078104993597952, 0.8865647626709574, 0.9391100702576113, 0.9470355731225296, 0.9640287769784173, 0.9393617021276596, 0.9615885416666666]
 precisions [0.9177972865123704, 0.91101152368758, 0.8849557522123894, 0.9484777517564403, 0.9446640316205533, 0.962589928057554, 0.926595744680851, 0.9615885416666666]
 recalls [0.9241819632881085, 0.9161331626120358, 0.8817377312952535, 0.9391100702576113, 0.9517786561264822, 0.9525179856115108, 0.9382978723404255, 0.9606119791666666]
 f1scores [0.9164004472798783, 0.9033209609148398, 0.8745832382991947, 0.9544228354067178, 0.9496594164964801, 0.9687930474299359, 0.929981391244439, 0.9610053721436158]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.939 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.907 
=> Acc: 0.736 Precision 0.736 Recall 0.736 F1 0.717 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.866 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.950 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.917 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.861 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.942 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.846 


accs [0.9417398244213887, 0.9174135723431498, 0.7361222847948512, 0.8770491803278688, 0.9494071146245059, 0.9179856115107914, 0.8734042553191489, 0.9417317708333334, 0.8720770288858322]
 precisions [0.9385474860335196, 0.9148527528809219, 0.7417538213998391, 0.8840749414519906, 0.9462450592885375, 0.9309352517985612, 0.8776595744680851, 0.9420572916666666, 0.8617606602475929]
 recalls [0.9417398244213887, 0.8956466069142125, 0.7345132743362832, 0.8711943793911007, 0.9233201581027668, 0.9223021582733812, 0.8968085106382979, 0.9391276041666666, 0.8651994497936726]
 f1scores [0.9356044825737848, 0.9075834052350631, 0.7183852097268388, 0.875009991497332, 0.9455673693551218, 0.9035811748627628, 0.8858161246084716, 0.9395117404491165, 0.8458120598665108]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.914 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.866 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.789 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.919 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.970 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.860 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.811 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 


accs [0.9193934557063048, 0.8924455825864277, 0.8230088495575221, 0.9613583138173302, 0.9201581027667984, 0.9712230215827338, 0.8659574468085106, 0.9332682291666666, 0.844566712517194, 0.9762962962962963]
 precisions [0.928172386272945, 0.882842509603073, 0.8390989541432019, 0.9508196721311475, 0.9114624505928853, 0.9741007194244604, 0.8627659574468085, 0.927734375, 0.8328748280605227, 0.9681481481481482]
 recalls [0.928172386272945, 0.8905249679897568, 0.8527755430410298, 0.9531615925058547, 0.9169960474308301, 0.9683453237410072, 0.8659574468085106, 0.9345703125, 0.8211829436038515, 0.977037037037037]
 f1scores [0.9152956190359369, 0.8590648052801735, 0.7843605745659269, 0.9719864329151022, 0.9056118634460738, 0.9737888317092158, 0.8483389991070179, 0.9342378452491518, 0.786445841286092, 0.9652051609098024]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.814 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.762 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.873 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.863 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.876 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.847 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.805 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.878 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.905 


accs [0.9688747007182761, 0.8585147247119078, 0.8165728077232502, 0.8758782201405152, 0.8695652173913043, 0.8906474820143885, 0.8563829787234043, 0.8111979166666666, 0.8844566712517193, 0.9577777777777777, 0.9128919860627178]
 precisions [0.965682362330407, 0.853393085787452, 0.7827835880933226, 0.882903981264637, 0.8632411067193676, 0.8776978417266187, 0.8287234042553191, 0.8014322916666666, 0.8975240715268226, 0.9629629629629629, 0.9189895470383276]
 recalls [0.9672785315243416, 0.852112676056338, 0.7900241351568785, 0.9004683840749415, 0.8766798418972332, 0.8920863309352518, 0.8425531914893617, 0.8095703125, 0.9016506189821183, 0.96, 0.9155052264808362]
 f1scores [0.9669084859906114, 0.8129939106499876, 0.7382373511797848, 0.8798574254475622, 0.8825265571470029, 0.8485705394222745, 0.8087075624000951, 0.8166072056793379, 0.866305185039703, 0.9594625996418589, 0.9041325128217201]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.899 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.804 
=> Acc: 0.759 Precision 0.759 Recall 0.759 F1 0.698 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.920 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.919 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.804 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.862 
=> Acc: 0.778 Precision 0.778 Recall 0.778 F1 0.780 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.772 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.928 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.841 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.980 


accs [0.902633679169992, 0.8405889884763125, 0.7586484312148029, 0.9192037470725996, 0.924901185770751, 0.8215827338129497, 0.8691489361702127, 0.7783203125, 0.8005502063273727, 0.9281481481481482, 0.8458188153310104, 0.980649188514357]
 precisions [0.9010375099760575, 0.852752880921895, 0.7739340305711987, 0.9215456674473068, 0.916205533596838, 0.818705035971223, 0.8276595744680851, 0.7672526041666666, 0.7998624484181568, 0.9348148148148148, 0.8466898954703833, 0.9906367041198502]
 recalls [0.9074221867517956, 0.8201024327784892, 0.7795655671761866, 0.905152224824356, 0.9193675889328063, 0.8273381294964028, 0.8553191489361702, 0.7718098958333334, 0.8033012379642366, 0.9251851851851852, 0.8571428571428571, 0.9887640449438202]
 f1scores [0.9005408087405578, 0.8214072231525886, 0.7210008236898836, 0.910576291721017, 0.9173694968850551, 0.795898750769221, 0.8484530704589737, 0.7719225087744885, 0.7877530779782832, 0.927066985470643, 0.8363021684642185, 0.9871631659495581]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.899 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.818 
=> Acc: 0.797 Precision 0.797 Recall 0.797 F1 0.719 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.908 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.827 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.866 
=> Acc: 0.724 Precision 0.724 Recall 0.724 F1 0.711 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.848 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.838 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.876 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.940 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.948 


accs [0.902633679169992, 0.8463508322663252, 0.7972646822204345, 0.9074941451990632, 0.841106719367589, 0.879136690647482, 0.7244680851063829, 0.8518880208333334, 0.8569463548830811, 0.9703703703703703, 0.8763066202090593, 0.9388264669163545, 0.9467084639498433]
 precisions [0.9185953711093376, 0.8277848911651728, 0.7996781979082864, 0.8981264637002342, 0.8395256916996048, 0.8661870503597122, 0.6957446808510638, 0.8404947916666666, 0.859697386519945, 0.9644444444444444, 0.8641114982578397, 0.9531835205992509, 0.94858934169279]
 recalls [0.9337589784517158, 0.8514724711907811, 0.7924376508447305, 0.9028103044496487, 0.8403162055335969, 0.8920863309352518, 0.7085106382978723, 0.8411458333333334, 0.844566712517194, 0.9681481481481482, 0.8658536585365854, 0.9444444444444444, 0.9467084639498433]
 f1scores [0.9201306189248539, 0.8221853680641814, 0.6937917732668002, 0.891252835045403, 0.8203293657014529, 0.8890225039978837, 0.7104807860342397, 0.8361262293969913, 0.8085178920722456, 0.9555661968011716, 0.8628621445701089, 0.9434566102361197, 0.94979713061291]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.917 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.818 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.714 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.813 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.884 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.869 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.814 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.842 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.813 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.849 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.959 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.934 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.890 


accs [0.9201915403032721, 0.8457106274007683, 0.7851971037811746, 0.8290398126463701, 0.8853754940711462, 0.8892086330935252, 0.8180851063829787, 0.8430989583333334, 0.8370013755158184, 0.945925925925926, 0.8536585365853658, 0.9581772784019975, 0.9335423197492163, 0.8957169459962756]
 precisions [0.9265762170790104, 0.8418693982074263, 0.8004827031375704, 0.8477751756440282, 0.8853754940711462, 0.902158273381295, 0.8361702127659575, 0.8509114583333334, 0.8480055020632737, 0.9414814814814815, 0.8571428571428571, 0.9488139825218477, 0.9222570532915361, 0.8910614525139665]
 recalls [0.9090183559457302, 0.8425096030729834, 0.7996781979082864, 0.8583138173302107, 0.8766798418972332, 0.9136690647482014, 0.8202127659574469, 0.841796875, 0.8301237964236589, 0.9503703703703704, 0.8684668989547039, 0.9550561797752809, 0.9297805642633229, 0.8966480446927374]
 f1scores [0.9286395699848974, 0.8334033859150386, 0.7016483153640574, 0.8438864790293398, 0.8721364415164595, 0.8907344007810041, 0.8065497257896996, 0.8396409066878668, 0.8107731489439132, 0.9455751993188887, 0.855761846465111, 0.9462334186566681, 0.929995169638822, 0.8613335815967433]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.895 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.800 
=> Acc: 0.665 Precision 0.665 Recall 0.665 F1 0.581 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.795 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.865 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.826 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.838 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.763 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.846 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.928 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.861 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.966 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.900 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.852 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.888 


accs [0.8994413407821229, 0.8329065300896287, 0.6645213193885761, 0.8091334894613583, 0.8687747035573122, 0.8589928057553957, 0.851063829787234, 0.7740885416666666, 0.8638239339752407, 0.9288888888888889, 0.8667247386759582, 0.9650436953807741, 0.9015673981191222, 0.861266294227188, 0.8851236868858015]
 precisions [0.8994413407821229, 0.8380281690140845, 0.6645213193885761, 0.8243559718969555, 0.866403162055336, 0.860431654676259, 0.823404255319149, 0.7854817708333334, 0.8418156808803301, 0.9192592592592592, 0.8658536585365854, 0.9744069912609239, 0.8846394984326019, 0.8677839851024208, 0.8851236868858015]
 recalls [0.8994413407821229, 0.8604353393085787, 0.6492357200321802, 0.8372365339578455, 0.8790513833992095, 0.8532374100719424, 0.8106382978723404, 0.7854817708333334, 0.8638239339752407, 0.9392592592592592, 0.85801393728223, 0.9656679151061174, 0.8946708463949843, 0.8584729981378026, 0.883429345984412]
 f1scores [0.8988649186533488, 0.8051701691754845, 0.573005921383581, 0.8130480246197397, 0.8793770345699403, 0.8140040599587346, 0.819318365311069, 0.7674967938610037, 0.8608509647938822, 0.9301060251673373, 0.8599144946550984, 0.9718873298616065, 0.8918903545983374, 0.8446726873324284, 0.8807600239079487]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.873 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.862 
=> Acc: 0.634 Precision 0.634 Recall 0.634 F1 0.561 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.810 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.899 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.858 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.820 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.840 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.865 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.747 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.906 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.865 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.883 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 


accs [0.8770949720670391, 0.8783610755441741, 0.6339501206757844, 0.8313817330210773, 0.9019762845849802, 0.8762589928057554, 0.824468085106383, 0.8408203125, 0.8817056396148556, 0.9333333333333333, 0.7552264808362369, 0.9800249687890137, 0.9040752351097179, 0.8752327746741154, 0.8817350050830227, 0.9744034707158351]
 precisions [0.8866719872306464, 0.8732394366197183, 0.6090104585679806, 0.832552693208431, 0.9114624505928853, 0.8762589928057554, 0.8053191489361702, 0.8274739583333334, 0.8707015130674003, 0.9251851851851852, 0.7796167247386759, 0.9737827715355806, 0.9009404388714733, 0.8640595903165735, 0.8925787868519146, 0.9787418655097614]
 recalls [0.87390263367917, 0.8713188220230473, 0.6130329847144006, 0.8255269320843092, 0.9043478260869565, 0.8863309352517985, 0.8170212765957446, 0.833984375, 0.8727647867950481, 0.9377777777777778, 0.7534843205574913, 0.9812734082397003, 0.8984326018808777, 0.8594040968342644, 0.8868180277871908, 0.9739696312364425]
 f1scores [0.8887450976001293, 0.849812118480623, 0.575686048754822, 0.8140087850653265, 0.8988012257896789, 0.8179969541610548, 0.8065644546992299, 0.8286734786926946, 0.8468590406774418, 0.9364723173789656, 0.7533562799462526, 0.9740765079250963, 0.8828609558154135, 0.8670479567235011, 0.8914379541308625, 0.9770719968279659]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.881 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.780 
=> Acc: 0.725 Precision 0.725 Recall 0.725 F1 0.671 
=> Acc: 0.623 Precision 0.623 Recall 0.623 F1 0.595 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.760 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.760 
=> Acc: 0.750 Precision 0.750 Recall 0.750 F1 0.737 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.847 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.884 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.937 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.763 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.890 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.861 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.901 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 


accs [0.8842777334397446, 0.8233034571062741, 0.7248592115848753, 0.6229508196721312, 0.7857707509881423, 0.8057553956834532, 0.75, 0.8616536458333334, 0.8920220082530949, 0.9362962962962963, 0.7761324041811847, 0.9631710362047441, 0.8909090909090909, 0.8687150837988827, 0.8993561504574721, 0.9744034707158351, 0.9647577092511013]
 precisions [0.8874700718276137, 0.8418693982074263, 0.7103781174577635, 0.6065573770491803, 0.7857707509881423, 0.8086330935251799, 0.7351063829787234, 0.8483072916666666, 0.8995873452544704, 0.9244444444444444, 0.7900696864111498, 0.9619225967540574, 0.9009404388714733, 0.8696461824953445, 0.8902067095899695, 0.9813449023861172, 0.9691629955947136]
 recalls [0.8890662410215483, 0.8463508322663252, 0.7031375703942075, 0.6194379391100703, 0.7762845849802371, 0.8201438848920863, 0.747872340425532, 0.8463541666666666, 0.9016506189821183, 0.9274074074074075, 0.7874564459930313, 0.9656679151061174, 0.8890282131661442, 0.8538175046554934, 0.9010504913588614, 0.9748373101952278, 0.9743024963289281]
 f1scores [0.8910480868109198, 0.7879686448085194, 0.6722311112283629, 0.5756941611006754, 0.7427748191570778, 0.7872903933730021, 0.7238912426303459, 0.8399024502674208, 0.8916092175656329, 0.9412759408801474, 0.7970854282513345, 0.972218836430217, 0.8984930260514765, 0.8646114139071391, 0.8983789323240945, 0.9776676706960391, 0.9705897527608751]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.856 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.791 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.704 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.702 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.814 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.770 
=> Acc: 0.722 Precision 0.722 Recall 0.722 F1 0.723 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.810 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.826 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.913 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.804 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.973 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.845 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.887 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.870 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.937 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.780 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 


accs [0.8563447725458898, 0.8258642765685019, 0.7843925985518906, 0.7423887587822015, 0.825296442687747, 0.8086330935251799, 0.7223404255319149, 0.8255208333333334, 0.844566712517194, 0.9125925925925926, 0.813588850174216, 0.9719101123595506, 0.8514106583072101, 0.8938547486033519, 0.865130464249407, 0.9388286334056399, 0.8120411160058737, 0.9822294022617124]
 precisions [0.8715083798882681, 0.8271446862996159, 0.7602574416733708, 0.7189695550351288, 0.8205533596837945, 0.8043165467625899, 0.7074468085106383, 0.8310546875, 0.8370013755158184, 0.9222222222222223, 0.8013937282229965, 0.9719101123595506, 0.8539184952978056, 0.8677839851024208, 0.85191460521857, 0.9370932754880694, 0.8230543318649045, 0.9822294022617124]
 recalls [0.8459696727853152, 0.8322663252240717, 0.7731295253419147, 0.7177985948477752, 0.8466403162055336, 0.8, 0.7202127659574468, 0.8271484375, 0.827372764786795, 0.9051851851851852, 0.8397212543554007, 0.9712858926342073, 0.8664576802507837, 0.8798882681564246, 0.8739410369366316, 0.9362255965292842, 0.8149779735682819, 0.9822294022617124]
 f1scores [0.8507128053766918, 0.7998593638271678, 0.7080676298474651, 0.7190702470018152, 0.8232075866071394, 0.7818155866473225, 0.7260388934761893, 0.8057002624189012, 0.8029535964682306, 0.9064516132389642, 0.8310234920644272, 0.9692996377960238, 0.8567358175860524, 0.8690355135363396, 0.8787102499234054, 0.9291388400664606, 0.7908852302465988, 0.9827925802502527]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.812 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.780 
=> Acc: 0.681 Precision 0.681 Recall 0.681 F1 0.609 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.752 
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.728 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.772 
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.742 
=> Acc: 0.783 Precision 0.783 Recall 0.783 F1 0.770 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.883 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.936 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.814 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.851 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.846 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.855 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.971 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.821 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.924 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.888 


accs [0.819632881085395, 0.8181818181818182, 0.6814159292035398, 0.7857142857142857, 0.7747035573122529, 0.8043165467625899, 0.7531914893617021, 0.783203125, 0.8892709766162311, 0.9362962962962963, 0.8196864111498258, 0.9606741573033708, 0.8545454545454545, 0.8556797020484171, 0.8471704506946798, 0.9718004338394793, 0.8274596182085169, 0.9224555735056543, 0.8885898815931109]
 precisions [0.8435754189944135, 0.8149807938540333, 0.6637168141592921, 0.7740046838407494, 0.7675889328063241, 0.8244604316546763, 0.7446808510638298, 0.7666015625, 0.8927097661623109, 0.9348148148148148, 0.8214285714285714, 0.9694132334581773, 0.8557993730407524, 0.8324022346368715, 0.8336157234835649, 0.9787418655097614, 0.8465491923641704, 0.9240710823909531, 0.8864370290635092]
 recalls [0.8475658419792498, 0.8156209987195903, 0.66532582461786, 0.7634660421545667, 0.7438735177865613, 0.8244604316546763, 0.75, 0.7799479166666666, 0.890646492434663, 0.9355555555555556, 0.8336236933797909, 0.9700374531835206, 0.8583072100313479, 0.8212290502793296, 0.8397153507285666, 0.975704989154013, 0.8436123348017621, 0.9547657512116317, 0.8815931108719053]
 f1scores [0.8260020564137227, 0.7651145379237656, 0.5842584910223645, 0.7082188998878409, 0.7084979265529477, 0.7778661018970132, 0.7329344324502509, 0.7598056537384723, 0.8720192550299345, 0.9270973635391652, 0.7856854211553638, 0.9720984148375076, 0.8594590031964143, 0.8604520619851572, 0.861850946211826, 0.9805620108587295, 0.8199697493090812, 0.9316310348146708, 0.8928064783867049]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.880 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.780 
=> Acc: 0.733 Precision 0.733 Recall 0.733 F1 0.670 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.713 
=> Acc: 0.701 Precision 0.701 Recall 0.701 F1 0.650 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.781 
=> Acc: 0.645 Precision 0.645 Recall 0.645 F1 0.615 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.792 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.887 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.934 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.801 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.947 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.798 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.832 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.890 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.822 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.893 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.890 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.923 


accs [0.8818834796488427, 0.8181818181818182, 0.7329042638777152, 0.7400468384074942, 0.7011857707509881, 0.8100719424460432, 0.6446808510638298, 0.8157552083333334, 0.8995873452544704, 0.9340740740740741, 0.8057491289198606, 0.9463171036204744, 0.7893416927899687, 0.8389199255121043, 0.8891901050491359, 0.9596529284164859, 0.8267254038179148, 0.8917609046849758, 0.891280947255113, 0.9243697478991597]
 precisions [0.8922585794094174, 0.822663252240717, 0.7240547063555913, 0.7517564402810304, 0.7225296442687748, 0.8172661870503597, 0.6659574468085107, 0.8092447916666666, 0.8865199449793673, 0.9288888888888889, 0.7926829268292683, 0.9438202247191011, 0.780564263322884, 0.8426443202979516, 0.891562182311081, 0.9557483731019523, 0.8406754772393539, 0.9046849757673667, 0.8902045209903121, 0.9299719887955182]
 recalls [0.8675179569034318, 0.8201024327784892, 0.7264682220434433, 0.7365339578454333, 0.7343873517786561, 0.837410071942446, 0.6414893617021277, 0.81640625, 0.874828060522696, 0.942962962962963, 0.7970383275261324, 0.9456928838951311, 0.7836990595611285, 0.8435754189944135, 0.8902067095899695, 0.9531453362255965, 0.8619676945668135, 0.9063004846526656, 0.8918191603875134, 0.9187675070028011]
 f1scores [0.8802312160627148, 0.7784490646679258, 0.679401140761154, 0.7083916817310631, 0.6538479012308707, 0.7984979807236392, 0.6145626878031842, 0.7847830686127448, 0.8833616132293244, 0.9435524842426108, 0.8019023841273396, 0.9451693184327663, 0.7942782775142837, 0.8326647652249971, 0.8983721798168596, 0.9535076727476032, 0.8334863287332845, 0.8809063067806919, 0.8969469883691736, 0.9196881924149076]
done w/ time
All done
