Current date and time 
##### START task 10000 grs #####
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.9983291562238931]
 precisions [0.9974937343358395]
 recalls [0.9974937343358395]
 f1scores [0.9992112505482817]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.9791144527986633, 0.998422712933754]
 precisions [0.9799498746867168, 1.0]
 recalls [0.9782790309106099, 1.0]
 f1scores [0.9818196492290536, 1.0]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 


accs [0.9816207184628237, 0.9463722397476341, 0.9495677233429395]
 precisions [0.9799498746867168, 0.9558359621451105, 0.9502881844380403]
 recalls [0.9807852965747702, 0.9305993690851735, 0.9546109510086456]
 f1scores [0.9826811130180072, 0.9498480565127412, 0.9508356028176597]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.959 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.896 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.852 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.939 


accs [0.9582289055973267, 0.8927444794952681, 0.8479827089337176, 0.9397217928902627]
 precisions [0.9440267335004177, 0.8943217665615142, 0.8530259365994236, 0.9466769706336939]
 recalls [0.9532163742690059, 0.8958990536277602, 0.850864553314121, 0.9505409582689336]
 f1scores [0.960118018303526, 0.9037222999701198, 0.8486931973004216, 0.9544645662499459]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.949 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.924 
=> Acc: 0.665 Precision 0.665 Recall 0.665 F1 0.662 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.807 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 


accs [0.948203842940685, 0.9211356466876972, 0.6649855907780979, 0.8160741885625966, 0.9911764705882353]
 precisions [0.948203842940685, 0.889589905362776, 0.6563400576368876, 0.8191653786707882, 0.9860294117647059]
 recalls [0.9456975772765246, 0.9227129337539433, 0.6779538904899135, 0.8021638330757341, 0.9845588235294118]
 f1scores [0.9462393616673825, 0.9277134433757478, 0.6584418790639704, 0.7921587214550377, 0.9874676221621872]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.950 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.889 
=> Acc: 0.728 Precision 0.728 Recall 0.728 F1 0.715 
=> Acc: 0.720 Precision 0.720 Recall 0.720 F1 0.715 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.937 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.882 


accs [0.948203842940685, 0.886435331230284, 0.7276657060518732, 0.7202472952086554, 0.9382352941176471, 0.8876889848812095]
 precisions [0.9456975772765246, 0.8785488958990536, 0.7348703170028819, 0.7225656877897991, 0.9536764705882353, 0.896328293736501]
 recalls [0.9699248120300752, 0.8769716088328076, 0.7536023054755043, 0.7217928902627512, 0.9595588235294118, 0.8768898488120951]
 f1scores [0.9512394895182716, 0.8828158290491285, 0.7062852837186757, 0.7039313611292723, 0.9497891492529359, 0.8759520167697472]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.859 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.934 
=> Acc: 0.781 Precision 0.781 Recall 0.781 F1 0.789 
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.772 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.972 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.823 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 


accs [0.8738512949039264, 0.9353312302839116, 0.7809798270893372, 0.7712519319938176, 0.9727941176470588, 0.8315334773218143, 0.993050193050193]
 precisions [0.8521303258145363, 0.9242902208201893, 0.7687319884726225, 0.7465224111282844, 0.9683823529411765, 0.8207343412526998, 0.9938223938223938]
 recalls [0.8680033416875522, 0.9321766561514195, 0.7492795389048992, 0.7550231839258115, 0.9661764705882353, 0.8336933045356372, 0.993050193050193]
 f1scores [0.8426501477974758, 0.9307070236648336, 0.7895257383828491, 0.7396262765975448, 0.9671873811046542, 0.8113623058616952, 0.9953566148552684]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.936 
=> Acc: 0.741 Precision 0.741 Recall 0.741 F1 0.725 
=> Acc: 0.733 Precision 0.733 Recall 0.733 F1 0.738 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.759 
=> Acc: 0.756 Precision 0.756 Recall 0.756 F1 0.743 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.930 


accs [0.9598997493734336, 0.9353312302839116, 0.7413544668587896, 0.7333848531684699, 0.7897058823529411, 0.755939524838013, 0.9907335907335907, 0.9387755102040817]
 precisions [0.9507101086048454, 0.9022082018927445, 0.734149855907781, 0.7217928902627512, 0.8073529411764706, 0.8207343412526998, 0.9899613899613899, 0.9519807923169268]
 recalls [0.9532163742690059, 0.9258675078864353, 0.7219020172910663, 0.740340030911901, 0.8014705882352942, 0.8012958963282938, 0.9837837837837838, 0.9471788715486195]
 f1scores [0.9452222631419224, 0.925154913623623, 0.7143792817145566, 0.7311362015842637, 0.7667183101628277, 0.7563746004553725, 0.9817576684537167, 0.9223442092431219]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 33 34 35 36 37 38 39]
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.919 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.896 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.806 
=> Acc: 0.730 Precision 0.730 Recall 0.730 F1 0.730 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.769 
=> Acc: 0.639 Precision 0.639 Recall 0.639 F1 0.563 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.899 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.923 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.984 


accs [0.9223057644110275, 0.8990536277602523, 0.8040345821325648, 0.7295208655332303, 0.7911764705882353, 0.6393088552915767, 0.8965250965250965, 0.9243697478991597, 0.9847494553376906]
 precisions [0.9172932330827067, 0.8848580441640379, 0.8249279538904899, 0.7480680061823802, 0.7970588235294118, 0.6241900647948164, 0.8849420849420849, 0.9267707082833133, 0.9945533769063181]
 recalls [0.9264828738512949, 0.88801261829653, 0.787463976945245, 0.723338485316847, 0.799264705882353, 0.6479481641468683, 0.8864864864864865, 0.936374549819928, 0.9934640522875817]
 f1scores [0.8968038941394264, 0.8987170248070477, 0.803705409055483, 0.7180441646271908, 0.759015712970495, 0.5649894768647308, 0.8972120557388308, 0.9039002901397749, 0.9934099023060445]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.942 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.850 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.829 
=> Acc: 0.718 Precision 0.718 Recall 0.718 F1 0.721 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.890 
=> Acc: 0.741 Precision 0.741 Recall 0.741 F1 0.715 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.862 
=> Acc: 0.683 Precision 0.683 Recall 0.683 F1 0.634 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.957 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.883 


accs [0.9423558897243107, 0.8564668769716088, 0.8249279538904899, 0.7179289026275116, 0.8985294117647059, 0.7408207343412527, 0.8671814671814672, 0.6830732292917167, 0.9586056644880174, 0.8880208333333334]
 precisions [0.9465329991645781, 0.8659305993690851, 0.8234870317002881, 0.7256568778979907, 0.9022058823529412, 0.7105831533477321, 0.8540540540540541, 0.6458583433373349, 0.9727668845315904, 0.8858506944444444]
 recalls [0.9565580618212197, 0.8753943217665615, 0.8105187319884726, 0.740340030911901, 0.8955882352941177, 0.7041036717062635, 0.8625482625482626, 0.7118847539015606, 0.9662309368191722, 0.8810763888888888]
 f1scores [0.9519168963740536, 0.8710357887327982, 0.8201267351915889, 0.7103926411843982, 0.872214619162221, 0.687129203837507, 0.8462849793920162, 0.6180301678217855, 0.9764174761471484, 0.8830346998721297]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.877 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.832 
=> Acc: 0.720 Precision 0.720 Recall 0.720 F1 0.729 
=> Acc: 0.679 Precision 0.679 Recall 0.679 F1 0.684 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.769 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.733 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.918 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.802 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.854 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.969 


accs [0.8822055137844611, 0.8296529968454258, 0.7197406340057637, 0.6792890262751159, 0.8058823529411765, 0.7494600431965442, 0.918918918918919, 0.8367346938775511, 0.9368191721132898, 0.8693576388888888, 0.9667774086378738]
 precisions [0.8805346700083542, 0.8817034700315457, 0.7038904899135446, 0.7009273570324575, 0.8051470588235294, 0.734341252699784, 0.9135135135135135, 0.8223289315726291, 0.9357298474945533, 0.8732638888888888, 0.9800664451827242]
 recalls [0.8696741854636592, 0.8485804416403786, 0.7262247838616714, 0.7032457496136012, 0.8294117647058824, 0.7321814254859611, 0.9127413127413128, 0.8547418967587035, 0.9411764705882353, 0.8671875, 0.9966777408637874]
 f1scores [0.8802921191336667, 0.8196953172508377, 0.723805687829942, 0.696751663869539, 0.7816876379712057, 0.7367179566426774, 0.9219092063756434, 0.8119949991524212, 0.9253575424025167, 0.8471100641483084, 0.96442198646424]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 33 34 35 36 37 38 39 40 41 43 44 45 46 47 48 49
 50 51 52 53]
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.889 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.843 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.743 
=> Acc: 0.736 Precision 0.736 Recall 0.736 F1 0.738 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.927 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.753 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.799 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.716 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.858 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.819 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.825 


accs [0.8947368421052632, 0.8454258675078864, 0.7420749279538905, 0.7364760432766615, 0.9294117647058824, 0.7624190064794817, 0.8023166023166023, 0.7719087635054022, 0.9368191721132898, 0.8693576388888888, 0.8571428571428571, 0.8427222403126018]
 precisions [0.8913951545530493, 0.8343848580441641, 0.7046109510086456, 0.7210200927357032, 0.9308823529411765, 0.6954643628509719, 0.8115830115830116, 0.7430972388955582, 0.9368191721132898, 0.8862847222222222, 0.867109634551495, 0.8420709866492999]
 recalls [0.8989139515455304, 0.8406940063091483, 0.7449567723342939, 0.7534775888717156, 0.9338235294117647, 0.7062634989200864, 0.8324324324324325, 0.7767106842737095, 0.9335511982570807, 0.8524305555555556, 0.8172757475083057, 0.836860957342885]
 f1scores [0.8834434326179608, 0.8336844016060049, 0.7263343881739723, 0.7316695802548769, 0.9251230649292793, 0.7313683557258797, 0.8335501833143507, 0.6962254008759301, 0.9277335191623436, 0.8446218261263786, 0.7833876013683553, 0.822427613036807]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
 49 50 51 53 54 55 56 57 58 59]
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.923 
=> Acc: 0.768 Precision 0.768 Recall 0.768 F1 0.755 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.850 
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.751 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.804 
=> Acc: 0.706 Precision 0.706 Recall 0.706 F1 0.689 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.926 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.762 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.947 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.855 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.827 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.862 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 


accs [0.9256474519632414, 0.7681388012618297, 0.8487031700288185, 0.7542503863987635, 0.8191176470588235, 0.7062634989200864, 0.9243243243243243, 0.7899159663865546, 0.9466230936819172, 0.86328125, 0.8305647840531561, 0.873005535656138, 0.973547472838923]
 precisions [0.9197994987468672, 0.749211356466877, 0.829250720461095, 0.7349304482225657, 0.8014705882352942, 0.673866090712743, 0.9158301158301159, 0.7887154861944778, 0.9433551198257081, 0.8394097222222222, 0.8704318936877077, 0.8746336698143927, 0.9759093056211621]
 recalls [0.923141186299081, 0.7917981072555205, 0.8342939481268011, 0.7295208655332303, 0.7970588235294118, 0.6954643628509719, 0.9142857142857143, 0.7839135654261705, 0.9411764705882353, 0.8611111111111112, 0.8770764119601329, 0.8677955063497232, 0.9806329711856401]
 f1scores [0.9168813523330023, 0.7937977476971891, 0.8483194880341568, 0.7321212445629628, 0.7845278474719315, 0.6754761095561392, 0.9067469513290106, 0.7502848631239549, 0.9560473680051806, 0.8397029196255584, 0.847746580413542, 0.857329567065087, 0.9809250881284697]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 40 41 42 43 44 45 46 47 48
 49 50 51 52 53 54 55 56 58 59 60 61 62 63 64]
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.729 
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.793 
=> Acc: 0.680 Precision 0.680 Recall 0.680 F1 0.678 
=> Acc: 0.657 Precision 0.657 Recall 0.657 F1 0.649 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.795 
=> Acc: 0.657 Precision 0.657 Recall 0.657 F1 0.581 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.884 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.764 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.924 
=> Acc: 0.739 Precision 0.739 Recall 0.739 F1 0.715 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.913 
=> Acc: 0.692 Precision 0.692 Recall 0.692 F1 0.630 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.975 


accs [0.7786131996658312, 0.7933753943217665, 0.6801152737752162, 0.6568778979907264, 0.8397058823529412, 0.6565874730021598, 0.8857142857142857, 0.7863145258103241, 0.9237472766884531, 0.7387152777777778, 0.9169435215946844, 0.6919570172582221, 0.9560699102503543, 0.9757174392935982]
 precisions [0.7802840434419381, 0.8264984227129337, 0.707492795389049, 0.6561051004636785, 0.8455882352941176, 0.6328293736501079, 0.8849420849420849, 0.8055222088835534, 0.9324618736383442, 0.7612847222222222, 0.8970099667774086, 0.6815369586453924, 0.9579593764761455, 0.9381898454746137]
 recalls [0.7827903091060986, 0.8249211356466877, 0.6959654178674352, 0.6591962905718701, 0.8213235294117647, 0.6587473002159827, 0.8864864864864865, 0.8079231692677071, 0.9291938997821351, 0.7369791666666666, 0.9102990033222591, 0.6906545099316184, 0.9537080774681153, 0.9492273730684326]
 f1scores [0.7212567059415391, 0.8134362274201203, 0.6844946734157396, 0.6480121743926255, 0.7703385390192424, 0.5441504946057996, 0.890746968167125, 0.7816561012361529, 0.9562302191817821, 0.716323393330893, 0.9037455196872781, 0.6202641547338936, 0.9564786801887039, 0.9627024008933557]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24
 25 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 68 69]
=> Acc: 0.770 Precision 0.770 Recall 0.770 F1 0.711 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.819 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.806 
=> Acc: 0.697 Precision 0.697 Recall 0.697 F1 0.677 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.930 
=> Acc: 0.620 Precision 0.620 Recall 0.620 F1 0.544 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.866 
=> Acc: 0.666 Precision 0.666 Recall 0.666 F1 0.610 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.908 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.851 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.788 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.765 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.941 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.760 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 


accs [0.7702589807852965, 0.8296529968454258, 0.8054755043227666, 0.6970633693972179, 0.9294117647058824, 0.6198704103671706, 0.871042471042471, 0.6662665066026411, 0.9128540305010894, 0.8667534722222222, 0.7906976744186046, 0.7883425594268968, 0.9404818138875768, 0.8344370860927153, 0.9680851063829787]
 precisions [0.7635756056808688, 0.8375394321766562, 0.8090778097982709, 0.7194744976816074, 0.9477941176470588, 0.6630669546436285, 0.8810810810810811, 0.680672268907563, 0.9139433551198257, 0.8641493055555556, 0.8205980066445183, 0.8000651253663302, 0.9352857817666509, 0.7770419426048565, 0.983451536643026]
 recalls [0.7652464494569757, 0.8264984227129337, 0.8004322766570605, 0.7241112828438949, 0.9286764705882353, 0.6479481641468683, 0.8633204633204633, 0.6782713085234093, 0.9041394335511983, 0.8767361111111112, 0.8006644518272426, 0.7730380983393031, 0.9338686820973076, 0.8101545253863135, 0.9775413711583925]
 f1scores [0.7008526032179542, 0.7831242481603846, 0.8145285655089219, 0.6984346211052126, 0.9304608917844039, 0.5385794484321125, 0.8548977342309788, 0.6331892556248786, 0.9040450053478282, 0.8378876137502781, 0.8241616202303419, 0.7330363924556959, 0.947116200694655, 0.7322195927387749, 0.9815353254706507]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 20 21 22 23 24
 25 26 27 29 30 32 33 34 35 36 37 38 39 40 41 43 44 45 46 47 48 49 50 51
 52 53 54 55 56 58 59 60 61 62 63 64 65 66 68 69 71 72 73 74]
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.884 
=> Acc: 0.680 Precision 0.680 Recall 0.680 F1 0.666 
=> Acc: 0.702 Precision 0.702 Recall 0.702 F1 0.661 
=> Acc: 0.722 Precision 0.722 Recall 0.722 F1 0.703 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.848 
=> Acc: 0.590 Precision 0.590 Recall 0.590 F1 0.512 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.870 
=> Acc: 0.760 Precision 0.760 Recall 0.760 F1 0.717 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.920 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.808 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.827 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.704 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.911 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.729 
=> Acc: 0.800 Precision 0.800 Recall 0.800 F1 0.791 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 


accs [0.8897243107769424, 0.6798107255520505, 0.7017291066282421, 0.7217928902627512, 0.8610294117647059, 0.5896328293736501, 0.8694980694980695, 0.7599039615846338, 0.9215686274509803, 0.8133680555555556, 0.8305647840531561, 0.7258222077499186, 0.911195087387813, 0.7880794701986755, 0.8002364066193853, 0.943024861878453]
 precisions [0.8989139515455304, 0.667192429022082, 0.7053314121037464, 0.6993817619783617, 0.8485294117647059, 0.6069114470842333, 0.877992277992278, 0.7815126050420168, 0.9074074074074074, 0.8098958333333334, 0.8438538205980066, 0.7144252686421361, 0.908833254605574, 0.7836644591611479, 0.8132387706855791, 0.9388812154696132]
 recalls [0.8880534670008354, 0.6293375394321766, 0.6952449567723343, 0.6877897990726429, 0.8330882352941177, 0.6436285097192225, 0.8733590733590734, 0.7527010804321729, 0.9117647058823529, 0.796875, 0.813953488372093, 0.7297297297297297, 0.9196976854038734, 0.7262693156732892, 0.8085106382978723, 0.9437154696132597]
 f1scores [0.8887031244220726, 0.670111370229926, 0.6546259670786719, 0.6974177833039857, 0.8190609552190711, 0.573693962070372, 0.8669137295084652, 0.7202039634008165, 0.9078496184104617, 0.7987868091648029, 0.8718593303657995, 0.6891825620538057, 0.9088154972770722, 0.7282651473013393, 0.7853489210842498, 0.935288334191257]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 43 44 45 46 47 48
 49 50 51 52 53 54 55 56 57 58 59 61 63 64 65 66 67 70 71 73 74 75 76 77
 78 79]
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.949 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.794 
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.742 
=> Acc: 0.711 Precision 0.711 Recall 0.711 F1 0.687 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.904 
=> Acc: 0.650 Precision 0.650 Recall 0.650 F1 0.603 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.810 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.723 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.905 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.801 
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.767 
=> Acc: 0.685 Precision 0.685 Recall 0.685 F1 0.666 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.880 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.879 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.744 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.879 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 


accs [0.9540517961570593, 0.8012618296529969, 0.7427953890489913, 0.7109737248840804, 0.9066176470588235, 0.6501079913606912, 0.8138996138996138, 0.7647058823529411, 0.9030501089324618, 0.8107638888888888, 0.770764119601329, 0.6851188537935526, 0.8771846953235711, 0.8807947019867549, 0.7494089834515366, 0.881560773480663, 0.973908111174135]
 precisions [0.9640768588137009, 0.805993690851735, 0.7550432276657061, 0.7210200927357032, 0.9205882352941176, 0.67170626349892, 0.8216216216216217, 0.7490996398559424, 0.9041394335511983, 0.8133680555555556, 0.760797342192691, 0.6887007489417128, 0.8587623996221068, 0.8543046357615894, 0.7541371158392435, 0.8777624309392266, 0.9795802609188883]
 recalls [0.9640768588137009, 0.8186119873817035, 0.7521613832853026, 0.7063369397217929, 0.9095588235294118, 0.652267818574514, 0.8123552123552124, 0.7563025210084033, 0.9172113289760349, 0.8125, 0.8106312292358804, 0.7040052100293064, 0.8705715635333019, 0.8410596026490066, 0.7446808510638298, 0.8843232044198895, 0.9750425411230856]
 f1scores [0.9483839588679291, 0.8233198597910987, 0.7210459047721282, 0.7064445345321735, 0.9086297828214202, 0.6415802601054598, 0.79811146901447, 0.7449973696552733, 0.9112623745390367, 0.8106722196866085, 0.7705895721230678, 0.6796087862780678, 0.8600746224157121, 0.8549581833124715, 0.7499899051838422, 0.87514714986484, 0.9758988321836007]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18 19 20 21 22 23 24 25
 26 27 29 30 31 32 33 34 36 37 38 39 40 41 43 44 45 47 48 49 50 52 53 54
 55 56 58 59 61 62 63 64 65 66 68 69 70 71 72 73 74 75 76 78 79 80 81 82
 84]
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.862 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.831 
=> Acc: 0.700 Precision 0.700 Recall 0.700 F1 0.684 
=> Acc: 0.683 Precision 0.683 Recall 0.683 F1 0.672 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.840 
=> Acc: 0.650 Precision 0.650 Recall 0.650 F1 0.588 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.822 
=> Acc: 0.694 Precision 0.694 Recall 0.694 F1 0.646 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.920 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.784 
=> Acc: 0.708 Precision 0.708 Recall 0.708 F1 0.698 
=> Acc: 0.704 Precision 0.704 Recall 0.704 F1 0.682 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.887 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.802 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.823 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.804 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.718 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.930 


accs [0.8771929824561403, 0.8343848580441641, 0.6995677233429395, 0.6831530139103554, 0.8433823529411765, 0.6501079913606912, 0.8223938223938224, 0.6938775510204082, 0.920479302832244, 0.7916666666666666, 0.707641196013289, 0.7036795831976554, 0.8852149267831837, 0.8300220750551877, 0.817966903073286, 0.801450276243094, 0.7855927396483268, 0.9318712085860943]
 precisions [0.885547201336675, 0.8170347003154574, 0.7363112391930836, 0.625193199381762, 0.8470588235294118, 0.6673866090712743, 0.8223938223938224, 0.6818727490996399, 0.9357298474945533, 0.7886284722222222, 0.6511627906976745, 0.7206121784435038, 0.8951346244685876, 0.8145695364238411, 0.8191489361702128, 0.8090469613259669, 0.7941009642654566, 0.9300046663555763]
 recalls [0.8880534670008354, 0.8217665615141956, 0.6988472622478387, 0.6646058732612056, 0.8595588235294118, 0.673866090712743, 0.8185328185328186, 0.6866746698679472, 0.9215686274509803, 0.7690972222222222, 0.6511627906976745, 0.7163790296320417, 0.894189891355692, 0.7991169977924945, 0.7706855791962175, 0.8000690607734806, 0.8048780487804879, 0.9407372841810546]
 f1scores [0.8635540471668858, 0.8121188793210754, 0.6934191344849365, 0.6343889693580864, 0.8619054501205767, 0.5982559530562311, 0.831552743146692, 0.6611040278759578, 0.911540997580621, 0.764804566022991, 0.6540479463250446, 0.6791730210506837, 0.8947711099283818, 0.784185209567698, 0.7864408697317273, 0.8069305436362818, 0.7218704020505271, 0.9198944234349673]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 18 19 20 21 22 23 24 25 26
 27 28 29 30 31 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 71 72 73 74 75 76 77 78
 79 80 81 82 83 84 87 89]
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.901 
=> Acc: 0.760 Precision 0.760 Recall 0.760 F1 0.748 
=> Acc: 0.761 Precision 0.761 Recall 0.761 F1 0.746 
=> Acc: 0.463 Precision 0.463 Recall 0.463 F1 0.422 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.892 
=> Acc: 0.657 Precision 0.657 Recall 0.657 F1 0.623 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.811 
=> Acc: 0.655 Precision 0.655 Recall 0.655 F1 0.624 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.872 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.807 
=> Acc: 0.658 Precision 0.658 Recall 0.658 F1 0.592 
=> Acc: 0.752 Precision 0.752 Recall 0.752 F1 0.738 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.908 
=> Acc: 0.658 Precision 0.658 Recall 0.658 F1 0.626 
=> Acc: 0.734 Precision 0.734 Recall 0.734 F1 0.711 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.872 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.896 
=> Acc: 0.411 Precision 0.411 Recall 0.411 F1 0.234 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.915 


accs [0.9047619047619048, 0.7602523659305994, 0.760806916426513, 0.46290571870170016, 0.8948529411764706, 0.6565874730021598, 0.8115830115830116, 0.6554621848739496, 0.8747276688453159, 0.8138020833333334, 0.6578073089700996, 0.7518723542819928, 0.9055266887104393, 0.6578366445916115, 0.7340425531914894, 0.8670580110497238, 0.9018718094157686, 0.4111059262715819, 0.9144111192392099]
 precisions [0.8822055137844611, 0.7712933753943217, 0.770893371757925, 0.4899536321483771, 0.8860294117647058, 0.6846652267818575, 0.8455598455598455, 0.6470588235294118, 0.8943355119825708, 0.8172743055555556, 0.6843853820598007, 0.7372191468577011, 0.9154463863958432, 0.6423841059602649, 0.7364066193853428, 0.8622237569060773, 0.8944980147475894, 0.4041063929071395, 0.9231894659839064]
 recalls [0.8822055137844611, 0.7791798107255521, 0.7427953890489913, 0.4752704791344668, 0.8941176470588236, 0.6673866090712743, 0.8162162162162162, 0.6698679471788715, 0.8867102396514162, 0.8233506944444444, 0.6910299003322259, 0.7297297297297297, 0.923004251299008, 0.6821192052980133, 0.7695035460992907, 0.8577348066298343, 0.8808848553601815, 0.3947736817545497, 0.9136795903438186]
 f1scores [0.8937083081479447, 0.7563696310919944, 0.747625293152294, 0.45636651075595375, 0.9101468673568369, 0.6598982739245436, 0.8182169249436259, 0.6292608255952928, 0.9019857235732645, 0.8077678692698947, 0.6425804264068142, 0.7273519990755584, 0.9132854618856875, 0.6278326434673184, 0.7550649765049939, 0.8735739434093812, 0.877922221092304, 0.230856591741133, 0.9199163147268397]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 21 22 23 24 25
 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 43 44 45 47 48 49 50 51
 53 54 55 56 58 59 61 63 65 66 67 70 71 72 73 74 75 76 77 78 79 80 81 83
 84 85 86 87 88 89 90 91 92 94]
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.919 
=> Acc: 0.689 Precision 0.689 Recall 0.689 F1 0.646 
=> Acc: 0.719 Precision 0.719 Recall 0.719 F1 0.681 
=> Acc: 0.611 Precision 0.611 Recall 0.611 F1 0.577 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.898 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.714 
=> Acc: 0.745 Precision 0.745 Recall 0.745 F1 0.728 
=> Acc: 0.623 Precision 0.623 Recall 0.623 F1 0.555 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.820 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.819 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.771 
=> Acc: 0.689 Precision 0.689 Recall 0.689 F1 0.652 
=> Acc: 0.387 Precision 0.387 Recall 0.387 F1 0.253 
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.737 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.809 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.821 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.800 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.787 
=> Acc: 0.713 Precision 0.713 Recall 0.713 F1 0.657 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.958 


accs [0.9164578111946533, 0.6892744479495269, 0.7190201729106628, 0.6105100463678517, 0.9014705882352941, 0.7257019438444925, 0.7451737451737451, 0.6230492196878752, 0.8169934640522876, 0.8389756944444444, 0.7840531561461794, 0.6887007489417128, 0.38734057628719887, 0.7748344370860927, 0.8203309692671394, 0.8142265193370166, 0.8275666477595008, 0.7914139057396173, 0.7132406730065838, 0.9572025052192067]
 precisions [0.9373433583959899, 0.7018927444794952, 0.7471181556195965, 0.5973724884080371, 0.9058823529411765, 0.712742980561555, 0.7351351351351352, 0.6194477791116446, 0.8028322440087146, 0.8276909722222222, 0.8073089700996677, 0.7007489417127971, 0.3826169107227208, 0.8035320088300221, 0.7907801418439716, 0.8214779005524862, 0.8077141236528644, 0.7890807279514699, 0.7008046817849305, 0.9603340292275574]
 recalls [0.9314954051796157, 0.6703470031545742, 0.7435158501440923, 0.606646058732612, 0.9088235294117647, 0.7429805615550756, 0.7444015444015444, 0.6362545018007203, 0.7788671023965141, 0.8315972222222222, 0.7807308970099668, 0.701400195376099, 0.3783656117146906, 0.7947019867549668, 0.8073286052009456, 0.818024861878453, 0.7935337492909813, 0.8007466168922072, 0.7103145574250183, 0.9613778705636743]
 f1scores [0.9341691996954081, 0.6021069526152858, 0.6728379490751898, 0.5695327730941593, 0.8992124772406633, 0.6928255134727717, 0.7268279495589903, 0.558163767091675, 0.7979858066372236, 0.8195563333864125, 0.7675077939762796, 0.6749024000621273, 0.2501774832028389, 0.8013157965375635, 0.7924849406192127, 0.8168506301678347, 0.7822178520498959, 0.7878683065892913, 0.6481315920561324, 0.9657116157055572]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 


accs [0.9833234067897558]
 precisions [0.9827278141751042]
 recalls [0.9839189994044074]
 f1scores [0.9847599902015409]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.904 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.9029184038117928, 0.9915584415584415]
 precisions [0.8999404407385349, 0.9902597402597403]
 recalls [0.8945801072066706, 0.9850649350649351]
 f1scores [0.8960046369345702, 0.9903019442697409]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.856 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 


accs [0.8582489577129243, 0.9551948051948052, 0.9899645808736718]
 precisions [0.8481238832638476, 0.9571428571428572, 0.9935064935064936]
 recalls [0.8648004764740918, 0.9564935064935065, 0.9881936245572609]
 f1scores [0.8534736783209672, 0.9530008659309643, 0.9916399796120619]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.786 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.938 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.7986896962477665, 0.938961038961039, 0.9775678866587958, 1.0]
 precisions [0.8147706968433591, 0.9201298701298701, 0.974025974025974, 1.0]
 recalls [0.8195354377605718, 0.9207792207792208, 0.9787485242030697, 1.0]
 f1scores [0.7954686525484087, 0.9284895390434269, 0.9696634961968564, 1.0]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.784 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.890 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.989 


accs [0.8088147706968434, 0.8909090909090909, 0.9580873671782763, 0.9804878048780488, 0.9896373056994818]
 precisions [0.8010720667063729, 0.8948051948051948, 0.961629279811098, 0.9634146341463414, 1.0]
 recalls [0.790946992257296, 0.8811688311688312, 0.9592680047225501, 0.9707317073170731, 1.0]
 f1scores [0.7847888511065493, 0.8762932384390201, 0.962468611133475, 0.9746156148758667, 0.9852584269662922]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.764 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.942 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.957 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.951 


accs [0.7820131030375224, 0.8974025974025974, 0.9421487603305785, 0.9560975609756097, 0.9689119170984456, 0.9533632286995516]
 precisions [0.7671232876712328, 0.8811688311688312, 0.9474616292798111, 0.9146341463414634, 0.927461139896373, 0.9466367713004484]
 recalls [0.7742703990470519, 0.8818181818181818, 0.9474616292798111, 0.9365853658536586, 0.9378238341968912, 0.9493273542600897]
 f1scores [0.7586835303227851, 0.8739312294607956, 0.9450749054396399, 0.946179224431439, 0.9403032007513177, 0.9385302351754383]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.783 Precision 0.783 Recall 0.783 F1 0.750 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.814 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.924 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.903 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.919 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.976 


accs [0.7832042882668255, 0.8285714285714286, 0.9262101534828807, 0.9365853658536586, 0.9067357512953368, 0.920627802690583, 0.975]
 precisions [0.7814175104228708, 0.8396103896103896, 0.9297520661157025, 0.9609756097560975, 0.9067357512953368, 0.9067264573991032, 0.9863636363636363]
 recalls [0.7766527695056581, 0.8409090909090909, 0.9279811097992916, 0.9634146341463414, 0.9119170984455959, 0.9139013452914798, 0.9727272727272728]
 f1scores [0.7580423363086701, 0.8223944142250035, 0.9312946062121945, 0.948958966676319, 0.905626458868743, 0.9087958421414004, 0.9805445865577571]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 31 32 33 34]
=> Acc: 0.758 Precision 0.758 Recall 0.758 F1 0.745 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.759 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.892 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.759 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.645 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.7581893984514592, 0.7733766233766234, 0.8943329397874853, 0.9512195121951219, 0.7823834196891192, 0.9251121076233184, 0.6988636363636364, 0.9920886075949367]
 precisions [0.7689100655151876, 0.7772727272727272, 0.8931523022432113, 0.9682926829268292, 0.7772020725388601, 0.931390134529148, 0.725, 0.995253164556962]
 recalls [0.7587849910661107, 0.772077922077922, 0.8949232585596222, 0.948780487804878, 0.7461139896373057, 0.9278026905829596, 0.7375, 0.992879746835443]
 f1scores [0.7445022369764891, 0.7567590812056684, 0.9009447507434526, 0.9365081628789438, 0.7725801367891515, 0.9246414122899326, 0.6589803927279754, 0.9904487168891147]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.811 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.748 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.933 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.905 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.839 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.865 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.859 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.934 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.899 


accs [0.8171530673019655, 0.7694805194805194, 0.9344746162927982, 0.9097560975609756, 0.844559585492228, 0.8757847533632287, 0.8636363636363636, 0.9359177215189873, 0.9046052631578947]
 precisions [0.8165574746873139, 0.787012987012987, 0.9297520661157025, 0.875609756097561, 0.8238341968911918, 0.8807174887892377, 0.8534090909090909, 0.9295886075949367, 0.8898026315789473]
 recalls [0.8195354377605718, 0.7779220779220779, 0.9208972845336482, 0.8853658536585366, 0.8031088082901554, 0.8708520179372198, 0.8420454545454545, 0.9311708860759493, 0.9013157894736842]
 f1scores [0.8229963211760847, 0.7519522182362431, 0.9268392559085837, 0.911091267260898, 0.8182581627909254, 0.8696683588096189, 0.8471499994234797, 0.9382432393785933, 0.9117929387504768]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.801 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.813 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.925 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.835 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.768 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.834 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.791 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.847 
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.720 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.932 


accs [0.8052412150089339, 0.8272727272727273, 0.9238488783943329, 0.8634146341463415, 0.8082901554404145, 0.8358744394618834, 0.7954545454545454, 0.8504746835443038, 0.7532894736842105, 0.9343065693430657]
 precisions [0.824895771292436, 0.8383116883116883, 0.9268004722550177, 0.8317073170731707, 0.8134715025906736, 0.8291479820627803, 0.7818181818181819, 0.8512658227848101, 0.7960526315789473, 0.9178832116788321]
 recalls [0.8004764740917213, 0.8097402597402598, 0.9167650531286895, 0.8463414634146341, 0.7512953367875648, 0.8448430493273542, 0.821590909090909, 0.8488924050632911, 0.7911184210526315, 0.9124087591240876]
 f1scores [0.7966292086964019, 0.8275158932149331, 0.9189074718626647, 0.8609984350951126, 0.7410686558289299, 0.834771650071555, 0.8081285410667786, 0.8294599148831365, 0.71110663628448, 0.923997414980772]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.811 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.825 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.906 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.926 
=> Acc: 0.777 Precision 0.777 Recall 0.777 F1 0.771 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.773 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.770 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.821 
=> Acc: 0.748 Precision 0.748 Recall 0.748 F1 0.720 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.867 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.986 


accs [0.8183442525312686, 0.8415584415584415, 0.9049586776859504, 0.9292682926829269, 0.7772020725388601, 0.7757847533632287, 0.7738636363636363, 0.8251582278481012, 0.7483552631578947, 0.8686131386861314, 0.9862637362637363]
 precisions [0.8237045860631328, 0.8045454545454546, 0.9073199527744983, 0.9195121951219513, 0.7927461139896373, 0.7973094170403587, 0.7977272727272727, 0.821993670886076, 0.7598684210526315, 0.8302919708029197, 0.9876373626373627]
 recalls [0.8284693269803455, 0.8201298701298702, 0.9285714285714286, 0.948780487804878, 0.8186528497409327, 0.7914798206278026, 0.8261363636363637, 0.8243670886075949, 0.7713815789473685, 0.8467153284671532, 0.9876373626373627]
 f1scores [0.8067606624880824, 0.7772557658492069, 0.9198139161669433, 0.9517261633286571, 0.831368172748818, 0.7980832763232614, 0.7954127878355199, 0.8130595249401977, 0.7475110159070304, 0.8389006114896074, 0.976298851096975]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
 49 50 51 52 53 54]
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.836 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.813 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.884 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.828 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.790 
=> Acc: 0.658 Precision 0.658 Recall 0.658 F1 0.629 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.767 
=> Acc: 0.748 Precision 0.748 Recall 0.748 F1 0.722 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.856 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 


accs [0.8481238832638476, 0.8253246753246753, 0.884887839433294, 0.9390243902439024, 0.8341968911917098, 0.7955156950672646, 0.6579545454545455, 0.7729430379746836, 0.7483552631578947, 0.8521897810218978, 0.9601648351648352, 0.9833249115715007]
 precisions [0.8433591423466349, 0.8389610389610389, 0.871900826446281, 0.9682926829268292, 0.8290155440414507, 0.8139013452914798, 0.6443181818181818, 0.7832278481012658, 0.7680921052631579, 0.843065693430657, 0.9793956043956044, 0.9833249115715007]
 recalls [0.8463371054198928, 0.827922077922078, 0.8742621015348289, 0.9536585365853658, 0.8238341968911918, 0.8103139013452915, 0.6420454545454546, 0.7935126582278481, 0.7483552631578947, 0.7901459854014599, 0.9725274725274725, 0.9818089944416372]
 f1scores [0.821095057067587, 0.8130375083342098, 0.8575323718523888, 0.9603092775046825, 0.8255785917546294, 0.7965274916690299, 0.6310068365667857, 0.7618686736549537, 0.7398482115254605, 0.8044177640364827, 0.9739915754715891, 0.9813556047482763]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 46 47 48 49
 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.777 Precision 0.777 Recall 0.777 F1 0.760 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.874 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.864 
=> Acc: 0.666 Precision 0.666 Recall 0.666 F1 0.640 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.774 
=> Acc: 0.746 Precision 0.746 Recall 0.746 F1 0.725 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.675 
=> Acc: 0.561 Precision 0.561 Recall 0.561 F1 0.538 
=> Acc: 0.758 Precision 0.758 Recall 0.758 F1 0.718 
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.750 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.910 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.972 


accs [0.7766527695056581, 0.8792207792207792, 0.8612750885478159, 0.6658536585365854, 0.7823834196891192, 0.7461883408071749, 0.6988636363636364, 0.5609177215189873, 0.7582236842105263, 0.7536496350364964, 0.9615384615384616, 0.9115715007579586, 0.9729916897506925]
 precisions [0.7480643240023823, 0.887012987012987, 0.8778040141676505, 0.6585365853658537, 0.772020725388601, 0.7448430493273542, 0.7159090909090909, 0.5886075949367089, 0.7532894736842105, 0.7627737226277372, 0.9656593406593407, 0.9090449722081859, 0.9667590027700831]
 recalls [0.756998213222156, 0.8785714285714286, 0.871900826446281, 0.6731707317073171, 0.7927461139896373, 0.7461883408071749, 0.7204545454545455, 0.6131329113924051, 0.7516447368421053, 0.7627737226277372, 0.9697802197802198, 0.9070237493683678, 0.9632963988919667]
 f1scores [0.756663022126405, 0.8741586305920774, 0.8695431228769458, 0.6699042893059834, 0.7902327367269926, 0.7203784220688464, 0.6768204587279805, 0.5335468952705325, 0.7449572521609594, 0.7554347222780977, 0.9650024027473473, 0.904107083073719, 0.9693160082884272]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49
 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.841 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.800 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.850 
=> Acc: 0.727 Precision 0.727 Recall 0.727 F1 0.648 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.798 
=> Acc: 0.700 Precision 0.700 Recall 0.700 F1 0.691 
=> Acc: 0.697 Precision 0.697 Recall 0.697 F1 0.694 
=> Acc: 0.669 Precision 0.669 Recall 0.669 F1 0.649 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.805 
=> Acc: 0.642 Precision 0.642 Recall 0.642 F1 0.648 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.895 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.929 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.778 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.910 


accs [0.8415723645026801, 0.8103896103896104, 0.846517119244392, 0.7268292682926829, 0.8134715025906736, 0.7, 0.696590909090909, 0.6685126582278481, 0.8125, 0.6423357664233577, 0.896978021978022, 0.9292572006063669, 0.788781163434903, 0.9100917431192661]
 precisions [0.848719475878499, 0.798051948051948, 0.8618654073199528, 0.6365853658536585, 0.8549222797927462, 0.7089686098654708, 0.6795454545454546, 0.6685126582278481, 0.7944078947368421, 0.6295620437956204, 0.8708791208791209, 0.9358261748357757, 0.788781163434903, 0.9123853211009174]
 recalls [0.8522930315664086, 0.8298701298701299, 0.8583234946871311, 0.6439024390243903, 0.7927461139896373, 0.7121076233183856, 0.6829545454545455, 0.6645569620253164, 0.8042763157894737, 0.6678832116788321, 0.8887362637362637, 0.9206670035371399, 0.7853185595567868, 0.9137614678899083]
 f1scores [0.8281448870302466, 0.7946582962393143, 0.8467509963062223, 0.6444016527195611, 0.836380573449539, 0.6947415470842155, 0.6648463561205522, 0.6589428186894686, 0.7512523479274668, 0.6762972312615092, 0.8777243753699666, 0.9181281283128147, 0.7799538050661607, 0.9126556561493858]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24
 25 26 27 28 29 30 31 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48 49 50
 51 52 53 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.806 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.855 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.874 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.931 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.767 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.779 
=> Acc: 0.706 Precision 0.706 Recall 0.706 F1 0.677 
=> Acc: 0.736 Precision 0.736 Recall 0.736 F1 0.725 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.802 
=> Acc: 0.675 Precision 0.675 Recall 0.675 F1 0.660 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.920 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.769 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.827 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.988 


accs [0.813579511614056, 0.861038961038961, 0.872491145218418, 0.9365853658536586, 0.7875647668393783, 0.8022421524663678, 0.7056818181818182, 0.7357594936708861, 0.8223684210526315, 0.6751824817518248, 0.9230769230769231, 0.9641232945932289, 0.7790858725761773, 0.8293577981651377, 0.9874723655121592]
 precisions [0.8076235854675402, 0.8525974025974026, 0.8801652892561983, 0.8975609756097561, 0.8497409326424871, 0.7847533632286996, 0.7465909090909091, 0.7341772151898734, 0.8125, 0.6496350364963503, 0.929945054945055, 0.9575543203638202, 0.8074792243767313, 0.8353211009174312, 0.9882092851879145]
 recalls [0.8040500297796307, 0.8616883116883117, 0.8937426210153483, 0.9048780487804878, 0.8341968911917098, 0.8139013452914798, 0.6897727272727273, 0.7484177215189873, 0.8240131578947368, 0.6459854014598541, 0.9175824175824175, 0.956543708943911, 0.8206371191135734, 0.8293577981651377, 0.9830508474576272]
 f1scores [0.7930715398178024, 0.8486112123133112, 0.8771378277062677, 0.912705593370965, 0.8274038691662338, 0.7783007009344693, 0.6796936408264995, 0.7390397718432805, 0.7816856487613351, 0.6800998989517306, 0.9276696439823094, 0.949860727973127, 0.797885258901066, 0.8392641944683931, 0.9870713672692913]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 46 47 48 49
 51 52 53 54 55 56 57 58 59 60 61 62 63 64 66 67 68 69 70 71 72 73 74]
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.800 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.870 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.854 
=> Acc: 0.663 Precision 0.663 Recall 0.663 F1 0.633 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.797 
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.716 
=> Acc: 0.585 Precision 0.585 Recall 0.585 F1 0.546 
=> Acc: 0.672 Precision 0.672 Recall 0.672 F1 0.633 
=> Acc: 0.660 Precision 0.660 Recall 0.660 F1 0.642 
=> Acc: 0.659 Precision 0.659 Recall 0.659 F1 0.649 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.838 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.949 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.791 
=> Acc: 0.654 Precision 0.654 Recall 0.654 F1 0.654 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.855 


accs [0.7957117331745086, 0.8707792207792208, 0.8541912632821723, 0.6634146341463415, 0.8082901554404145, 0.7466367713004485, 0.5852272727272727, 0.6724683544303798, 0.6595394736842105, 0.6587591240875912, 0.8406593406593407, 0.9479535118746841, 0.8047091412742382, 0.6536697247706422, 0.9852616064848931, 0.8607014093739758]
 precisions [0.798094103633115, 0.8642857142857143, 0.8612750885478159, 0.6829268292682927, 0.7927461139896373, 0.7547085201793722, 0.6102272727272727, 0.6724683544303798, 0.6480263157894737, 0.666058394160584, 0.8269230769230769, 0.9590702374936837, 0.7880886426592798, 0.6587155963302752, 0.9867354458364038, 0.8492297607341855]
 recalls [0.7927337701012508, 0.8603896103896104, 0.8583234946871311, 0.6560975609756098, 0.7616580310880829, 0.7349775784753363, 0.6022727272727273, 0.6598101265822784, 0.6710526315789473, 0.6386861313868614, 0.8282967032967034, 0.9479535118746841, 0.8095567867036011, 0.6610091743119266, 0.9859985261606485, 0.8538184201901016]
 f1scores [0.8038257944057428, 0.8616129055033614, 0.8691287487970548, 0.6564679875393133, 0.771694269615382, 0.7124115090743646, 0.5542546429915789, 0.6594947779609255, 0.6300972060034866, 0.6595285731139247, 0.8777123296802312, 0.9446879816167186, 0.7443740027587069, 0.6573735008232989, 0.9838582969948957, 0.8601047213647895]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 33 34 35 36 37 38 39 42 43 44 45 46 47 48 49 51 52
 53 54 55 56 57 58 59 60 61 62 63 64 65 66 68 69 70 71 72 73 74 75 76 77
 78 79]
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.774 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.817 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.884 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.868 
=> Acc: 0.736 Precision 0.736 Recall 0.736 F1 0.728 
=> Acc: 0.687 Precision 0.687 Recall 0.687 F1 0.657 
=> Acc: 0.715 Precision 0.715 Recall 0.715 F1 0.681 
=> Acc: 0.738 Precision 0.738 Recall 0.738 F1 0.730 
=> Acc: 0.745 Precision 0.745 Recall 0.745 F1 0.724 
=> Acc: 0.631 Precision 0.631 Recall 0.631 F1 0.631 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.730 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.730 Precision 0.730 Recall 0.730 F1 0.724 
=> Acc: 0.687 Precision 0.687 Recall 0.687 F1 0.671 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.967 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.857 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.965 


accs [0.7927337701012508, 0.8246753246753247, 0.8831168831168831, 0.8682926829268293, 0.7357512953367875, 0.6874439461883408, 0.7147727272727272, 0.7381329113924051, 0.7450657894736842, 0.6313868613138686, 0.7651098901098901, 0.9257200606366852, 0.7299168975069252, 0.686697247706422, 0.9675755342667649, 0.8626679777122255, 0.9658500371195249]
 precisions [0.7808219178082192, 0.8461038961038961, 0.8783943329397875, 0.8414634146341463, 0.6735751295336787, 0.6883408071748879, 0.759090909090909, 0.7199367088607594, 0.7384868421052632, 0.6441605839416058, 0.7527472527472527, 0.9166245578575037, 0.7375346260387812, 0.6697247706422018, 0.9661016949152542, 0.8672566371681416, 0.955456570155902]
 recalls [0.8016676593210245, 0.8363636363636363, 0.8707201889020071, 0.8634146341463415, 0.6632124352331606, 0.6878923766816144, 0.7079545454545455, 0.7357594936708861, 0.7105263157894737, 0.6295620437956204, 0.7870879120879121, 0.934310257705912, 0.7375346260387812, 0.6568807339449542, 0.9690493736182756, 0.8806948541461815, 0.96362286562732]
 f1scores [0.7723480210466976, 0.8305849517473938, 0.8900398112723321, 0.8652320964752231, 0.6576992205129356, 0.6589794893460542, 0.7030228429337365, 0.7083496897692977, 0.6863619970754489, 0.6446181460029395, 0.7165315116821329, 0.9253742567178886, 0.7292876832349663, 0.6566955208611198, 0.9670079299740599, 0.8662665591075692, 0.9629055563871314]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 43 46 47 48 49 50 51 52
 53 54 55 56 57 58 59 60 61 63 64 65 66 68 69 70 71 74 75 76 77 78 79 80
 81 82 84]
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.794 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.832 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.889 
=> Acc: 0.666 Precision 0.666 Recall 0.666 F1 0.607 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.756 
=> Acc: 0.668 Precision 0.668 Recall 0.668 F1 0.649 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.690 
=> Acc: 0.678 Precision 0.678 Recall 0.678 F1 0.626 
=> Acc: 0.623 Precision 0.623 Recall 0.623 F1 0.611 
=> Acc: 0.648 Precision 0.648 Recall 0.648 F1 0.624 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.860 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.884 
=> Acc: 0.736 Precision 0.736 Recall 0.736 F1 0.701 
=> Acc: 0.620 Precision 0.620 Recall 0.620 F1 0.567 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.702 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.806 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.801 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 


accs [0.7963073257891602, 0.8415584415584415, 0.8902007083825265, 0.6658536585365854, 0.7616580310880829, 0.6681614349775785, 0.6988636363636364, 0.678006329113924, 0.6233552631578947, 0.6478102189781022, 0.8612637362637363, 0.8847902981303689, 0.7361495844875346, 0.6201834862385321, 0.7759764185703758, 0.8187479514913143, 0.8240534521158129, 0.9913119026933102]
 precisions [0.8028588445503275, 0.8467532467532467, 0.8872491145218417, 0.5926829268292683, 0.7512953367875648, 0.6497757847533633, 0.725, 0.6938291139240507, 0.6365131578947368, 0.6496350364963503, 0.8791208791208791, 0.8974229408792319, 0.7292243767313019, 0.6403669724770642, 0.7877671333824613, 0.823992133726647, 0.8181143281365999, 0.9887054735013032]
 recalls [0.8266825491363907, 0.8409090909090909, 0.8990554899645808, 0.6195121951219512, 0.7098445595854922, 0.673542600896861, 0.7159090909090909, 0.6669303797468354, 0.6430921052631579, 0.6076642335766423, 0.8598901098901099, 0.8903486609398686, 0.7292243767313019, 0.6334862385321101, 0.7811348563006633, 0.8154703375942314, 0.8195991091314031, 0.9913119026933102]
 f1scores [0.7911491097705661, 0.8321876486443804, 0.8795493087404038, 0.5975281564409586, 0.6955965880084871, 0.638682264031529, 0.6881062846734646, 0.6381101719952372, 0.6059418579611149, 0.6444660405678377, 0.9078603903496487, 0.9042057701498031, 0.6724379968176002, 0.5834072582740644, 0.7103259217800131, 0.8136781516178961, 0.8022962100663442, 0.991429313333029]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24
 26 27 28 29 30 31 32 33 34 35 36 38 39 40 41 42 43 44 45 47 48 49 51 52
 53 54 55 56 57 58 59 60 61 63 64 65 66 67 68 69 70 71 72 74 76 77 78 79
 80 81 82 83 84 85 86 88 89]
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.788 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.861 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.851 
=> Acc: 0.744 Precision 0.744 Recall 0.744 F1 0.738 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.777 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.753 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.713 
=> Acc: 0.693 Precision 0.693 Recall 0.693 F1 0.659 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.723 
=> Acc: 0.664 Precision 0.664 Recall 0.664 F1 0.605 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.854 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.702 
=> Acc: 0.715 Precision 0.715 Recall 0.715 F1 0.716 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.695 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.852 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.912 
=> Acc: 0.704 Precision 0.704 Recall 0.704 F1 0.632 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.885 


accs [0.798094103633115, 0.862987012987013, 0.8541912632821723, 0.7439024390243902, 0.7823834196891192, 0.7654708520179372, 0.7261363636363637, 0.6930379746835443, 0.7401315789473685, 0.6642335766423357, 0.853021978021978, 0.9105608893380496, 0.7423822714681441, 0.7146788990825688, 0.765659543109801, 0.855457227138643, 0.9168522642910171, 0.7037358818418766, 0.8871331828442438]
 precisions [0.7891602144133413, 0.861038961038961, 0.8606847697756789, 0.7439024390243902, 0.7616580310880829, 0.7704035874439462, 0.7295454545454545, 0.678006329113924, 0.7154605263157895, 0.5875912408759124, 0.8653846153846154, 0.9297625063163214, 0.7153739612188366, 0.6839449541284404, 0.7324981577008106, 0.8639790232710587, 0.8990348923533779, 0.7106863596872285, 0.8874556594646889]
 recalls [0.7832042882668255, 0.8733766233766234, 0.858913813459268, 0.7365853658536585, 0.7046632124352331, 0.7582959641255606, 0.7181818181818181, 0.6772151898734177, 0.7302631578947368, 0.5948905109489051, 0.8365384615384616, 0.9171298635674583, 0.71398891966759, 0.7036697247706422, 0.7531319086219602, 0.8492297607341855, 0.8997772828507795, 0.7080799304952216, 0.8874556594646889]
 f1scores [0.7873301529468494, 0.8435892380575254, 0.8655388281589858, 0.7061322611062513, 0.6809590639340054, 0.757065229956103, 0.6999392575159025, 0.6424468112368973, 0.7110431378189425, 0.5667680327792098, 0.8590781476657939, 0.9147182429805658, 0.6673095233575839, 0.7011578902217264, 0.6920183684567108, 0.8561166848650748, 0.9033979837639678, 0.6377452822794625, 0.8901670883253605]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8 10 11 13 14 15 16 17 18 19 20 21 22 24 26 27
 28 29 30 31 32 33 34 35 36 38 39 40 42 43 44 45 47 48 49 51 52 53 55 56
 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 74 75 76 77 78 79 80 81
 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.761 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.813 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.862 
=> Acc: 0.739 Precision 0.739 Recall 0.739 F1 0.724 
=> Acc: 0.767 Precision 0.767 Recall 0.767 F1 0.771 
=> Acc: 0.800 Precision 0.800 Recall 0.800 F1 0.788 
=> Acc: 0.589 Precision 0.589 Recall 0.589 F1 0.552 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.727 
=> Acc: 0.704 Precision 0.704 Recall 0.704 F1 0.675 
=> Acc: 0.622 Precision 0.622 Recall 0.622 F1 0.596 
=> Acc: 0.691 Precision 0.691 Recall 0.691 F1 0.665 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 
=> Acc: 0.711 Precision 0.711 Recall 0.711 F1 0.673 
=> Acc: 0.665 Precision 0.665 Recall 0.665 F1 0.675 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.695 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.803 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.820 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.927 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.835 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 


accs [0.7647409172126266, 0.8168831168831169, 0.8624557260920898, 0.7390243902439024, 0.7668393782383419, 0.8, 0.5886363636363636, 0.754746835443038, 0.7039473684210527, 0.6222627737226277, 0.6909340659340659, 0.8969176351692774, 0.711218836565097, 0.6651376146788991, 0.7730287398673544, 0.8141592920353983, 0.8337045285820341, 0.9287576020851434, 0.8390841663979361, 0.9702127659574468]
 precisions [0.779630732578916, 0.8071428571428572, 0.8577331759149941, 0.7097560975609756, 0.8238341968911918, 0.810762331838565, 0.5795454545454546, 0.747626582278481, 0.71875, 0.698905109489051, 0.6813186813186813, 0.9095502779181405, 0.703601108033241, 0.6912844036697248, 0.7686072218128224, 0.821697803998689, 0.8351893095768375, 0.9409209383145091, 0.8329571106094809, 0.9591489361702128]
 recalls [0.7772483621203097, 0.811038961038961, 0.8707201889020071, 0.7146341463414634, 0.7979274611398963, 0.8076233183856503, 0.5943181818181819, 0.7507911392405063, 0.6792763157894737, 0.6678832116788321, 0.6923076923076923, 0.9044972208185953, 0.6814404432132964, 0.6880733944954128, 0.7818717759764185, 0.8194034742707309, 0.8389012620638456, 0.944396177237185, 0.8468236052886166, 0.9719148936170213]
 f1scores [0.7894946080110066, 0.8016513228682077, 0.8750364058892324, 0.7238932344060287, 0.7415231327845905, 0.8059841032982599, 0.5569079356939505, 0.7523418309765935, 0.6794899888317041, 0.6314608874407346, 0.657275675274093, 0.9045856510452713, 0.6411705029416657, 0.6991908603631047, 0.6978724153050961, 0.81964603887715, 0.825095023925263, 0.9389306517958321, 0.8237523056428172, 0.9622494961945197]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 


accs [0.9930555555555556]
 precisions [0.9969135802469136]
 recalls [0.9953703703703703]
 f1scores [0.9920507936507936]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 


accs [0.9112654320987654, 0.9872574572835215]
 precisions [0.9297839506172839, 0.9872574572835215]
 recalls [0.9236111111111112, 0.9866782507964089]
 f1scores [0.9057304846640587, 0.9839828298018581]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.928 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.982 


accs [0.9282407407407407, 0.9316536345207066, 0.9827760891590679]
 precisions [0.9328703703703703, 0.9409209383145091, 0.9766970618034447]
 recalls [0.9212962962962963, 0.9273095858673617, 0.9746707193515705]
 f1scores [0.9285414963807168, 0.9351521848173249, 0.9706806826643442]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.777 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.927 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.946 


accs [0.7870370370370371, 0.9435273675065161, 0.9240121580547113, 0.9468085106382979]
 precisions [0.8155864197530864, 0.9397625253402838, 0.9108409321175278, 0.9665653495440729]
 recalls [0.7839506172839507, 0.9426585577758471, 0.9331306990881459, 0.9513677811550152]
 f1scores [0.7768484096615162, 0.9417178862987216, 0.9285148276669117, 0.9586555666845191]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.871 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.898 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.927 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.907 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.8688271604938271, 0.8997972777295106, 0.9270516717325228, 0.9103343465045592, 0.9888888888888889]
 precisions [0.8672839506172839, 0.8969012452939473, 0.9179331306990881, 0.9179331306990881, 0.9833333333333333]
 recalls [0.8557098765432098, 0.9029829134086301, 0.9057750759878419, 0.9164133738601824, 0.9888888888888889]
 f1scores [0.8685751527400527, 0.8931872914086872, 0.9167506542186542, 0.9195655772489614, 0.9876382731766583]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.915 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.914 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.777 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.984 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.870 


accs [0.9151234567901234, 0.9331016507384883, 0.9138804457953394, 0.7796352583586627, 0.9833333333333333, 0.8814317673378076]
 precisions [0.8888888888888888, 0.9220967274833478, 0.9209726443768997, 0.7674772036474165, 0.9777777777777777, 0.8829231916480239]
 recalls [0.9143518518518519, 0.9296264118158123, 0.9179331306990881, 0.7720364741641338, 0.9777777777777777, 0.8963460104399702]
 f1scores [0.903878260534419, 0.919686947971587, 0.9165114421085857, 0.774718813407561, 0.9941980239646837, 0.8876351781482755]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23 24
 25 26 27 28 29]
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.843 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.940 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.909 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.815 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.940 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.744 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.981 


accs [0.8472222222222222, 0.9406313350709528, 0.9098277608915907, 0.8237082066869301, 0.9444444444444444, 0.7486950037285608, 0.9825174825174825]
 precisions [0.8464506172839507, 0.9400521285838401, 0.9078014184397163, 0.7644376899696048, 0.9388888888888889, 0.732289336316182, 0.9737762237762237]
 recalls [0.8518518518518519, 0.9409209383145091, 0.8834853090172239, 0.8024316109422492, 0.9222222222222223, 0.7360178970917226, 0.9685314685314685]
 f1scores [0.8450779144695932, 0.9463819950967356, 0.8999714644252368, 0.7799239380503967, 0.961151037303827, 0.737757046510361, 0.9741289674880683]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23 24
 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.834 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.870 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.908 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.773 
=> Acc: 0.672 Precision 0.672 Recall 0.672 F1 0.625 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.810 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.919 


accs [0.8379629629629629, 0.8696785403996524, 0.9078014184397163, 0.7796352583586627, 0.6722222222222223, 0.8113348247576435, 0.9388111888111889, 0.9224965706447188]
 precisions [0.8132716049382716, 0.879814653924124, 0.8996960486322189, 0.7720364741641338, 0.7222222222222222, 0.8016405667412378, 0.9143356643356644, 0.9279835390946503]
 recalls [0.8479938271604939, 0.879814653924124, 0.9067882472137792, 0.8024316109422492, 0.7166666666666667, 0.808351976137211, 0.9527972027972028, 0.9252400548696845]
 f1scores [0.8446003833552818, 0.8805477898914175, 0.9057085709916655, 0.7692033492336016, 0.620126188158844, 0.7958207941764179, 0.9345710775438743, 0.90974551238639]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.761 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.827 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.717 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.864 
=> Acc: 0.488 Precision 0.488 Recall 0.488 F1 0.462 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.901 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.892 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 


accs [0.7631172839506173, 0.896611642050391, 0.8237082066869301, 0.7264437689969605, 0.8555555555555555, 0.488441461595824, 0.9090909090909091, 0.8916323731138546, 0.9900456242223143]
 precisions [0.7561728395061729, 0.9003764842166232, 0.7852077001013171, 0.7066869300911854, 0.85, 0.4854586129753915, 0.9230769230769231, 0.8888888888888888, 0.9896308585649108]
 recalls [0.7584876543209876, 0.9003764842166232, 0.790273556231003, 0.7507598784194529, 0.8555555555555555, 0.4772557792692021, 0.9318181818181818, 0.8984910836762688, 0.9929489838241393]
 f1scores [0.7593730108093656, 0.905760675127337, 0.8002195468756421, 0.7338618604043953, 0.8370052754648967, 0.4508233904913129, 0.8931143703860572, 0.8988014289189448, 0.9910004699278729]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.759 Precision 0.759 Recall 0.759 F1 0.762 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.906 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.865 
=> Acc: 0.676 Precision 0.676 Recall 0.676 F1 0.656 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.863 
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.716 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.838 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.870 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.901 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.893 


accs [0.7592592592592593, 0.9079061685490878, 0.8611955420466059, 0.6762917933130699, 0.8611111111111112, 0.7427293064876958, 0.8566433566433567, 0.8724279835390947, 0.8992119452509332, 0.8995492594977463]
 precisions [0.7692901234567902, 0.9000868809730669, 0.8551165146909828, 0.6854103343465046, 0.8388888888888889, 0.7300521998508576, 0.8164335664335665, 0.864883401920439, 0.8934052260472832, 0.9085640695428203]
 recalls [0.7631172839506173, 0.9064581523313061, 0.851063829787234, 0.6504559270516718, 0.8222222222222222, 0.7114093959731543, 0.8601398601398601, 0.887517146776406, 0.8884280381584405, 0.8889246619446233]
 f1scores [0.7828106833678186, 0.9147790646739787, 0.8387838148093415, 0.6621782269051145, 0.8523269024866302, 0.6982914250001173, 0.8222237886732813, 0.8849402727697102, 0.899389496461253, 0.8963343585119464]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.842 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.874 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.867 
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.789 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.806 
=> Acc: 0.746 Precision 0.746 Recall 0.746 F1 0.708 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.837 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.861 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.950 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.796 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.979 


accs [0.841820987654321, 0.876339415001448, 0.8662613981762918, 0.7978723404255319, 0.8055555555555556, 0.7457121551081283, 0.8513986013986014, 0.864883401920439, 0.9493985897967648, 0.8036059240180297, 0.9784673844205193]
 precisions [0.8410493827160493, 0.8841587025774689, 0.8905775075987842, 0.78419452887538, 0.7777777777777778, 0.7531692766592095, 0.8479020979020979, 0.8628257887517147, 0.9510576524263791, 0.8042498390212492, 0.9829005699810006]
 recalls [0.8287037037037037, 0.8682305241818709, 0.9027355623100304, 0.8115501519756839, 0.8111111111111111, 0.7412378821774795, 0.8688811188811189, 0.8635116598079561, 0.9581086686022398, 0.8100450740502254, 0.9816339455351488]
 f1scores [0.8389559269449816, 0.8790769441770498, 0.8741946229159856, 0.7728508983897899, 0.7858883242162606, 0.7261719373635219, 0.8427450871859385, 0.8579555004685233, 0.9529619883074965, 0.7947134164751545, 0.985465802214606]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 24 25
 26 27 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50
 51 52 53 54]
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.826 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.895 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.881 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.685 
=> Acc: 0.611 Precision 0.611 Recall 0.611 F1 0.558 
=> Acc: 0.643 Precision 0.643 Recall 0.643 F1 0.593 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.773 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.874 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.805 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.944 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.847 


accs [0.8317901234567902, 0.895742832319722, 0.8824721377912867, 0.6990881458966566, 0.6111111111111112, 0.6428038777032066, 0.8181818181818182, 0.8820301783264746, 0.9498133554541683, 0.8200257566001288, 0.9449018366054465, 0.8723679948169744]
 precisions [0.8233024691358025, 0.8934260063712713, 0.8591691995947315, 0.6398176291793313, 0.65, 0.6674123788217748, 0.8059440559440559, 0.8813443072702332, 0.9481542928245541, 0.8116548615582743, 0.9449018366054465, 0.8665370910268869]
 recalls [0.8101851851851852, 0.8890819577179264, 0.8470111448834853, 0.6747720364741642, 0.6833333333333333, 0.6368381804623415, 0.7937062937062938, 0.8559670781893004, 0.9506428867689756, 0.8032839665164199, 0.9309689677010766, 0.8720440557175251]
 f1scores [0.7951494306323587, 0.885206223204802, 0.8402921848422563, 0.644784456283639, 0.5515367137806162, 0.5882219539341975, 0.7403759156392118, 0.8693765993011766, 0.9454687561696217, 0.8047661249327522, 0.930726159222937, 0.8445694980604304]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20 22 23 24 25 26
 27 29 30 32 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 51 52 53 54
 55 56 57 58 59]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [1.0]
 recalls [1.0]
 f1scores [1.0]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.952 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 


accs [0.949685534591195, 0.9695835283107159]
 precisions [0.940251572327044, 0.972391202620496]
 recalls [0.9465408805031447, 0.9649040711277492]
 f1scores [0.9348393855321675, 0.9630609786682598]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.725 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.907 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 


accs [0.7924528301886793, 0.9054749649040711, 0.9906807131280388]
 precisions [0.8113207547169812, 0.912962096396818, 0.9927066450567261]
 recalls [0.7955974842767296, 0.9096864763687412, 0.9870340356564019]
 f1scores [0.7391714463552224, 0.9148416571001026, 0.9916069492081029]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.406 Precision 0.406 Recall 0.406 F1 0.342 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.860 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.921 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.905 


accs [0.4056603773584906, 0.85774450163781, 0.9222042139384117, 0.9115168539325843]
 precisions [0.42452830188679247, 0.8699110903135236, 0.9347649918962723, 0.9241573033707865]
 recalls [0.4339622641509434, 0.8582124473561067, 0.9384116693679092, 0.9339887640449438]
 f1scores [0.34858620353908903, 0.8730972982639157, 0.9289260221972884, 0.9017113398065779]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.810 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.856 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.857 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 


accs [0.8238993710691824, 0.8568086102012167, 0.9550243111831442, 0.8637640449438202, 0.9524940617577197]
 precisions [0.7547169811320755, 0.8731867103416003, 0.9615072933549432, 0.8735955056179775, 0.9738717339667459]
 recalls [0.7830188679245284, 0.8727187646233037, 0.9619124797406807, 0.8778089887640449, 0.9691211401425178]
 f1scores [0.7869262230632947, 0.8576807610582383, 0.9673584051068721, 0.859367854705505, 0.9657067323061934]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.701 Precision 0.701 Recall 0.701 F1 0.695 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.897 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.785 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.895 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 


accs [0.7012578616352201, 0.8961160505381376, 0.9246353322528363, 0.8075842696629213, 0.8931116389548693, 0.9751626256652868]
 precisions [0.6415094339622641, 0.9012634534394011, 0.9331442463533225, 0.7612359550561798, 0.8883610451306413, 0.9781194559432289]
 recalls [0.7169811320754716, 0.8956481048198409, 0.9209886547811994, 0.7808988764044944, 0.9192399049881235, 0.9858072146658782]
 f1scores [0.6784969976181013, 0.9026730539160086, 0.926164772672621, 0.7958772754164751, 0.9186344824028494, 0.9816562187342621]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.761 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.879 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.917 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.817 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.843 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.931 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 


accs [0.789308176100629, 0.8844174075807206, 0.9161264181523501, 0.8441011235955056, 0.8456057007125891, 0.9308101714961561, 0.9878345498783455]
 precisions [0.7672955974842768, 0.8830135704258306, 0.919773095623987, 0.8075842696629213, 0.8788598574821853, 0.9278533412182141, 0.9762773722627737]
 recalls [0.7452830188679245, 0.8909686476368741, 0.9096434359805511, 0.7949438202247191, 0.8741092636579573, 0.9225310467179184, 0.9841849148418491]
 f1scores [0.7541894087136083, 0.878625212023383, 0.9198164931428435, 0.7870299936833954, 0.8665816260900059, 0.9375426964156353, 0.978885986780236]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 33 34]
=> Acc: 0.758 Precision 0.758 Recall 0.758 F1 0.718 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.815 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.818 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.791 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.953 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.907 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.938 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 


accs [0.7578616352201258, 0.8362189985961629, 0.813614262560778, 0.8103932584269663, 0.9524940617577197, 0.905972797161443, 0.9385644768856448, 0.9878934624697336]
 precisions [0.7358490566037735, 0.8394946186242396, 0.7978119935170178, 0.800561797752809, 0.9667458432304038, 0.9207569485511532, 0.9409975669099757, 0.9854721549636803]
 recalls [0.7641509433962265, 0.8324754328497894, 0.8014586709886548, 0.8188202247191011, 0.9643705463182898, 0.908929627439385, 0.9464720194647201, 0.9790153349475383]
 f1scores [0.7143735375790288, 0.8156679955407666, 0.8162873669378856, 0.7866836880985826, 0.9592932198847217, 0.9255315983667556, 0.9456733189198259, 0.9783038578343934]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.761 Precision 0.761 Recall 0.761 F1 0.755 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.822 
=> Acc: 0.647 Precision 0.647 Recall 0.647 F1 0.658 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.786 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.910 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.869 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.867 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.937 


accs [0.7610062893081762, 0.8418343472157229, 0.646677471636953, 0.7949438202247191, 0.9097387173396675, 0.8687167356593731, 0.962287104622871, 0.8748991121872478, 0.9389140271493213]
 precisions [0.7578616352201258, 0.8455779129620964, 0.6410048622366289, 0.8286516853932584, 0.9192399049881235, 0.8456534594914252, 0.962287104622871, 0.8797417271993543, 0.9443438914027149]
 recalls [0.7484276729559748, 0.8516612072999532, 0.6555915721231766, 0.7921348314606742, 0.9263657957244655, 0.8752217622708457, 0.962287104622871, 0.8579499596448749, 0.930316742081448]
 f1scores [0.7095027665640822, 0.8252242331921025, 0.6631543377239224, 0.7816674041287115, 0.9231231362359124, 0.8617415381401171, 0.9641748649519843, 0.8578324980205266, 0.9281680378132926]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.832 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.825 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.895 
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.698 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.884 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.922 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.858 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.903 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.961 


accs [0.8522012578616353, 0.8451099672437997, 0.8962722852512156, 0.7429775280898876, 0.8907363420427553, 0.9254878769958604, 0.9215328467153284, 0.8595641646489104, 0.9040723981900453, 0.9615806805708014]
 precisions [0.8584905660377359, 0.8357510528778662, 0.8845218800648298, 0.7317415730337079, 0.8883610451306413, 0.9420461265523359, 0.9105839416058394, 0.8458434221146085, 0.8891402714932126, 0.9538968166849616]
 recalls [0.7767295597484277, 0.8568086102012167, 0.8881685575364667, 0.7331460674157303, 0.8907363420427553, 0.9337670017740982, 0.9257907542579076, 0.8426150121065376, 0.9036199095022625, 0.9637760702524698]
 f1scores [0.755624306182666, 0.8425243808605716, 0.8815405344560346, 0.6866443064057963, 0.8918254766808034, 0.9242432435076614, 0.9131242214523955, 0.8438890777560315, 0.8811896071058763, 0.9557028997425683]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 49]
=> Acc: 0.692 Precision 0.692 Recall 0.692 F1 0.666 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.825 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.774 
=> Acc: 0.596 Precision 0.596 Recall 0.596 F1 0.554 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.890 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.830 
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.743 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.846 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.930 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.978 


accs [0.6918238993710691, 0.8301357042583061, 0.7901134521880064, 0.5955056179775281, 0.8907363420427553, 0.9319929036073329, 0.8321167883211679, 0.7530266343825666, 0.8493212669683258, 0.9308452250274424, 0.9772841998990409]
 precisions [0.7232704402515723, 0.8062704726251755, 0.7653970826580226, 0.6235955056179775, 0.8741092636579573, 0.9384979302188055, 0.8211678832116789, 0.7465698143664246, 0.8434389140271493, 0.9352360043907794, 0.9863705199394245]
 recalls [0.7012578616352201, 0.815629386991109, 0.7670178282009724, 0.5491573033707865, 0.8551068883610451, 0.9367238320520402, 0.829683698296837, 0.7643260694108152, 0.834841628959276, 0.9275521405049396, 0.9787985865724381]
 f1scores [0.6715336927760505, 0.8193743739976476, 0.7577961328138059, 0.5321143720084273, 0.9028702487925792, 0.9419580051463086, 0.8386492228193221, 0.7444645277725005, 0.8493739295027082, 0.9295504300682957, 0.9795544649435829]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
 49 50 51 52 53 54]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [1.0]
 recalls [1.0]
 f1scores [1.0]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.964 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.9659863945578231, 0.9982547993019197]
 precisions [0.9727891156462585, 0.9982547993019197]
 recalls [0.9931972789115646, 0.9982547993019197]
 f1scores [0.9832589289819593, 0.9981937636027093]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.926 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.952 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 


accs [0.9251700680272109, 0.956369982547993, 0.9870967741935484]
 precisions [0.9387755102040817, 0.9528795811518325, 0.9829493087557604]
 recalls [0.9183673469387755, 0.9581151832460733, 0.9834101382488479]
 f1scores [0.9370380751030642, 0.9533953751097766, 0.9738080785400521]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.882 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.935 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.969 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 


accs [0.8877551020408163, 0.9354275741710296, 0.9700460829493087, 0.9849086576648134]
 precisions [0.8945578231292517, 0.9162303664921466, 0.9691244239631336, 0.9864972200158856]
 recalls [0.8979591836734694, 0.9336823734729494, 0.9663594470046083, 0.9872915011914217]
 f1scores [0.9398788267458738, 0.9446481192741014, 0.9684116530147564, 0.9873176964481015]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.918 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.904 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.955 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 


accs [0.9183673469387755, 0.9109947643979057, 0.9691244239631336, 0.9539316918189039, 0.9777094542659492]
 precisions [0.9285714285714286, 0.9144851657940664, 0.9594470046082949, 0.9618745035742653, 0.9769408147578785]
 recalls [0.9149659863945578, 0.9057591623036649, 0.964516129032258, 0.9626687847498014, 0.9823212913143735]
 f1scores [0.9184999541075316, 0.9164841823168561, 0.965436805053022, 0.9511201422575739, 0.9809590598865121]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.721 Precision 0.721 Recall 0.721 F1 0.722 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.919 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.920 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.934 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.999 


accs [0.7210884353741497, 0.9179755671902269, 0.9617511520737327, 0.9221604447974583, 0.9346656418139893, 0.998443579766537]
 precisions [0.7448979591836735, 0.9057591623036649, 0.9543778801843318, 0.90945194598888, 0.9454265949269792, 1.0]
 recalls [0.7346938775510204, 0.8987783595113438, 0.964516129032258, 0.9189833200953137, 0.9338970023059185, 0.9976653696498055]
 f1scores [0.764852193254298, 0.9078542921745815, 0.9604280087821433, 0.9125607415804492, 0.9211316274091879, 0.9992310043716369]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.738 Precision 0.738 Recall 0.738 F1 0.732 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.869 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.917 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.939 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.856 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 
=> Acc: 0.995 Precision 0.995 Recall 0.995 F1 0.995 


accs [0.7380952380952381, 0.8778359511343804, 0.9165898617511521, 0.938046068308181, 0.8631821675634127, 0.9704280155642023, 0.9947698744769874]
 precisions [0.7040816326530612, 0.9022687609075044, 0.9248847926267281, 0.9444003177124702, 0.8647194465795542, 0.9587548638132296, 0.99581589958159]
 recalls [0.6972789115646258, 0.9040139616055847, 0.9248847926267281, 0.9404289118347895, 0.8685626441199078, 0.954863813229572, 0.997907949790795]
 f1scores [0.6933036867955533, 0.9042367839271328, 0.910604226363114, 0.9487105498535732, 0.8769758276882363, 0.9560312392900101, 0.9907601994677414]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.752 Precision 0.752 Recall 0.752 F1 0.748 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.858 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.898 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.962 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.856 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.974 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.902 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 


accs [0.7517006802721088, 0.8621291448516579, 0.9, 0.9626687847498014, 0.8608762490392006, 0.9750972762645914, 0.9027196652719666, 0.9325490196078431]
 precisions [0.7653061224489796, 0.8551483420593369, 0.9092165898617511, 0.965845909451946, 0.8531898539584934, 0.9743190661478599, 0.9058577405857741, 0.9262745098039216]
 recalls [0.8027210884353742, 0.8586387434554974, 0.896774193548387, 0.9642573471008737, 0.8693312836279785, 0.9758754863813229, 0.9246861924686193, 0.9231372549019607]
 f1scores [0.7636630382919819, 0.8691123707640038, 0.8939627058394317, 0.9642429772312289, 0.8558558064480108, 0.9704065279691928, 0.9125080848465521, 0.9219910358481517]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 25 26 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.800 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.899 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.923 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.898 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.888 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.916 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.858 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.881 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 


accs [0.7959183673469388, 0.9057591623036649, 0.923963133640553, 0.9007148530579825, 0.8900845503458877, 0.9151750972762646, 0.856694560669456, 0.8784313725490196, 0.9943246311010215]
 precisions [0.7040816326530612, 0.9354275741710296, 0.9142857142857143, 0.9038919777601271, 0.8962336664104535, 0.91284046692607, 0.8765690376569037, 0.8815686274509804, 0.9931895573212258]
 recalls [0.8027210884353742, 0.8970331588132635, 0.9096774193548387, 0.8951548848292296, 0.8908531898539584, 0.9167315175097276, 0.8682008368200836, 0.8831372549019608, 0.9909194097616345]
 f1scores [0.7573355287101777, 0.8943653011487246, 0.9068587599470325, 0.9038567346747653, 0.896923094313488, 0.9096455605224826, 0.880746943968493, 0.8666233748870835, 0.993043790568491]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.721 Precision 0.721 Recall 0.721 F1 0.715 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.849 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.921 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.910 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.816 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.919 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.831 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.875 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.955 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 


accs [0.7210884353741497, 0.8586387434554974, 0.9221198156682028, 0.90945194598888, 0.8239815526518063, 0.9198443579766536, 0.8305439330543933, 0.8752941176470588, 0.9580022701475596, 0.937483230480279]
 precisions [0.7585034013605442, 0.8516579406631762, 0.9285714285714286, 0.9396346306592533, 0.8124519600307456, 0.9346303501945525, 0.8462343096234309, 0.8698039215686274, 0.9432463110102156, 0.9294338610142205]
 recalls [0.673469387755102, 0.8621291448516579, 0.9248847926267281, 0.926131850675139, 0.8270561106840891, 0.9120622568093385, 0.8493723849372385, 0.8580392156862745, 0.9375709421112373, 0.9305071102763617]
 f1scores [0.6881703381633778, 0.8641264452493115, 0.9222850837721854, 0.9199897134340386, 0.8091702855716549, 0.9285741243973396, 0.8405674789166664, 0.8772880123015433, 0.9543808623916888, 0.940026496176201]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 24
 25 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49]
=> Acc: 0.697 Precision 0.697 Recall 0.697 F1 0.700 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.867 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.902 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.875 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.893 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.785 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.859 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.885 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.921 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.918 


accs [0.6972789115646258, 0.8778359511343804, 0.9055299539170507, 0.937251787132645, 0.8777863182167563, 0.8957198443579767, 0.7907949790794979, 0.8627450980392157, 0.8864926220204313, 0.9221894284947679, 0.9235074626865671]
 precisions [0.7551020408163265, 0.8795811518324608, 0.9152073732718894, 0.9332803812549643, 0.8862413528055342, 0.8856031128404669, 0.8190376569037657, 0.8486274509803922, 0.9125993189557321, 0.9219211161792327, 0.9309701492537313]
 recalls [0.7448979591836735, 0.8691099476439791, 0.908294930875576, 0.931691818903892, 0.8677940046118371, 0.909727626459144, 0.7981171548117155, 0.8392156862745098, 0.9046538024971623, 0.9254091762811913, 0.9365671641791045]
 f1scores [0.6510983468946165, 0.8461585420515816, 0.9046095757573205, 0.9320749475788915, 0.8746849671629351, 0.8976813828322857, 0.7955633972574664, 0.8603744410753096, 0.9042721107563236, 0.923377291432538, 0.9412018381795179]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49
 50 51 52 53 54]
=> Acc: 0.707 Precision 0.707 Recall 0.707 F1 0.695 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.895 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.923 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.901 
=> Acc: 0.821 Precision 0.821 Recall 0.821 F1 0.808 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.783 Precision 0.783 Recall 0.783 F1 0.782 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.870 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.910 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.908 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.919 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 


accs [0.7074829931972789, 0.900523560209424, 0.9225806451612903, 0.9015091342335186, 0.8209069946195234, 0.9836575875486381, 0.7834728033472803, 0.8658823529411764, 0.9103291713961408, 0.9101153742956801, 0.9235074626865671, 0.9603214465092919]
 precisions [0.7006802721088435, 0.8917975567190227, 0.9175115207373272, 0.8888006354249405, 0.8324365872405841, 0.9758754863813229, 0.8023012552301255, 0.8525490196078431, 0.9148694665153235, 0.907968875771398, 0.9235074626865671, 0.958312405826218]
 recalls [0.6802721088435374, 0.8970331588132635, 0.9262672811059908, 0.9110405083399523, 0.8447348193697156, 0.9813229571984435, 0.8043933054393305, 0.8776470588235294, 0.9216799091940976, 0.9017976925140864, 0.9272388059701493, 0.9593169261677549]
 f1scores [0.6412074935827615, 0.9008568492692142, 0.9113564773535557, 0.9154718570212619, 0.8275933522590952, 0.9723857580536907, 0.8281324101187222, 0.8600275408946108, 0.9084242698636252, 0.9041203774313933, 0.9097075034707889, 0.9556942201518568]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
 26 27 28 29 31 32 33 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 51
 52 53 54 55 56 57 58 59]
=> Acc: 0.643 Precision 0.643 Recall 0.643 F1 0.629 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.820 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.913 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.876 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.856 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.867 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.818 
=> Acc: 0.781 Precision 0.781 Recall 0.781 F1 0.772 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.937 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.904 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.795 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.889 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.883 


accs [0.6428571428571429, 0.8551483420593369, 0.9124423963133641, 0.8697378872120731, 0.8601076095311299, 0.8669260700389105, 0.8169456066945606, 0.7811764705882352, 0.9375709421112373, 0.9074322511403273, 0.8432835820895522, 0.8970366649924661, 0.8895934352853413]
 precisions [0.673469387755102, 0.8167539267015707, 0.908294930875576, 0.8840349483717236, 0.8539584934665642, 0.8692607003891051, 0.8002092050209205, 0.7858823529411765, 0.9318955732122588, 0.8945532599946338, 0.7966417910447762, 0.9126067302862882, 0.9007832898172323]
 recalls [0.6632653061224489, 0.8429319371727748, 0.9096774193548387, 0.8617950754567116, 0.8524212144504227, 0.8739299610894942, 0.803347280334728, 0.7529411764705882, 0.9398410896708286, 0.902334317145157, 0.8022388059701493, 0.9055750878955299, 0.9045132413278627]
 f1scores [0.6833300492610836, 0.7846448300380375, 0.9064396313563021, 0.8832906285692056, 0.8510870034714726, 0.8592764471435306, 0.807431541060064, 0.7773539637522001, 0.9356359239805258, 0.8966566817453625, 0.802476552604826, 0.9017112405759388, 0.887664214410021]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  4  5  7  8  9 11 12 13 14 15 17 18 19 20 21 22 23 24 25 26 28
 29 30 31 32 33 34 35 36 37 38 40 41 42 43 44 45 46 47 48 49 50 51 52 53
 54 55 56 57 58 59 61 62 63 64]
=> Acc: 0.619 Precision 0.619 Recall 0.619 F1 0.626 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.805 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.917 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.886 
=> Acc: 0.750 Precision 0.750 Recall 0.750 F1 0.725 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.823 
=> Acc: 0.711 Precision 0.711 Recall 0.711 F1 0.681 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.855 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.874 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.886 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.894 
=> Acc: 0.677 Precision 0.677 Recall 0.677 F1 0.610 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.936 


accs [0.6190476190476191, 0.8115183246073299, 0.9165898617511521, 0.8832406671961874, 0.7501921598770177, 0.9626459143968872, 0.8242677824267782, 0.7113725490196079, 0.8592508513053349, 0.8784545210625168, 0.8992537313432836, 0.8945253641386238, 0.6773591943304738, 0.9353396901072706]
 precisions [0.6598639455782312, 0.8272251308900523, 0.9004608294930876, 0.8776806989674345, 0.744043043812452, 0.9649805447470817, 0.8117154811715481, 0.6909803921568628, 0.8683314415437003, 0.8687952777032466, 0.8880597014925373, 0.8910095429432446, 0.6766132040283477, 0.9383194278903456]
 recalls [0.6530612244897959, 0.8272251308900523, 0.9096774193548387, 0.8832406671961874, 0.7594158339738662, 0.9657587548638132, 0.8158995815899581, 0.6933333333333334, 0.8637911464245176, 0.8709417762275289, 0.8694029850746269, 0.8985434455047715, 0.69041402461768, 0.9356376638855781]
 f1scores [0.6667105696374307, 0.8139307338991477, 0.9000445932530082, 0.8890723804207962, 0.7111911887361123, 0.9683790228630562, 0.8058585184988896, 0.6551179645264827, 0.8592651416091636, 0.8766112331251055, 0.8695457081214363, 0.8971358999591397, 0.6107295590460481, 0.9301831153547477]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51
 52 53 55 56 57 58 59 60 61 62 63 64 65 67 68 69]
=> Acc: 0.711 Precision 0.711 Recall 0.711 F1 0.680 
=> Acc: 0.717 Precision 0.717 Recall 0.717 F1 0.697 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.892 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.778 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.719 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.890 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.784 
=> Acc: 0.700 Precision 0.700 Recall 0.700 F1 0.690 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.889 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.803 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.867 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.902 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.847 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.686 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 


accs [0.7108843537414966, 0.7172774869109948, 0.8935483870967742, 0.789515488482923, 0.7401998462720983, 0.888715953307393, 0.7876569037656904, 0.7003921568627451, 0.8910329171396141, 0.8226455594311779, 0.8824626865671642, 0.9000502260170768, 0.8604998135024244, 0.7404648390941597, 0.9808575803981623]
 precisions [0.6938775510204082, 0.6963350785340314, 0.8940092165898618, 0.812549642573471, 0.7555726364335127, 0.8770428015564202, 0.799163179916318, 0.6784313725490196, 0.9182746878547106, 0.8180842500670781, 0.8992537313432836, 0.8995479658463084, 0.8716896680343156, 0.7514898688915376, 0.9754977029096478]
 recalls [0.6904761904761905, 0.6596858638743456, 0.880184331797235, 0.778395552025417, 0.7524980784012298, 0.8840466926070039, 0.7981171548117155, 0.7090196078431372, 0.8864926220204313, 0.8213039978535015, 0.8843283582089553, 0.9020592667001507, 0.8698246922790004, 0.7428486293206198, 0.9808575803981623]
 f1scores [0.6626224309443355, 0.6568910597448973, 0.8898382778128011, 0.7741455424187873, 0.7189510778300523, 0.8943345715051763, 0.7660196282218006, 0.7024428091482458, 0.8883391657006205, 0.8118543383653231, 0.8767594822299047, 0.8961495483952824, 0.8474780908358805, 0.6871393263971284, 0.9831662516288053]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24 25 26
 27 28 29 30 31 32 33 34 35 36 37 38 40 42 43 44 45 46 47 48 49 50 51 52
 54 55 56 57 59 61 62 63 64 65 66 67 68 69 70 71 72 73 74]
=> Acc: 0.639 Precision 0.639 Recall 0.639 F1 0.609 
=> Acc: 0.661 Precision 0.661 Recall 0.661 F1 0.651 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.847 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.807 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.754 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.888 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.819 
=> Acc: 0.637 Precision 0.637 Recall 0.637 F1 0.621 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.867 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.830 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.829 
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.751 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.855 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.858 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.719 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.962 


accs [0.6394557823129252, 0.6614310645724258, 0.8506912442396314, 0.8061953931691819, 0.7694081475787855, 0.8848249027237354, 0.8169456066945606, 0.6368627450980392, 0.8717366628830874, 0.8365977998390126, 0.8675373134328358, 0.7709693621295831, 0.8545318910854159, 0.8629320619785459, 0.7802450229709035, 0.9604651162790697]
 precisions [0.5680272108843537, 0.6928446771378709, 0.8456221198156681, 0.8030182684670373, 0.7640276710222905, 0.8996108949416343, 0.7960251046025104, 0.6533333333333333, 0.8433598183881952, 0.8204990609068956, 0.8246268656716418, 0.7689603214465093, 0.8586348377471092, 0.8718712753277712, 0.7580398162327718, 0.9697674418604652]
 recalls [0.6292517006802721, 0.6928446771378709, 0.8276497695852535, 0.8101667990468626, 0.7755572636433513, 0.8941634241245137, 0.8002092050209205, 0.6690196078431373, 0.8581157775255391, 0.8234504963777838, 0.8376865671641791, 0.7589151180311401, 0.8716896680343156, 0.8638259833134684, 0.7833078101071975, 0.9720930232558139]
 f1scores [0.5609557752975853, 0.6816587553721847, 0.8345702260335581, 0.8048535683632962, 0.7752435430606421, 0.897355534937766, 0.8329131932398847, 0.6396922372657149, 0.8690323066479845, 0.8245998819864491, 0.8235308094979652, 0.7373044719375852, 0.8650108073079608, 0.8543240434343836, 0.7125200389718804, 0.9719678277665829]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  2  3  4  5  6  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25 26
 28 29 31 32 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48 49 50 51 52 54
 55 56 57 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79]
=> Acc: 0.633 Precision 0.633 Recall 0.633 F1 0.600 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.823 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.896 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.908 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.769 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.918 
=> Acc: 0.735 Precision 0.735 Recall 0.735 F1 0.722 
=> Acc: 0.655 Precision 0.655 Recall 0.655 F1 0.637 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.863 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.845 
=> Acc: 0.821 Precision 0.821 Recall 0.821 F1 0.768 
=> Acc: 0.709 Precision 0.709 Recall 0.709 F1 0.689 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.824 
=> Acc: 0.807 Precision 0.807 Recall 0.807 F1 0.813 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.698 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.959 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.867 


accs [0.6326530612244898, 0.837696335078534, 0.8963133640552995, 0.9086576648133439, 0.781706379707917, 0.9167315175097276, 0.7353556485355649, 0.6549019607843137, 0.8626560726447219, 0.8567212235041588, 0.8208955223880597, 0.7091913611250628, 0.8437150317045878, 0.8072109654350417, 0.7656967840735069, 0.958139534883721, 0.8754019292604501]
 precisions [0.7108843537414966, 0.8324607329842932, 0.9059907834101383, 0.9086576648133439, 0.7901614142966948, 0.9198443579766536, 0.7207112970711297, 0.6658823529411765, 0.8513053348467651, 0.8526965387711296, 0.8208955223880597, 0.7327975891511803, 0.8176053711301753, 0.7949940405244339, 0.7327718223583461, 0.9627906976744186, 0.8818327974276527]
 recalls [0.6428571428571429, 0.8184991273996509, 0.8990783410138249, 0.8967434471803019, 0.7678708685626441, 0.9206225680933852, 0.7217573221757322, 0.6611764705882353, 0.8399545970488081, 0.8419640461497183, 0.8190298507462687, 0.6981416373681567, 0.8366281238343901, 0.8048271752085816, 0.7580398162327718, 0.958139534883721, 0.8633440514469454]
 f1scores [0.6254236318970215, 0.7998562786785043, 0.9031853142020584, 0.9060593101174051, 0.7709911777487888, 0.9236667791886664, 0.7333116419097102, 0.6478859562766028, 0.8559741765994987, 0.829143923441819, 0.7492467146754985, 0.6847283148751137, 0.8218364307803446, 0.8176367992367028, 0.6988629026590788, 0.9495639719995357, 0.871282232019721]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25
 26 27 28 29 32 33 34 35 36 37 38 40 42 43 44 45 46 47 48 49 50 51 52 54
 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 75 77 78 79 80
 82 83]
=> Acc: 0.595 Precision 0.595 Recall 0.595 F1 0.573 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.847 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.899 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.781 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.801 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.920 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.826 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.782 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.788 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.885 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.739 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.879 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.822 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.830 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.703 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.920 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.752 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.835 


accs [0.5952380952380952, 0.8464223385689355, 0.9013824884792627, 0.789515488482923, 0.8162951575710992, 0.9182879377431906, 0.8263598326359832, 0.7850980392156863, 0.8240635641316686, 0.8867722028441105, 0.7817164179104478, 0.880462079357107, 0.8328981723237598, 0.833134684147795, 0.7664624808575804, 0.9232558139534883, 0.7548231511254019, 0.8437917222963952]
 precisions [0.5476190476190477, 0.8638743455497382, 0.8990783410138249, 0.7926926131850676, 0.7909300538047656, 0.9237354085603113, 0.799163179916318, 0.7615686274509804, 0.8286038592508513, 0.8854306412664341, 0.8003731343283582, 0.8593671521848317, 0.854904886236479, 0.8393921334922527, 0.7618683001531393, 0.9372093023255814, 0.7893890675241158, 0.855807743658211]
 recalls [0.5816326530612245, 0.8586387434554974, 0.8990783410138249, 0.7918983320095314, 0.7740199846272099, 0.9385214007782101, 0.805439330543933, 0.7749019607843137, 0.8093076049943246, 0.8840890796887577, 0.7835820895522388, 0.880462079357107, 0.8336441626258858, 0.848927294398093, 0.7633996937212864, 0.9372093023255814, 0.7588424437299035, 0.8544726301735648]
 f1scores [0.5734141072745618, 0.8351985414352537, 0.9051824860643185, 0.792629119027371, 0.7840085782818322, 0.9391440524353992, 0.8001721488816875, 0.7816113045791008, 0.8096096666472, 0.8847942785639079, 0.7464984055916142, 0.8670854429956861, 0.81670247756568, 0.8346858199701861, 0.72231680058688, 0.9052980836487909, 0.7382935552938247, 0.8540579814042232]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  2  4  5  6  7  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 25 26 27
 28 29 32 33 34 35 36 38 41 42 43 44 45 46 47 48 49 50 51 52 54 55 56 57
 58 59 60 61 62 63 64 65 67 68 69 70 71 72 73 74 75 76 77 78 79 80 82 83
 84 85 86 87 88 89]
=> Acc: 0.469 Precision 0.469 Recall 0.469 F1 0.417 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.869 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.887 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.901 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.770 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.944 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.809 
=> Acc: 0.683 Precision 0.683 Recall 0.683 F1 0.666 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.871 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.880 
=> Acc: 0.759 Precision 0.759 Recall 0.759 F1 0.713 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.947 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.785 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.782 
=> Acc: 0.712 Precision 0.712 Recall 0.712 F1 0.667 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.859 
=> Acc: 0.759 Precision 0.759 Recall 0.759 F1 0.753 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.818 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.949 


accs [0.46938775510204084, 0.8760907504363001, 0.8884792626728111, 0.9023034154090548, 0.7855495772482706, 0.9447470817120622, 0.8117154811715481, 0.6831372549019608, 0.8683314415437003, 0.8832841427421518, 0.7593283582089553, 0.9482672024108488, 0.8030585602387169, 0.7943980929678188, 0.7120980091883614, 0.8604651162790697, 0.7588424437299035, 0.8144192256341789, 0.9511677282377919]
 precisions [0.42857142857142855, 0.8691099476439791, 0.8829493087557604, 0.8967434471803019, 0.7732513451191392, 0.9431906614785992, 0.801255230125523, 0.6909803921568628, 0.8819523269012486, 0.8851623289508989, 0.7966417910447762, 0.9372174786539428, 0.8045505408429691, 0.7866507747318237, 0.7182235834609495, 0.8604651162790697, 0.7612540192926045, 0.807743658210948, 0.9522292993630573]
 recalls [0.47959183673469385, 0.8691099476439791, 0.896774193548387, 0.8959491660047657, 0.7524980784012298, 0.9377431906614786, 0.805439330543933, 0.7058823529411765, 0.8842224744608399, 0.8838207673732225, 0.7518656716417911, 0.9387242591662481, 0.7914957105557627, 0.7666865315852205, 0.6852986217457887, 0.8813953488372093, 0.7548231511254019, 0.8144192256341789, 0.9532908704883227]
 f1scores [0.4080975723622783, 0.892356168809253, 0.8861797639153565, 0.9063345932794474, 0.748491187475309, 0.9429940836982095, 0.7903808462369634, 0.6574591188345693, 0.8756217566805746, 0.8825904385949359, 0.7303181495732485, 0.9469554187946262, 0.7756173766031192, 0.7695535040746313, 0.6680332651651878, 0.8881110627313159, 0.7585850362790793, 0.8260868175365319, 0.9438699365663753]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 1  2  3  4  5  6  8  9 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 27
 28 29 31 32 33 34 35 36 37 38 39 40 41 42 43 45 46 47 48 49 50 51 52 53
 54 55 57 58 59 60 61 62 63 64 65 67 68 69 70 71 72 73 75 76 78 79 81 82
 83 84 85 86 87 88 89 90 91 93 94]
done w/ time
All done
