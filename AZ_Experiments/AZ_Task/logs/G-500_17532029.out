Current date and time 
##### START task 10000 grs #####
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.997 Precision 0.997 Recall 0.997 F1 0.997 


accs [0.9967783505154639]
 precisions [0.9967783505154639]
 recalls [0.9954896907216495]
 f1scores [0.9973776985893729]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.946 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.989 


accs [0.9439432989690721, 0.9899928520371694]
 precisions [0.9503865979381443, 0.9864188706218727]
 recalls [0.9497422680412371, 0.993566833452466]
 f1scores [0.9410624874564766, 0.9857863264607291]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.919 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.967 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9188144329896907, 0.9685489635453896, 1.0]
 precisions [0.9110824742268041, 0.9635453895639743, 0.9970059880239521]
 recalls [0.9104381443298969, 0.9664045746962115, 0.9985029940119761]
 f1scores [0.909549635953449, 0.9660772352201448, 0.9970581873242483]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.840 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.898 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.945 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.931 


accs [0.8569587628865979, 0.9013581129378128, 0.9491017964071856, 0.9330015313935681]
 precisions [0.854381443298969, 0.8977841315225161, 0.9476047904191617, 0.9395099540581929]
 recalls [0.8498711340206185, 0.9135096497498213, 0.9476047904191617, 0.9272588055130169]
 f1scores [0.8465257655480519, 0.896823166374505, 0.9282116303402885, 0.9306144470236581]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.810 
=> Acc: 0.750 Precision 0.750 Recall 0.750 F1 0.733 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.916 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.889 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 


accs [0.8137886597938144, 0.7498213009292352, 0.9176646706586826, 0.8878254211332313, 0.9902097902097902]
 precisions [0.8305412371134021, 0.7612580414581844, 0.9191616766467066, 0.9023736600306279, 0.9846153846153847]
 recalls [0.8105670103092784, 0.7462473195139385, 0.9131736526946108, 0.8878254211332313, 0.9874125874125874]
 f1scores [0.7933774313283111, 0.7341598052656362, 0.9026850446240957, 0.8892527133589143, 0.9866847661921078]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.884 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.828 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.888 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.857 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.882 
=> Acc: 0.995 Precision 0.995 Recall 0.995 F1 0.995 


accs [0.8930412371134021, 0.8391708363116511, 0.8862275449101796, 0.8610260336906586, 0.8888111888111888, 0.9949748743718593]
 precisions [0.8762886597938144, 0.8491779842744818, 0.8802395209580839, 0.8675344563552833, 0.9006993006993007, 0.998324958123953]
 recalls [0.8730670103092784, 0.8220157255182273, 0.8802395209580839, 0.8610260336906586, 0.8874125874125874, 0.9974874371859297]
 f1scores [0.8742537965581967, 0.8300282528746358, 0.8815702289064975, 0.8572167228462984, 0.8853440642660729, 0.9974567388214505]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.820 
=> Acc: 0.666 Precision 0.666 Recall 0.666 F1 0.637 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.874 
=> Acc: 0.712 Precision 0.712 Recall 0.712 F1 0.688 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.819 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.947 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.952 


accs [0.8221649484536082, 0.6661901358112938, 0.8772455089820359, 0.7117151607963247, 0.83006993006993, 0.948073701842546, 0.9532163742690059]
 precisions [0.8060567010309279, 0.6976411722659042, 0.8967065868263473, 0.7113323124042878, 0.8216783216783217, 0.9396984924623115, 0.9736842105263158]
 recalls [0.8047680412371134, 0.688348820586133, 0.8817365269461078, 0.6795558958652373, 0.8349650349650349, 0.9422110552763819, 0.9619883040935673]
 f1scores [0.7962491297021241, 0.6559762449292589, 0.8687558615873311, 0.6761049307597771, 0.8272133595916614, 0.9522633937551073, 0.9558028713980246]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 27 28 29 30 32 33 34]
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.787 
=> Acc: 0.783 Precision 0.783 Recall 0.783 F1 0.765 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.779 
=> Acc: 0.705 Precision 0.705 Recall 0.705 F1 0.664 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.766 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.736 
=> Acc: 0.623 Precision 0.623 Recall 0.623 F1 0.562 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.971 


accs [0.7925257731958762, 0.7827019299499642, 0.7964071856287425, 0.7048238897396631, 0.8090909090909091, 0.7420435510887772, 0.6228070175438597, 0.9721283783783784]
 precisions [0.7777061855670103, 0.7812723373838456, 0.8248502994011976, 0.7052067381316999, 0.8111888111888111, 0.7077051926298158, 0.6403508771929824, 0.9733952702702703]
 recalls [0.8002577319587629, 0.7598284488920658, 0.8053892215568862, 0.7036753445635529, 0.8125874125874126, 0.7378559463986599, 0.6198830409356725, 0.9721283783783784]
 f1scores [0.7831885684435689, 0.7736150850676545, 0.7980624909762257, 0.6543026279672135, 0.771770698897113, 0.7312960744495742, 0.5657288984701464, 0.970367438154763]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
 27 28 29 31 32 33 34 35 36 38 39]
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.760 
=> Acc: 0.751 Precision 0.751 Recall 0.751 F1 0.733 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.805 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.781 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.816 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.796 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.756 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.879 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.772 


accs [0.7648195876288659, 0.7512508934953538, 0.8023952095808383, 0.7882848392036753, 0.8328671328671329, 0.8056951423785594, 0.7660818713450293, 0.8796452702702703, 0.7836477987421384]
 precisions [0.7841494845360825, 0.7569692637598284, 0.8083832335329342, 0.8016845329249617, 0.8195804195804196, 0.7864321608040201, 0.7543859649122807, 0.8847128378378378, 0.7836477987421384]
 recalls [0.7731958762886598, 0.7648320228734811, 0.7949101796407185, 0.8062787136294027, 0.813986013986014, 0.7830820770519263, 0.7631578947368421, 0.8771114864864865, 0.7842767295597485]
 f1scores [0.7560303252057905, 0.7334029940287374, 0.823228675194285, 0.7863268044011683, 0.8113224425925211, 0.7665680795213168, 0.7866611934643075, 0.8814691605598902, 0.7616507198650764]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 24
 25 28 29 30 31 33 34 35 36 38 39 40 41 42 43 44]
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.858 
=> Acc: 0.757 Precision 0.757 Recall 0.757 F1 0.750 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.893 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.749 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.831 
=> Acc: 0.732 Precision 0.732 Recall 0.732 F1 0.702 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.805 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.905 
=> Acc: 0.608 Precision 0.608 Recall 0.608 F1 0.568 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 


accs [0.8608247422680413, 0.7569692637598284, 0.8967065868263473, 0.7545941807044411, 0.8349650349650349, 0.7319932998324958, 0.8157894736842105, 0.9045608108108109, 0.6075471698113207, 0.9905511811023622]
 precisions [0.8427835051546392, 0.7591136526090064, 0.8922155688622755, 0.7396630934150077, 0.8048951048951049, 0.7345058626465661, 0.8099415204678363, 0.8910472972972973, 0.6289308176100629, 0.9905511811023622]
 recalls [0.8595360824742269, 0.7676912080057183, 0.8787425149700598, 0.7369831546707504, 0.8090909090909091, 0.7504187604690117, 0.8187134502923976, 0.8973817567567568, 0.6062893081761006, 0.9952755905511811]
 f1scores [0.8336184692111728, 0.7576217218355419, 0.8730849722502126, 0.7496586693570728, 0.8020264023889216, 0.7115253462798498, 0.8038378273511133, 0.9124951544890108, 0.5747603570923935, 0.9936574120408768]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20 22 23 24 25 27
 28 29 31 32 33 34 35 36 37 38 39 40 41 42 44 47 48 49]
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.791 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.861 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.692 
=> Acc: 0.667 Precision 0.667 Recall 0.667 F1 0.625 
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.696 
=> Acc: 0.714 Precision 0.714 Recall 0.714 F1 0.669 
=> Acc: 0.711 Precision 0.711 Recall 0.711 F1 0.693 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.859 
=> Acc: 0.669 Precision 0.669 Recall 0.669 F1 0.650 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.834 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 


accs [0.8054123711340206, 0.862759113652609, 0.7649700598802395, 0.6665390505359877, 0.7433566433566433, 0.7135678391959799, 0.7105263157894737, 0.859375, 0.6691823899371069, 0.831496062992126, 0.9438155136268344]
 precisions [0.8247422680412371, 0.8598999285203717, 0.7365269461077845, 0.6833843797856048, 0.7517482517482518, 0.7160804020100503, 0.7222222222222222, 0.8589527027027027, 0.6792452830188679, 0.8598425196850393, 0.9446540880503145]
 recalls [0.8195876288659794, 0.852037169406719, 0.7470059880239521, 0.6787901990811639, 0.7377622377622378, 0.7043551088777219, 0.7251461988304093, 0.8581081081081081, 0.6893081761006289, 0.8362204724409449, 0.9429769392033543]
 f1scores [0.79295642147275, 0.8555227335149045, 0.6771284297715306, 0.6270531690688552, 0.6997954396249552, 0.669176828176465, 0.6621929529473489, 0.8564752103749012, 0.6581551681180347, 0.8199639890916026, 0.939095486558109]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20 21 22 23 24 25
 28 29 30 31 32 33 34 35 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
 53 54]
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.741 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.840 
=> Acc: 0.728 Precision 0.728 Recall 0.728 F1 0.658 
=> Acc: 0.709 Precision 0.709 Recall 0.709 F1 0.678 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.793 
=> Acc: 0.678 Precision 0.678 Recall 0.678 F1 0.610 
=> Acc: 0.760 Precision 0.760 Recall 0.760 F1 0.742 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.831 
=> Acc: 0.652 Precision 0.652 Recall 0.652 F1 0.623 
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.787 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 


accs [0.7628865979381443, 0.8484631879914224, 0.7275449101796407, 0.7086523736600306, 0.813986013986014, 0.6775544388609716, 0.7602339181286549, 0.8336148648648649, 0.6522012578616352, 0.7874015748031497, 0.9253668763102726, 0.9944495837187789]
 precisions [0.7667525773195877, 0.856325947105075, 0.7290419161676647, 0.7082695252679939, 0.8223776223776224, 0.7202680067001676, 0.7222222222222222, 0.8277027027027027, 0.6660377358490566, 0.752755905511811, 0.9182389937106918, 0.9935245143385754]
 recalls [0.7654639175257731, 0.8498927805575411, 0.7260479041916168, 0.7036753445635529, 0.83006993006993, 0.6725293132328308, 0.7192982456140351, 0.8348817567567568, 0.6522012578616352, 0.8078740157480315, 0.9283018867924528, 0.9921369102682701]
 f1scores [0.7525409122462688, 0.849606078213182, 0.6308625066978899, 0.6671974885307146, 0.8070190160088251, 0.6046476385083098, 0.7337691583765823, 0.8330015649024904, 0.6240765193854951, 0.7858124718266251, 0.9125257283763017, 0.9958223927444021]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  5  6  7  9 10 11 12 13 14 15 16 17 19 20 22 23 24 25 26 27
 29 30 31 32 33 34 35 36 38 39 40 41 42 44 46 47 48 49 51 52 53 54 55 57
 59]
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.741 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.738 
=> Acc: 0.690 Precision 0.690 Recall 0.690 F1 0.651 
=> Acc: 0.725 Precision 0.725 Recall 0.725 F1 0.685 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.770 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.807 
=> Acc: 0.664 Precision 0.664 Recall 0.664 F1 0.656 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.861 
=> Acc: 0.626 Precision 0.626 Recall 0.626 F1 0.574 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.816 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.780 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.803 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 


accs [0.7751288659793815, 0.7548248749106504, 0.6901197604790419, 0.725114854517611, 0.8090909090909091, 0.8174204355108877, 0.6637426900584795, 0.8640202702702703, 0.6257861635220126, 0.8362204724409449, 0.7953878406708595, 0.8196114708603145, 0.9655172413793104]
 precisions [0.759020618556701, 0.7441029306647605, 0.7305389221556886, 0.7120980091883614, 0.8104895104895105, 0.8132328308207705, 0.6637426900584795, 0.8673986486486487, 0.6314465408805031, 0.8503937007874016, 0.7853249475890985, 0.8043478260869565, 0.9504310344827587]
 recalls [0.7545103092783505, 0.7598284488920658, 0.7275449101796407, 0.7159264931087289, 0.8153846153846154, 0.7989949748743719, 0.6286549707602339, 0.8640202702702703, 0.6257861635220126, 0.8299212598425196, 0.7932914046121593, 0.8006475485661425, 0.9353448275862069]
 f1scores [0.7588189437902566, 0.7262988329987687, 0.695315189605828, 0.6911109584021317, 0.7556039281425686, 0.8052133118898539, 0.6461084446481307, 0.8493245019541631, 0.5883061399791141, 0.8117906688038404, 0.7853948215945913, 0.7795775947607237, 0.9407391951402324]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  5  6  7  8  9 10 11 12 14 15 16 17 19 20 21 22 23 24 25 26
 27 28 29 33 34 35 36 37 38 39 40 41 42 43 44 47 49 50 51 52 53 54 55 56
 57 58 59 60 61 62 63]
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.703 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.723 
=> Acc: 0.737 Precision 0.737 Recall 0.737 F1 0.698 
=> Acc: 0.709 Precision 0.709 Recall 0.709 F1 0.662 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.794 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.805 
=> Acc: 0.532 Precision 0.532 Recall 0.532 F1 0.469 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.809 
=> Acc: 0.584 Precision 0.584 Recall 0.584 F1 0.541 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.806 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.876 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.807 
=> Acc: 0.731 Precision 0.731 Recall 0.731 F1 0.700 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 


accs [0.7467783505154639, 0.7419585418155825, 0.7365269461077845, 0.7094180704441041, 0.823076923076923, 0.8040201005025126, 0.5321637426900585, 0.816722972972973, 0.5836477987421383, 0.8141732283464567, 0.8733752620545073, 0.8126734505087881, 0.7306034482758621, 0.9693454846727423]
 precisions [0.7184278350515464, 0.7598284488920658, 0.7455089820359282, 0.7109494640122511, 0.8048951048951049, 0.821608040201005, 0.4590643274853801, 0.8108108108108109, 0.5742138364779874, 0.8299212598425196, 0.8742138364779874, 0.8020351526364478, 0.7306034482758621, 0.9743164871582436]
 recalls [0.7229381443298969, 0.7605432451751251, 0.7455089820359282, 0.7040581929555896, 0.8111888111888111, 0.8073701842546064, 0.5350877192982456, 0.7884290540540541, 0.579874213836478, 0.8267716535433071, 0.8725366876310272, 0.786308973172988, 0.728448275862069, 0.9710024855012428]
 f1scores [0.6835531179628264, 0.7239129395630719, 0.6791654806291919, 0.6681601032321163, 0.7757408320340977, 0.8266177721142386, 0.4425715352754236, 0.7858572129837749, 0.5223628642297047, 0.8244857443585001, 0.8796467017267314, 0.7830788717047363, 0.732489841917955, 0.9754352817345332]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
 26 27 29 30 31 32 33 34 35 37 38 39 40 41 42 43 45 46 47 49 51 52 53 55
 57 58 59 60 62 63 64 65 66 68]
=> Acc: 0.728 Precision 0.728 Recall 0.728 F1 0.678 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.800 
=> Acc: 0.722 Precision 0.722 Recall 0.722 F1 0.675 
=> Acc: 0.665 Precision 0.665 Recall 0.665 F1 0.636 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.831 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.904 
=> Acc: 0.567 Precision 0.567 Recall 0.567 F1 0.560 
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.769 
=> Acc: 0.509 Precision 0.509 Recall 0.509 F1 0.452 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.694 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.900 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.883 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.815 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 


accs [0.7280927835051546, 0.8041458184417442, 0.7215568862275449, 0.6650076569678407, 0.8405594405594405, 0.9028475711892797, 0.5672514619883041, 0.7706925675675675, 0.5088050314465409, 0.9622047244094488, 0.6993710691823899, 0.900555041628122, 0.8836206896551724, 0.8409279204639603, 0.9750830564784053]
 precisions [0.7119845360824743, 0.8162973552537527, 0.7589820359281437, 0.669218989280245, 0.8391608391608392, 0.9053601340033501, 0.6228070175438597, 0.7795608108108109, 0.4811320754716981, 0.968503937007874, 0.710691823899371, 0.9135060129509713, 0.8900862068965517, 0.8268434134217068, 0.9833887043189369]
 recalls [0.7048969072164949, 0.7726947819871337, 0.6991017964071856, 0.6527565084226646, 0.8510489510489511, 0.8844221105527639, 0.5146198830409356, 0.7905405405405406, 0.5106918238993711, 0.9622047244094488, 0.7014675052410901, 0.9014801110083256, 0.896551724137931, 0.8550124275062138, 0.9700996677740864]
 f1scores [0.6715285362948581, 0.7974955265768118, 0.6791722407110564, 0.6266822866833891, 0.822864491927359, 0.8890854656912686, 0.5076849262429199, 0.7760638837582459, 0.45165360050285724, 0.9730144006778456, 0.7195627640264143, 0.9167027307905229, 0.9017253707035374, 0.8157630146318728, 0.977369751479978]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  4  5  7  9 10 11 12 14 15 16 17 19 20 22 23 24 25 26 28 29 31
 32 33 34 35 36 37 38 39 40 41 42 45 46 47 48 51 52 53 54 55 56 57 59 60
 61 62 63 64 66 67 70 71 72]
=> Acc: 0.733 Precision 0.733 Recall 0.733 F1 0.699 
=> Acc: 0.744 Precision 0.744 Recall 0.744 F1 0.714 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.762 
=> Acc: 0.665 Precision 0.665 Recall 0.665 F1 0.636 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.767 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.848 
=> Acc: 0.482 Precision 0.482 Recall 0.482 F1 0.477 
=> Acc: 0.707 Precision 0.707 Recall 0.707 F1 0.701 
=> Acc: 0.612 Precision 0.612 Recall 0.612 F1 0.550 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.726 
=> Acc: 0.708 Precision 0.708 Recall 0.708 F1 0.669 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.790 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.811 
=> Acc: 0.673 Precision 0.673 Recall 0.673 F1 0.605 
=> Acc: 0.653 Precision 0.653 Recall 0.653 F1 0.570 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.931 


accs [0.7332474226804123, 0.7441029306647605, 0.7724550898203593, 0.6653905053598775, 0.7958041958041958, 0.8492462311557789, 0.4824561403508772, 0.7065033783783784, 0.6119496855345912, 0.7622047244094489, 0.7081761006289308, 0.8048103607770583, 0.8125, 0.6727423363711682, 0.6528239202657807, 0.9311087190527448]
 precisions [0.7190721649484536, 0.7376697641172266, 0.8053892215568862, 0.6849157733537519, 0.8195804195804196, 0.8509212730318257, 0.49122807017543857, 0.703125, 0.6031446540880503, 0.7968503937007874, 0.7249475890985325, 0.7844588344125809, 0.790948275862069, 0.6975973487986744, 0.6688815060908084, 0.9230355220667384]
 recalls [0.7364690721649485, 0.7105075053609721, 0.7769461077844312, 0.6669218989280244, 0.7979020979020979, 0.8802345058626466, 0.4678362573099415, 0.707347972972973, 0.6163522012578616, 0.784251968503937, 0.7194968553459119, 0.7876965772432932, 0.8254310344827587, 0.676056338028169, 0.6622369878183831, 0.9354144241119483]
 f1scores [0.6683891682469254, 0.7072982887414984, 0.7687884628369483, 0.6340507495050323, 0.783564475281051, 0.8810298015460616, 0.51181076459002, 0.696341569581854, 0.5185303541704238, 0.7806569909640342, 0.6873084890748815, 0.7745406222683917, 0.7965583173977319, 0.5891882077512992, 0.5715742467386944, 0.9276647690052322]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15 16 17 19 20 21 22 23 24 25
 27 29 32 33 34 35 37 38 39 41 42 44 46 47 48 49 51 52 53 54 55 56 57 59
 60 61 62 63 64 66 67 68 70 71 72 73 76 77 79]
=> Acc: 0.750 Precision 0.750 Recall 0.750 F1 0.733 
=> Acc: 0.691 Precision 0.691 Recall 0.691 F1 0.640 
=> Acc: 0.659 Precision 0.659 Recall 0.659 F1 0.616 
=> Acc: 0.663 Precision 0.663 Recall 0.663 F1 0.637 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.798 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.900 
=> Acc: 0.629 Precision 0.629 Recall 0.629 F1 0.583 
=> Acc: 0.694 Precision 0.694 Recall 0.694 F1 0.669 
=> Acc: 0.619 Precision 0.619 Recall 0.619 F1 0.554 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.863 
=> Acc: 0.748 Precision 0.748 Recall 0.748 F1 0.677 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.847 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.793 
=> Acc: 0.666 Precision 0.666 Recall 0.666 F1 0.605 
=> Acc: 0.644 Precision 0.644 Recall 0.644 F1 0.566 
=> Acc: 0.545 Precision 0.545 Recall 0.545 F1 0.442 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.904 


accs [0.75, 0.6912080057183703, 0.6586826347305389, 0.663093415007657, 0.8216783216783217, 0.8961474036850922, 0.6286549707602339, 0.6942567567567568, 0.6188679245283019, 0.8677165354330708, 0.7484276729559748, 0.862627197039778, 0.7952586206896551, 0.6661143330571665, 0.6439645625692137, 0.5446716899892358, 0.9058500914076782]
 precisions [0.7551546391752577, 0.6940671908506075, 0.655688622754491, 0.6849157733537519, 0.8041958041958042, 0.8927973199329984, 0.6081871345029239, 0.6794763513513513, 0.6245283018867924, 0.8346456692913385, 0.7392033542976939, 0.8612395929694727, 0.7995689655172413, 0.6603148301574151, 0.6622369878183831, 0.5419806243272336, 0.9021937842778793]
 recalls [0.7487113402061856, 0.6854896354538956, 0.6467065868263473, 0.6722817764165391, 0.8244755244755245, 0.8877721943048577, 0.5906432748538012, 0.7043918918918919, 0.6220125786163522, 0.8645669291338582, 0.740880503144654, 0.8732654949121184, 0.7952586206896551, 0.6975973487986744, 0.6627906976744186, 0.5371367061356297, 0.8875685557586838]
 f1scores [0.7364734480475823, 0.6340183431766053, 0.5746341870231493, 0.6564758134634257, 0.7897100941001539, 0.887586006570736, 0.5600264973677571, 0.7006686971212532, 0.551660590992842, 0.8638084622076084, 0.6795810260969188, 0.8636934705506937, 0.778601975019536, 0.6006758478539123, 0.5840434579251754, 0.4402591826685683, 0.9020649737011185]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  5  7  9 10 11 13 14 15 16 17 19 20 21 22 23 24 25 26 27 28
 29 33 34 35 36 38 39 40 41 42 44 45 46 47 49 51 52 53 54 55 57 58 59 60
 61 62 65 66 68 69 70 71 72 73 74 75 77 79 81 82 83 84]
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.708 
=> Acc: 0.657 Precision 0.657 Recall 0.657 F1 0.601 
=> Acc: 0.723 Precision 0.723 Recall 0.723 F1 0.664 
=> Acc: 0.673 Precision 0.673 Recall 0.673 F1 0.629 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.777 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.900 
=> Acc: 0.550 Precision 0.550 Recall 0.550 F1 0.502 
=> Acc: 0.640 Precision 0.640 Recall 0.640 F1 0.611 
=> Acc: 0.632 Precision 0.632 Recall 0.632 F1 0.611 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.888 
=> Acc: 0.730 Precision 0.730 Recall 0.730 F1 0.673 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.842 
=> Acc: 0.694 Precision 0.694 Recall 0.694 F1 0.660 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.828 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.809 
=> Acc: 0.630 Precision 0.630 Recall 0.630 F1 0.559 
=> Acc: 0.783 Precision 0.783 Recall 0.783 F1 0.747 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.859 


accs [0.7474226804123711, 0.6568977841315226, 0.7230538922155688, 0.6730474732006125, 0.7895104895104895, 0.8986599664991625, 0.5497076023391813, 0.6397804054054054, 0.6320754716981132, 0.8913385826771654, 0.7295597484276729, 0.8464384828862165, 0.6939655172413793, 0.84009942004971, 0.8089700996677741, 0.6297093649085038, 0.783363802559415, 0.8708551483420593]
 precisions [0.7435567010309279, 0.6804860614724804, 0.7290419161676647, 0.6791730474732006, 0.8048951048951049, 0.9087102177554439, 0.5350877192982456, 0.6579391891891891, 0.6679245283018868, 0.8976377952755905, 0.7337526205450734, 0.820536540240518, 0.7262931034482759, 0.8177299088649544, 0.8006644518272426, 0.6184068891280947, 0.7605118829981719, 0.8586387434554974]
 recalls [0.7519329896907216, 0.6611865618298784, 0.7514970059880239, 0.6680704441041347, 0.7937062937062938, 0.8969849246231156, 0.5614035087719298, 0.65625, 0.6333333333333333, 0.8976377952755905, 0.7387840670859539, 0.8501387604070305, 0.709051724137931, 0.8185584092792046, 0.7890365448504983, 0.6157158234660925, 0.7906764168190128, 0.8673647469458988]
 f1scores [0.7217105420570251, 0.5962009602610424, 0.6709830398355132, 0.638294157394643, 0.769317312106432, 0.9057589553504986, 0.4661740190895814, 0.6300426824242182, 0.6317241065282932, 0.8724219680152734, 0.6902900749370805, 0.8326821400414838, 0.6618270962853352, 0.803898780288234, 0.7824149298232823, 0.5559994355368986, 0.7240973278630716, 0.8487449186001923]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  5  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 24 25 29
 32 33 34 35 36 37 38 39 40 41 42 43 44 47 49 51 52 53 54 55 56 57 58 59
 61 62 63 65 66 68 69 70 71 72 73 75 76 77 79 80 82 83 84 86 87 88 89]
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.698 
=> Acc: 0.694 Precision 0.694 Recall 0.694 F1 0.664 
=> Acc: 0.781 Precision 0.781 Recall 0.781 F1 0.778 
=> Acc: 0.701 Precision 0.701 Recall 0.701 F1 0.675 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.800 
=> Acc: 0.723 Precision 0.723 Recall 0.723 F1 0.713 
=> Acc: 0.491 Precision 0.491 Recall 0.491 F1 0.431 
=> Acc: 0.638 Precision 0.638 Recall 0.638 F1 0.609 
=> Acc: 0.558 Precision 0.558 Recall 0.558 F1 0.532 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.861 
=> Acc: 0.692 Precision 0.692 Recall 0.692 F1 0.628 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.804 
=> Acc: 0.625 Precision 0.625 Recall 0.625 F1 0.572 
=> Acc: 0.647 Precision 0.647 Recall 0.647 F1 0.590 
=> Acc: 0.724 Precision 0.724 Recall 0.724 F1 0.722 
=> Acc: 0.627 Precision 0.627 Recall 0.627 F1 0.566 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.823 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.753 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.952 


accs [0.7493556701030928, 0.6940671908506075, 0.781437125748503, 0.7006125574272588, 0.8125874125874126, 0.7227805695142379, 0.49122807017543857, 0.6380912162162162, 0.5578616352201258, 0.8598425196850393, 0.6918238993710691, 0.8094357076780758, 0.625, 0.6470588235294118, 0.7236987818383167, 0.6270182992465017, 0.8354661791590493, 0.7690517742873764, 0.9502262443438914]
 precisions [0.7635309278350515, 0.7205146533238027, 0.8173652694610778, 0.7323889739663093, 0.8286713286713286, 0.7160804020100503, 0.47076023391812866, 0.6473817567567568, 0.550314465408805, 0.8960629921259843, 0.6981132075471698, 0.8122109158186864, 0.6379310344827587, 0.6536868268434134, 0.7153931339977851, 0.6496232508073198, 0.8254113345521024, 0.7789412449098313, 0.9502262443438914]
 recalls [0.7654639175257731, 0.7205146533238027, 0.811377245508982, 0.7163093415007658, 0.8216783216783217, 0.7219430485762144, 0.47368421052631576, 0.6545608108108109, 0.5528301886792453, 0.8866141732283465, 0.6935010482180294, 0.8117483811285846, 0.6206896551724138, 0.6661143330571665, 0.707641196013289, 0.6490850376749193, 0.840036563071298, 0.7766143106457243, 0.9547511312217195]
 f1scores [0.6892844768688446, 0.6901027591947975, 0.8084671639852832, 0.675590421061169, 0.8102067299765132, 0.7240596459144969, 0.43066541065693836, 0.6228438351702741, 0.5118477371224623, 0.8625197136256336, 0.6243215179348764, 0.8016866512763808, 0.59407420377966, 0.6052877869751627, 0.7300978304376026, 0.5837102316499836, 0.8438035334814087, 0.7602262252031547, 0.9442207822280576]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15 16 17 19 20 22 23 24 25 26
 27 29 30 32 33 34 35 36 38 39 40 41 42 44 45 47 49 51 52 53 55 56 57 58
 59 60 61 62 63 64 65 66 67 69 70 71 72 76 77 79 80 81 82 83 84 86 88 89
 91 92 93 94]
=> Acc: 0.684 Precision 0.684 Recall 0.684 F1 0.636 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.754 
=> Acc: 0.672 Precision 0.672 Recall 0.672 F1 0.626 
=> Acc: 0.673 Precision 0.673 Recall 0.673 F1 0.634 
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.760 
=> Acc: 0.736 Precision 0.736 Recall 0.736 F1 0.677 
=> Acc: 0.620 Precision 0.620 Recall 0.620 F1 0.563 
=> Acc: 0.606 Precision 0.606 Recall 0.606 F1 0.566 
=> Acc: 0.663 Precision 0.663 Recall 0.663 F1 0.610 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.760 
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.683 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.947 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.769 
=> Acc: 0.572 Precision 0.572 Recall 0.572 F1 0.521 
=> Acc: 0.699 Precision 0.699 Recall 0.699 F1 0.630 
=> Acc: 0.640 Precision 0.640 Recall 0.640 F1 0.585 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.827 
=> Acc: 0.645 Precision 0.645 Recall 0.645 F1 0.587 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.811 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 


accs [0.6842783505154639, 0.7662616154395997, 0.6721556886227545, 0.6726646248085758, 0.7986013986013986, 0.7361809045226131, 0.6198830409356725, 0.6059966216216216, 0.6628930817610063, 0.7763779527559055, 0.7467505241090147, 0.9472710453283997, 0.7887931034482759, 0.5716652858326429, 0.698781838316722, 0.639935414424112, 0.8345521023765996, 0.6445607911576497, 0.8190045248868778, 0.9611440906637885]
 precisions [0.6617268041237113, 0.7719799857040743, 0.6931137724550899, 0.6711332312404288, 0.8132867132867133, 0.7470686767169179, 0.5292397660818714, 0.6009290540540541, 0.680503144654088, 0.7826771653543307, 0.7249475890985325, 0.9417206290471786, 0.790948275862069, 0.5260977630488816, 0.7009966777408638, 0.6307857911733046, 0.8107861060329068, 0.6329261198371146, 0.8416289592760181, 0.9638424177010254]
 recalls [0.6681701030927835, 0.7669764117226591, 0.6586826347305389, 0.6703675344563553, 0.8125874125874126, 0.7311557788944724, 0.5847953216374269, 0.5869932432432432, 0.6559748427672956, 0.7669291338582677, 0.7509433962264151, 0.9426456984273821, 0.7650862068965517, 0.5509527754763878, 0.6960132890365448, 0.6410118406889128, 0.8372943327239488, 0.6591041303083188, 0.7873303167420814, 0.9616837560712358]
 f1scores [0.6327077155787182, 0.7595530370248381, 0.6408554132726547, 0.6376974379517832, 0.7457713101529444, 0.6702340407843, 0.5590196078431372, 0.5613708681210021, 0.6232835822593792, 0.7649643175938461, 0.6845384211672323, 0.9356172991001792, 0.7509266842571238, 0.4865841425453123, 0.6381051845810768, 0.5699231582748909, 0.8346683220673994, 0.5973355180460814, 0.799861644814238, 0.9553674616908694]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.9888381532217149]
 precisions [0.9903602232369355]
 recalls [0.9939117199391172]
 f1scores [0.9913873744045475]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.862 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.975 


accs [0.8660578386605784, 0.9744483159117305]
 precisions [0.8599695585996956, 0.9796747967479674]
 recalls [0.863013698630137, 0.9849012775842044]
 f1scores [0.8651314679489694, 0.9788845593238396]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.915 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 


accs [0.9142567224759005, 0.9639953542392566, 0.9868620515411825]
 precisions [0.9193302891933028, 0.967479674796748, 0.9838302172814553]
 recalls [0.9249112125824455, 0.959349593495935, 0.9853461344113188]
 f1scores [0.904023402082975, 0.9690058854681316, 0.9832643098731639]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.812 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.880 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.993 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.886 


accs [0.8183663115169965, 0.8803716608594657, 0.9924204143506822, 0.8965065502183406]
 precisions [0.8082191780821918, 0.8960511033681765, 0.9853461344113188, 0.894759825327511]
 recalls [0.8203957382039574, 0.889082462253194, 0.9843355229914098, 0.8868995633187773]
 f1scores [0.812845825615897, 0.8899057654549362, 0.9858463353484904, 0.879828597781367]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.758 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.800 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.832 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.7706747843734145, 0.8019744483159117, 0.9762506316321374, 0.8528384279475982, 1.0]
 precisions [0.7691527143581938, 0.8019744483159117, 0.9747347145022739, 0.8668122270742358, 1.0]
 recalls [0.7874175545408422, 0.81068524970964, 0.9787771601819101, 0.8493449781659389, 0.9949494949494949]
 f1scores [0.7711807036319968, 0.7990448655907928, 0.9830003240470578, 0.8305387284846046, 1.0]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.750 Precision 0.750 Recall 0.750 F1 0.714 
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.780 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.879 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.985 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.7503805175038052, 0.7926829268292683, 0.9464375947448206, 0.8895196506550218, 0.98989898989899, 0.9890510948905109]
 precisions [0.7331303906646373, 0.7833914053426249, 0.9368367862556847, 0.9061135371179039, 0.9595959595959596, 0.9908759124087592]
 recalls [0.7245053272450532, 0.7950058072009292, 0.9338049519959576, 0.8973799126637555, 0.9646464646464646, 0.9945255474452555]
 f1scores [0.694427867051118, 0.7673355424645089, 0.9421203093734185, 0.8928938271803146, 0.9667573115186384, 0.9907294243899905]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.834 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.818 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.791 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.970 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.908 


accs [0.8361237950279046, 0.8193960511033682, 0.9580596260737746, 0.8122270742358079, 0.9494949494949495, 0.968978102189781, 0.9136630343671417]
 precisions [0.8554033485540334, 0.8054587688734031, 0.9590702374936837, 0.8248908296943231, 0.9696969696969697, 0.9653284671532847, 0.90360435875943]
 recalls [0.8422120750887874, 0.8205574912891986, 0.9641232945932289, 0.8061135371179039, 0.9696969696969697, 0.9671532846715328, 0.9195305951383068]
 f1scores [0.8423699724187754, 0.7997914276972126, 0.9554871903963618, 0.7963486319317822, 0.9790472556104357, 0.9622010096710853, 0.913630908971526]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 22 23 25 26
 27 28 29 30 31 33 34]
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.853 
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.795 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.785 
=> Acc: 0.414 Precision 0.414 Recall 0.414 F1 0.232 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.935 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.943 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.810 


accs [0.8548959918822933, 0.7984901277584204, 0.9676604345629105, 0.8021834061135371, 0.41414141414141414, 0.9355231143552312, 0.9446772841575859, 0.8433079434167573]
 precisions [0.8533739218670725, 0.8211382113821138, 0.9590702374936837, 0.7956331877729258, 0.36363636363636365, 0.9373479318734793, 0.9388097233864208, 0.8487486398258978]
 recalls [0.8422120750887874, 0.813588850174216, 0.9706922688226377, 0.8135371179039301, 0.42424242424242425, 0.9464720194647201, 0.9388097233864208, 0.8509249183895539]
 f1scores [0.8549251694824507, 0.8112041323366327, 0.9663206090633878, 0.7835069885246766, 0.2111851009690867, 0.9383475176578626, 0.9364787745101957, 0.815274119540596]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 21 22 23 24
 25 26 27 28 29 30 31 33 34 35 36 37 38 39]
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.769 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.806 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.672 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.712 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.896 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.928 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.798 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 


accs [0.7792998477929984, 0.8077816492450639, 0.9621020717534108, 0.725764192139738, 0.803030303030303, 0.8953771289537713, 0.9321039396479464, 0.8117519042437432, 0.9944903581267218]
 precisions [0.7874175545408422, 0.8112659698025552, 0.965133906013138, 0.7532751091703057, 0.7777777777777778, 0.9002433090024331, 0.911986588432523, 0.8008705114254625, 0.987603305785124]
 recalls [0.7924911212582445, 0.8286875725900116, 0.9696816574027286, 0.7502183406113537, 0.7525252525252525, 0.8990267639902676, 0.9086336965632859, 0.8248095756256801, 0.9917355371900827]
 f1scores [0.7596840432131384, 0.8091956675975368, 0.9668013628891977, 0.6814191087332466, 0.6979748496944698, 0.9102920591312189, 0.9299211135587212, 0.793577558493121, 0.9898336642171512]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 23 24 25
 26 27 28 29 30 31 32 33 34 37 38 39 40 41 42]
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.843 
=> Acc: 0.698 Precision 0.698 Recall 0.698 F1 0.677 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.749 
=> Acc: 0.783 Precision 0.783 Recall 0.783 F1 0.729 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.803 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.927 
=> Acc: 0.557 Precision 0.557 Recall 0.557 F1 0.514 
=> Acc: 0.730 Precision 0.730 Recall 0.730 F1 0.679 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.940 


accs [0.8488077118214105, 0.6980255516840883, 0.9525012632642749, 0.77117903930131, 0.7828282828282829, 0.8260340632603407, 0.9312657166806371, 0.5571273122959739, 0.7300275482093664, 0.9414634146341463]
 precisions [0.8564180618975139, 0.7078977932636469, 0.953511874684184, 0.7668122270742358, 0.7323232323232324, 0.8242092457420924, 0.9253981559094719, 0.5462459194776932, 0.7369146005509641, 0.9406504065040651]
 recalls [0.8604769152714358, 0.7131242740998839, 0.9489641232945932, 0.7641921397379913, 0.7626262626262627, 0.8114355231143552, 0.9304274937133278, 0.5364526659412405, 0.7300275482093664, 0.9341463414634147]
 f1scores [0.8575300143734367, 0.699975888780882, 0.9554723167288927, 0.7346252280828451, 0.7227780063074181, 0.8224362566952801, 0.937227450139336, 0.5034734446624416, 0.7078717151263044, 0.9402367663149283]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 22 23 24 25
 26 27 28 29 30 31 33 36 37 38 39 40 41 42 43 45 46 47 48 49]
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.806 
=> Acc: 0.672 Precision 0.672 Recall 0.672 F1 0.646 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.875 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.762 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.885 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.877 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.932 
=> Acc: 0.601 Precision 0.601 Recall 0.601 F1 0.531 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.874 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.904 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.986 


accs [0.8092338914256723, 0.6724738675958188, 0.876200101061142, 0.7737991266375546, 0.8838383838383839, 0.8844282238442822, 0.9337803855825649, 0.6006528835690969, 0.8732782369146006, 0.9028455284552845, 0.9859154929577465]
 precisions [0.8001014713343481, 0.6718931475029036, 0.8847902981303689, 0.7650655021834061, 0.9141414141414141, 0.8765206812652068, 0.9295892707460185, 0.6267682263329706, 0.8829201101928374, 0.9008130081300812, 0.9818913480885312]
 recalls [0.8148148148148148, 0.6718931475029036, 0.898433552299141, 0.7707423580786026, 0.8939393939393939, 0.8710462287104623, 0.922883487007544, 0.5952121871599565, 0.8691460055096418, 0.9008130081300812, 0.9778672032193159]
 f1scores [0.8044569131753525, 0.6416881443572786, 0.8913258311208381, 0.755827065689526, 0.8721526573548214, 0.8671765237982779, 0.9437217629022436, 0.5460588889840564, 0.8784096518724824, 0.8955192844862616, 0.9799725578004225]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 21 22 23 25
 26 27 28 29 30 31 33 34 37 38 39 41 42 43 44 45 46 47 48 49 50 51 53 54]
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.831 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.774 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.874 
=> Acc: 0.706 Precision 0.706 Recall 0.706 F1 0.680 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.853 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.890 
=> Acc: 0.725 Precision 0.725 Recall 0.725 F1 0.674 
=> Acc: 0.497 Precision 0.497 Recall 0.497 F1 0.433 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.803 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.914 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.905 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.877 


accs [0.8259766615930999, 0.7822299651567944, 0.875189489641233, 0.7056768558951965, 0.8484848484848485, 0.8917274939172749, 0.7250628667225482, 0.4972796517954298, 0.8181818181818182, 0.9138211382113821, 0.9074446680080482, 0.8894941634241245]
 precisions [0.8356164383561644, 0.7932636469221835, 0.8797372410308236, 0.7131004366812227, 0.8585858585858586, 0.9032846715328468, 0.7468566638725901, 0.5092491838955386, 0.8526170798898072, 0.9085365853658537, 0.9074446680080482, 0.890272373540856]
 recalls [0.8340943683409436, 0.775842044134727, 0.8746841839312784, 0.7043668122270742, 0.8686868686868687, 0.9002433090024331, 0.7435037720033529, 0.5310119695321001, 0.8553719008264463, 0.9150406504065041, 0.8933601609657947, 0.8848249027237354]
 f1scores [0.8409316959438996, 0.7818844157049656, 0.8827031897346348, 0.6789281136159739, 0.8364220838940641, 0.8891563587031259, 0.6782373704767346, 0.4359657936272122, 0.8279942326235872, 0.9152320014059214, 0.8970707774177745, 0.8765213837330315]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 20 23 25 26 27 29
 30 31 32 33 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
 56 57]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [1.0]
 recalls [0.9994366197183099]
 f1scores [0.9994151034151034]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 


accs [0.9915492957746479, 0.9963031423290203]
 precisions [0.9853521126760564, 0.9944547134935305]
 recalls [0.9859154929577465, 0.9981515711645101]
 f1scores [0.9849499757310038, 0.994444325367056]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.954 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 


accs [0.9538028169014084, 0.955637707948244, 0.9581313353900397]
 precisions [0.9532394366197183, 0.9741219963031423, 0.9568091670339357]
 recalls [0.9453521126760563, 0.9648798521256932, 0.9559277214631996]
 f1scores [0.9467239437592163, 0.9637605779294034, 0.9551791953487545]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.888 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.951 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.899 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.8912676056338028, 0.9500924214417745, 0.9008373732921993, 0.9980694980694981]
 precisions [0.8873239436619719, 0.9537892791127541, 0.8854120758043191, 1.0]
 recalls [0.8918309859154929, 0.9482439926062847, 0.8946672542970472, 1.0]
 f1scores [0.8860975302901076, 0.958359655070131, 0.8945568677627959, 0.9981620049322345]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.824 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.856 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.782 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.749 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 


accs [0.824225352112676, 0.8650646950092421, 0.7919788453063024, 0.7760617760617761, 0.9431403234220136]
 precisions [0.8230985915492958, 0.8502772643253235, 0.8096077567210225, 0.7586872586872587, 0.94679186228482]
 recalls [0.8343661971830986, 0.8558225508317929, 0.7977082415160864, 0.7664092664092664, 0.9509650495565989]
 f1scores [0.8329639586677923, 0.8604407248430748, 0.7820227266255066, 0.7574781401958116, 0.9563139661814464]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.879 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.756 
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.781 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.904 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.815 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.956 


accs [0.8828169014084507, 0.7615526802218114, 0.7933010136624064, 0.9054054054054054, 0.8163797600417319, 0.9594272076372315]
 precisions [0.8783098591549295, 0.7430683918669131, 0.7950639048038783, 0.8861003861003861, 0.8205529473135107, 0.9618138424821002]
 recalls [0.8608450704225352, 0.7190388170055453, 0.8007933010136624, 0.8764478764478765, 0.837245696400626, 0.9665871121718377]
 f1scores [0.8601574265182551, 0.7267450396334243, 0.7786091364614645, 0.8808826726625952, 0.8289496517288043, 0.9604793914386033]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 27 28 29]
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.847 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.855 
=> Acc: 0.741 Precision 0.741 Recall 0.741 F1 0.730 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.840 
=> Acc: 0.778 Precision 0.778 Recall 0.778 F1 0.772 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.854 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 


accs [0.8461971830985916, 0.8613678373382625, 0.7408550022036139, 0.8416988416988417, 0.7782994261867501, 0.8591885441527446, 0.9591152815013405]
 precisions [0.8647887323943662, 0.8428835489833642, 0.7315998237108858, 0.8494208494208494, 0.7741262389149713, 0.8973747016706444, 0.9597855227882037]
 recalls [0.8704225352112676, 0.8743068391866913, 0.75495813133539, 0.861003861003861, 0.792905581637976, 0.8544152744630071, 0.9644772117962467]
 f1scores [0.8497422027515842, 0.8523642195665584, 0.7390523801626507, 0.8636999065922544, 0.7813191268201348, 0.8780458950560563, 0.9632759096652175]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 27 28 30 31 32 33 34]
=> Acc: 0.728 Precision 0.728 Recall 0.728 F1 0.712 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.914 
=> Acc: 0.674 Precision 0.674 Recall 0.674 F1 0.663 
=> Acc: 0.730 Precision 0.730 Recall 0.730 F1 0.747 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.866 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.707 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.935 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 


accs [0.727887323943662, 0.9168207024029574, 0.6743058616130454, 0.7297297297297297, 0.865414710485133, 0.7852028639618138, 0.9363270777479893, 0.9962852897473997]
 precisions [0.727887323943662, 0.9149722735674677, 0.6579991185544293, 0.7277992277992278, 0.8508085550339072, 0.7899761336515513, 0.9369973190348525, 0.9933135215453195]
 recalls [0.7323943661971831, 0.9168207024029574, 0.6593212869105333, 0.750965250965251, 0.8596765779864372, 0.7350835322195705, 0.9423592493297587, 0.9940564635958395]
 f1scores [0.7234843841211334, 0.901691831319815, 0.6502938982895279, 0.7311360908163141, 0.8601135936327043, 0.6826191616602575, 0.9485954571634334, 0.9956310888828309]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24
 25 26 27 29 30 31 32 33 35 36 38 39]
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.840 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.878 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.827 
=> Acc: 0.707 Precision 0.707 Recall 0.707 F1 0.685 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.826 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.800 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.873 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 


accs [0.8411267605633803, 0.8872458410351202, 0.8364918466284706, 0.7065637065637066, 0.8398539384454877, 0.8233890214797136, 0.8726541554959786, 0.9323922734026746, 0.9927440633245382]
 precisions [0.8377464788732394, 0.8743068391866913, 0.8347289554869987, 0.7065637065637066, 0.8179447052686489, 0.8042959427207638, 0.8793565683646113, 0.9487369985141159, 0.9934036939313984]
 recalls [0.8580281690140845, 0.9020332717190388, 0.8342882327016307, 0.667953667953668, 0.8299426186750131, 0.8042959427207638, 0.868632707774799, 0.937592867756315, 0.9881266490765171]
 f1scores [0.8534647310697476, 0.8674872500597933, 0.8107109349134871, 0.7003143090287193, 0.8156443327735069, 0.8040690082285383, 0.859865827666012, 0.9302973549654542, 0.9920174583071851]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.836 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.831 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.735 
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.750 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.832 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.793 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.890 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.913 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 


accs [0.836056338028169, 0.844731977818854, 0.7818422212428383, 0.752895752895753, 0.8346374543557642, 0.8162291169451074, 0.8927613941018767, 0.9108469539375929, 0.9149076517150396, 0.943327239488117]
 precisions [0.8495774647887324, 0.833641404805915, 0.7800793301013662, 0.7606177606177607, 0.8262910798122066, 0.847255369928401, 0.8947721179624665, 0.9182763744427934, 0.9135883905013192, 0.9567336989640464]
 recalls [0.8416901408450704, 0.8317929759704251, 0.7708241516086382, 0.747104247104247, 0.8335941575378195, 0.7947494033412887, 0.886058981233244, 0.8937592867756315, 0.91688654353562, 0.9506398537477148]
 f1scores [0.838893574472098, 0.8314233388788942, 0.7355005743442137, 0.7199047750844301, 0.8332264709570977, 0.8008366708564619, 0.9050483490353702, 0.907464236927208, 0.9214564272229268, 0.938905636277001]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24
 25 26 28 30 31 32 33 34 35 37 38 39 40 41 43 44 45 46 47 48 49]
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.782 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.852 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.771 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.769 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.805 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.809 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.866 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.895 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.917 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.927 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.982 


accs [0.7892957746478874, 0.8539741219963032, 0.7888937858087263, 0.7625482625482626, 0.812206572769953, 0.8257756563245824, 0.8706434316353887, 0.8974739970282318, 0.9195250659630607, 0.926873857404022, 0.9829437776373974]
 precisions [0.8022535211267605, 0.8207024029574861, 0.7897752313794624, 0.7818532818532818, 0.8148148148148148, 0.8305489260143198, 0.8753351206434317, 0.8870728083209509, 0.91688654353562, 0.9280926264472883, 0.9797852179406191]
 recalls [0.7949295774647888, 0.8724584103512015, 0.7875716174526223, 0.7818532818532818, 0.792905581637976, 0.8114558472553699, 0.8726541554959786, 0.8855869242199108, 0.9036939313984169, 0.9183424741011579, 0.9772583701831965]
 f1scores [0.8030141244021409, 0.8555990832725348, 0.7663628523026508, 0.7380689102312354, 0.8091599311493048, 0.7924403712229801, 0.8933884361850728, 0.9039554672349677, 0.9196666029505195, 0.9248055540456799, 0.9826344045169403]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  6  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24 25 27
 29 30 31 32 33 34 35 38 39 40 41 43 44 45 46 48 49 50 51 52 53 54]
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.737 
=> Acc: 0.752 Precision 0.752 Recall 0.752 F1 0.722 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.743 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.810 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.803 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.781 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.876 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.780 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.919 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.909 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.972 


accs [0.7492957746478873, 0.7523105360443623, 0.7650947553988541, 0.803088803088803, 0.8142931664058425, 0.7899761336515513, 0.8780160857908847, 0.812035661218425, 0.9195250659630607, 0.91102985984156, 0.9589387239418825, 0.9715832205683356]
 precisions [0.7487323943661972, 0.756007393715342, 0.755839576906126, 0.7741312741312741, 0.800208659363589, 0.801909307875895, 0.8666219839142091, 0.799405646359584, 0.9221635883905013, 0.926873857404022, 0.9538850284270373, 0.959404600811908]
 recalls [0.7385915492957746, 0.7837338262476895, 0.75716174526223, 0.8243243243243243, 0.8153364632237872, 0.7875894988066826, 0.8699731903485255, 0.8164933135215453, 0.9281002638522428, 0.9183424741011579, 0.9608338597599495, 0.9675236806495264]
 f1scores [0.7409068910501778, 0.7285851353091533, 0.7560150539860958, 0.7833471464820579, 0.7845417888995816, 0.7623032124059081, 0.8766072991264305, 0.7942103372106465, 0.9213106452682611, 0.9077232561301086, 0.9627968373720996, 0.9744092401010989]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  2  4  5  6  7  8  9 10 12 13 14 15 16 18 19 20 21 22 23 24 25 27 28
 29 30 31 32 33 35 37 38 39 40 41 43 44 45 46 47 48 49 50 52 53 55 56 57
 58 59]
=> Acc: 0.730 Precision 0.730 Recall 0.730 F1 0.718 
=> Acc: 0.767 Precision 0.767 Recall 0.767 F1 0.734 
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.775 
=> Acc: 0.714 Precision 0.714 Recall 0.714 F1 0.708 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.767 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.823 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.870 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.817 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.873 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.769 
=> Acc: 0.745 Precision 0.745 Recall 0.745 F1 0.728 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.902 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 


accs [0.7295774647887324, 0.767097966728281, 0.7871308946672543, 0.7142857142857143, 0.784037558685446, 0.837708830548926, 0.8739946380697051, 0.8417533432392273, 0.8687335092348285, 0.773308957952468, 0.7454200884396716, 0.9039242219215156, 0.9632792485055508]
 precisions [0.731830985915493, 0.7837338262476895, 0.7844865579550463, 0.7413127413127413, 0.7861241523213354, 0.801909307875895, 0.878686327077748, 0.8320950965824666, 0.8779683377308707, 0.7745277269957344, 0.7631080227416298, 0.918809201623816, 0.9632792485055508]
 recalls [0.7267605633802817, 0.7707948243992606, 0.7902159541648304, 0.7355212355212355, 0.7793427230046949, 0.8042959427207638, 0.871313672922252, 0.8350668647845468, 0.8515831134564644, 0.7757464960390006, 0.7593177511054959, 0.9228687415426252, 0.9615713065755764]
 f1scores [0.709233155573532, 0.7715187979667933, 0.7768487960375615, 0.7042511403028644, 0.7648301873552951, 0.7720129211868753, 0.8811597427049481, 0.8239864558450138, 0.8674197741397709, 0.7676245515491045, 0.7488623661494376, 0.910231168268783, 0.9754358086412264]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15 17 18 19 20 21 22 23 24 25
 27 28 29 30 31 32 33 35 37 38 39 40 41 43 44 45 46 47 48 49 50 51 52 53
 54 55 56 57 59 60 61 62 63 64]
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.826 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.849 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.746 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.885 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.805 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.854 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.866 
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.753 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.876 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.808 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.895 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.891 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.922 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.929 


accs [0.8276056338028169, 0.8595194085027726, 0.7655354781842221, 0.8822393822393823, 0.8169014084507042, 0.863961813842482, 0.8646112600536193, 0.7986627043090639, 0.8726912928759895, 0.8135283363802559, 0.8951358180669615, 0.8930987821380244, 0.9265584970111016, 0.9260700389105059]
 precisions [0.8349295774647887, 0.8539741219963032, 0.751432349052446, 0.888030888030888, 0.7902973395931142, 0.847255369928401, 0.8652815013404825, 0.8194650817236255, 0.8812664907651715, 0.8226691042047533, 0.9134554643082754, 0.9079837618403248, 0.9231426131511529, 0.9416342412451362]
 recalls [0.8445070422535211, 0.8373382624768947, 0.7730277655354781, 0.862934362934363, 0.8038601982263954, 0.8114558472553699, 0.8612600536193029, 0.8268945022288261, 0.862796833773087, 0.8098720292504571, 0.9077700568540745, 0.8849797023004059, 0.9180187873612298, 0.9416342412451362]
 f1scores [0.833834108823061, 0.8431147766181724, 0.7396527960218325, 0.8414181167755773, 0.7666804637739976, 0.8255583595087936, 0.8779167462971811, 0.7594581730190216, 0.8696268677837974, 0.8100471851446496, 0.9025190844716814, 0.8953861592161492, 0.8996370697188972, 0.9386710155000761]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  5  6  7  8  9 10 11 12 14 15 18 19 20 21 23 25 27 30 31 32 33
 34 35 38 39 40 41 42 43 44 45 46 47 48 49 50 52 53 54 55 56 57 58 59 60
 64 65 66 67 68 69]
=> Acc: 0.602 Precision 0.602 Recall 0.602 F1 0.540 
=> Acc: 0.660 Precision 0.660 Recall 0.660 F1 0.621 
=> Acc: 0.778 Precision 0.778 Recall 0.778 F1 0.764 
=> Acc: 0.676 Precision 0.676 Recall 0.676 F1 0.644 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.788 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.734 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.879 
=> Acc: 0.783 Precision 0.783 Recall 0.783 F1 0.704 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.789 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.801 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.895 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.779 
=> Acc: 0.532 Precision 0.532 Recall 0.532 F1 0.466 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.771 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.908 


accs [0.6016901408450704, 0.6598890942698706, 0.7783164389598942, 0.6756756756756757, 0.7892540427751695, 0.7732696897374701, 0.8800268096514745, 0.7830609212481426, 0.7955145118733509, 0.8031687995124924, 0.897662665824384, 0.774018944519621, 0.5320239111870196, 0.7821011673151751, 0.9100903023164507]
 precisions [0.6005633802816901, 0.6136783733826248, 0.7910973997355664, 0.6737451737451737, 0.8137715179968701, 0.7684964200477327, 0.8746648793565683, 0.7674591381872214, 0.7961741424802111, 0.8068251066422912, 0.903348073278585, 0.7550744248985115, 0.5123825789923142, 0.7976653696498055, 0.8861405575186494]
 recalls [0.6045070422535211, 0.6451016635859519, 0.7831643895989423, 0.6891891891891891, 0.7965571205007824, 0.7613365155131265, 0.8827077747989276, 0.7667161961367014, 0.7908970976253298, 0.8123095673369897, 0.9058749210360075, 0.7861975642760487, 0.5977796754910333, 0.8184176394293126, 0.8896741264232431]
 f1scores [0.5378909745131837, 0.6138431206999908, 0.7794775625837337, 0.6866914884542983, 0.7983965021023329, 0.7243672574597062, 0.882272577786615, 0.6944249237411257, 0.7974632170560717, 0.8079653413380583, 0.9054150604162003, 0.7955989722316835, 0.5080281576779446, 0.7723509263714681, 0.8876636923618065]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  6  7  8  9 10 11 12 14 15 16 17 18 19 20 21 22 23 24 25 27 30
 31 32 33 35 38 39 40 41 42 43 44 45 46 47 48 49 50 52 53 54 56 58 59 60
 61 63 64 65 66 67 68 69 70 71 73 74]
=> Acc: 0.597 Precision 0.597 Recall 0.597 F1 0.516 
=> Acc: 0.643 Precision 0.643 Recall 0.643 F1 0.578 
=> Acc: 0.797 Precision 0.797 Recall 0.797 F1 0.767 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.846 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.826 
=> Acc: 0.542 Precision 0.542 Recall 0.542 F1 0.494 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.872 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.692 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.821 
=> Acc: 0.797 Precision 0.797 Recall 0.797 F1 0.795 
=> Acc: 0.764 Precision 0.764 Recall 0.764 F1 0.747 
=> Acc: 0.723 Precision 0.723 Recall 0.723 F1 0.709 
=> Acc: 0.671 Precision 0.671 Recall 0.671 F1 0.665 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.782 
=> Acc: 0.685 Precision 0.685 Recall 0.685 F1 0.622 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 


accs [0.5966197183098592, 0.6432532347504621, 0.7972675187307183, 0.8532818532818532, 0.8268127282211789, 0.5417661097852029, 0.8726541554959786, 0.7615156017830609, 0.8093667546174143, 0.7970749542961609, 0.7637397346809854, 0.7225981055480379, 0.6712211784799317, 0.8015564202334631, 0.685119748723989, 0.9800664451827242]
 precisions [0.5757746478873239, 0.6081330868761553, 0.7761128250330542, 0.7992277992277992, 0.8523735002608243, 0.5513126491646778, 0.881367292225201, 0.774888558692422, 0.8245382585751979, 0.7848872638634978, 0.7567909033480733, 0.7023004059539919, 0.6754910333048676, 0.7795071335927367, 0.6984687868080094, 0.9850498338870431]
 recalls [0.5887323943661972, 0.55637707948244, 0.7866901718818863, 0.8397683397683398, 0.8455920709441836, 0.568019093078759, 0.8793565683646113, 0.7667161961367014, 0.8153034300791556, 0.7995124923826935, 0.7612128869235628, 0.6901217861975643, 0.6959863364645602, 0.7859922178988327, 0.6949352179034158, 0.9750830564784053]
 f1scores [0.5065472023614183, 0.6011907771325724, 0.7492372575949113, 0.8209835572037119, 0.847484614372323, 0.5006144858090827, 0.8903964348815379, 0.6952699325186618, 0.8239289394002764, 0.7855701527711828, 0.7500634872110314, 0.7124204847775599, 0.6980877257235703, 0.7611834985233442, 0.6261760638362333, 0.9873375531913776]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  2  3  4  5  7  8  9 10 12 13 14 15 17 18 19 20 21 22 23 24 25 26 27
 28 30 31 32 33 35 38 39 40 41 42 43 44 45 48 50 52 53 54 56 58 59 60 61
 65 66 67 68 69 70 71 72 73 74 76 79]
=> Acc: 0.629 Precision 0.629 Recall 0.629 F1 0.574 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.800 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.790 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.867 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.812 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.789 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.865 
=> Acc: 0.719 Precision 0.719 Recall 0.719 F1 0.654 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.892 
=> Acc: 0.572 Precision 0.572 Recall 0.572 F1 0.525 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.784 
=> Acc: 0.678 Precision 0.678 Recall 0.678 F1 0.666 
=> Acc: 0.571 Precision 0.571 Recall 0.571 F1 0.464 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.780 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.796 
=> Acc: 0.687 Precision 0.687 Recall 0.687 F1 0.628 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 


accs [0.6292957746478873, 0.8170055452865065, 0.8021154693697664, 0.8687258687258688, 0.8116849243609807, 0.8162291169451074, 0.8632707774798928, 0.7191679049034175, 0.8911609498680739, 0.5716026812918952, 0.7959570435881238, 0.6779431664411367, 0.5713065755764304, 0.7911802853437094, 0.8080094228504122, 0.6868770764119602, 0.9769167353668591]
 precisions [0.6135211267605634, 0.8243992606284658, 0.7941824592331423, 0.8532818532818532, 0.8179447052686489, 0.8210023866348448, 0.8612600536193029, 0.7325408618127786, 0.8924802110817942, 0.5971968312004875, 0.770056854074542, 0.7050067658998647, 0.6122971818958155, 0.7911802853437094, 0.8029053788771103, 0.6918604651162791, 0.9826875515251443]
 recalls [0.6416901408450705, 0.8410351201478743, 0.8056412516527105, 0.8108108108108109, 0.8111632759520083, 0.8544152744630071, 0.8619302949061662, 0.7377414561664191, 0.9089709762532981, 0.5978062157221207, 0.7946936197094125, 0.6698240866035182, 0.5952177625960717, 0.7963683527885862, 0.800942285041225, 0.7151162790697675, 0.9798021434460017]
 f1scores [0.5735710551373836, 0.8181639348330535, 0.7873900137736629, 0.8494063619240938, 0.8272997209356866, 0.8050436869671722, 0.8827924887925853, 0.6552851224591699, 0.8967693624751318, 0.538262329141536, 0.7820137477161877, 0.7016708505415483, 0.47876611558815074, 0.7509346510484438, 0.7846880807888839, 0.6488798037999354, 0.9853817773928867]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  2  3  5  6  7  8  9 10 11 12 13 14 15 18 19 20 21 22 23 24 25 26 28
 30 32 33 34 35 37 38 39 40 41 42 44 45 46 48 49 50 52 53 54 55 56 59 60
 61 63 64 65 66 67 68 69 70 72 73 74 76 79 80 81 82 83 84]
=> Acc: 0.704 Precision 0.704 Recall 0.704 F1 0.646 
=> Acc: 0.555 Precision 0.555 Recall 0.555 F1 0.530 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.806 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.740 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.807 
=> Acc: 0.635 Precision 0.635 Recall 0.635 F1 0.554 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.881 
=> Acc: 0.760 Precision 0.760 Recall 0.760 F1 0.669 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.876 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.698 
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.749 
=> Acc: 0.530 Precision 0.530 Recall 0.530 F1 0.505 
=> Acc: 0.628 Precision 0.628 Recall 0.628 F1 0.566 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.786 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.805 
=> Acc: 0.394 Precision 0.394 Recall 0.394 F1 0.288 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.983 


accs [0.7036619718309859, 0.5545286506469501, 0.8166593212869105, 0.7664092664092664, 0.8101199791340636, 0.6348448687350835, 0.8800268096514745, 0.7600297176820208, 0.8839050131926122, 0.7404021937842779, 0.7542640555906507, 0.530446549391069, 0.627668659265585, 0.7924773022049286, 0.8138987043580683, 0.39368770764119604, 0.9509480626545754, 0.9823008849557522]
 precisions [0.7036619718309859, 0.5545286506469501, 0.7968267959453503, 0.7606177606177607, 0.8085550339071466, 0.6467780429594272, 0.8800268096514745, 0.7273402674591382, 0.8858839050131926, 0.7483241925655089, 0.7504737839545167, 0.577807848443843, 0.6498719043552519, 0.77431906614786, 0.817432273262662, 0.4219269102990033, 0.9694971145919209, 0.9823008849557522]
 recalls [0.7030985915492958, 0.5822550831792976, 0.8047598060819744, 0.696911196911197, 0.8028169014084507, 0.6372315035799523, 0.8833780160857909, 0.7704309063893017, 0.8773087071240105, 0.7397928092626447, 0.7548957675300063, 0.5886332882273342, 0.6780529461998293, 0.7937743190661478, 0.8135060855908912, 0.42524916943521596, 0.9624896949711459, 0.9867256637168141]
 f1scores [0.6284720560796837, 0.5574487480907556, 0.791699141471096, 0.6979812734658678, 0.8017490232690703, 0.5370830310768071, 0.8937091032323629, 0.6571005375053953, 0.8798422297873808, 0.7105322231649639, 0.7326214164687351, 0.530901097655039, 0.5696708743716531, 0.766417462441093, 0.8006586765878211, 0.29708102714181905, 0.9536571764732755, 0.9775265081864909]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  2  4  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 23 25 26 30 31 32
 33 35 38 39 40 41 42 43 44 45 46 48 49 50 51 52 53 55 56 59 60 61 64 65
 66 68 69 70 73 74 75 76 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.708 Precision 0.708 Recall 0.708 F1 0.703 
=> Acc: 0.608 Precision 0.608 Recall 0.608 F1 0.565 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.790 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.891 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.789 
=> Acc: 0.420 Precision 0.420 Recall 0.420 F1 0.305 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.903 
=> Acc: 0.636 Precision 0.636 Recall 0.636 F1 0.546 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.896 
=> Acc: 0.728 Precision 0.728 Recall 0.728 F1 0.694 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.887 
=> Acc: 0.530 Precision 0.530 Recall 0.530 F1 0.445 
=> Acc: 0.645 Precision 0.645 Recall 0.645 F1 0.550 
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.729 
=> Acc: 0.669 Precision 0.669 Recall 0.669 F1 0.635 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.706 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.910 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.908 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.905 


accs [0.708169014084507, 0.6081330868761553, 0.8047598060819744, 0.8861003861003861, 0.7892540427751695, 0.4200477326968974, 0.9054959785522788, 0.6359583952451708, 0.895778364116095, 0.7276051188299817, 0.8932406822488945, 0.530446549391069, 0.6447480785653288, 0.7470817120622568, 0.6686297605025521, 0.7616279069767442, 0.9138499587798846, 0.9092920353982301, 0.9048747461069736]
 precisions [0.7261971830985916, 0.589648798521257, 0.7805200528867342, 0.8011583011583011, 0.7965571205007824, 0.44630071599045346, 0.8900804289544236, 0.6054977711738484, 0.8812664907651715, 0.7361365021328459, 0.9077700568540745, 0.5399188092016238, 0.6029035012809565, 0.754863813229572, 0.6568511974872399, 0.7632890365448505, 0.9225061830173125, 0.9070796460176991, 0.9102911306702776]
 recalls [0.731830985915493, 0.5637707948243993, 0.8038783605112384, 0.8223938223938224, 0.8158581116327596, 0.39618138424821003, 0.9081769436997319, 0.6344725111441307, 0.8905013192612137, 0.7282145033516149, 0.8875552747946936, 0.4776725304465494, 0.6157130657557643, 0.754863813229572, 0.6709854731056144, 0.7466777408637874, 0.9097279472382522, 0.9026548672566371, 0.9157075152335816]
 f1scores [0.7120282875784957, 0.5545162006408402, 0.7626594645312469, 0.8114600647362437, 0.7973005763589521, 0.2993729953677079, 0.8976476780161248, 0.5254215229798966, 0.8971324175373974, 0.7057825123750544, 0.8952664264167141, 0.42899802810882887, 0.5316404666338892, 0.7480870130393271, 0.6288904094960643, 0.7137475782885767, 0.9185770885540849, 0.9008969040173106, 0.9057416061120585]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  4  8  9 10 11 12 14 15 16 18 20 21 22 23 24 25 27 30 31 33 35
 36 37 38 39 40 41 42 43 44 45 46 48 50 52 53 54 55 56 57 58 59 60 61 64
 65 66 68 69 70 72 73 74 75 76 78 79 80 82 83 84 85 86 87 88 89 90 91 92
 93 94]
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.762 
=> Acc: 0.547 Precision 0.547 Recall 0.547 F1 0.433 
=> Acc: 0.767 Precision 0.767 Recall 0.767 F1 0.746 
=> Acc: 0.703 Precision 0.703 Recall 0.703 F1 0.665 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.783 
=> Acc: 0.525 Precision 0.525 Recall 0.525 F1 0.416 
=> Acc: 0.733 Precision 0.733 Recall 0.733 F1 0.708 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.754 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.628 Precision 0.628 Recall 0.628 F1 0.553 
=> Acc: 0.759 Precision 0.759 Recall 0.759 F1 0.728 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.797 
=> Acc: 0.591 Precision 0.591 Recall 0.591 F1 0.503 
=> Acc: 0.739 Precision 0.739 Recall 0.739 F1 0.702 
=> Acc: 0.636 Precision 0.636 Recall 0.636 F1 0.602 
=> Acc: 0.710 Precision 0.710 Recall 0.710 F1 0.642 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.856 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.852 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.859 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 


accs [0.7712676056338028, 0.5471349353049908, 0.7672983693256942, 0.7027027027027027, 0.7845592070944184, 0.5250596658711217, 0.7332439678284183, 0.7652303120356612, 0.8812664907651715, 0.6276660572821451, 0.7586860391661402, 0.8078484438430311, 0.5909479077711358, 0.7392996108949417, 0.6360424028268551, 0.7101328903654485, 0.8635614179719703, 0.8584070796460177, 0.8564658090724442, 0.9788732394366197]
 precisions [0.7453521126760564, 0.5231053604436229, 0.7769942706037902, 0.6988416988416989, 0.7829942618675013, 0.5059665871121718, 0.7198391420911529, 0.774888558692422, 0.8839050131926122, 0.6075563680682511, 0.7732154137713203, 0.8240866035182679, 0.5824081981212639, 0.7315175097276264, 0.6246564585787201, 0.707641196013289, 0.8697444352844188, 0.8539823008849557, 0.8598510494245092, 0.9812206572769953]
 recalls [0.7622535211267606, 0.5397412199630314, 0.7712648743940062, 0.6911196911196911, 0.7772561293688054, 0.5417661097852029, 0.7540214477211796, 0.7563150074294205, 0.8984168865435356, 0.6197440585009141, 0.7567909033480733, 0.8159675236806495, 0.6088812980358668, 0.7211413748378729, 0.6105221829603455, 0.7001661129568106, 0.877164056059357, 0.8628318584070797, 0.8642518618821936, 0.9874804381846636]
 f1scores [0.757913389985633, 0.4185355088779977, 0.7671176673372414, 0.6713257140621801, 0.7556821423153729, 0.4238016452035066, 0.6932894289838549, 0.7501789064584032, 0.8731596196108405, 0.5711863321785123, 0.7209176010537367, 0.8046850489309545, 0.5121764780706426, 0.6845985284563612, 0.5976093900297459, 0.6379480254961793, 0.8608150060156566, 0.8762441857393568, 0.8681500967076788, 0.9812238564002085]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.991 


accs [0.9915038232795242]
 precisions [0.9957519116397621]
 recalls [0.9957519116397621]
 f1scores [0.9967696857430699]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.914 
=> Acc: 0.997 Precision 0.997 Recall 0.997 F1 0.997 


accs [0.913338997451147, 0.9972826086956522]
 precisions [0.897196261682243, 0.9976708074534162]
 recalls [0.903143585386576, 0.9972826086956522]
 f1scores [0.9174530696839005, 0.9961703936615434]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.921 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.937 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.994 


accs [0.9209855564995751, 0.9386645962732919, 0.9933035714285714]
 precisions [0.9167374681393373, 0.9297360248447205, 0.9977678571428571]
 recalls [0.9175870858113849, 0.9464285714285714, 0.9933035714285714]
 f1scores [0.9143592981232619, 0.9411889996615163, 0.9953430829862236]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.898 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.948 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 


accs [0.8988954970263382, 0.9491459627329193, 0.9575892857142857, 0.980007404664939]
 precisions [0.9082412914188616, 0.9483695652173914, 0.9419642857142857, 0.9814883376527213]
 recalls [0.9048428207306712, 0.9448757763975155, 0.9665178571428571, 0.9803776379118845]
 f1scores [0.9130791806379828, 0.9488758190827451, 0.9467981851740694, 0.9813345204443111]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19]
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.790 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.947 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.922 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.890 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.7986406117247239, 0.9460403726708074, 0.921875, 0.8955942243613476, 1.0]
 precisions [0.8096856414613424, 0.9464285714285714, 0.9397321428571429, 0.9048500555349871, 1.0]
 recalls [0.7986406117247239, 0.9557453416149069, 0.9575892857142857, 0.9011477230655313, 1.0]
 f1scores [0.7865178400000868, 0.9497470964535981, 0.9434909749168716, 0.8937334970926774, 1.0]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.772 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.874 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.817 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.832 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.935 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 


accs [0.784197111299915, 0.875388198757764, 0.8258928571428571, 0.8526471677156608, 0.9373219373219374, 0.975609756097561]
 precisions [0.7774001699235344, 0.8804347826086957, 0.8214285714285714, 0.8407997038134024, 0.9287749287749287, 0.9588414634146342]
 recalls [0.7952421410365336, 0.8804347826086957, 0.8125, 0.8548685671973343, 0.9544159544159544, 0.9733231707317073]
 f1scores [0.7637485768202147, 0.8750266622290814, 0.8252121428388672, 0.8201286546184192, 0.9455376685180974, 0.9665145617776361]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19 20 21 23 24 25
 26 27 28 29]
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.740 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.847 
=> Acc: 0.701 Precision 0.701 Recall 0.701 F1 0.684 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.900 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.933 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.856 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 


accs [0.7544604927782498, 0.844332298136646, 0.7008928571428571, 0.9085523880044428, 0.9316239316239316, 0.854420731707317, 0.9802143446001649]
 precisions [0.7765505522514868, 0.8486024844720497, 0.6875, 0.8915216586449464, 0.9344729344729344, 0.8475609756097561, 0.9814509480626545]
 recalls [0.7349192863211554, 0.859860248447205, 0.6897321428571429, 0.9089226212513883, 0.9401709401709402, 0.84375, 0.9810387469084914]
 f1scores [0.7567487254453191, 0.8369620687127484, 0.6544911427270665, 0.8877127720935206, 0.9301832248527763, 0.8409650449207536, 0.9801920957511262]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 16 18 19 20 21 22 23 25 26 27
 28 29 30 31 32 33 34]
=> Acc: 0.717 Precision 0.717 Recall 0.717 F1 0.703 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.862 
=> Acc: 0.734 Precision 0.734 Recall 0.734 F1 0.716 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.964 
=> Acc: 0.756 Precision 0.756 Recall 0.756 F1 0.747 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.979 


accs [0.7170773152081563, 0.8614130434782609, 0.734375, 0.9403924472417623, 0.9629629629629629, 0.7560975609756098, 0.9558944765045342, 0.9783599088838268]
 precisions [0.7272727272727273, 0.8757763975155279, 0.7433035714285714, 0.9344687152906331, 0.9287749287749287, 0.7599085365853658, 0.9629018961253092, 0.9813971146545178]
 recalls [0.7434154630416313, 0.8711180124223602, 0.7433035714285714, 0.9348389485375787, 0.9572649572649573, 0.7903963414634146, 0.9579554822753503, 0.9844343204252088]
 f1scores [0.7060394842394282, 0.8541987960749413, 0.7201148356828386, 0.9287223811800593, 0.9408940879908622, 0.7550313254746547, 0.9606968470404802, 0.9800897883618667]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 16 17 18 19 20 21 22 23 24 25
 26 28 29 30 32 33 34 35 36 37 38 39]
=> Acc: 0.767 Precision 0.767 Recall 0.767 F1 0.749 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.920 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.770 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.939 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.940 
=> Acc: 0.706 Precision 0.706 Recall 0.706 F1 0.688 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.897 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 


accs [0.7672047578589635, 0.9180900621118012, 0.7879464285714286, 0.9396519807478712, 0.9430199430199431, 0.7057926829268293, 0.8990107172300082, 0.9381169324221716, 0.9709737827715356]
 precisions [0.7544604927782498, 0.906444099378882, 0.7834821428571429, 0.9378008145131432, 0.9344729344729344, 0.7035060975609756, 0.9068425391591096, 0.9555808656036446, 0.9653558052434457]
 recalls [0.7757009345794392, 0.9169254658385093, 0.7879464285714286, 0.9348389485375787, 0.9572649572649573, 0.6875, 0.8994229183841714, 0.945709946848899, 0.9747191011235955]
 f1scores [0.7236885646734619, 0.9198892057770145, 0.7608003093974595, 0.9272555694124973, 0.9347449979078352, 0.6625309493903198, 0.90696819540599, 0.9391762590919074, 0.9673470277755838]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 13 15 16 18 19 20 21 22 23 24 25 26 27
 28 29 30 31 32 33 34 35 36 37 38 39 40 42 43 44]
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.855 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.948 
=> Acc: 0.616 Precision 0.616 Recall 0.616 F1 0.499 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.968 
=> Acc: 0.761 Precision 0.761 Recall 0.761 F1 0.763 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.912 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.910 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.831 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 


accs [0.8564146134239592, 0.9472049689440993, 0.6160714285714286, 0.9107737874861163, 0.9686609686609686, 0.760670731707317, 0.9154987633965375, 0.9096431283219438, 0.8370786516853933, 0.9461490294301816]
 precisions [0.8504672897196262, 0.9479813664596274, 0.5558035714285714, 0.9041095890410958, 0.9686609686609686, 0.743140243902439, 0.909315746084089, 0.9157175398633257, 0.8239700374531835, 0.947401377582968]
 recalls [0.8683092608326253, 0.9355590062111802, 0.6316964285714286, 0.9044798222880415, 0.9629629629629629, 0.7530487804878049, 0.9159109645507008, 0.9134396355353075, 0.8347378277153558, 0.9411396368190357]
 f1scores [0.8673658435932717, 0.9410348708885667, 0.4919540793238094, 0.890513124108254, 0.9834415344000826, 0.7357911977331248, 0.9105012485264965, 0.9102675071751183, 0.8216151249692958, 0.950704904122175]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  3  4  5  6  7  8  9 10 11 13 15 16 17 18 19 20 21 22 25 27 28 29
 30 31 32 33 34 35 36 37 38 39 41 42 43 44 45 46 47 48]
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.853 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 
=> Acc: 0.770 Precision 0.770 Recall 0.770 F1 0.686 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.897 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.945 
=> Acc: 0.585 Precision 0.585 Recall 0.585 F1 0.571 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.877 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.918 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.887 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 


accs [0.8547153780798641, 0.9433229813664596, 0.7700892857142857, 0.9007774898185857, 0.9430199430199431, 0.5846036585365854, 0.8792250618301731, 0.9198936977980258, 0.8876404494382022, 0.9517845961177207, 0.979702300405954]
 precisions [0.8351741716227697, 0.937888198757764, 0.7165178571428571, 0.9192891521658645, 0.9401709401709402, 0.6074695121951219, 0.8882934872217643, 0.9217919514047077, 0.9063670411985019, 0.9511584220413275, 0.9824086603518268]
 recalls [0.8385726423109601, 0.9464285714285714, 0.7209821428571429, 0.917067752684191, 0.9515669515669516, 0.5914634146341463, 0.8907666941467436, 0.9202733485193622, 0.900749063670412, 0.9486537257357546, 0.9824086603518268]
 f1scores [0.8112993120045185, 0.9444063129094495, 0.6707341644356768, 0.9196281459547551, 0.9459333115570626, 0.5556626918799173, 0.9011390663434078, 0.9241758498383386, 0.9060661640705108, 0.9540018989892097, 0.9804185587333762]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 13 14 15 16 18 19 21 22 23 24 25 26 27
 28 29 30 31 32 33 34 35 36 37 38 42 43 44 46 47 48 50 51 52 53 54]
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.842 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.927 
=> Acc: 0.739 Precision 0.739 Recall 0.739 F1 0.660 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.887 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.965 
=> Acc: 0.520 Precision 0.520 Recall 0.520 F1 0.516 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.852 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.845 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.935 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.916 


accs [0.8513169073916738, 0.9274068322981367, 0.7388392857142857, 0.8885597926693817, 0.9658119658119658, 0.5198170731707317, 0.910964550700742, 0.8462414578587699, 0.8459737827715356, 0.9342517219787101, 0.9546684709066305, 0.9215517241379311]
 precisions [0.8530161427357689, 0.9235248447204969, 0.7410714285714286, 0.8815253609774157, 0.9544159544159544, 0.5548780487804879, 0.9187963726298434, 0.8557327258921792, 0.851123595505618, 0.9229805886036319, 0.9519621109607578, 0.9224137931034483]
 recalls [0.8640611724723875, 0.9243012422360248, 0.6986607142857143, 0.884857460199926, 0.9743589743589743, 0.5426829268292683, 0.9208573784006595, 0.8542141230068337, 0.8618913857677902, 0.9292423293675642, 0.9607577807848444, 0.9318965517241379]
 f1scores [0.8275175403116929, 0.9201818188378355, 0.6597031531015534, 0.8872632877643782, 0.965311452701193, 0.541073504131351, 0.9220284835199886, 0.8426644067815638, 0.8502755094576653, 0.9152770541519331, 0.9488923495912095, 0.9290268924949426]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  3  4  5  6  7  8  9 10 11 13 14 16 18 19 20 21 22 23 24 25 26 27
 28 29 30 31 32 33 34 35 36 37 38 39 40 42 44 45 46 47 48 49 50 52 53 55
 56 57 59]
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.775 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.562 Precision 0.562 Recall 0.562 F1 0.466 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.838 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.958 
=> Acc: 0.495 Precision 0.495 Recall 0.495 F1 0.482 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.904 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.845 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.842 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.757 Precision 0.757 Recall 0.757 F1 0.761 
=> Acc: 0.685 Precision 0.685 Recall 0.685 F1 0.635 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.946 


accs [0.7706032285471538, 0.9588509316770186, 0.5625, 0.8485746019992595, 0.9601139601139601, 0.4946646341463415, 0.9064303380049464, 0.8416856492027335, 0.8417602996254682, 0.9511584220413275, 0.7571041948579161, 0.6853448275862069, 0.9471407976934166]
 precisions [0.7867459643160578, 0.9569099378881988, 0.5357142857142857, 0.8404294705664569, 0.9629629629629629, 0.46265243902439024, 0.9134377576257213, 0.832953682611997, 0.849250936329588, 0.9511584220413275, 0.7679296346414073, 0.6974137931034483, 0.9466602594906295]
 recalls [0.7816482582837723, 0.9596273291925466, 0.5334821428571429, 0.8345057386153276, 0.9601139601139601, 0.47027439024390244, 0.903957131079967, 0.8310554290053151, 0.848314606741573, 0.9567939887288667, 0.7537212449255751, 0.6758620689655173, 0.9432964920711197]
 f1scores [0.8002257904261707, 0.9562419169387422, 0.4407210799082793, 0.8329468911733953, 0.9628936834830271, 0.45654967872484375, 0.9102761529092686, 0.8343238046595148, 0.841540835375112, 0.9469119281944618, 0.765141900233546, 0.6437784022313144, 0.9520886003931665]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  3  4  5  6  7  8  9 10 13 16 18 19 20 21 23 24 25 28 29 30 31 32
 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48 49 50 51 52 54 55 58 59 60
 61 62 63 64]
=> Acc: 0.732 Precision 0.732 Recall 0.732 F1 0.711 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.867 
=> Acc: 0.603 Precision 0.603 Recall 0.603 F1 0.493 
=> Acc: 0.741 Precision 0.741 Recall 0.741 F1 0.682 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.975 
=> Acc: 0.659 Precision 0.659 Recall 0.659 F1 0.642 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.861 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.881 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.769 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.873 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.869 
=> Acc: 0.672 Precision 0.672 Recall 0.672 F1 0.618 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.921 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.969 


accs [0.7315208156329651, 0.8707298136645962, 0.6026785714285714, 0.740836727138097, 0.9743589743589743, 0.6592987804878049, 0.8627370156636439, 0.8804100227790432, 0.7691947565543071, 0.876017532874139, 0.868064952638701, 0.6724137931034483, 0.9240749639596348, 0.9713261648745519]
 precisions [0.7340696686491079, 0.8831521739130435, 0.5513392857142857, 0.7345427619400222, 0.9601139601139601, 0.6692073170731707, 0.8812860676009893, 0.8750949126803341, 0.7411048689138576, 0.8791484032561052, 0.8565629228687416, 0.675, 0.9221528111484864, 0.9498207885304659]
 recalls [0.7281223449447749, 0.8676242236024845, 0.578125, 0.7289892632358386, 0.9572649572649573, 0.6280487804878049, 0.8676834295136027, 0.8747152619589977, 0.7645131086142322, 0.8816530995616781, 0.8592692828146143, 0.6681034482758621, 0.9269581931763575, 0.967741935483871]
 f1scores [0.7109969053266243, 0.8574811436735352, 0.47057219169430464, 0.692409542489868, 0.9910129782696415, 0.6481005906911019, 0.8883587851841271, 0.8731344377369403, 0.7805354843820252, 0.8845070906378455, 0.8651783723509731, 0.6153891060352322, 0.9299928317172246, 0.9572592962240469]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 18 19 20 21 24 26 27 28
 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52
 55 56 57 58 60 61 62 63 64 65 66 69]
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.797 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.882 
=> Acc: 0.708 Precision 0.708 Recall 0.708 F1 0.640 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.798 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.953 
=> Acc: 0.660 Precision 0.660 Recall 0.660 F1 0.658 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.909 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.876 
=> Acc: 0.732 Precision 0.732 Recall 0.732 F1 0.730 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.871 
=> Acc: 0.752 Precision 0.752 Recall 0.752 F1 0.748 
=> Acc: 0.677 Precision 0.677 Recall 0.677 F1 0.678 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.890 
=> Acc: 0.552 Precision 0.552 Recall 0.552 F1 0.420 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.841 


accs [0.806287170773152, 0.8839285714285714, 0.7075892857142857, 0.8041466123657904, 0.9515669515669516, 0.6600609756097561, 0.9113767518549052, 0.876993166287016, 0.7317415730337079, 0.8741390106449592, 0.7523680649526387, 0.6767241379310345, 0.8923594425756848, 0.5519713261648745, 0.8651794374393792]
 precisions [0.800339847068819, 0.890139751552795, 0.7053571428571429, 0.7919289152165865, 0.9601139601139601, 0.6829268292682927, 0.9060181368507831, 0.8777524677296887, 0.7368913857677902, 0.8728866624921728, 0.7341001353179973, 0.6862068965517242, 0.889476213358962, 0.5483870967741935, 0.8506304558680893]
 recalls [0.7502124044180118, 0.8847049689440993, 0.8013392857142857, 0.8011847463902259, 0.9515669515669516, 0.6737804878048781, 0.909315746084089, 0.8796507213363706, 0.7495318352059925, 0.8804007514088916, 0.7449255751014885, 0.6956896551724138, 0.888995675156175, 0.5591397849462365, 0.8457807953443259]
 f1scores [0.7734813621537142, 0.8898081508954154, 0.6362041524347009, 0.7916188723034743, 0.9635286941101505, 0.6844728072561702, 0.9156386950629903, 0.878615667960136, 0.7419348853266958, 0.8679301635409965, 0.7430836287487366, 0.7087806041907252, 0.8860847210164684, 0.4101717723633508, 0.8317567320367939]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  3  4  5  6  7  8  9 10 11 12 13 15 16 18 19 21 23 25 26 27 28 29
 30 32 33 34 35 36 37 38 41 42 43 44 45 46 47 48 49 50 51 52 54 55 60 61
 62 64 66 67 69 70 71 72 73 74]
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.832 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.918 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.758 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.841 
=> Acc: 0.493 Precision 0.493 Recall 0.493 F1 0.396 
=> Acc: 0.588 Precision 0.588 Recall 0.588 F1 0.574 
=> Acc: 0.705 Precision 0.705 Recall 0.705 F1 0.680 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.845 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.832 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.857 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.742 
=> Acc: 0.198 Precision 0.198 Recall 0.198 F1 0.066 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.720 
=> Acc: 0.674 Precision 0.674 Recall 0.674 F1 0.604 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.823 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.777 


accs [0.8394222599830077, 0.9192546583850931, 0.7633928571428571, 0.8515364679748242, 0.4928774928774929, 0.5884146341463414, 0.7048639736191261, 0.8538344722854974, 0.8328651685393258, 0.8666249217282405, 0.7401894451962111, 0.19827586206896552, 0.7630946660259491, 0.6738351254480287, 0.8322017458777885, 0.7845528455284553]
 precisions [0.8334749362786746, 0.9332298136645962, 0.7388392857142857, 0.8582006664198445, 0.4444444444444444, 0.600609756097561, 0.685078318219291, 0.8511769172361427, 0.8366104868913857, 0.8584846587351284, 0.7327469553450608, 0.1956896551724138, 0.7381066794810187, 0.6774193548387096, 0.8273520853540253, 0.794425087108014]
 recalls [0.8394222599830077, 0.9394409937888198, 0.7522321428571429, 0.8611625323954091, 0.5185185185185185, 0.6059451219512195, 0.7159934047815334, 0.8458618071374335, 0.8300561797752809, 0.873512836568566, 0.7253044654939107, 0.19482758620689655, 0.7453147525228255, 0.6702508960573477, 0.8205625606207565, 0.7874564459930313]
 f1scores [0.8214199840600873, 0.9249611034720342, 0.770350346080474, 0.8503173473623598, 0.380140306122449, 0.59306089371345, 0.6795486043856146, 0.8416012153553257, 0.8263236305898077, 0.8545427235923911, 0.7273248104002539, 0.07022032693674485, 0.693045548622736, 0.5761288282071326, 0.8110181162113819, 0.7887802084425068]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 26 28 29
 30 32 33 34 35 36 37 38 39 40 41 42 44 46 48 49 50 51 52 54 55 57 59 60
 61 62 63 64 66 68 69 70 71 72 74 75 76 77 78 79]
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.776 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.913 
=> Acc: 0.540 Precision 0.540 Recall 0.540 F1 0.546 
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.726 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.941 
=> Acc: 0.620 Precision 0.620 Recall 0.620 F1 0.628 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.832 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.848 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.834 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.835 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.772 
=> Acc: 0.522 Precision 0.522 Recall 0.522 F1 0.462 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.780 
=> Acc: 0.634 Precision 0.634 Recall 0.634 F1 0.470 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.778 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.716 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 


accs [0.7858963466440102, 0.9161490683229814, 0.5401785714285714, 0.7789707515734913, 0.9401709401709402, 0.6196646341463414, 0.8380049464138499, 0.85041761579347, 0.8328651685393258, 0.8346900438321854, 0.7631935047361299, 0.521551724137931, 0.8010571840461317, 0.6344086021505376, 0.7904946653734238, 0.7288037166085947, 0.9928057553956835]
 precisions [0.820730671197961, 0.9262422360248447, 0.5379464285714286, 0.7571269900037023, 0.9487179487179487, 0.6326219512195121, 0.8248145094806265, 0.8580106302201974, 0.8431647940074907, 0.8528490920475892, 0.7713125845737483, 0.5646551724137931, 0.7972128784238347, 0.5806451612903226, 0.8021338506304558, 0.70267131242741, 0.9952038369304557]
 recalls [0.7824978759558199, 0.9103260869565217, 0.546875, 0.7737874861162533, 0.9259259259259259, 0.6303353658536586, 0.8466611706512778, 0.8432042520880789, 0.8436329588014981, 0.8647463994990607, 0.7631935047361299, 0.5275862068965518, 0.7688611244593945, 0.5734767025089605, 0.8040737148399612, 0.7032520325203252, 0.9808153477218226]
 f1scores [0.772835858413712, 0.9213464348223427, 0.5846628687395812, 0.7306178426929121, 0.9466557833411138, 0.6231713881800861, 0.825406746821397, 0.8408011406726386, 0.8389649714555985, 0.8546672141703311, 0.7718478232510548, 0.47407945192865775, 0.7769623834304806, 0.41600553484055736, 0.7736070548900779, 0.7047502635641141, 0.9830898016449474]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  8  9 11 12 13 16 17 18 19 21 22 23 24 25 27 28 29
 30 32 33 34 35 36 37 39 40 41 42 43 44 46 48 50 51 52 54 55 57 59 60 61
 62 63 64 66 67 69 70 71 72 73 74 75 77 78 79 80 81 83 84]
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.808 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.921 
=> Acc: 0.708 Precision 0.708 Recall 0.708 F1 0.693 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.750 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.944 
=> Acc: 0.627 Precision 0.627 Recall 0.627 F1 0.620 
=> Acc: 0.725 Precision 0.725 Recall 0.725 F1 0.652 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.842 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.865 
=> Acc: 0.738 Precision 0.738 Recall 0.738 F1 0.704 
=> Acc: 0.644 Precision 0.644 Recall 0.644 F1 0.613 
=> Acc: 0.425 Precision 0.425 Recall 0.425 F1 0.352 
=> Acc: 0.778 Precision 0.778 Recall 0.778 F1 0.743 
=> Acc: 0.588 Precision 0.588 Recall 0.588 F1 0.451 
=> Acc: 0.761 Precision 0.761 Recall 0.761 F1 0.737 
=> Acc: 0.611 Precision 0.611 Recall 0.611 F1 0.570 
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.733 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.910 


accs [0.8241291418861513, 0.921972049689441, 0.7075892857142857, 0.7937800814513143, 0.9430199430199431, 0.6265243902439024, 0.7246496290189612, 0.8413059984813971, 0.8637640449438202, 0.7382592360676268, 0.6441136671177267, 0.425, 0.7779913503123498, 0.5878136200716846, 0.7613967022308439, 0.6114982578397212, 0.7793764988009593, 0.9164556962025316]
 precisions [0.820730671197961, 0.90527950310559, 0.6383928571428571, 0.7919289152165865, 0.9373219373219374, 0.6196646341463414, 0.7126957955482275, 0.8561123766135156, 0.8670411985018727, 0.7357545397620538, 0.6366711772665764, 0.4396551724137931, 0.8106679481018741, 0.5806451612903226, 0.7643064985451018, 0.6039488966318235, 0.7721822541966427, 0.9164556962025316]
 recalls [0.836873406966865, 0.9231366459627329, 0.7254464285714286, 0.7730470196223621, 0.9572649572649573, 0.6219512195121951, 0.7246496290189612, 0.8553530751708428, 0.8745318352059925, 0.7288666249217283, 0.638700947225981, 0.44568965517241377, 0.7914464199903892, 0.5627240143369175, 0.7817652764306499, 0.6155632984901278, 0.7697841726618705, 0.9253164556962026]
 f1scores [0.8184850167587824, 0.9094325264894794, 0.6217451542947054, 0.745195850792862, 0.9435118033121759, 0.6272618632459434, 0.6486910124236871, 0.8544628176687048, 0.8855458752495806, 0.7078234106280435, 0.6078215222902315, 0.3620661311578157, 0.7724614445487582, 0.44357864357864357, 0.7413031523055612, 0.559203028129739, 0.6966841048404142, 0.9191269553462729]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  2  3  4  5  6  7  8  9 10 12 13 14 15 16 18 19 20 21 22 25 26 28 29
 30 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 50 51 52 53 54 55
 56 57 60 61 62 63 64 65 66 67 69 70 71 72 73 74 75 77 78 79 80 85 86 87]
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.815 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.874 
=> Acc: 0.614 Precision 0.614 Recall 0.614 F1 0.610 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.708 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.924 
=> Acc: 0.691 Precision 0.691 Recall 0.691 F1 0.688 
=> Acc: 0.714 Precision 0.714 Recall 0.714 F1 0.661 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.850 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.788 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.815 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.749 
=> Acc: 0.535 Precision 0.535 Recall 0.535 F1 0.485 
=> Acc: 0.751 Precision 0.751 Recall 0.751 F1 0.720 
=> Acc: 0.541 Precision 0.541 Recall 0.541 F1 0.442 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.780 
=> Acc: 0.594 Precision 0.594 Recall 0.594 F1 0.534 
=> Acc: 0.204 Precision 0.204 Recall 0.204 F1 0.068 
=> Acc: 0.599 Precision 0.599 Recall 0.599 F1 0.481 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.833 


accs [0.8215802888700084, 0.8773291925465838, 0.6138392857142857, 0.7726767863754165, 0.9287749287749287, 0.6905487804878049, 0.7143446001648804, 0.8526955201214882, 0.7944756554307116, 0.8202880400751409, 0.7489851150202977, 0.5353448275862069, 0.7506006727534839, 0.5412186379928315, 0.7856450048496605, 0.5940766550522648, 0.2038369304556355, 0.5987341772151898, 0.8448844884488449]
 precisions [0.8045879354290569, 0.8804347826086957, 0.5982142857142857, 0.772306553128471, 0.9373219373219374, 0.7057926829268293, 0.7131079967023908, 0.8352315869400152, 0.7818352059925093, 0.8209142141515341, 0.7537212449255751, 0.5120689655172413, 0.7477174435367612, 0.5412186379928315, 0.8234723569350145, 0.5830429732868757, 0.18465227817745802, 0.579746835443038, 0.8382838283828383]
 recalls [0.8232795242141037, 0.8757763975155279, 0.578125, 0.7697149203998519, 0.9458689458689459, 0.7042682926829268, 0.7213520197856554, 0.8485193621867881, 0.7954119850187266, 0.8159048215403882, 0.7422192151556157, 0.5137931034482759, 0.7409899086977415, 0.6344086021505376, 0.8215324927255092, 0.5836236933797909, 0.20623501199040767, 0.5708860759493671, 0.834983498349835]
 f1scores [0.7988162196685903, 0.8771563035526964, 0.6012322282093787, 0.7108270619801808, 0.9413277163513433, 0.6989905240441925, 0.6748631124478957, 0.8394555663309349, 0.80143538163158, 0.8283458207315288, 0.7320022077724107, 0.4907550858431076, 0.7252345816351077, 0.4492052980132451, 0.8302715804937624, 0.5358549106395997, 0.061663286004056794, 0.4861757147444997, 0.8759607804443348]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  3  4  6  7  8  9 10 13 14 15 16 18 19 20 21 23 24 25 26 27 28 29
 30 31 32 33 34 35 36 37 38 41 42 43 44 45 46 47 48 49 50 51 52 55 56 58
 60 61 62 63 64 66 67 70 71 72 74 75 77 78 79 80 83 85 86 91 92 93 94]
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.780 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.806 
=> Acc: 0.551 Precision 0.551 Recall 0.551 F1 0.530 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.710 
=> Acc: 0.778 Precision 0.778 Recall 0.778 F1 0.763 
=> Acc: 0.662 Precision 0.662 Recall 0.662 F1 0.664 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.871 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.839 
=> Acc: 0.800 Precision 0.800 Recall 0.800 F1 0.800 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.875 
=> Acc: 0.760 Precision 0.760 Recall 0.760 F1 0.761 
=> Acc: 0.682 Precision 0.682 Recall 0.682 F1 0.652 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.724 
=> Acc: 0.330 Precision 0.330 Recall 0.330 F1 0.237 
=> Acc: 0.697 Precision 0.697 Recall 0.697 F1 0.664 
=> Acc: 0.559 Precision 0.559 Recall 0.559 F1 0.496 
=> Acc: 0.528 Precision 0.528 Recall 0.528 F1 0.415 
=> Acc: 0.413 Precision 0.413 Recall 0.413 F1 0.286 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.705 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.915 


accs [0.7952421410365336, 0.812888198757764, 0.5513392857142857, 0.7719363198815253, 0.7777777777777778, 0.6615853658536586, 0.8697444352844188, 0.8405466970387244, 0.8000936329588015, 0.8835316217908579, 0.7604871447902571, 0.6818965517241379, 0.762614127823162, 0.32974910394265233, 0.6973811833171678, 0.5586527293844367, 0.5275779376498801, 0.41265822784810124, 0.7722772277227723, 0.9164948453608247]
 precisions [0.820730671197961, 0.8132763975155279, 0.6026785714285714, 0.7711958533876342, 0.7720797720797721, 0.6547256097560976, 0.8639736191261336, 0.8451025056947609, 0.8057116104868914, 0.8697557921102066, 0.7483085250338295, 0.678448275862069, 0.7688611244593945, 0.2974910394265233, 0.7022308438409312, 0.5598141695702671, 0.49640287769784175, 0.40632911392405063, 0.7425742574257426, 0.9118556701030928]
 recalls [0.8258283772302464, 0.8066770186335404, 0.6026785714285714, 0.7726767863754165, 0.8091168091168092, 0.6425304878048781, 0.8656224237427865, 0.8276385725132878, 0.8132022471910112, 0.8741390106449592, 0.7516914749661705, 0.6956896551724138, 0.7712638154733301, 0.3225806451612903, 0.7129000969932104, 0.5429732868757259, 0.5107913669064749, 0.39746835443037976, 0.7986798679867987, 0.9170103092783505]
 f1scores [0.8117707618070064, 0.8207383723922776, 0.5934818741612713, 0.708774898207154, 0.7607392414874078, 0.6604292555575546, 0.8616108489324166, 0.8524683809094725, 0.8183216940881766, 0.8589832346642545, 0.7399608070067838, 0.6648626342871022, 0.7126634949898141, 0.2797036840358447, 0.6698914070382591, 0.4947224777363049, 0.3917310181531176, 0.27869407587717443, 0.7461511141570358, 0.9172388306055698]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.985 


accs [0.9855855855855856]
 precisions [0.9851351351351352]
 recalls [0.9842342342342343]
 f1scores [0.9792408761063249]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.992 


accs [0.959009009009009, 0.991304347826087]
 precisions [0.9468468468468468, 0.9942028985507246]
 recalls [0.936036036036036, 0.9884057971014493]
 f1scores [0.9558939847589896, 0.9942586574892939]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.878 
=> Acc: 0.748 Precision 0.748 Recall 0.748 F1 0.756 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 


accs [0.8788288288288288, 0.7478260869565218, 0.957721246864923]
 precisions [0.8644144144144145, 0.7710144927536232, 0.9691866714439269]
 recalls [0.8585585585585586, 0.7681159420289855, 0.9656037262629882]
 f1scores [0.8689591259539586, 0.7816929170177096, 0.9601431274485807]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.814 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.829 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.840 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 


accs [0.8175675675675675, 0.8231884057971014, 0.8437835901110713, 0.9849564528899446]
 precisions [0.818018018018018, 0.808695652173913, 0.8394840558939448, 0.9869358669833729]
 recalls [0.7990990990990992, 0.8115942028985508, 0.8316015764958796, 0.9837688044338876]
 f1scores [0.8100689429495421, 0.8649687343784507, 0.8336535000766478, 0.9895291459787952]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  5  6  7  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.809 
=> Acc: 0.751 Precision 0.751 Recall 0.751 F1 0.690 
=> Acc: 0.756 Precision 0.756 Recall 0.756 F1 0.737 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.914 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 


accs [0.8108108108108109, 0.7507246376811594, 0.7560014331780723, 0.9144893111638955, 0.9742790335151987]
 precisions [0.813963963963964, 0.736231884057971, 0.7689000358294518, 0.9049881235154394, 0.9711613406079501]
 recalls [0.7981981981981981, 0.7710144927536232, 0.7635256180580438, 0.9121140142517815, 0.9672642244738893]
 f1scores [0.8015932177083405, 0.7231264144692038, 0.7320768182749292, 0.9149301681861657, 0.9753080486641623]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 20 21 22 24]
done w/ time
All done
