Current date and time 
##### START task 10000 grs #####
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.995 Precision 0.995 Recall 0.995 F1 0.995 


accs [0.9954695222405272]
 precisions [0.9942339373970346]
 recalls [0.9962932454695222]
 f1scores [0.9931196600881609]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9868204283360791, 1.0]
 precisions [0.984349258649094, 1.0]
 recalls [0.9880560131795717, 1.0]
 f1scores [0.9872188270598355, 1.0]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.969 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.917 


accs [0.9699341021416804, 0.9745762711864406, 0.9184413230629814]
 precisions [0.9563426688632619, 0.9872881355932204, 0.9320344358858178]
 recalls [0.9658154859967051, 0.961864406779661, 0.9247847757136384]
 f1scores [0.9653353030170813, 0.9755442704009152, 0.9197117878308211]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.865 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.875 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 


accs [0.8822075782537068, 0.9322033898305084, 0.8781150883552333, 0.9897084048027445]
 precisions [0.9069192751235585, 0.961864406779661, 0.8676937018577254, 0.983704974271012]
 recalls [0.8883855024711697, 0.9533898305084746, 0.8704123244222927, 0.9888507718696398]
 f1scores [0.8602378454173415, 0.9330538160590205, 0.8767391367732287, 0.9939088016338156]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.865 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.945 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.898 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.946 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.936 


accs [0.8838550247116969, 0.9449152542372882, 0.8975985500679655, 0.9476843910806175, 0.9352841868317389]
 precisions [0.8867380560131796, 0.9364406779661016, 0.8912550974173086, 0.9468267581475128, 0.9425998874507597]
 recalls [0.8752059308072487, 0.9533898305084746, 0.9057544177616674, 0.9313893653516295, 0.9189645469893079]
 f1scores [0.8737557103124518, 0.9340694967593063, 0.8939814970801525, 0.9259690524353512, 0.9267701351764097]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.853 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.897 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.870 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.910 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.8657331136738056, 0.8983050847457628, 0.8695061169007703, 0.9433962264150944, 0.9138998311761396, 0.9916247906197655]
 precisions [0.8797364085667215, 0.923728813559322, 0.8767557770729497, 0.9485420240137221, 0.9144625773776027, 0.9865996649916248]
 recalls [0.8616144975288303, 0.9194915254237288, 0.864521975532397, 0.951114922813036, 0.915588069780529, 0.9891122278056952]
 f1scores [0.8603770584382702, 0.9146305241150602, 0.8688510028418139, 0.9506298783414187, 0.9217705985481288, 0.9878060607149702]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.831 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.836 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.914 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.934 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.917 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.947 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 


accs [0.8554365733113674, 0.8389830508474576, 0.9161758042591753, 0.9331046312178388, 0.9200900393922341, 0.9463986599664992, 0.9591977869986169]
 precisions [0.8488467874794069, 0.8728813559322034, 0.9089261440869959, 0.9305317324185248, 0.9229037703995498, 0.940536013400335, 0.9550484094052559]
 recalls [0.8500823723228995, 0.8686440677966102, 0.9057544177616674, 0.9399656946826758, 0.911648846370287, 0.9447236180904522, 0.9591977869986169]
 f1scores [0.8349885105863233, 0.8513848836639923, 0.914342474448232, 0.9408259164804876, 0.9040935209135524, 0.9448496061626577, 0.9642888562779778]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.826 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.820 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.907 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.900 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.912 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.929 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.922 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.976 


accs [0.8389621087314663, 0.8050847457627118, 0.9034888989578613, 0.9005145797598628, 0.9105233539673607, 0.9296482412060302, 0.9225449515905948, 0.9753867791842475]
 precisions [0.8360790774299836, 0.8347457627118644, 0.9098323516085184, 0.8996569468267581, 0.9184018007878447, 0.9355108877721943, 0.9073305670816044, 0.9817158931082982]
 recalls [0.8484349258649094, 0.8347457627118644, 0.9107385591300408, 0.9133790737564322, 0.9138998311761396, 0.9279731993299832, 0.9183955739972337, 0.9887482419127989]
 f1scores [0.8080200369463004, 0.8319791981677559, 0.9160418851405456, 0.9168095875547578, 0.9165906995106763, 0.9535504327631432, 0.9144866923795645, 0.973037880385441]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.812 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.867 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.862 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.926 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.930 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.878 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.887 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.897 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.861 


accs [0.8389621087314663, 0.8686440677966102, 0.8572723153602175, 0.9253859348198971, 0.9307822172200337, 0.8760469011725294, 0.8879668049792531, 0.9029535864978903, 0.870915907873594]
 precisions [0.8484349258649094, 0.8686440677966102, 0.8676937018577254, 0.9296740994854202, 0.9290939786156444, 0.8835845896147404, 0.876210235131397, 0.9036568213783404, 0.8778789501874665]
 recalls [0.8401976935749588, 0.9194915254237288, 0.8749433620299049, 0.9065180102915952, 0.9178390545863815, 0.8685092127303182, 0.8921161825726142, 0.8952180028129395, 0.8719871451526513]
 f1scores [0.812124704435891, 0.854370052898844, 0.8642565685182524, 0.9327455267381761, 0.9309137258383077, 0.8798461442567875, 0.8656266939074951, 0.9228592425861791, 0.8855564242240568]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.800 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.796 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.852 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.913 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.915 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.922 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.910 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.919 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.920 


accs [0.8270181219110379, 0.8008474576271186, 0.8536474852741278, 0.9150943396226415, 0.9178390545863815, 0.923785594639866, 0.9322268326417704, 0.9184247538677919, 0.919121585431173, 0.9244444444444444]
 precisions [0.8266062602965404, 0.8389830508474576, 0.851835070231083, 0.9133790737564322, 0.9167135621834552, 0.9229480737018425, 0.9315352697095436, 0.9142053445850914, 0.901981788966256, 0.96]
 recalls [0.8228995057660626, 0.8008474576271186, 0.8486633439057544, 0.9219554030874786, 0.9229037703995498, 0.9045226130653267, 0.9370677731673582, 0.919831223628692, 0.9196572040707016, 0.9466666666666667]
 f1scores [0.777378626356773, 0.7869370634476046, 0.8454883133842316, 0.9217714725860187, 0.9234354042081003, 0.9156658337931068, 0.937623067534647, 0.900130568755276, 0.9072515186254927, 0.9427170233383955]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.753 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.827 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.853 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.915 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.889 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.870 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.843 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.939 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.7932454695222405, 0.8347457627118644, 0.8572723153602175, 0.9133790737564322, 0.8947664603263928, 0.873534338358459, 0.9370677731673582, 0.8614627285513361, 0.9384038564542047, 0.9511111111111111, 0.9978586723768736]
 precisions [0.8183690280065898, 0.8050847457627118, 0.8658812868146806, 0.9125214408233276, 0.8975801913337085, 0.8710217755443886, 0.9363762102351314, 0.8762306610407876, 0.937868237814676, 0.96, 0.9957173447537473]
 recalls [0.7924217462932455, 0.8135593220338984, 0.8595378341640235, 0.9331046312178388, 0.8823860438942037, 0.8819095477386935, 0.9370677731673582, 0.8748241912798875, 0.9319764327798608, 0.9451851851851852, 0.9957173447537473]
 f1scores [0.7530391392674142, 0.832156035638242, 0.8578893810346913, 0.9192980022985904, 0.8923745193850534, 0.8534975787570829, 0.9261171321380612, 0.8547844388174941, 0.9326267408639117, 0.9575442886274874, 0.9976430626321445]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.756 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.856 
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.789 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.948 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.880 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.862 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.899 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.893 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.916 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.885 
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 


accs [0.7920098846787479, 0.8601694915254238, 0.7874943362029905, 0.9459691252144082, 0.8823860438942037, 0.8693467336683417, 0.8990318118948825, 0.9092827004219409, 0.9164434922335297, 0.9629629629629629, 0.8843683083511777, 0.9986338797814208]
 precisions [0.7965403624382208, 0.9067796610169492, 0.7951971001359311, 0.9451114922813036, 0.8823860438942037, 0.8659966499162479, 0.9121715076071922, 0.8938115330520394, 0.9196572040707016, 0.9496296296296296, 0.9164882226980728, 0.9986338797814208]
 recalls [0.7990115321252059, 0.8686440677966102, 0.7893067512460353, 0.9545454545454546, 0.8756330894766461, 0.8752093802345059, 0.9239280774550485, 0.8938115330520394, 0.9089448312801286, 0.9629629629629629, 0.8822269807280514, 1.0]
 f1scores [0.7558293095224767, 0.8458712163445951, 0.8149347103764508, 0.9337356030470205, 0.8699950488555658, 0.8378029814689508, 0.9100521309377774, 0.8834914709824039, 0.921090622732002, 0.9639933628042898, 0.9120041141731333, 0.9987420763626684]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.797 Precision 0.797 Recall 0.797 F1 0.763 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.794 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.800 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.923 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.914 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.840 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.885 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.870 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.900 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.939 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.876 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.928 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.867 


accs [0.7965403624382208, 0.7923728813559322, 0.801087449025827, 0.9228130360205832, 0.9150253235790659, 0.855108877721943, 0.8845089903181189, 0.8790436005625879, 0.90037493304767, 0.9437037037037037, 0.8715203426124197, 0.930327868852459, 0.8852459016393442]
 precisions [0.785831960461285, 0.8347457627118644, 0.7911191662890802, 0.9288164665523156, 0.8975801913337085, 0.8534338358458962, 0.8948824343015215, 0.8804500703234881, 0.9126941617568292, 0.9511111111111111, 0.9143468950749465, 0.9234972677595629, 0.8950122078828043]
 recalls [0.814662273476112, 0.8432203389830508, 0.7788853647485274, 0.91852487135506, 0.9015194147439505, 0.8534338358458962, 0.9004149377593361, 0.8818565400843882, 0.9062667380824853, 0.9585185185185185, 0.9207708779443254, 0.9139344262295082, 0.8838507150331357]
 f1scores [0.7727806862105704, 0.835278777835834, 0.8087421428187225, 0.9336312400714023, 0.9027959904865963, 0.8345273973459586, 0.8845088334896587, 0.9047718653390959, 0.8995771407125233, 0.9400165079340208, 0.9029768345830522, 0.9315327117709573, 0.8786484627334337]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.805 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.926 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.839 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.892 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.905 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.874 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.867 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.901 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.942 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.940 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.884 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.917 


accs [0.8274299835255354, 0.9279661016949152, 0.8368826461259629, 0.8936535162950258, 0.9071468767585819, 0.8752093802345059, 0.8713692946058091, 0.9071729957805907, 0.9410819496518479, 0.9422222222222222, 0.9764453961456103, 0.9494535519125683, 0.8946634112312521, 0.9176904176904177]
 precisions [0.8340197693574959, 0.9152542372881356, 0.8441323062981423, 0.9005145797598628, 0.9060213843556556, 0.8827470686767169, 0.8506224066390041, 0.9142053445850914, 0.950187466523835, 0.9111111111111111, 0.9764453961456103, 0.9453551912568307, 0.8988489710498779, 0.9275184275184275]
 recalls [0.8336079077429983, 0.885593220338983, 0.8486633439057544, 0.9039451114922813, 0.9026449071468767, 0.8777219430485762, 0.8865836791147994, 0.9149085794655415, 0.9357257632565613, 0.922962962962963, 0.9807280513918629, 0.9398907103825137, 0.886989884897105, 0.9385749385749386]
 f1scores [0.7971863613240578, 0.9252134769991912, 0.8535898012639491, 0.8884538086283852, 0.90581392937594, 0.8795484013101141, 0.8763780498378162, 0.8995238567273646, 0.9462661699428521, 0.9463807090793598, 0.9955506117908787, 0.9415979584019774, 0.8752934079696306, 0.9380338549230476]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.784 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.865 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.803 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.896 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.865 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.865 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.842 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.900 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.934 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.892 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.881 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.854 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.871 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 


accs [0.8035420098846787, 0.8728813559322034, 0.8024467603081106, 0.8953687821612349, 0.8722566122678672, 0.8668341708542714, 0.8478561549100968, 0.9043600562587905, 0.9341189073379753, 0.9762962962962963, 0.892933618843683, 0.8838797814207651, 0.8716428322288106, 0.8722358722358723, 0.9703504043126685]
 precisions [0.8134266886326195, 0.885593220338983, 0.7979157227004984, 0.9039451114922813, 0.8790095666854248, 0.8685092127303182, 0.8374827109266944, 0.90014064697609, 0.9234065345474023, 0.9718518518518519, 0.8907922912205567, 0.9084699453551912, 0.8636205092431113, 0.8624078624078624, 0.9703504043126685]
 recalls [0.8212520593080724, 0.8898305084745762, 0.8015405527865881, 0.9030874785591767, 0.8705683736634777, 0.8726968174204355, 0.8298755186721992, 0.9205344585091421, 0.9394750937332619, 0.965925925925926, 0.8501070663811563, 0.9043715846994536, 0.8761771886989885, 0.8513513513513513, 0.9757412398921833]
 f1scores [0.7951627799287133, 0.8600048398410817, 0.7994439942420669, 0.899498940418721, 0.8683210406866657, 0.8797170936628982, 0.8309294070291952, 0.8897684978214168, 0.9241492912882366, 0.9707597993840693, 0.8883277918150689, 0.8777033554312453, 0.8526774143561522, 0.8663466890602226, 0.97118902034498]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.780 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.852 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.685 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.895 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.862 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.768 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.858 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.923 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.941 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.883 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.890 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.834 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.888 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.896 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.933 


accs [0.8093080724876441, 0.864406779661017, 0.7285908473040327, 0.9691252144082333, 0.8964546989307822, 0.8634840871021775, 0.7731673582295989, 0.8649789029535865, 0.9228709159078736, 0.9451851851851852, 0.8779443254817987, 0.8907103825136612, 0.853505406348099, 0.8918918918918919, 0.894878706199461, 0.9319880418535127]
 precisions [0.8183690280065898, 0.8389830508474576, 0.7000453103760761, 0.9622641509433962, 0.8919527293190771, 0.8626465661641541, 0.780774550484094, 0.879746835443038, 0.9287627209426889, 0.9348148148148148, 0.892933618843683, 0.9084699453551912, 0.8625741192884548, 0.8648648648648649, 0.9272237196765498, 0.929745889387145]
 recalls [0.8084843492586491, 0.8050847457627118, 0.7068418667874944, 0.9562607204116638, 0.895329206527856, 0.8693467336683417, 0.7558782849239281, 0.8537271448663853, 0.9234065345474023, 0.9451851851851852, 0.9014989293361885, 0.8989071038251366, 0.8650156958493198, 0.8955773955773956, 0.9137466307277629, 0.9387144992526159]
 f1scores [0.7789272685192214, 0.7862488738204132, 0.6840431651209363, 0.95579503976638, 0.8980579682598316, 0.8682405931778554, 0.7612082311997623, 0.8635702839314412, 0.9213254775598273, 0.9278425598314113, 0.8797087619303042, 0.910729854529167, 0.8512891532670833, 0.8783922256326606, 0.9514490755305415, 0.9411143753200063]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.754 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.817 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.732 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.915 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.898 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.854 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.863 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.893 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.934 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.919 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.919 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.865 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.825 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.919 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.880 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.873 


accs [0.7792421746293245, 0.8347457627118644, 0.742183960126869, 0.9150943396226415, 0.9003939223410242, 0.855108877721943, 0.8644536652835408, 0.90014064697609, 0.93626138189609, 0.9259259259259259, 0.9443254817987152, 0.9221311475409836, 0.872689222183467, 0.8316953316953317, 0.921832884097035, 0.8781763826606876, 0.8734869191721983]
 precisions [0.7924217462932455, 0.8305084745762712, 0.7544177616674218, 0.885934819897084, 0.9105233539673607, 0.8291457286432161, 0.8623789764868603, 0.9057665260196905, 0.9255490091055169, 0.9540740740740741, 0.9336188436830836, 0.9193989071038251, 0.8730380188350192, 0.8611793611793612, 0.8840970350404312, 0.8714499252615845, 0.8793440062475596]
 recalls [0.8043657331136738, 0.864406779661017, 0.7562301767104667, 0.8996569468267581, 0.9065841305571187, 0.8458961474036851, 0.8741355463347165, 0.9008438818565401, 0.9244777718264595, 0.9451851851851852, 0.961456102783726, 0.8825136612021858, 0.8667596791070806, 0.8636363636363636, 0.9191374663072777, 0.8819133034379671, 0.8703631393986724]
 f1scores [0.7747868069268252, 0.8695341068185168, 0.7508643894208736, 0.8849495627374967, 0.9065666128883025, 0.8557841361926638, 0.8596203083485896, 0.9025886380046572, 0.9306407336918678, 0.9426780658169841, 0.9501355649741032, 0.9297121935708617, 0.8596595347611427, 0.8420726053105708, 0.9099835178689538, 0.8681916023332306, 0.8716116666005874]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.757 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.905 
=> Acc: 0.698 Precision 0.698 Recall 0.698 F1 0.652 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.867 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.854 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.794 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.808 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.884 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.949 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.790 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.889 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.829 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.915 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.907 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.844 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.886 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.874 


accs [0.7796540362438221, 0.902542372881356, 0.6977797915722701, 0.8662092624356775, 0.8576252110298256, 0.7906197654941374, 0.8229598893499308, 0.8924050632911392, 0.9319764327798608, 0.9511111111111111, 0.7944325481798715, 0.8920765027322405, 0.853505406348099, 0.9164619164619164, 0.9110512129380054, 0.8475336322869955, 0.8891058180398282, 0.8744561839651958]
 precisions [0.7887149917627677, 0.9110169491525424, 0.6977797915722701, 0.8662092624356775, 0.8446820483961733, 0.7822445561139029, 0.8333333333333334, 0.9106891701828411, 0.923942153186931, 0.9629629629629629, 0.7837259100642399, 0.8934426229508197, 0.851063829787234, 0.8918918918918919, 0.9029649595687331, 0.8557548579970105, 0.8684107770402186, 0.8862647607209447]
 recalls [0.7953047775947282, 0.864406779661017, 0.6923425464431355, 0.885934819897084, 0.8739448508722566, 0.7596314907872697, 0.8526970954356846, 0.8924050632911392, 0.9255490091055169, 0.9585185185185185, 0.8479657387580299, 0.8975409836065574, 0.860481339379142, 0.9017199017199017, 0.8867924528301887, 0.8445440956651719, 0.8691917219836002, 0.8986948415164698]
 f1scores [0.7711650987246845, 0.9183479525137935, 0.6697987302426494, 0.8713899460585885, 0.8537722871302897, 0.7791296363947433, 0.8090168489872906, 0.8722023142555321, 0.9280250295267767, 0.9560307876826084, 0.8312322480945532, 0.8914393219285225, 0.8479907799266624, 0.8958201055582128, 0.8596640692640692, 0.8613633126993794, 0.8737177942537453, 0.8727416183605715]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.796 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.909 
=> Acc: 0.707 Precision 0.707 Recall 0.707 F1 0.680 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.869 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.886 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.820 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.795 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.908 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.930 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.923 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.793 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.856 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.853 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.860 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.916 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.914 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.863 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.865 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 


accs [0.8117792421746294, 0.9152542372881356, 0.7072949705482555, 0.8679245283018868, 0.8846370287000562, 0.8157453936348409, 0.8091286307053942, 0.9113924050632911, 0.9303695768612747, 0.9244444444444444, 0.8201284796573876, 0.8633879781420765, 0.8639693058946634, 0.8697788697788698, 0.9164420485175202, 0.9170403587443946, 0.8648965247950019, 0.8669981354878806, 0.986815415821501]
 precisions [0.8237232289950577, 0.9364406779661016, 0.686905301314001, 0.8662092624356775, 0.8930782217220034, 0.8534338358458962, 0.8229598893499308, 0.9036568213783404, 0.9367970005356187, 0.922962962962963, 0.828693790149893, 0.8811475409836066, 0.8573421695151726, 0.8734643734643734, 0.8840970350404312, 0.9185351270553064, 0.8750488090589613, 0.8719701678060907, 0.9807302231237323]
 recalls [0.8167215815485996, 0.9279661016949152, 0.7068418667874944, 0.8807890222984562, 0.8880135059088351, 0.855108877721943, 0.8112033195020747, 0.9071729957805907, 0.9394750937332619, 0.9392592592592592, 0.8137044967880086, 0.889344262295082, 0.8646668991977677, 0.8796068796068796, 0.9056603773584906, 0.905829596412556, 0.8617727450214759, 0.8912367930391547, 0.9797160243407708]
 f1scores [0.8109731627753616, 0.8661430147368729, 0.6645051387637958, 0.8489521430133984, 0.8886828779965521, 0.8577939284507048, 0.7753379914666114, 0.9124966915132905, 0.929801503740222, 0.9104996475838535, 0.8326056266584537, 0.8653928034819423, 0.8482020920212042, 0.852829308503949, 0.8977802077074871, 0.9046807510922411, 0.8544344403545706, 0.8653413872886289, 0.9782303373515614]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.766 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.835 
=> Acc: 0.701 Precision 0.701 Recall 0.701 F1 0.657 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.882 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.876 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.842 
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.739 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.909 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.947 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.943 
=> Acc: 0.777 Precision 0.777 Recall 0.777 F1 0.768 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.872 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.837 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.864 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.905 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.797 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.861 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 


accs [0.7796540362438221, 0.8432203389830508, 0.7014046216583598, 0.8799313893653516, 0.8756330894766461, 0.8375209380234506, 0.7531120331950207, 0.9170182841068917, 0.948580610605249, 0.9466666666666667, 0.7773019271948608, 0.8811475409836066, 0.8472270666201605, 0.871007371007371, 0.9137466307277629, 0.8168908819133034, 0.8812963686060132, 0.8663766314481044, 0.973630831643002, 0.9611853088480802]
 precisions [0.7903624382207578, 0.8771186440677966, 0.7009515178975986, 0.87221269296741, 0.8936409679234665, 0.8299832495812395, 0.7199170124481328, 0.9240506329113924, 0.9400107123727905, 0.9540740740740741, 0.8244111349036403, 0.8469945355191257, 0.8597837460760377, 0.8832923832923832, 0.9164420485175202, 0.8071748878923767, 0.8684107770402186, 0.8682411435674332, 0.9746450304259635, 0.9565943238731218]
 recalls [0.7874794069192751, 0.8728813559322034, 0.6887177163570458, 0.8576329331046312, 0.8643781654473832, 0.8567839195979899, 0.7752420470262794, 0.9261603375527426, 0.9384038564542047, 0.9451851851851852, 0.8029978586723768, 0.8797814207650273, 0.8489710498779212, 0.8636363636363636, 0.9326145552560647, 0.8221225710014948, 0.8660679422100742, 0.8607830950901181, 0.9705882352941176, 0.9599332220367279]
 f1scores [0.7771625964437617, 0.8635063170704834, 0.6573460020126409, 0.875479452853393, 0.8863836104507262, 0.8330631490894831, 0.7358760263283868, 0.9160299363390244, 0.951708242805957, 0.9523529478088925, 0.8133354305475538, 0.867360605404129, 0.8403630204053713, 0.8692933506365097, 0.88131312823751, 0.8104751915256945, 0.8773906679938583, 0.8489486785251608, 0.9732380131276539, 0.9604355754641555]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.9915700737618546]
 precisions [0.9894625922023182]
 recalls [0.9915700737618546]
 f1scores [0.9846358939858918]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.984 
=> Acc: 0.997 Precision 0.997 Recall 0.997 F1 0.997 


accs [0.9852476290832455, 0.9971680302076777]
 precisions [0.9915700737618546, 0.9959093769666457]
 recalls [0.9841938883034773, 0.9955947136563876]
 f1scores [0.9883505204055553, 0.9962406636542379]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.993 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.990 


accs [0.9852476290832455, 0.9924480805538074, 0.9893238434163701]
 precisions [0.9873551106427819, 0.9952800503461297, 0.9928825622775801]
 recalls [0.9884088514225501, 0.9946507237256136, 0.99644128113879]
 f1scores [0.9882240042706807, 0.9949456720660408, 0.9965903344650726]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.982 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.943 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 


accs [0.9810326659641728, 0.9921334172435494, 0.9501779359430605, 0.9615051903114187]
 precisions [0.9726027397260274, 0.9940213971050975, 0.9572953736654805, 0.9679930795847751]
 recalls [0.9694415173867229, 0.9946507237256136, 0.9181494661921709, 0.9684256055363322]
 f1scores [0.9741447255524086, 0.994420484653963, 0.942960814205797, 0.9714413870034992]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.933 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.908 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.980 


accs [0.9747102212855637, 0.9830081812460667, 0.9395017793594306, 0.9087370242214533, 0.9807264640474426]
 precisions [0.9726027397260274, 0.9855254877281309, 0.9395017793594306, 0.903114186851211, 0.9814677538917717]
 recalls [0.9652265542676501, 0.9842668344870988, 0.9217081850533808, 0.9156574394463668, 0.9881393624907339]
 f1scores [0.9771118996022089, 0.9822650370213944, 0.9032389937106918, 0.9111011516804426, 0.9825791898008209]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.917 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.923 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 


accs [0.9557428872497366, 0.9933920704845814, 0.9181494661921709, 0.9662629757785467, 0.9258710155670867, 0.9777918781725888]
 precisions [0.9494204425711275, 0.9924480805538074, 0.9074733096085409, 0.9610726643598616, 0.9295774647887324, 0.9774746192893401]
 recalls [0.9683877766069547, 0.9943360604153556, 0.9181494661921709, 0.9658304498269896, 0.9340252038547072, 0.9803299492385786]
 f1scores [0.9647921230852555, 0.9926626091962485, 0.9545192980836544, 0.9675324202138114, 0.9305782140387514, 0.9760715162432616]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.960 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.983 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.935 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.817 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.920 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.955 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 


accs [0.9610115911485775, 0.9823788546255506, 0.9395017793594306, 0.8248269896193772, 0.9206819866567828, 0.9536802030456852, 0.9738933030646992]
 precisions [0.9631190727081138, 0.9792322215229704, 0.9501779359430605, 0.8187716262975778, 0.9058561897702001, 0.9447969543147208, 0.9761634506242906]
 recalls [0.9546891464699684, 0.9814348646947766, 0.9359430604982206, 0.8109861591695502, 0.9214232765011119, 0.9508248730964467, 0.9829738933030647]
 f1scores [0.9509585056015002, 0.984776865075031, 0.96108034368965, 0.8069343535043899, 0.922351738328793, 0.9612332172774632, 0.9826855431721814]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.937 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.860 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.889 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.902 


accs [0.9557428872497366, 0.9704216488357458, 0.9359430604982206, 0.8568339100346021, 0.8917716827279466, 0.9498730964467005, 0.9659477866061293, 0.9067441110035496]
 precisions [0.9620653319283456, 0.9745122718691, 0.9359430604982206, 0.8542387543252595, 0.9065974796145293, 0.9501903553299492, 0.9580022701475596, 0.8999677315262988]
 recalls [0.9673340358271865, 0.9719949653870359, 0.9501779359430605, 0.8650519031141869, 0.8977020014825797, 0.9533629441624365, 0.9670828603859251, 0.8986769925782511]
 f1scores [0.9558562168063016, 0.9750212290335473, 0.9341425479091383, 0.8556547960668324, 0.8908332152499259, 0.9473796558211893, 0.9526443570672087, 0.8919816243659502]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.919 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.889 
=> Acc: 0.797 Precision 0.797 Recall 0.797 F1 0.795 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.831 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.875 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.807 


accs [0.9631190727081138, 0.9874134675896791, 0.9217081850533808, 0.8897058823529411, 0.7968865826538176, 0.8413705583756346, 0.9114642451759364, 0.8783478541464989, 0.8219852337981952]
 precisions [0.9768177028451, 0.986469477658905, 0.9074733096085409, 0.898356401384083, 0.7798369162342476, 0.8401015228426396, 0.9114642451759364, 0.8841561794127137, 0.8433141919606235]
 recalls [0.9599578503688093, 0.987728130899937, 0.9181494661921709, 0.8724048442906575, 0.7902149740548554, 0.8331218274111675, 0.9137343927355278, 0.8825427557276541, 0.8113207547169812]
 f1scores [0.970250322666993, 0.9853498590904234, 0.8926067995227424, 0.8889846744602721, 0.7883069703049783, 0.8358811115413852, 0.9163265963279474, 0.8597915965226994, 0.7993842738308324]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.670 Precision 0.670 Recall 0.670 F1 0.664 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.877 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.930 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.926 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.858 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.806 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 


accs [0.9736564805057956, 0.9839521711768408, 0.9252669039145908, 0.6704152249134948, 0.8799110452186805, 0.9295685279187818, 0.9296254256526674, 0.8625363020329139, 0.8236259228876128, 0.9786507258753202]
 precisions [0.9683877766069547, 0.9845814977973568, 0.9217081850533808, 0.657871972318339, 0.9006671608598962, 0.9232233502538071, 0.9307604994324631, 0.8731848983543078, 0.8113207547169812, 0.9837745516652434]
 recalls [0.9757639620653319, 0.987728130899937, 0.9537366548042705, 0.6790657439446367, 0.8776871756856931, 0.9197335025380711, 0.9307604994324631, 0.8502742820264602, 0.8146021328958163, 0.9854824935952178]
 f1scores [0.9675528181561882, 0.983735939169104, 0.9499797946682534, 0.6676150610371436, 0.8892737717769575, 0.9268154686322067, 0.9202947168417411, 0.8595856784793094, 0.788948331831439, 0.9631526392029247]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.924 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.627 Precision 0.627 Recall 0.627 F1 0.640 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.846 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.864 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.909 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.804 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.845 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.954 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.892 


accs [0.9251844046364595, 0.9477658904971681, 0.9679715302491103, 0.6271626297577855, 0.8517420311341735, 0.8591370558375635, 0.9114642451759364, 0.8170377541142304, 0.8515176374077112, 0.955593509820666, 0.8976109215017065]
 precisions [0.9325605900948367, 0.9499685336689742, 0.9395017793594306, 0.6423010380622838, 0.859896219421794, 0.8689720812182741, 0.9012485811577753, 0.8170377541142304, 0.85233798195242, 0.9350982066609735, 0.9021615472127418]
 recalls [0.9157007376185459, 0.9446192573945877, 0.9644128113879004, 0.6440311418685121, 0.8554484803558191, 0.8705583756345178, 0.9137343927355278, 0.8186511777992901, 0.8457752255947498, 0.9436379163108455, 0.89419795221843]
 f1scores [0.9176342622419378, 0.9484378930931486, 0.9570558862397631, 0.6530566935669229, 0.851982255322253, 0.8677167233461323, 0.9216895818841087, 0.8033531483025046, 0.8353432542165864, 0.9369849470836378, 0.8988411999075646]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.954 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.929 
=> Acc: 0.687 Precision 0.687 Recall 0.687 F1 0.675 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.899 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.829 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.818 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.855 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.947 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.886 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.773 


accs [0.9704952581664911, 0.9556324732536187, 0.9288256227758007, 0.6868512110726643, 0.8984432913269088, 0.824238578680203, 0.8808172531214529, 0.8254275572765408, 0.8638228055783429, 0.946199829205807, 0.9044368600682594, 0.7878048780487805]
 precisions [0.964172813487882, 0.9512271869100063, 0.9395017793594306, 0.6660899653979239, 0.910303928836175, 0.8312182741116751, 0.8842224744608399, 0.8360761535979349, 0.8695652173913043, 0.946199829205807, 0.875995449374289, 0.751219512195122]
 recalls [0.9747102212855637, 0.9518565135305224, 0.9572953736654805, 0.6799307958477508, 0.9140103780578206, 0.8274111675126904, 0.9035187287173666, 0.8167150693772185, 0.8777686628383922, 0.9547395388556789, 0.875995449374289, 0.7951219512195122]
 f1scores [0.9648009414018093, 0.9486266528555347, 0.9452565960042465, 0.6636854333118314, 0.894406491306418, 0.8264175541368853, 0.8939794265429459, 0.808963272803642, 0.8468000893940794, 0.9563061030613127, 0.8783225803074532, 0.7896449323911069]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.955 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.882 
=> Acc: 0.626 Precision 0.626 Recall 0.626 F1 0.626 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.924 
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.833 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.888 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.786 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.854 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.885 
=> Acc: 0.671 Precision 0.671 Recall 0.671 F1 0.602 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.913 


accs [0.9483667017913593, 0.9556324732536187, 0.8861209964412812, 0.6258650519031141, 0.9251297257227576, 0.8321700507614214, 0.8898978433598184, 0.7950951919974185, 0.8613617719442166, 0.9496157130657558, 0.8919226393629124, 0.6707317073170732, 0.9129804205946338]
 precisions [0.9367755532139094, 0.9477658904971681, 0.8612099644128114, 0.5938581314878892, 0.9058561897702001, 0.8334390862944162, 0.8864926220204313, 0.7986447241045499, 0.8564397046759639, 0.9299743808710503, 0.8930602957906713, 0.6341463414634146, 0.9180565627266135]
 recalls [0.9325605900948367, 0.9546884833228445, 0.8861209964412812, 0.6085640138408305, 0.9095626389918459, 0.8229695431472082, 0.8989784335981839, 0.8054211035818006, 0.8564397046759639, 0.9479077711357814, 0.8816837315130831, 0.6878048780487804, 0.9100797679477882]
 f1scores [0.9355404990374522, 0.9561289376376918, 0.8827092644376375, 0.6216905031931628, 0.8946143870358727, 0.836394949976652, 0.9098049034390453, 0.7878229736686708, 0.8675660551621126, 0.9469015837836003, 0.8814683599694412, 0.6126238602158336, 0.9158508505459768]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.967 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.958 
=> Acc: 0.604 Precision 0.604 Recall 0.604 F1 0.600 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.926 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.830 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.835 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.820 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.832 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.811 
=> Acc: 0.724 Precision 0.724 Recall 0.724 F1 0.671 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.834 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.885 


accs [0.9662802950474183, 0.9496538703587162, 0.9608540925266904, 0.6042387543252595, 0.9310600444773907, 0.8239213197969543, 0.8342792281498297, 0.8292997741206841, 0.8351107465135357, 0.9333902647309992, 0.8350398179749715, 0.724390243902439, 0.8368382886149384, 0.890015600624025]
 precisions [0.958904109589041, 0.9528005034612964, 0.9430604982206405, 0.6038062283737025, 0.9243884358784284, 0.8283629441624365, 0.8263337116912599, 0.8267182962245886, 0.8679245283018868, 0.9342442356959864, 0.820250284414107, 0.697560975609756, 0.8419144307469181, 0.8946957878315133]
 recalls [0.9494204425711275, 0.9515418502202643, 0.9501779359430605, 0.615916955017301, 0.9280948851000741, 0.8343908629441624, 0.8342792281498297, 0.8222007099064215, 0.8318293683347006, 0.9376601195559351, 0.8304891922639362, 0.6804878048780488, 0.8419144307469181, 0.8884555382215289]
 f1scores [0.9692883299611085, 0.9474529494559597, 0.9446855765427665, 0.6002996083149383, 0.9239488681729565, 0.8317069457503642, 0.8173755168904847, 0.8022696042454477, 0.8246776194545216, 0.9398630302980194, 0.8116515852856832, 0.6364433619545509, 0.8436843410186219, 0.8863340014484894]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.937 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.970 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.943 
=> Acc: 0.677 Precision 0.677 Recall 0.677 F1 0.663 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.881 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.903 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.903 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.837 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.819 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.903 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.875 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.736 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.843 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.863 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.9357218124341412, 0.9694776589049717, 0.9466192170818505, 0.6769031141868512, 0.8836174944403261, 0.9016497461928934, 0.9046538024971623, 0.8486608583414005, 0.8269073010664479, 0.9035012809564474, 0.8805460750853242, 0.7634146341463415, 0.8498912255257433, 0.8634945397815913, 0.9922613929492692]
 precisions [0.9378292939936775, 0.9716803020767778, 0.9572953736654805, 0.6686851211072664, 0.882876204595997, 0.9010152284263959, 0.9080590238365494, 0.8554372378186512, 0.8342904019688269, 0.8992314261315115, 0.8805460750853242, 0.7878048780487805, 0.8527918781725888, 0.8705148205928237, 0.9974204643164231]
 recalls [0.9304531085353003, 0.9694776589049717, 0.9466192170818505, 0.652681660899654, 0.8843587842846553, 0.8984771573604061, 0.8933030646992054, 0.8499515972894482, 0.8211648892534865, 0.9111870196413322, 0.863481228668942, 0.7780487804878049, 0.8411892675852066, 0.8642745709828393, 0.9957007738607051]
 f1scores [0.9313437566496642, 0.9722521268531172, 0.9323045446672479, 0.6451507355627479, 0.8748001896811809, 0.8976058112608065, 0.8968713863211866, 0.8540728306701487, 0.8249830301880039, 0.9125678272456756, 0.8823525857186801, 0.7207034266638015, 0.8558377074216714, 0.8662302921535929, 0.9949427669934583]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.903 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.882 
=> Acc: 0.674 Precision 0.674 Recall 0.674 F1 0.672 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.852 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.883 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.813 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.852 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.821 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.956 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.892 
=> Acc: 0.659 Precision 0.659 Recall 0.659 F1 0.633 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.795 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.815 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.968 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 


accs [0.9041095890410958, 0.9782882315921964, 0.8790035587188612, 0.6738754325259516, 0.8532246108228317, 0.8803934010152284, 0.8286038592508513, 0.856082607292675, 0.8252666119770303, 0.9547395388556789, 0.8987485779294653, 0.6585365853658537, 0.8005801305293692, 0.8174726989079563, 0.9690455717970765, 0.9373513084853291]
 precisions [0.8998946259220232, 0.9792322215229704, 0.8790035587188612, 0.6799307958477508, 0.8665678280207562, 0.8822969543147208, 0.8206583427922814, 0.8551145530816392, 0.8121410992616899, 0.9479077711357814, 0.9044368600682594, 0.6951219512195121, 0.8005801305293692, 0.8182527301092044, 0.9544282029234737, 0.9389373513084853]
 recalls [0.9041095890410958, 0.9782882315921964, 0.896797153024911, 0.6799307958477508, 0.8702742772424018, 0.881979695431472, 0.8251986379114642, 0.8609228783478542, 0.8252666119770303, 0.9376601195559351, 0.9112627986348123, 0.6609756097560976, 0.7737490935460478, 0.8393135725429017, 0.94067067927773, 0.9349722442505948]
 f1scores [0.9027304121265572, 0.974642692298989, 0.8796009872480461, 0.6685709056897715, 0.8458249033558729, 0.8864600478624503, 0.8315174384300201, 0.8517808009693537, 0.8027889220845774, 0.9457883269368395, 0.8905931835689163, 0.6728395635129863, 0.7857968774864823, 0.8295910478261999, 0.9600913767136809, 0.9378154112737531]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.892 
=> Acc: 0.718 Precision 0.718 Recall 0.718 F1 0.707 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.849 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.915 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.839 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.862 
=> Acc: 0.737 Precision 0.737 Recall 0.737 F1 0.716 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.921 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.829 
=> Acc: 0.685 Precision 0.685 Recall 0.685 F1 0.686 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.748 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.871 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.964 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.903 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 


accs [0.9546891464699684, 0.9814348646947766, 0.900355871886121, 0.7179930795847751, 0.8502594514455152, 0.9152918781725888, 0.8535754824063564, 0.8683446272991288, 0.7366694011484823, 0.9214346712211785, 0.8395904436860068, 0.6853658536585366, 0.7628716461203771, 0.8736349453978159, 0.9630266552020637, 0.9080095162569389, 0.9487926727726894]
 precisions [0.9494204425711275, 0.9820641913152927, 0.8398576512455516, 0.6998269896193772, 0.8799110452186805, 0.930520304568528, 0.8365493757094211, 0.872539528880284, 0.7284659557013946, 0.9120409906063194, 0.8475540386803185, 0.748780487804878, 0.7831762146482959, 0.8619344773790951, 0.9578675838349097, 0.9167327517842981, 0.9508742714404663]
 recalls [0.946259220231823, 0.9823788546255506, 0.8505338078291815, 0.7054498269896193, 0.8650852483320979, 0.9289340101522843, 0.8172531214528944, 0.8664085188770572, 0.760459392945037, 0.9111870196413322, 0.8668941979522184, 0.7048780487804878, 0.7686729514140682, 0.8712948517940717, 0.9475494411006019, 0.908802537668517, 0.9512905911740216]
 f1scores [0.9614542169414637, 0.9835141245506638, 0.8818686429203793, 0.7048512336752417, 0.8686705015742888, 0.9346517583165422, 0.8124777178899952, 0.866470380473966, 0.7146578672629681, 0.906471947529418, 0.833967590680715, 0.6426892510921064, 0.7591520844536577, 0.8706825035548981, 0.95305415401388, 0.9056931685829195, 0.9487791470287157]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.839 
=> Acc: 0.742 Precision 0.742 Recall 0.742 F1 0.726 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.912 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.884 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.818 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.888 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.740 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.893 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.804 
=> Acc: 0.695 Precision 0.695 Recall 0.695 F1 0.701 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.799 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.835 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.900 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.906 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 


accs [0.9515279241306639, 0.9499685336689742, 0.8398576512455516, 0.7422145328719724, 0.9169755374351372, 0.8816624365482234, 0.8376844494892168, 0.8909325588899645, 0.7694831829368335, 0.8975234842015372, 0.8407281001137656, 0.6951219512195121, 0.8027556200145033, 0.8361934477379095, 0.9028374892519346, 0.9064234734337827, 0.9500416319733556, 0.9744897959183674]
 precisions [0.9546891464699684, 0.9550031466331026, 0.896797153024911, 0.740484429065744, 0.910303928836175, 0.8708756345177665, 0.7911464245175936, 0.8899645046789287, 0.7497949138638228, 0.9222886421861657, 0.8065984072810012, 0.7341463414634146, 0.7962291515591008, 0.8291731669266771, 0.9011177987962167, 0.8913560666137986, 0.9562864279766861, 0.9770408163265306]
 recalls [0.958904109589041, 0.9550031466331026, 0.9181494661921709, 0.7339965397923875, 0.910303928836175, 0.879758883248731, 0.8342792281498297, 0.883188125201678, 0.7514356029532404, 0.910333048676345, 0.8191126279863481, 0.7073170731707317, 0.7955039883973894, 0.8307332293291732, 0.9028374892519346, 0.8969072164948454, 0.9592006661115737, 0.9744897959183674]
 f1scores [0.95792696231069, 0.9490876959677046, 0.8743512367823747, 0.7040190256835863, 0.9052966153170084, 0.874902569701636, 0.7860196709558417, 0.8895510577423902, 0.7511872605313039, 0.910151241310779, 0.7730754732768688, 0.7006646478696168, 0.7912360666345813, 0.8453653275791002, 0.9040277822635787, 0.8886276361866564, 0.950823775415665, 0.9643503869641764]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.882 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.954 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.888 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.745 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.864 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.886 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.726 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.899 
=> Acc: 0.719 Precision 0.719 Recall 0.719 F1 0.687 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.908 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.820 
=> Acc: 0.546 Precision 0.546 Recall 0.546 F1 0.538 
=> Acc: 0.761 Precision 0.761 Recall 0.761 F1 0.741 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.798 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.896 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.882 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.925 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.975 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.954 


accs [0.8830347734457323, 0.9534298300818125, 0.8896797153024911, 0.7737889273356401, 0.8673091178650852, 0.8864213197969543, 0.7741203178206584, 0.9019038399483704, 0.7194421657095981, 0.9120409906063194, 0.825938566552901, 0.5463414634146342, 0.7614213197969543, 0.8018720748829953, 0.8976784178847808, 0.8842188739095955, 0.9296419650291424, 0.9770408163265306, 0.9547038327526133]
 precisions [0.898840885142255, 0.9584644430459408, 0.8754448398576512, 0.7724913494809689, 0.8613787991104522, 0.8848350253807107, 0.7616345062429057, 0.8983543078412392, 0.7260049220672683, 0.9137489325362937, 0.8077360637087599, 0.551219512195122, 0.7737490935460478, 0.8010920436817472, 0.8598452278589854, 0.8889770023790642, 0.9238134887593672, 0.9464285714285714, 0.9677700348432056]
 recalls [0.9041095890410958, 0.9562617998741346, 0.9217081850533808, 0.7798442906574394, 0.8695329873980726, 0.8895939086294417, 0.7673098751418842, 0.9090029041626331, 0.7087776866283839, 0.9214346712211785, 0.8316268486916951, 0.5829268292682926, 0.7802755620014503, 0.8221528861154446, 0.8890799656061908, 0.8691514670896114, 0.9321398834304746, 0.9668367346938775, 0.9677700348432056]
 f1scores [0.9114244184700249, 0.9565367763593267, 0.8792171014226758, 0.7519899171044206, 0.8680393901621475, 0.8942503693290533, 0.6989134133427617, 0.8926571170031188, 0.6906625436752598, 0.90873897929532, 0.8418254195319929, 0.5540593625381429, 0.7520267451219086, 0.8157361258410223, 0.8910329602628521, 0.8974236133613172, 0.9197083419025169, 0.9720690639098791, 0.9663196557523577]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.793 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.887 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.855 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.807 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.756 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.876 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.819 
=> Acc: 0.722 Precision 0.722 Recall 0.722 F1 0.713 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.819 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.845 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.956 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.845 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.923 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.814 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.956 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.931 


accs [0.9367755532139094, 0.9713656387665198, 0.8078291814946619, 0.8970588235294118, 0.8954781319495922, 0.8810279187817259, 0.8626560726447219, 0.8234914488544692, 0.7621000820344545, 0.8838599487617421, 0.8373151308304891, 0.7219512195121951, 0.823060188542422, 0.8494539781591264, 0.9570077386070507, 0.8501189532117367, 0.925895087427144, 0.8188775510204082, 0.9573170731707317, 0.9309815950920245]
 precisions [0.928345626975764, 0.9704216488357458, 0.8149466192170819, 0.8871107266435986, 0.8910303928836175, 0.8902284263959391, 0.8388195232690124, 0.8212326556953856, 0.7448728465955702, 0.8719043552519214, 0.8623435722411832, 0.7658536585365854, 0.8469905728788978, 0.84399375975039, 0.9613069647463457, 0.8564631245043616, 0.9313072439633638, 0.8443877551020408, 0.9703832752613241, 0.9202453987730062]
 recalls [0.9272918861959958, 0.9710509754562618, 0.8327402135231317, 0.8992214532871973, 0.8910303928836175, 0.8718274111675127, 0.8331441543700341, 0.8267182962245886, 0.7530762920426579, 0.8693424423569599, 0.8293515358361775, 0.7536585365853659, 0.8245105148658448, 0.8260530421216848, 0.9570077386070507, 0.8429817605075337, 0.9358867610324729, 0.8188775510204082, 0.9581881533101045, 0.9340490797546013]
 f1scores [0.9337682541515555, 0.9716878282718234, 0.7930112672715414, 0.8875354358961982, 0.8937689101499908, 0.8902188679130854, 0.8333665645614052, 0.8142603487670375, 0.7633637604794629, 0.8702337427734005, 0.8193014146146169, 0.7099199232859611, 0.8260235375126997, 0.8339765522888282, 0.965752682919808, 0.8616481721278845, 0.9255572859792135, 0.8298567792366752, 0.956875770484394, 0.9136691236808868]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [1.0]
 recalls [1.0]
 f1scores [1.0]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 


accs [0.9923469387755102, 0.9884437596302003]
 precisions [0.9917091836734694, 0.9915254237288136]
 recalls [0.9933035714285714, 0.9938366718027735]
 f1scores [0.991847011157002, 0.9891650094871391]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.923 


accs [0.9920280612244898, 0.977657935285054, 0.9267734553775744]
 precisions [0.9901147959183674, 0.9745762711864406, 0.937070938215103]
 recalls [0.9888392857142857, 0.9668721109399075, 0.9416475972540046]
 f1scores [0.9891321010304399, 0.9663478641206222, 0.9309624086878989]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.952 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.922 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 


accs [0.9773596938775511, 0.9506933744221879, 0.9279176201372997, 0.9803038829487901]
 precisions [0.9728954081632653, 0.9429892141756548, 0.937070938215103, 0.9808666291502532]
 recalls [0.9808673469387755, 0.9460708782742681, 0.9336384439359268, 0.9808666291502532]
 f1scores [0.9769999724575715, 0.9408365509678542, 0.9434652448843742, 0.9787398063721522]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.961 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.940 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9760841836734694, 0.9599383667180277, 0.9427917620137299, 0.9701744513224536, 1.0]
 precisions [0.9764030612244898, 0.9460708782742681, 0.9244851258581236, 0.9774901519414744, 1.0]
 recalls [0.9757653061224489, 0.9599383667180277, 0.948512585812357, 0.971862689926843, 1.0]
 f1scores [0.9740412200467914, 0.963671446466859, 0.9283166570492247, 0.9749653566154697, 0.9967689401341933]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.941 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.834 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.886 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 


accs [0.9642857142857143, 0.9422187981510015, 0.8569794050343249, 0.9667979741136747, 0.8865979381443299, 0.98676293622142]
 precisions [0.9690688775510204, 0.9530046224961479, 0.8638443935926774, 0.9746764209341587, 0.9140893470790378, 0.9849578820697954]
 recalls [0.9658801020408163, 0.9460708782742681, 0.8466819221967964, 0.9724254361283061, 0.9175257731958762, 0.9879663056558363]
 f1scores [0.9667399922896539, 0.9502197025187094, 0.8403883211404294, 0.9711752111606635, 0.8945087501938855, 0.9846184479116973]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.925 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.882 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.979 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.945 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 


accs [0.9489795918367347, 0.926040061633282, 0.8832951945080092, 0.9482273494653911, 0.979381443298969, 0.9452466907340553, 0.9746835443037974]
 precisions [0.9505739795918368, 0.9368258859784283, 0.8775743707093822, 0.9493528418683174, 0.9862542955326461, 0.9518652226233454, 0.9772151898734177]
 recalls [0.9499362244897959, 0.9314329738058552, 0.879862700228833, 0.95160382667417, 0.9725085910652921, 0.9464500601684718, 0.9696202531645569]
 f1scores [0.9491286693377597, 0.9335075176335806, 0.8720912604497265, 0.9522924276369599, 0.9828587058188576, 0.946300680266609, 0.981959734418505]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.959 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.884 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.901 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.922 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.986 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.962 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.827 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 


accs [0.9607780612244898, 0.886748844375963, 0.9073226544622426, 0.927405740011255, 0.9862542955326461, 0.9632972322503008, 0.8430379746835444, 0.9841269841269841]
 precisions [0.96875, 0.8805855161787365, 0.902745995423341, 0.9302194710185706, 0.9896907216494846, 0.9578820697954272, 0.8531645569620253, 0.9834656084656085]
 recalls [0.9690688775510204, 0.8813559322033898, 0.9267734553775744, 0.9223410241980866, 0.9828178694158075, 0.9645006016847172, 0.8278481012658228, 0.9828042328042328]
 f1scores [0.9649289704269985, 0.8948439561469623, 0.8982094648392722, 0.9219698974851793, 0.9856849292456124, 0.9628569772287362, 0.8489958500074108, 0.9866292923752942]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.916 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.903 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.913 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.813 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.944 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.958 


accs [0.9642857142857143, 0.9167950693374423, 0.9096109839816934, 0.915588069780529, 0.9828178694158075, 0.9500601684717208, 0.8253164556962025, 0.9457671957671958, 0.9594721960414703]
 precisions [0.9636479591836735, 0.9121725731895224, 0.9130434782608695, 0.9240292628024761, 0.979381443298969, 0.9446450060168472, 0.8278481012658228, 0.9398148148148148, 0.9608859566446748]
 recalls [0.9633290816326531, 0.923728813559322, 0.9267734553775744, 0.9223410241980866, 0.9759450171821306, 0.9428399518652226, 0.8708860759493671, 0.9417989417989417, 0.9604147031102733]
 f1scores [0.9620699062761474, 0.9210911170105367, 0.9085364196541011, 0.9222192894470217, 0.9931854478161014, 0.9461889700345496, 0.8384441631652599, 0.9321980641588427, 0.9594607117616804]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.923 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.910 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.906 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.984 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.954 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.744 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.932 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.937 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.946 


accs [0.9751275510204082, 0.923728813559322, 0.9118993135011442, 0.911648846370287, 0.9828178694158075, 0.95367027677497, 0.7645569620253164, 0.9312169312169312, 0.937794533459001, 0.95]
 precisions [0.9719387755102041, 0.9252696456086287, 0.9096109839816934, 0.907709622960045, 0.9965635738831615, 0.9482551143200962, 0.8177215189873418, 0.9371693121693122, 0.9491046182846371, 0.934]
 recalls [0.9732142857142857, 0.9167950693374423, 0.9130434782608695, 0.9054586381541925, 0.9896907216494846, 0.9584837545126353, 0.7620253164556962, 0.9279100529100529, 0.9547596606974552, 0.952]
 f1scores [0.9732937806210138, 0.9336717898492937, 0.9035177171702404, 0.91119477598599, 0.9890552930247587, 0.9525327500538301, 0.7904371692557033, 0.9316790473527228, 0.9378989438209988, 0.9600838656795749]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.950 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.891 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.910 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.859 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.994 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.878 
=> Acc: 0.625 Precision 0.625 Recall 0.625 F1 0.569 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.916 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.952 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.866 


accs [0.9508928571428571, 0.8913713405238829, 0.9130434782608695, 0.867191896454699, 0.993127147766323, 0.881468110709988, 0.6253164556962025, 0.916005291005291, 0.9524033930254477, 0.96, 0.8762049720953831]
 precisions [0.9521683673469388, 0.8936825885978429, 0.8810068649885584, 0.8958919527293191, 0.979381443298969, 0.8802647412755716, 0.6379746835443038, 0.9047619047619048, 0.9514608859566447, 0.966, 0.8833079654997463]
 recalls [0.9457908163265306, 0.8975346687211094, 0.897025171624714, 0.8829487900956668, 0.9656357388316151, 0.881468110709988, 0.6506329113924051, 0.8902116402116402, 0.943449575871819, 0.964, 0.8574327752409944]
 f1scores [0.9431990605080782, 0.894919111452827, 0.8910521652085892, 0.8653146856344207, 0.985972844859736, 0.8788674677706588, 0.6291351500180494, 0.9135012961427205, 0.9451743481116861, 0.958454553549324, 0.8501064214679988]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.924 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.927 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.889 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.874 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.860 
=> Acc: 0.684 Precision 0.684 Recall 0.684 F1 0.599 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.897 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.948 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.862 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.869 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 


accs [0.9231505102040817, 0.9275808936825886, 0.8924485125858124, 0.8806978052898143, 0.979381443298969, 0.8724428399518652, 0.6835443037974683, 0.8981481481481481, 0.9491046182846371, 0.866, 0.8812785388127854, 0.9738846572361263]
 precisions [0.9288903061224489, 0.9221879815100154, 0.8821510297482837, 0.8767585818795723, 0.9759450171821306, 0.8724428399518652, 0.6683544303797468, 0.9120370370370371, 0.9566446748350612, 0.876, 0.8812785388127854, 0.9836779107725789]
 recalls [0.9336734693877551, 0.9183359013867488, 0.9004576659038902, 0.8857625211029826, 0.9828178694158075, 0.8604091456077015, 0.6987341772151898, 0.9166666666666666, 0.9594721960414703, 0.866, 0.8721461187214612, 0.9782372143634385]
 f1scores [0.9281452086268901, 0.9141550358319355, 0.8920408693923125, 0.8807216020712136, 0.9899092402753004, 0.848829016840476, 0.6333821963239714, 0.9137184464640263, 0.9667601804272451, 0.8533217001659817, 0.8591250034019391, 0.9793156539540471]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.904 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.867 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.817 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.923 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.871 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.665 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.949 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.908 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.718 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.800 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.972 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 


accs [0.9059311224489796, 0.8705701078582434, 0.8215102974828375, 0.9257175014068655, 0.979381443298969, 0.8772563176895307, 0.7291139240506329, 0.9477513227513228, 0.910933081998115, 0.762, 0.8193810248604769, 0.9727965179542981, 0.980106100795756]
 precisions [0.9017857142857143, 0.8459167950693375, 0.8135011441647597, 0.935846933033202, 0.9828178694158075, 0.885078219013237, 0.7037974683544304, 0.9444444444444444, 0.9038642789820923, 0.76, 0.8224251648909183, 0.9575625680087051, 0.9721485411140584]
 recalls [0.8966836734693877, 0.8736517719568567, 0.816933638443936, 0.9347214406302757, 0.9725085910652921, 0.8790613718411552, 0.6835443037974683, 0.9490740740740741, 0.9066918001885014, 0.72, 0.8046676813800101, 0.9684439608269858, 0.9827586206896551]
 f1scores [0.8881891102896018, 0.8535799704629428, 0.8096222254762357, 0.930348231223021, 0.9832333339074317, 0.860660293092111, 0.6562438059684487, 0.946542154219008, 0.9030764568233414, 0.6856811579317872, 0.7912594264687502, 0.9670304960715207, 0.9960029295228671]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.937 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.910 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.902 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.844 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.827 
=> Acc: 0.696 Precision 0.696 Recall 0.696 F1 0.643 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.894 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.935 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.803 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.940 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.961 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.960 


accs [0.9381377551020408, 0.9129429892141756, 0.9016018306636155, 0.8519977490151941, 0.9621993127147767, 0.8399518652226233, 0.6962025316455697, 0.8948412698412699, 0.9363807728557965, 0.952, 0.823947234906139, 0.9379760609357998, 0.9615384615384616, 0.9605018587360595]
 precisions [0.9378188775510204, 0.8959938366718028, 0.9061784897025171, 0.8666291502532358, 0.9725085910652921, 0.8525872442839952, 0.6759493670886076, 0.906084656084656, 0.9392082940622055, 0.964, 0.8254693049213597, 0.9390642002176278, 0.9694960212201591, 0.9577137546468402]
 recalls [0.9336734693877551, 0.9029275808936826, 0.9153318077803204, 0.871131119864941, 0.9828178694158075, 0.8495788206979543, 0.6936708860759494, 0.9126984126984127, 0.9293119698397738, 0.952, 0.8361237950279046, 0.941240478781284, 0.9748010610079576, 0.9405204460966543]
 f1scores [0.9382249339712361, 0.8914103555770018, 0.9218774895968572, 0.8348735994028985, 0.9613497539743386, 0.8262066249661968, 0.5967434602645195, 0.902312519968145, 0.9282602802706486, 0.9635096471644694, 0.7890505389806769, 0.9312526288758842, 0.961835996423542, 0.9532277368993061]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.941 
=> Acc: 0.767 Precision 0.767 Recall 0.767 F1 0.726 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.917 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.842 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.783 
=> Acc: 0.676 Precision 0.676 Recall 0.676 F1 0.606 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.923 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.925 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.771 
=> Acc: 0.770 Precision 0.770 Recall 0.770 F1 0.723 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.869 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.907 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.984 


accs [0.9400510204081632, 0.7665639445300462, 0.9187643020594966, 0.8576252110298256, 0.9690721649484536, 0.8116726835138387, 0.6759493670886076, 0.9226190476190477, 0.9269557021677662, 0.784, 0.7701674277016742, 0.8759521218715995, 0.9708222811671088, 0.9052044609665427, 0.9845797995373939]
 precisions [0.9394132653061225, 0.7942989214175655, 0.9107551487414187, 0.8531232414181205, 0.9690721649484536, 0.8134777376654633, 0.6810126582278481, 0.9113756613756614, 0.9189443920829407, 0.792, 0.7544393708777271, 0.8868335146898803, 0.9734748010610079, 0.9270446096654275, 0.9946029298380878]
 recalls [0.9397321428571429, 0.7434514637904468, 0.9061784897025171, 0.8688801350590883, 0.9484536082474226, 0.8297232250300842, 0.6759493670886076, 0.9226190476190477, 0.9245994344957588, 0.814, 0.7366818873668188, 0.8726877040261154, 0.96684350132626, 0.9117100371747212, 0.9907478797224364]
 f1scores [0.9346560976503726, 0.7126351776178717, 0.9313454443437719, 0.8453840536081467, 0.9696590200570219, 0.7893738810390245, 0.5824765121359549, 0.9259819460358691, 0.9277933295987607, 0.746092339116485, 0.7118678034302015, 0.8675417499600192, 0.9726305916786716, 0.9108080930514918, 0.9864659874703066]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.953 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.805 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.869 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.857 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.817 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.751 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.895 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.870 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.808 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.908 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.855 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.888 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.970 


accs [0.9537627551020408, 0.8289676425269645, 0.8718535469107551, 0.863252673044457, 0.9518900343642611, 0.8405535499398316, 0.7924050632911392, 0.8941798941798942, 0.9613572101790764, 0.874, 0.8346017250126839, 0.911860718171926, 0.9827586206896551, 0.8526951672862454, 0.889745566692367, 0.970873786407767]
 precisions [0.9528061224489796, 0.8351309707241911, 0.8649885583524027, 0.8666291502532358, 0.9553264604810997, 0.8483754512635379, 0.7746835443037975, 0.8948412698412699, 0.9566446748350612, 0.862, 0.823947234906139, 0.8879216539717084, 0.9721485411140584, 0.8703531598513011, 0.8951426368542791, 0.9870550161812298]
 recalls [0.9566326530612245, 0.8228043143297381, 0.8398169336384439, 0.8694428812605515, 0.9518900343642611, 0.8237063778580024, 0.7645569620253164, 0.8948412698412699, 0.9613572101790764, 0.866, 0.832572298325723, 0.9194776931447225, 0.9681697612732095, 0.8513011152416357, 0.9090208172706246, 0.9838187702265372]
 f1scores [0.9465038317534502, 0.8160990219005836, 0.8381544737456454, 0.8632591079466423, 0.9560343274370812, 0.8163363336813243, 0.7232501053840517, 0.8993350883121719, 0.9659571666469304, 0.8618009585635734, 0.8216017058713089, 0.9141959460263935, 0.9748273507111558, 0.8560317279513378, 0.8904084646642133, 0.9898953818496544]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.859 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.872 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.861 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.971 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.900 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.844 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.851 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.953 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.767 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.789 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.868 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.854 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.876 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.972 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.970 


accs [0.9732142857142857, 0.8651771956856703, 0.8729977116704806, 0.8728193584693303, 0.9690721649484536, 0.9019253910950662, 0.8481012658227848, 0.8485449735449735, 0.9542884071630537, 0.788, 0.8183663115169965, 0.8748639825897715, 0.9496021220159151, 0.8503717472118959, 0.882035466461064, 0.9741100323624595, 0.9710327455919395]
 precisions [0.9722576530612245, 0.8713405238828967, 0.88558352402746, 0.8863252673044457, 0.9450171821305842, 0.9043321299638989, 0.8253164556962025, 0.8677248677248677, 0.9580584354382657, 0.816, 0.8001014713343481, 0.8596300326441785, 0.9376657824933687, 0.8587360594795539, 0.8866615265998458, 0.9870550161812298, 0.9785894206549118]
 recalls [0.9665178571428571, 0.8605546995377504, 0.8890160183066361, 0.8688801350590883, 0.9553264604810997, 0.8916967509025271, 0.8151898734177215, 0.8670634920634921, 0.9594721960414703, 0.804, 0.8026382546930492, 0.8650707290533188, 0.9535809018567639, 0.8471189591078067, 0.8619892058596762, 0.970873786407767, 0.9767002518891688]
 f1scores [0.9701878577063777, 0.8599103142082939, 0.8947055099933937, 0.8583780786977829, 0.948721787866455, 0.8817214163248954, 0.8122143765678761, 0.8556478467295079, 0.9547500622910283, 0.8251430361191016, 0.7755880205344783, 0.8686878238856643, 0.9369732893156548, 0.855760173004317, 0.872168707926973, 0.9778432507087693, 0.9717030607513333]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.965 
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.785 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.901 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.840 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.947 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.785 
=> Acc: 0.663 Precision 0.663 Recall 0.663 F1 0.596 
=> Acc: 0.821 Precision 0.821 Recall 0.821 F1 0.818 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.941 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.959 
=> Acc: 0.785 Precision 0.785 Recall 0.785 F1 0.743 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.864 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.857 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.882 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.916 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 


accs [0.9658801020408163, 0.7981510015408321, 0.902745995423341, 0.855374226223973, 0.9450171821305842, 0.8146811070998796, 0.6632911392405063, 0.8214285714285714, 0.9420358152686145, 0.962, 0.7848807711821411, 0.8792165397170838, 0.9588859416445623, 0.8564126394052045, 0.8828064764841943, 0.9158576051779935, 0.9502518891687658, 0.897208985704561]
 precisions [0.9655612244897959, 0.8058551617873652, 0.8901601830663616, 0.8559369724254361, 0.9621993127147767, 0.8068592057761733, 0.6278481012658228, 0.8306878306878307, 0.9363807728557965, 0.974, 0.7924911212582445, 0.8748639825897715, 0.9482758620689655, 0.8596654275092936, 0.8812644564379337, 0.9029126213592233, 0.9552896725440806, 0.8938053097345132]
 recalls [0.9661989795918368, 0.8189522342064715, 0.8981693363844394, 0.8638154192459201, 0.9518900343642611, 0.8303249097472925, 0.6253164556962025, 0.8313492063492064, 0.9297832233741753, 0.958, 0.7909690512430239, 0.8998911860718172, 0.946949602122016, 0.8559479553903345, 0.8889745566692367, 0.9255663430420712, 0.9483627204030227, 0.8866575901974132]
 f1scores [0.9645669132058223, 0.7786149651042311, 0.9026306080707343, 0.8401742118729274, 0.9459848367238065, 0.794083404286432, 0.5768934121127713, 0.812849211972293, 0.9417604609476367, 0.9462712296707674, 0.7253374921639042, 0.8654453227877525, 0.954828835066208, 0.8460895858710973, 0.8694211972404521, 0.919590204054226, 0.9465464432254084, 0.9009678170296425]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.946 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.775 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.954 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.831 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.980 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.846 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.688 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.831 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.935 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.716 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.854 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.860 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.809 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.938 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.874 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 


accs [0.9467474489795918, 0.7835130970724191, 0.954233409610984, 0.8458075407990996, 0.979381443298969, 0.8622141997593261, 0.7291139240506329, 0.830026455026455, 0.937794533459001, 0.96, 0.7544393708777271, 0.8672470076169749, 0.9575596816976127, 0.8629182156133829, 0.812644564379337, 0.9385113268608414, 0.9527707808564232, 0.8761061946902655, 0.9396599012616567]
 precisions [0.951530612244898, 0.7704160246533128, 0.9530892448512586, 0.8548114800225098, 0.9587628865979382, 0.8772563176895307, 0.7240506329113924, 0.8326719576719577, 0.9288407163053722, 0.964, 0.7625570776255708, 0.8835690968443961, 0.9310344827586207, 0.8503717472118959, 0.8010794140323825, 0.9676375404530745, 0.9496221662468514, 0.8706603131381893, 0.927591881513988]
 recalls [0.9499362244897959, 0.7889060092449923, 0.9416475972540046, 0.8564997186268992, 0.9759450171821306, 0.8561973525872443, 0.759493670886076, 0.8452380952380952, 0.9382657869934025, 0.976, 0.7503805175038052, 0.8998911860718172, 0.9562334217506632, 0.8559479553903345, 0.8111025443330764, 0.9255663430420712, 0.948992443324937, 0.8781484002722941, 0.9292375205704883]
 f1scores [0.9534372110324991, 0.7644861122621649, 0.9485832609887179, 0.8389972664143415, 0.9764060214799605, 0.8497636881007594, 0.7203973670122877, 0.8286179676425494, 0.9323609655611309, 0.9757154454291225, 0.728464838242162, 0.871544770624368, 0.9542469948706327, 0.8762166439700113, 0.8016779400756858, 0.9136389712705298, 0.9484139795061696, 0.89148540628685, 0.9316683318296093]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.941 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.770 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.897 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.857 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.947 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.806 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.761 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.869 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.902 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.817 
=> Acc: 0.752 Precision 0.752 Recall 0.752 F1 0.719 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.882 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.957 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.860 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.864 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.896 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.855 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.885 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.931 


accs [0.9419642857142857, 0.8035439137134053, 0.8958810068649885, 0.8655036578503095, 0.9450171821305842, 0.8219013237063778, 0.779746835443038, 0.8677248677248677, 0.9043355325164939, 0.818, 0.7519025875190258, 0.8879216539717084, 0.9588859416445623, 0.8605947955390335, 0.8673862760215882, 0.8867313915857605, 0.9496221662468514, 0.8601089176310415, 0.8891936368623149, 0.9331184528605962]
 precisions [0.9496173469387755, 0.8220338983050848, 0.8958810068649885, 0.8688801350590883, 0.9587628865979382, 0.8176895306859205, 0.7518987341772152, 0.8624338624338624, 0.9024505183788878, 0.844, 0.7681380010147133, 0.8998911860718172, 0.9522546419098143, 0.8638475836431226, 0.866615265998458, 0.8867313915857605, 0.9527707808564232, 0.8464942137508509, 0.8688974218321448, 0.9315068493150684]
 recalls [0.9467474489795918, 0.8020030816640986, 0.9038901601830663, 0.8733821046707935, 0.9587628865979382, 0.8122743682310469, 0.8025316455696202, 0.871031746031746, 0.9038642789820923, 0.838, 0.7579908675799086, 0.8966267682263329, 0.9655172413793104, 0.8610594795539034, 0.8905165767154973, 0.8996763754045307, 0.9439546599496221, 0.8413886997957795, 0.8699945145364784, 0.9419822723609992]
 f1scores [0.9437766108324673, 0.7565201592205264, 0.8881045309431155, 0.8767476982769971, 0.9721603378802939, 0.7986627472838432, 0.7503188021907959, 0.873755836244207, 0.9045905948646109, 0.834693202517329, 0.6922836799340037, 0.876495717505334, 0.9570910097782074, 0.8632307887169153, 0.8733629600214247, 0.8721675403606455, 0.9393824927145875, 0.8371931755853922, 0.8722742793689428, 0.9286667238229815]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 


accs [0.9851362510322048]
 precisions [0.9843104872006606]
 recalls [0.9752270850536746]
 f1scores [0.9797111880091801]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.974 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 


accs [0.976878612716763, 0.992821645499724]
 precisions [0.9727497935590421, 0.9966869133075649]
 recalls [0.9752270850536746, 0.9966869133075649]
 f1scores [0.972075811451535, 0.9957090802321534]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.956 
=> Acc: 0.993 Precision 0.993 Recall 0.993 F1 0.993 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.975 


accs [0.9554087530966143, 0.992821645499724, 0.9760956175298805]
 precisions [0.9570602807597027, 0.9966869133075649, 0.9551792828685259]
 recalls [0.9512799339388934, 0.9922694643843181, 0.9711155378486056]
 f1scores [0.9473514306863532, 0.9933326096306029, 0.9697820231942218]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.922 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.995 Precision 0.995 Recall 0.995 F1 0.995 


accs [0.9207266721717589, 0.9878520154610713, 0.9701195219123506, 0.9950704225352113]
 precisions [0.9388934764657308, 0.9867476532302595, 0.9681274900398407, 0.9922535211267606]
 recalls [0.921552436003303, 0.9878520154610713, 0.9780876494023905, 0.9915492957746479]
 f1scores [0.9181992310583776, 0.98691814536469, 0.9607572288607955, 0.9951842666871371]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.876 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.941 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.950 


accs [0.8786127167630058, 0.9867476532302595, 0.9422310756972112, 0.9894366197183099, 0.9505027068832174]
 precisions [0.8810900082576383, 0.9861954721148537, 0.9631474103585658, 0.9887323943661972, 0.9624903325599381]
 recalls [0.8802642444260942, 0.9850911098840419, 0.9551792828685259, 0.9908450704225352, 0.9497293116782676]
 f1scores [0.8640557458008484, 0.9890591304414313, 0.9685123055726859, 0.9865302382094392, 0.9535652702931827]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.930 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.930 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.935 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.888 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.770 


accs [0.9339388934764657, 0.9878520154610713, 0.9292828685258964, 0.9330985915492958, 0.8952049497293116, 0.8279569892473119]
 precisions [0.93476465730801, 0.9823302043070127, 0.9362549800796812, 0.9197183098591549, 0.8874709976798144, 0.8172043010752689]
 recalls [0.9405450041288191, 0.9845389287686361, 0.9372509960159362, 0.9274647887323944, 0.8940448569218871, 0.8279569892473119]
 f1scores [0.9338029529297014, 0.9856529215063045, 0.9428880211345072, 0.9284943883811042, 0.8959996268844419, 0.7870643828206383]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.878 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.949 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.900 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.813 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 


accs [0.8786127167630058, 0.981225842076201, 0.9482071713147411, 0.9767605633802817, 0.9044856921887084, 0.8365591397849462, 0.9907192575406032]
 precisions [0.8678777869529315, 0.9762562120375483, 0.9571713147410359, 0.9732394366197183, 0.9037122969837587, 0.8, 0.9918793503480279]
 recalls [0.8769611890999174, 0.9757040309221424, 0.9372509960159362, 0.9774647887323944, 0.9079659706109822, 0.8451612903225807, 0.994199535962877]
 f1scores [0.8695879754999007, 0.9732515906624645, 0.9522320190634332, 0.9775286432667414, 0.901888030311943, 0.7983032255715742, 0.9905796853765118]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.889 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.902 
=> Acc: 0.697 Precision 0.697 Recall 0.697 F1 0.659 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.953 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 


accs [0.8901734104046243, 0.9806736609607951, 0.9392430278884463, 0.9732394366197183, 0.902938901778809, 0.6967741935483871, 0.9535962877030162, 0.9742895805142084]
 precisions [0.8620974401321222, 0.9779127553837659, 0.9472111553784861, 0.9704225352112676, 0.9044856921887084, 0.7204301075268817, 0.9489559164733179, 0.9688768606224628]
 recalls [0.8654004954582989, 0.9817780231916069, 0.9432270916334662, 0.9746478873239437, 0.9091260634184068, 0.7032258064516129, 0.9559164733178654, 0.972936400541272]
 f1scores [0.8604455126395114, 0.9822220898476368, 0.948764135021259, 0.9739549854511376, 0.9137016256413478, 0.6841888834695034, 0.9494442342862897, 0.9723319815376058]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.898 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.986 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.921 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.915 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.918 
=> Acc: 0.695 Precision 0.695 Recall 0.695 F1 0.648 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.878 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.872 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 


accs [0.9009083402146986, 0.9861954721148537, 0.9252988047808764, 0.9204225352112676, 0.9184068058778035, 0.6946236559139785, 0.8897911832946636, 0.8768606224627875, 0.9842406876790831]
 precisions [0.8918249380677127, 0.9861954721148537, 0.9282868525896414, 0.9063380281690141, 0.92846094354215, 0.6408602150537634, 0.9071925754060325, 0.8890392422192152, 0.9928366762177651]
 recalls [0.8819157720891825, 0.9867476532302595, 0.9292828685258964, 0.9190140845070423, 0.9215003866976025, 0.6301075268817204, 0.8839907192575406, 0.8768606224627875, 0.9885386819484241]
 f1scores [0.8896249072000508, 0.9900578460543817, 0.9188924944649166, 0.9058804830986762, 0.9215850708427494, 0.6335864376780549, 0.8834179537909845, 0.8933098186138453, 0.9826664570597157]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.883 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.979 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.940 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.926 
=> Acc: 0.720 Precision 0.720 Recall 0.720 F1 0.682 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.915 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.870 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.958 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.984 


accs [0.8827415359207267, 0.9784649364991718, 0.9442231075697212, 0.9408450704225352, 0.9273008507347255, 0.7204301075268817, 0.9164733178654292, 0.8687415426251691, 0.9570200573065902, 0.9848942598187311]
 precisions [0.8720066061106524, 0.9729431253451132, 0.9243027888446215, 0.9373239436619718, 0.9303944315545244, 0.6623655913978495, 0.9013921113689095, 0.8917456021650879, 0.9656160458452722, 0.986404833836858]
 recalls [0.8455821635012386, 0.9751518498067366, 0.9342629482071713, 0.930281690140845, 0.9203402938901779, 0.6795698924731183, 0.8979118329466357, 0.8903924221921515, 0.9570200573065902, 0.9818731117824774]
 f1scores [0.8664592157202857, 0.9762277114036471, 0.9243876874387678, 0.9386824888090155, 0.9265805407725338, 0.611498487748002, 0.8946764900841089, 0.8906240406246357, 0.974306676326201, 0.9810471252790307]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.814 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.898 
=> Acc: 0.669 Precision 0.669 Recall 0.669 F1 0.653 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.877 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.900 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.941 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.838 


accs [0.8142031379025598, 0.9762562120375483, 0.9382470119521913, 0.9387323943661972, 0.9013921113689095, 0.6688172043010753, 0.8967517401392111, 0.8971583220568335, 0.9641833810888252, 0.9425981873111783, 0.852068345323741]
 precisions [0.8026424442609413, 0.9607951408061844, 0.9372509960159362, 0.9556338028169014, 0.9048723897911833, 0.6451612903225806, 0.8642691415313225, 0.9093369418132612, 0.9713467048710601, 0.93202416918429, 0.8462230215827338]
 recalls [0.8414533443435177, 0.9663169519602429, 0.9163346613545816, 0.952112676056338, 0.9129930394431555, 0.6903225806451613, 0.8735498839907193, 0.8863328822733424, 0.9627507163323782, 0.9622356495468278, 0.8498201438848921]
 f1scores [0.8158049599845617, 0.9734793162386838, 0.9424912180618822, 0.95325350899396, 0.9135523636419334, 0.6100072976354753, 0.8503450147222826, 0.862217357409164, 0.957183408121552, 0.9498083099163959, 0.8303419905457406]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.811 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.969 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.946 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.939 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.913 
=> Acc: 0.770 Precision 0.770 Recall 0.770 F1 0.738 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.859 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.844 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.931 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.938 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.824 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.945 


accs [0.8125516102394715, 0.969630038652678, 0.9452191235059761, 0.9401408450704225, 0.9145398298530549, 0.7698924731182796, 0.8642691415313225, 0.8525033829499323, 0.9312320916905444, 0.9395770392749244, 0.8385791366906474, 0.9451737451737452]
 precisions [0.800990916597853, 0.9679734953064605, 0.9302788844621513, 0.95, 0.9083526682134571, 0.7569892473118279, 0.8758700696055685, 0.8538565629228687, 0.9283667621776505, 0.959214501510574, 0.8421762589928058, 0.9552123552123553]
 recalls [0.7993393889347646, 0.9646604086140254, 0.9302788844621513, 0.9373239436619718, 0.9064191802010828, 0.7784946236559139, 0.8596287703016241, 0.8403247631935047, 0.9412607449856734, 0.9441087613293051, 0.8322841726618705, 0.9498069498069498]
 f1scores [0.7750966903358961, 0.9720723935971647, 0.9398687916652418, 0.9375970630962783, 0.9016355344065416, 0.7548291819522293, 0.8806586563174669, 0.8588260454057881, 0.954908784253526, 0.9390417772438504, 0.8231270036238486, 0.9446728395754409]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.802 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.966 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.911 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.902 
=> Acc: 0.703 Precision 0.703 Recall 0.703 F1 0.685 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.909 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.868 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.904 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.808 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.869 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 


accs [0.8018166804293972, 0.9652125897294312, 0.9113545816733067, 0.9323943661971831, 0.9037122969837587, 0.7032258064516129, 0.9106728538283063, 0.8700947225981055, 0.9598853868194842, 0.9063444108761329, 0.8151978417266187, 0.8671814671814672, 0.973536036036036]
 precisions [0.8067712634186622, 0.9541689674213142, 0.9133466135458167, 0.9338028169014084, 0.9191802010827533, 0.6967741935483871, 0.9048723897911833, 0.8795669824086604, 0.9484240687679083, 0.8670694864048338, 0.8138489208633094, 0.8517374517374517, 0.9718468468468469]
 recalls [0.8208092485549133, 0.9558255107675317, 0.9163346613545816, 0.9169014084507042, 0.9071925754060325, 0.6709677419354839, 0.8793503480278422, 0.878213802435724, 0.9713467048710601, 0.8851963746223565, 0.8192446043165468, 0.8826254826254826, 0.9701576576576577]
 f1scores [0.7939158621318665, 0.9566135243808173, 0.931422637660055, 0.9205489951401876, 0.8986385121605363, 0.6865194314598163, 0.9302013827222787, 0.8635488271207887, 0.9630317302330134, 0.8928495304846384, 0.8004955554102411, 0.8503720211255235, 0.9784323634251745]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.832 Precision 0.832 Recall 0.832 F1 0.829 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.941 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.920 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.954 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.897 
=> Acc: 0.613 Precision 0.613 Recall 0.613 F1 0.607 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.836 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.811 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.761 Precision 0.761 Recall 0.761 F1 0.762 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.817 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.868 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.863 


accs [0.8315441783649876, 0.9403644395361679, 0.9223107569721115, 0.954225352112676, 0.8982985305491106, 0.6129032258064516, 0.851508120649652, 0.8308525033829499, 0.9713467048710601, 0.7613293051359517, 0.8232913669064749, 0.8702702702702703, 0.9324324324324325, 0.8732510288065843]
 precisions [0.8216350123864574, 0.9348426283821093, 0.9103585657370518, 0.9408450704225352, 0.8967517401392111, 0.6279569892473118, 0.8723897911832946, 0.8484438430311232, 0.9555873925501432, 0.7507552870090635, 0.825089928057554, 0.8594594594594595, 0.9431306306306306, 0.8761316872427983]
 recalls [0.8274153592072667, 0.9480949751518498, 0.9133466135458167, 0.9422535211267605, 0.9044856921887084, 0.6193548387096774, 0.8584686774941995, 0.8443843031123139, 0.9555873925501432, 0.7598187311178247, 0.8201438848920863, 0.8633204633204633, 0.9420045045045045, 0.8798353909465021]
 f1scores [0.8240335367107203, 0.9434032124115699, 0.8899805933577405, 0.9423768246134984, 0.8920777651659464, 0.60898763947857, 0.8250687223444698, 0.8017630462805438, 0.9520955157762975, 0.7688599062533199, 0.8197755158995262, 0.8562131079530305, 0.938303906514909, 0.8799199233169583]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.803 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.895 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.874 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.929 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.874 
=> Acc: 0.626 Precision 0.626 Recall 0.626 F1 0.607 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.726 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.817 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.956 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.862 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.814 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.846 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.923 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.872 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.957 


accs [0.8026424442609413, 0.8939812258420762, 0.8774900398406374, 0.9330985915492958, 0.877030162412993, 0.6258064516129033, 0.7633410672853829, 0.8308525033829499, 0.9584527220630372, 0.8625377643504532, 0.8187949640287769, 0.8517374517374517, 0.9245495495495496, 0.8864197530864197, 0.9570885388375883]
 precisions [0.8183319570602807, 0.890668139149641, 0.8834661354581673, 0.9330985915492958, 0.8735498839907193, 0.5634408602150538, 0.7505800464037123, 0.8294993234100135, 0.9570200573065902, 0.8655589123867069, 0.8286870503597122, 0.8355212355212355, 0.9228603603603603, 0.8748971193415638, 0.9527430744160782]
 recalls [0.8208092485549133, 0.8928768636112645, 0.8804780876494024, 0.9373239436619718, 0.8836040216550657, 0.5849462365591398, 0.7923433874709976, 0.8660351826792964, 0.9383954154727794, 0.8489425981873112, 0.8129496402877698, 0.8308880308880309, 0.9251126126126126, 0.8609053497942387, 0.9557305812058664]
 f1scores [0.8163876413944967, 0.9052559740222819, 0.8816231187321408, 0.9326780148088343, 0.8635298309575388, 0.5830484193962454, 0.7134593664503172, 0.8246240497862267, 0.9722384845274975, 0.8737222425718223, 0.8194568679869807, 0.8607036230509244, 0.9292210693109844, 0.8549969761927085, 0.9572689563186978]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.817 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.931 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.905 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.822 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.865 
=> Acc: 0.510 Precision 0.510 Recall 0.510 F1 0.476 
=> Acc: 0.781 Precision 0.781 Recall 0.781 F1 0.731 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.843 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.806 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.848 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.887 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.893 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.821 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.965 


accs [0.8199834847233691, 0.932633903920486, 0.9043824701195219, 0.8380281690140845, 0.8677494199535963, 0.5096774193548387, 0.7807424593967517, 0.851150202976996, 0.9484240687679083, 0.8172205438066465, 0.8525179856115108, 0.8864864864864865, 0.8963963963963963, 0.8390946502057613, 0.9603476371537208, 0.9643097643097643]
 precisions [0.833195706028076, 0.9304251794588625, 0.8864541832669323, 0.8429577464788732, 0.8793503480278422, 0.535483870967742, 0.7737819025522041, 0.8308525033829499, 0.9455587392550143, 0.823262839879154, 0.8489208633093526, 0.8818532818532818, 0.8980855855855856, 0.8234567901234567, 0.9538294405214557, 0.960942760942761]
 recalls [0.8414533443435177, 0.9331860850358917, 0.8944223107569721, 0.8450704225352113, 0.8584686774941995, 0.5526881720430108, 0.7691415313225058, 0.8470906630581867, 0.9383954154727794, 0.850453172205438, 0.8511690647482014, 0.8687258687258688, 0.9003378378378378, 0.8477366255144033, 0.951113525258012, 0.9663299663299664]
 f1scores [0.8353525260848107, 0.9252967756411173, 0.9014434992475827, 0.8302255361754114, 0.8714776273721391, 0.526961993579825, 0.7339927208929558, 0.8277743298693464, 0.9278680756794879, 0.8121032288171908, 0.8547542338572647, 0.8885805091292871, 0.8866958234312381, 0.817000866358119, 0.9568947998837116, 0.9777664981766886]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.754 Precision 0.754 Recall 0.754 F1 0.748 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.858 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.892 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.887 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.862 
=> Acc: 0.553 Precision 0.553 Recall 0.553 F1 0.534 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.739 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.811 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.939 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.804 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.864 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.907 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.820 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.931 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 


accs [0.7539223781998349, 0.8558807288790723, 0.8924302788844621, 0.8943661971830986, 0.8662026295436969, 0.5526881720430108, 0.7958236658932715, 0.8470906630581867, 0.9369627507163324, 0.8126888217522659, 0.8664568345323741, 0.8965250965250965, 0.9065315315315315, 0.8337448559670781, 0.9391634980988594, 0.9306397306397306, 0.9522799575821845]
 precisions [0.7382328654004955, 0.8586416344561016, 0.9103585657370518, 0.8915492957746479, 0.8631090487238979, 0.5634408602150538, 0.8074245939675174, 0.8119079837618404, 0.9369627507163324, 0.8021148036253777, 0.8489208633093526, 0.8972972972972973, 0.8969594594594594, 0.8316872427983539, 0.9402498642042368, 0.9313131313131313, 0.9448568398727466]
 recalls [0.7514450867052023, 0.8575372722252899, 0.8934262948207171, 0.8823943661971831, 0.8604021655065739, 0.5225806451612903, 0.771461716937355, 0.8254397834912043, 0.9455587392550143, 0.8126888217522659, 0.8574640287769785, 0.8864864864864865, 0.9082207207207207, 0.8382716049382716, 0.9440521455730582, 0.9333333333333333, 0.9607635206786851]
 f1scores [0.7245473477779281, 0.8562470197162128, 0.8876721758905374, 0.8788341372079309, 0.8601464845086448, 0.5234467306483299, 0.722988864054882, 0.8118384576868894, 0.9463940770061015, 0.8116226416283258, 0.8360059114565862, 0.8994852757940184, 0.9087064567716954, 0.7892228501777251, 0.9359469502082565, 0.9223311533847044, 0.9576333909315654]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.786 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.847 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.862 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.895 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.861 
=> Acc: 0.553 Precision 0.553 Recall 0.553 F1 0.549 
=> Acc: 0.725 Precision 0.725 Recall 0.725 F1 0.704 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.884 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.957 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.897 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.859 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.860 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.945 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.829 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.848 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.921 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 


accs [0.7943848059454995, 0.842076200993926, 0.8615537848605578, 0.8971830985915493, 0.8650425367362722, 0.5526881720430108, 0.7250580046403712, 0.8809201623815968, 0.9570200573065902, 0.8987915407854985, 0.8637589928057554, 0.8617760617760618, 0.9453828828828829, 0.8349794238683128, 0.9402498642042368, 0.8451178451178452, 0.9215270413573701, 0.973851030110935]
 precisions [0.7985136251032204, 0.8625069022639426, 0.8545816733067729, 0.8852112676056338, 0.8503480278422274, 0.5827956989247312, 0.7494199535962877, 0.8958051420838972, 0.9598853868194842, 0.8987915407854985, 0.8673561151079137, 0.864092664092664, 0.9442567567567568, 0.8308641975308642, 0.9492123845736014, 0.8484848484848485, 0.9109225874867445, 0.9683042789223455]
 recalls [0.8018166804293972, 0.853672004417449, 0.8555776892430279, 0.8971830985915493, 0.87122969837587, 0.5698924731182796, 0.7134570765661253, 0.878213802435724, 0.9455587392550143, 0.8821752265861027, 0.877248201438849, 0.8694980694980695, 0.9453828828828829, 0.8316872427983539, 0.9437805540467138, 0.8417508417508418, 0.9066808059384942, 0.971473851030111]
 f1scores [0.7892118885552957, 0.8639660885421033, 0.8580900186562512, 0.8911350778413123, 0.8602746162461005, 0.5312762806666957, 0.6912562034856533, 0.8866591080112036, 0.9437350292951617, 0.8841923534350234, 0.8702159817901869, 0.8537693587653699, 0.9374956475483099, 0.8407267431520168, 0.9446734759935567, 0.8560541807024009, 0.9079963510598184, 0.9714851503146491]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.739 Precision 0.739 Recall 0.739 F1 0.735 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.852 
=> Acc: 0.835 Precision 0.835 Recall 0.835 F1 0.826 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.890 
=> Acc: 0.548 Precision 0.548 Recall 0.548 F1 0.479 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.802 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.851 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.774 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.853 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.833 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.913 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.785 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.928 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.893 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.859 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.937 


accs [0.7390586292320397, 0.9392600773053562, 0.853585657370518, 0.8345070422535211, 0.8917246713070379, 0.5483870967741935, 0.8329466357308585, 0.8470906630581867, 0.9756446991404012, 0.783987915407855, 0.8565647482014388, 0.8293436293436294, 0.9144144144144144, 0.8049382716049382, 0.9274850624660511, 0.8942760942760942, 0.8716861081654295, 0.9698890649762282, 0.9398592450415867]
 precisions [0.7448389760528489, 0.9353948094975152, 0.8675298804780877, 0.8302816901408451, 0.8940448569218871, 0.5225806451612903, 0.8190255220417634, 0.8362652232746955, 0.9656160458452722, 0.7915407854984894, 0.8664568345323741, 0.8254826254826255, 0.9234234234234234, 0.8152263374485597, 0.9345464421510049, 0.8929292929292929, 0.8695652173913043, 0.9722662440570523, 0.9379398592450416]
 recalls [0.7712634186622626, 0.9425731639977912, 0.8645418326693227, 0.8401408450704225, 0.891337973704563, 0.5311827956989247, 0.8248259860788864, 0.8362652232746955, 0.9598853868194842, 0.8096676737160121, 0.8637589928057554, 0.827027027027027, 0.9206081081081081, 0.802880658436214, 0.9239543726235742, 0.8841750841750842, 0.8822905620360552, 0.96513470681458, 0.9373000639795266]
 f1scores [0.7663557575778839, 0.9476446008107839, 0.8650980594927422, 0.8269567940917574, 0.8888149268502701, 0.4537764317697979, 0.7903769397821673, 0.8427652519793842, 0.9707476487367817, 0.7976820936367839, 0.8646278293737831, 0.8316824953004851, 0.9167653670613494, 0.7669735136517752, 0.9320391823623101, 0.8985585431597445, 0.8724984703286957, 0.9688218006921575, 0.9310032228673994]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.807 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.952 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.896 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.784 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.895 
=> Acc: 0.346 Precision 0.346 Recall 0.346 F1 0.250 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.778 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.861 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.850 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.836 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.902 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.905 
=> Acc: 0.794 Precision 0.794 Recall 0.794 F1 0.770 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.944 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.917 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.915 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.932 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.842 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.891 


accs [0.8125516102394715, 0.9519602429596907, 0.898406374501992, 0.7964788732394367, 0.897138437741686, 0.34623655913978496, 0.8120649651972158, 0.8673883626522327, 0.9742120343839542, 0.851963746223565, 0.8426258992805755, 0.9011583011583012, 0.9070945945945946, 0.7938271604938272, 0.9429657794676806, 0.9144781144781144, 0.9130434782608695, 0.9358161648177497, 0.8445297504798465, 0.8866213151927438]
 precisions [0.8307184145334434, 0.9447818884594147, 0.900398406374502, 0.8, 0.897138437741686, 0.3161290322580645, 0.8097447795823666, 0.8700947225981055, 0.9713467048710601, 0.8323262839879154, 0.8561151079136691, 0.8911196911196911, 0.9054054054054054, 0.802880658436214, 0.9478544269418794, 0.9191919191919192, 0.9088016967126193, 0.9294770206022187, 0.8426103646833013, 0.8775510204081632]
 recalls [0.815028901734104, 0.9536167863059083, 0.896414342629482, 0.7943661971830986, 0.8917246713070379, 0.34623655913978496, 0.8051044083526682, 0.8457374830852503, 0.9656160458452722, 0.8157099697885196, 0.852068345323741, 0.8972972972972973, 0.9155405405405406, 0.8004115226337448, 0.9470396523628463, 0.9205387205387205, 0.9056203605514316, 0.9342313787638669, 0.8419705694177864, 0.8684807256235828]
 f1scores [0.8174468705906948, 0.9515236580938013, 0.892962083979669, 0.7700037653134603, 0.891223800015122, 0.304929082491756, 0.771241936604304, 0.8578672861592569, 0.9766451207360664, 0.8245204508488209, 0.8483468476791817, 0.8967151230703541, 0.9035996284364378, 0.7589906335361084, 0.954699281702637, 0.9292917961344456, 0.9089588451033395, 0.9126535790184335, 0.8214438850602154, 0.9133093878674348]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.984 


accs [0.9830949284785435]
 precisions [0.988296488946684]
 recalls [0.9869960988296489]
 f1scores [0.9858530762599906]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 


accs [0.9811443433029909, 0.9776640297812936]
 precisions [0.9843953185955787, 0.9692880409492788]
 recalls [0.988296488946684, 0.9692880409492788]
 f1scores [0.9792468923815797, 0.9735875607939917]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.939 


accs [0.9245773732119635, 0.9781293624941834, 0.9411764705882353]
 precisions [0.9460338101430429, 0.9753373662168451, 0.9572925060435133]
 recalls [0.9148244473342002, 0.9790600279199628, 0.9572925060435133]
 f1scores [0.9335549659929392, 0.9774718312776155, 0.949809688976344]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.945 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.962 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.910 
=> Acc: 0.998 Precision 0.998 Recall 0.998 F1 0.998 


accs [0.9460338101430429, 0.9613773848301536, 0.9081385979049154, 0.9978401727861771]
 precisions [0.9479843953185956, 0.9609120521172638, 0.9073327961321515, 0.9978401727861771]
 recalls [0.9440832249674902, 0.9632387156817124, 0.9129734085414988, 0.9956803455723542]
 f1scores [0.9377091863606578, 0.9575439280015898, 0.9090950019948207, 0.9940569780021636]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.889 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.847 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.906 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.980 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.8862158647594278, 0.85248953001396, 0.9033037872683319, 0.980561555075594, 0.9889669007021064]
 precisions [0.8855656697009102, 0.8673801768264309, 0.8759065269943593, 0.9719222462203023, 0.9939819458375125]
 recalls [0.8907672301690507, 0.8706375058166589, 0.8823529411764706, 0.9956803455723542, 0.9939819458375125]
 f1scores [0.8873423933767685, 0.8587149122329629, 0.8979266777646128, 0.9842984822190456, 0.9931181402483735]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.922 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.893 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.918 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.972 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.868 


accs [0.9232769830949284, 0.886924150767799, 0.9210314262691378, 0.9870410367170627, 0.9719157472417251, 0.8845029239766082]
 precisions [0.9076723016905072, 0.9101907864122848, 0.9049153908138597, 0.9848812095032398, 0.9769307923771314, 0.868421052631579]
 recalls [0.9109232769830949, 0.8990228013029316, 0.9105560032232071, 0.9848812095032398, 0.9749247743229689, 0.8779239766081871]
 f1scores [0.9057647397884626, 0.9044513655970547, 0.8873538420531842, 0.9887368255466414, 0.9770397787099124, 0.8528477563140461]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.847 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.870 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.914 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.858 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.975 


accs [0.852405721716515, 0.8780828292228944, 0.9153908138597905, 0.9935205183585313, 0.9648946840521565, 0.868421052631579, 0.9756317689530686]
 precisions [0.8368010403120937, 0.8925081433224755, 0.9161966156325544, 0.9827213822894169, 0.9689067201604814, 0.8706140350877193, 0.9751805054151624]
 recalls [0.846553966189857, 0.8873894834806887, 0.9161966156325544, 0.9892008639308856, 0.9719157472417251, 0.8567251461988304, 0.973826714801444]
 f1scores [0.8407389021363907, 0.863153400425141, 0.9197253794342559, 0.9882615799642591, 0.9649482433042811, 0.8551317477227368, 0.9754626775747154]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.890 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.896 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.911 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.986 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.831 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.902 


accs [0.8914174252275683, 0.8985574685900419, 0.9081385979049154, 0.9848812095032398, 0.970912738214644, 0.8530701754385965, 0.9580324909747292, 0.9005376344086021]
 precisions [0.8927178153446034, 0.8822708236389019, 0.9298952457695407, 0.9870410367170627, 0.9568706118355065, 0.8530701754385965, 0.9684115523465704, 0.9139784946236559]
 recalls [0.8920676202860858, 0.8892508143322475, 0.9266720386784851, 0.978401727861771, 0.9558676028084253, 0.8391812865497076, 0.9652527075812274, 0.9112903225806451]
 f1scores [0.8846484412900603, 0.8911594364174185, 0.9086085183707915, 0.9815746180963572, 0.9766152522458048, 0.8480673283969488, 0.9609701258287615, 0.9082276578135062]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.885 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.943 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.828 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.943 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.837 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 


accs [0.8810143042912874, 0.890181479758027, 0.9443996776792909, 0.9676025917926566, 0.9699097291875627, 0.8538011695906432, 0.9462996389891697, 0.8413978494623656, 0.9771203155818541]
 precisions [0.8946684005201561, 0.8845974872033504, 0.9315068493150684, 0.978401727861771, 0.9719157472417251, 0.875, 0.9512635379061372, 0.8870967741935484, 0.9794871794871794]
 recalls [0.8758127438231469, 0.8813401582131224, 0.9395648670427075, 0.980561555075594, 0.9679037111334002, 0.8581871345029239, 0.9494584837545126, 0.8575268817204301, 0.980276134122288]
 f1scores [0.8824687537293233, 0.8726427576282255, 0.9417248454698784, 0.9762632681455109, 0.9541665481235839, 0.8358655222221028, 0.9419463131424379, 0.8356907432530851, 0.9773603691267632]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.911 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.856 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.892 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.967 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.857 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.948 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.892 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.960 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.972 


accs [0.91222366710013, 0.8636575151233131, 0.8896051571313457, 0.9676025917926566, 0.9378134403209629, 0.8706140350877193, 0.9485559566787004, 0.9032258064516129, 0.9609467455621302, 0.9714640198511166]
 precisions [0.9135240572171651, 0.8813401582131224, 0.8879935535858179, 0.9481641468682506, 0.9478435305917753, 0.8559941520467836, 0.9404332129963899, 0.8575268817204301, 0.9652859960552268, 0.9714640198511166]
 recalls [0.9265279583875162, 0.8729641693811075, 0.8992747784045125, 0.9352051835853131, 0.9438314944834504, 0.8669590643274854, 0.950812274368231, 0.9059139784946236, 0.9613412228796844, 0.9621588089330024]
 f1scores [0.9368794152638363, 0.8697630814632229, 0.9113764567744026, 0.9477064746391715, 0.9313951435148965, 0.8661558406176286, 0.9464568499733635, 0.8763776822486081, 0.9500891744168426, 0.9709085800936414]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.926 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.855 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.896 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.993 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.955 
=> Acc: 0.824 Precision 0.824 Recall 0.824 F1 0.806 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.926 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.863 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.969 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 


accs [0.9265279583875162, 0.862261516984644, 0.8960515713134569, 0.9935205183585313, 0.9558676028084253, 0.8238304093567251, 0.9273465703971119, 0.8655913978494624, 0.9321499013806707, 0.9696029776674938, 0.9755142017629774]
 precisions [0.9310793237971391, 0.865518845974872, 0.8799355358581789, 0.980561555075594, 0.9638916750250752, 0.8267543859649122, 0.9264440433212996, 0.8575268817204301, 0.927810650887574, 0.9689826302729528, 0.9676787463271302]
 recalls [0.9232769830949284, 0.8743601675197766, 0.9041095890410958, 0.980561555075594, 0.950852557673019, 0.8362573099415205, 0.9363718411552346, 0.8602150537634409, 0.9305719921104536, 0.9621588089330024, 0.9725759059745348]
 f1scores [0.9266480866792677, 0.8508979954909297, 0.8818442916994623, 0.9823079537160421, 0.9581540852012808, 0.8142913978864833, 0.9264748275952741, 0.8569117806558646, 0.9264213109282847, 0.9683942958598285, 0.9663750877656367]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.948 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.901 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.935 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.974 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.827 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.945 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.826 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.895 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.954 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.915 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.935 


accs [0.9499349804941483, 0.9497440670079107, 0.9033037872683319, 0.9352051835853131, 0.9729187562688064, 0.8391812865497076, 0.9462996389891697, 0.8225806451612904, 0.8970414201183432, 0.9540942928039702, 0.9147894221351616, 0.9351351351351351]
 precisions [0.9551365409622887, 0.9516053978594695, 0.8879935535858179, 0.9611231101511879, 0.9729187562688064, 0.831140350877193, 0.9499097472924187, 0.8629032258064516, 0.8899408284023669, 0.957196029776675, 0.9128305582761999, 0.9322901849217639]
 recalls [0.9466840052015605, 0.9511400651465798, 0.8904109589041096, 0.9546436285097192, 0.970912738214644, 0.8304093567251462, 0.9481046931407943, 0.8709677419354839, 0.8954635108481263, 0.9509925558312655, 0.9187071498530852, 0.9331436699857752]
 f1scores [0.9367184796151493, 0.9501069595229756, 0.9017256723146396, 0.9515178521262608, 0.9794954031920282, 0.8102418763926531, 0.9527037859055335, 0.8888728278754787, 0.8911374668890477, 0.9482999137840353, 0.9280100538135647, 0.9378258855424079]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.867 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.920 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.862 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.981 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.753 Precision 0.753 Recall 0.753 F1 0.739 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.935 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.856 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.941 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.933 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.880 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.866 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 


accs [0.8667100130039012, 0.9157747789669614, 0.863013698630137, 0.9827213822894169, 0.9498495486459378, 0.7529239766081871, 0.9368231046931408, 0.8575268817204301, 0.9400394477317554, 0.9323821339950372, 0.881488736532811, 0.8671408250355619, 0.9799196787148594]
 precisions [0.8725617685305592, 0.9218241042345277, 0.8662369057211926, 0.9870410367170627, 0.9428284854563691, 0.7602339181286549, 0.9458483754512635, 0.8467741935483871, 0.9396449704142011, 0.9193548387096774, 0.9000979431929481, 0.883072546230441, 0.9759036144578314]
 recalls [0.8719115734720416, 0.9255467659376454, 0.8670427074939565, 0.9697624190064795, 0.9358074222668004, 0.7668128654970761, 0.9476534296028881, 0.803763440860215, 0.9400394477317554, 0.9255583126550868, 0.8873653281096964, 0.8751066856330014, 0.9825970548862115]
 f1scores [0.8741128795664181, 0.9282237703070824, 0.8371085829050747, 0.9794827284613724, 0.9518346256258884, 0.7297638745760656, 0.9357535823360086, 0.8313884827390645, 0.9383605572221955, 0.9289463531022761, 0.8891973665248113, 0.8789818674655006, 0.9667429194883901]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.868 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.835 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.923 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.770 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.911 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.803 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.894 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.898 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.918 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.967 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.960 


accs [0.9369310793237972, 0.8683108422522103, 0.8396454472199839, 0.9200863930885529, 0.9618856569709128, 0.7953216374269005, 0.9111010830324909, 0.8091397849462365, 0.8978303747534516, 0.9627791563275434, 0.8991185112634672, 0.9172119487908962, 0.9678714859437751, 0.959047619047619]
 precisions [0.9408322496749024, 0.8576081898557468, 0.8533440773569702, 0.9438444924406048, 0.9638916750250752, 0.7755847953216374, 0.9120036101083032, 0.8494623655913979, 0.906508875739645, 0.9596774193548387, 0.8756121449559255, 0.9115220483641536, 0.9518072289156626, 0.9628571428571429]
 recalls [0.94148244473342, 0.8599348534201955, 0.8517324738114423, 0.9438444924406048, 0.9679037111334002, 0.8033625730994152, 0.9101985559566786, 0.8494623655913979, 0.8998027613412228, 0.9584367245657568, 0.8971596474045054, 0.9103840682788051, 0.9625167336010709, 0.9733333333333334]
 f1scores [0.9416568023215653, 0.8703914616934613, 0.8423610101807062, 0.9555883291732348, 0.9604343979819051, 0.7615355744449361, 0.9117337795817848, 0.8283504311797565, 0.8979287060028547, 0.9554017670376153, 0.900673078797195, 0.9120018945224773, 0.9530679047110558, 0.9649860225196235]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.954 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.805 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.857 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.787 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.902 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.809 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.890 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.802 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.853 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.956 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.886 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.920 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.940 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.951 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 


accs [0.9557867360208062, 0.8078175895765473, 0.8605962933118453, 0.8531317494600432, 0.9047141424272819, 0.8296783625730995, 0.8930505415162455, 0.8145161290322581, 0.8552268244575937, 0.956575682382134, 0.8883447600391773, 0.9203413940256046, 0.9424364123159303, 0.9523809523809523, 0.961730449251248]
 precisions [0.929778933680104, 0.8175895765472313, 0.8622078968573731, 0.8250539956803455, 0.9237713139418254, 0.8304093567251462, 0.894404332129964, 0.8091397849462365, 0.8564102564102564, 0.9528535980148883, 0.8903036238981391, 0.9120910384068279, 0.9250334672021419, 0.94, 0.9700499168053245]
 recalls [0.9401820546163849, 0.8087482550023266, 0.8702659145850121, 0.8056155507559395, 0.9077231695085256, 0.8340643274853801, 0.8907942238267148, 0.8172043010752689, 0.8678500986193294, 0.9491315136476427, 0.871694417238002, 0.9172119487908962, 0.9236947791164659, 0.9323809523809524, 0.956738768718802]
 f1scores [0.9496701166506402, 0.8025245790476335, 0.8535446924929545, 0.7954218130606578, 0.9440673749462449, 0.8243114387126645, 0.8830441941746164, 0.7753984026233833, 0.8494258340288343, 0.9540430936993488, 0.8425025299063036, 0.9180084099993898, 0.9457751059512491, 0.9446770587041625, 0.9693747966582731]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.902 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.884 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.795 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.945 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.774 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.925 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.821 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.753 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.938 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.890 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.907 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.943 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.927 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.923 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.985 


accs [0.9011703511053316, 0.8822708236389019, 0.8049959709911362, 0.9503239740820735, 0.9558676028084253, 0.7945906432748538, 0.9264440433212996, 0.8172043010752689, 0.7554240631163708, 0.9373449131513648, 0.8883447600391773, 0.9061166429587483, 0.9437751004016064, 0.9295238095238095, 0.9234608985024958, 0.9844179651695693]
 precisions [0.9206762028608583, 0.8818054909260121, 0.8291700241740532, 0.9308855291576674, 0.9568706118355065, 0.7755847953216374, 0.9219314079422383, 0.8252688172043011, 0.7727810650887574, 0.9460297766749379, 0.8893241919686582, 0.9140825035561878, 0.9544846050870147, 0.9266666666666666, 0.9450915141430949, 0.9871677360219981]
 recalls [0.8790637191157347, 0.8799441600744532, 0.806607574536664, 0.9546436285097192, 0.9458375125376128, 0.7850877192982456, 0.9169675090252708, 0.8279569892473119, 0.7759368836291913, 0.9423076923076923, 0.8795298726738492, 0.9132290184921764, 0.9491298527443106, 0.9066666666666666, 0.9450915141430949, 0.9825847846012832]
 f1scores [0.893062570757057, 0.8869507312345986, 0.8089602516878378, 0.9523915542336594, 0.9552707401181275, 0.789912036827653, 0.9172073402823985, 0.8332052145779201, 0.7671114855712359, 0.943727430641052, 0.9006377534079825, 0.916693184268096, 0.9495508954365679, 0.9112617267889325, 0.9121397007027522, 0.9882498861642949]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.910 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.862 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.825 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.956 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.940 
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.713 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.919 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.898 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.801 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.745 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.902 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.894 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.921 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.879 


accs [0.9102730819245773, 0.8580735225686366, 0.8356164383561644, 0.9568034557235421, 0.9408224674022067, 0.7426900584795322, 0.921028880866426, 0.8924731182795699, 0.8106508875739645, 0.955955334987593, 0.7473065621939275, 0.9018492176386913, 0.9504685408299867, 0.8971428571428571, 0.9217970049916805, 0.9706691109074244, 0.8862815884476535]
 precisions [0.9278283485045513, 0.855746859004188, 0.8283642224012893, 0.9568034557235421, 0.9398194583751254, 0.7331871345029239, 0.9106498194945848, 0.8360215053763441, 0.8043392504930966, 0.957196029776675, 0.7786483839373164, 0.8978662873399715, 0.9370816599732262, 0.9095238095238095, 0.9367720465890182, 0.9683776351970669, 0.8619133574007221]
 recalls [0.9154746423927178, 0.8585388552815263, 0.8364222401289283, 0.9503239740820735, 0.9458375125376128, 0.7324561403508771, 0.9160649819494585, 0.8494623655913979, 0.814595660749507, 0.957196029776675, 0.7610186092066601, 0.8995732574679943, 0.9477911646586346, 0.8942857142857142, 0.9334442595673876, 0.964711274060495, 0.8754512635379061]
 f1scores [0.913123675917927, 0.8585046383884458, 0.8188529834752458, 0.9572877574953134, 0.9408886395927402, 0.715226500530151, 0.9202952438069427, 0.8835787458999741, 0.7976953190159336, 0.954957722982067, 0.7867914313364415, 0.9019756856631475, 0.9306847245176119, 0.8989411555442267, 0.9244564537553843, 0.9732717940954343, 0.8469345169368395]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.868 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.917 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.858 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.929 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.830 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.952 
=> Acc: 0.790 Precision 0.790 Recall 0.790 F1 0.787 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.790 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.841 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.891 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.885 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.942 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.806 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 


accs [0.8751625487646294, 0.9171707771056306, 0.8622078968573731, 0.937365010799136, 0.9287863590772317, 0.8340643274853801, 0.9521660649819494, 0.7903225806451613, 0.8007889546351085, 0.9404466501240695, 0.8462291870714985, 0.8904694167852063, 0.9477911646586346, 0.8847619047619047, 0.940099833610649, 0.9596700274977086, 0.8158844765342961, 0.9481417458945549]
 precisions [0.8732119635890767, 0.9185667752442996, 0.8751007252215954, 0.9200863930885529, 0.9237713139418254, 0.8304093567251462, 0.9462996389891697, 0.782258064516129, 0.8055226824457594, 0.9491315136476427, 0.8158667972575906, 0.8887624466571835, 0.9370816599732262, 0.8657142857142858, 0.9351081530782029, 0.9555453712190651, 0.8050541516245487, 0.9351771823681936]
 recalls [0.8615084525357607, 0.9087947882736156, 0.8831587429492345, 0.937365010799136, 0.9287863590772317, 0.8391812865497076, 0.9548736462093863, 0.8118279569892473, 0.7861932938856016, 0.9522332506203474, 0.8344760039177277, 0.8933143669985776, 0.9504685408299867, 0.8733333333333333, 0.9450915141430949, 0.9523373052245646, 0.8231046931407943, 0.9533275713050994]
 f1scores [0.8646105006916457, 0.9159460181180894, 0.8578519938723972, 0.9187664013363495, 0.9285029334414137, 0.8169647113730699, 0.958817456126587, 0.8097349808711657, 0.778786483037534, 0.9385774141256332, 0.8274182201264398, 0.8919177947098864, 0.9423146874495198, 0.8823082177033681, 0.9437663194944861, 0.9644688622266899, 0.8321958659703569, 0.9423846590997227]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.930 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.758 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.807 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.913 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.827 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.922 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.850 
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.729 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.972 
=> Acc: 0.700 Precision 0.700 Recall 0.700 F1 0.698 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.853 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.808 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.895 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.942 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.900 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.867 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.929 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.933 


accs [0.9310793237971391, 0.762214983713355, 0.8138597904915391, 0.9157667386609071, 0.9317953861584755, 0.8406432748538012, 0.9228339350180506, 0.8521505376344086, 0.7428007889546351, 0.9720843672456576, 0.7002938295788442, 0.8509246088193456, 0.8273092369477911, 0.8961904761904762, 0.940099833610649, 0.9051329055912007, 0.8754512635379061, 0.9282627484874676, 0.9345475241889585]
 precisions [0.9336801040312094, 0.7673336435551419, 0.8275584206285254, 0.9028077753779697, 0.9438314944834504, 0.8472222222222222, 0.9268953068592057, 0.8655913978494624, 0.7577909270216963, 0.9789081885856079, 0.7091087169441724, 0.8472261735419631, 0.821954484605087, 0.8952380952380953, 0.913477537437604, 0.9028414298808433, 0.871841155234657, 0.9438202247191011, 0.9322709163346613]
 recalls [0.9304291287386216, 0.7915309446254072, 0.814665592264303, 0.9287257019438445, 0.9317953861584755, 0.8603801169590644, 0.9327617328519856, 0.8440860215053764, 0.7680473372781065, 0.9770471464019851, 0.7306562193927522, 0.8642958748221906, 0.8554216867469879, 0.8904761904761904, 0.9500831946755408, 0.9133822181484876, 0.8673285198555957, 0.9239412273120138, 0.93340922026181]
 f1scores [0.9320548573402763, 0.7799758063691045, 0.8144936490580278, 0.9406810581738524, 0.9318810169598324, 0.842099278740084, 0.9178370968018108, 0.8342554882164576, 0.7381022913289026, 0.9722471983911365, 0.7059272177262172, 0.8483024987737979, 0.8291288504970037, 0.9040711306323542, 0.9247220570495343, 0.8953216233700487, 0.8683569509098543, 0.9270239702738114, 0.9334574076155862]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.919 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.840 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.886 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.927 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.932 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.832 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.930 
=> Acc: 0.772 Precision 0.772 Recall 0.772 F1 0.769 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.795 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.952 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.768 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.868 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.864 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.892 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.945 
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.787 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.852 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.926 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 


accs [0.918075422626788, 0.840856212191717, 0.8879935535858179, 0.9287257019438445, 0.9358074222668004, 0.8552631578947368, 0.930956678700361, 0.771505376344086, 0.801577909270217, 0.9528535980148883, 0.7835455435847208, 0.8688477951635847, 0.9625167336010709, 0.8657142857142858, 0.8968386023294509, 0.9445462878093492, 0.7987364620938628, 0.8504753673293, 0.9271485486624929, 0.9827956989247312]
 precisions [0.9096228868660599, 0.8645881805490926, 0.8726833199033038, 0.9200863930885529, 0.9338014042126379, 0.8494152046783626, 0.9350180505415162, 0.7768817204301075, 0.8090729783037476, 0.9454094292803971, 0.7884427032321254, 0.8728307254623044, 0.9477911646586346, 0.8657142857142858, 0.891846921797005, 0.9459211732355637, 0.7906137184115524, 0.8461538461538461, 0.9151963574274331, 0.9870967741935484]
 recalls [0.9148244473342002, 0.845974872033504, 0.8839645447219984, 0.9287257019438445, 0.9287863590772317, 0.8669590643274854, 0.9305054151624549, 0.7688172043010753, 0.8248520710059172, 0.9534739454094293, 0.7923604309500489, 0.8756756756756757, 0.9531459170013387, 0.8685714285714285, 0.8968386023294509, 0.9472960586617782, 0.7806859205776173, 0.8625756266205704, 0.9208878770631759, 0.9913978494623656]
 f1scores [0.9056434682111629, 0.8479498657602118, 0.8786481136757354, 0.9377095765842569, 0.9394783684776294, 0.8298851677572173, 0.9397020259070666, 0.7682041107041107, 0.8029737146296764, 0.9563291881214825, 0.7838298524438604, 0.8717942467177082, 0.9547655247351365, 0.8565839791365985, 0.904794510380649, 0.9491064686310489, 0.7874451651118173, 0.8478488783142151, 0.9252723425376554, 0.9924579842466997]
done w/ time
All done
