Current date and time 
##### START task 10000 grs #####
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.998 


accs [0.998587570621469]
 precisions [0.9971751412429378]
 recalls [0.9929378531073446]
 f1scores [0.9984435568263887]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.963 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 


accs [0.961864406779661, 0.9783664459161148]
 precisions [0.980225988700565, 0.9841059602649007]
 recalls [0.963276836158192, 0.9845474613686535]
 f1scores [0.9646195144856872, 0.986403913979968]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.961 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.965 


accs [0.96045197740113, 0.9739514348785872, 0.9626497533474278]
 precisions [0.9562146892655368, 0.9805739514348786, 0.9626497533474278]
 recalls [0.96045197740113, 0.9757174392935982, 0.9605355884425651]
 f1scores [0.9678120297992587, 0.9762382159224252, 0.9518450470377576]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.958 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.975 
=> Acc: 0.702 Precision 0.702 Recall 0.702 F1 0.691 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 


accs [0.9562146892655368, 0.97439293598234, 0.7019027484143763, 0.9938775510204082]
 precisions [0.9590395480225988, 0.9708609271523179, 0.7237491190979564, 0.9959183673469387]
 recalls [0.961864406779661, 0.9770419426048566, 0.711768851303735, 0.9979591836734694]
 f1scores [0.9530411248520745, 0.9774086086962461, 0.7001206070187076, 0.9846096929337772]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.970 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.753 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.991 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.969 


accs [0.9491525423728814, 0.9708609271523179, 0.773784355179704, 0.9918367346938776, 0.9704978488014752]
 precisions [0.9449152542372882, 0.9739514348785872, 0.7744890768146582, 0.9734693877551021, 0.9766441303011678]
 recalls [0.963276836158192, 0.9660044150110375, 0.7639182522903453, 0.9857142857142858, 0.9827904118008605]
 f1scores [0.9482072068729177, 0.973481705074413, 0.7848358663741849, 0.9775679031765987, 0.9715365295634555]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.928 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.974 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [0.9689265536723164, 0.9730684326710817, 0.9260042283298098, 0.9734693877551021, 0.9496004917025199, 1.0]
 precisions [0.9661016949152542, 0.9699779249448124, 0.9316420014094433, 0.9673469387755103, 0.9526736324523664, 1.0]
 recalls [0.9576271186440678, 0.9717439293598233, 0.9464411557434813, 0.9775510204081632, 0.9459127228027043, 1.0]
 f1scores [0.9754678042996512, 0.9767954386357051, 0.9351583225963832, 0.9748331707586452, 0.9454321442618585, 1.0]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.928 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.896 
=> Acc: 0.541 Precision 0.541 Recall 0.541 F1 0.539 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.907 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.924 


accs [0.9350282485875706, 0.9050772626931567, 0.5412262156448203, 0.9061224489795918, 0.8973570989551322, 1.0, 0.9238451935081149]
 precisions [0.9378531073446328, 0.9019867549668874, 0.5517970401691332, 0.9081632653061225, 0.8936693300553166, 1.0, 0.9305035372451103]
 recalls [0.9180790960451978, 0.9011037527593819, 0.5503875968992248, 0.9408163265306122, 0.8887523048555623, 1.0, 0.9230129005409904]
 f1scores [0.9113424587022196, 0.8855386240540364, 0.5539221533429546, 0.9425705392556025, 0.8929102674120918, 1.0, 0.9312879940651948]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.895 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.890 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.847 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.896 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.988 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.893 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 


accs [0.9463276836158192, 0.8940397350993378, 0.8879492600422833, 0.8469387755102041, 0.89920098340504, 0.9869565217391304, 0.8963795255930087, 0.966875]
 precisions [0.9477401129943502, 0.9068432671081678, 0.8893587033121917, 0.8673469387755102, 0.89920098340504, 1.0, 0.8809821057012068, 0.971875]
 recalls [0.942090395480226, 0.9006622516556292, 0.8844256518675123, 0.8448979591836735, 0.9035033804548248, 0.991304347826087, 0.8909696213067, 0.975]
 f1scores [0.945860689828695, 0.9106587098567317, 0.8869863833701407, 0.8737541916022428, 0.916879905528744, 0.9918181818181818, 0.8841157837294151, 0.9595610841093404]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.876 
=> Acc: 0.725 Precision 0.725 Recall 0.725 F1 0.724 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.895 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.802 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.995 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.853 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.832 


accs [0.9731638418079096, 0.8803532008830022, 0.7251585623678647, 0.8959183673469387, 0.8088506453595574, 0.9956521739130435, 0.8539325842696629, 0.960625, 0.8665678280207562]
 precisions [0.9675141242937854, 0.8966887417218543, 0.7293868921775899, 0.8612244897959184, 0.8242163491087892, 0.9956521739130435, 0.8805659592176446, 0.96, 0.876945885841364]
 recalls [0.9731638418079096, 0.8869757174392936, 0.7399577167019028, 0.8714285714285714, 0.8254456054087277, 0.991304347826087, 0.8660008322929671, 0.96375, 0.8762045959970348]
 f1scores [0.9702417927393807, 0.8877115368172562, 0.7347479397131766, 0.8657244056026083, 0.8138270237206449, 0.9958604502293824, 0.8787327075897124, 0.969306658417079, 0.8450801445029787]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.955 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.877 
=> Acc: 0.720 Precision 0.720 Recall 0.720 F1 0.719 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.888 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.823 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.861 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.947 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.809 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 


accs [0.9562146892655368, 0.8834437086092716, 0.7195207892882312, 0.8857142857142857, 0.8272894898586355, 0.9782608695652174, 0.8635039533915938, 0.9475, 0.8495181616011861, 0.9910569105691057]
 precisions [0.9548022598870056, 0.8980132450331125, 0.7082452431289641, 0.8714285714285714, 0.8254456054087277, 0.9608695652173913, 0.8651685393258427, 0.9425, 0.843587842846553, 0.9926829268292683]
 recalls [0.9449152542372882, 0.8949227373068432, 0.7075405214940098, 0.8571428571428571, 0.8334357713583282, 0.9739130434782609, 0.856013316687474, 0.938125, 0.8495181616011861, 0.9934959349593496]
 f1scores [0.9513029353742599, 0.8904922538365696, 0.681476913712806, 0.885782232765752, 0.8164006371273105, 0.9598471323557234, 0.8621788258886506, 0.9391167066620186, 0.8092640463999059, 0.9952088476350351]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.758 Precision 0.758 Recall 0.758 F1 0.696 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.912 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.908 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.803 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.901 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.733 Precision 0.733 Recall 0.733 F1 0.695 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.917 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.793 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.940 


accs [0.7584745762711864, 0.9103752759381899, 0.9090909090909091, 0.8183673469387756, 0.901659496004917, 0.991304347826087, 0.7328339575530587, 0.915, 0.8391401037805782, 0.9772357723577236, 0.9439775910364145]
 precisions [0.7556497175141242, 0.9200883002207505, 0.9112050739957717, 0.7755102040816326, 0.8826060233558697, 1.0, 0.7290886392009988, 0.91125, 0.8309859154929577, 0.975609756097561, 0.9514472455648926]
 recalls [0.7443502824858758, 0.9112582781456954, 0.9182522903453136, 0.8122448979591836, 0.8801475107559926, 0.9869565217391304, 0.7428214731585518, 0.903125, 0.8235730170496665, 0.9626016260162602, 0.9234360410831]
 f1scores [0.6943486244506187, 0.9140160152593371, 0.8807249876674375, 0.753137792926459, 0.8815602597501242, 1.0, 0.707641921125233, 0.917225058646325, 0.7919220298746469, 0.9737355176144717, 0.9408302206885917]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.938 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.886 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.895 
=> Acc: 0.788 Precision 0.788 Recall 0.788 F1 0.788 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.845 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.781 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.892 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.793 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.846 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 


accs [0.942090395480226, 0.8860927152317881, 0.897815362931642, 0.7877551020408163, 0.8457283343577136, 0.9782608695652174, 0.795672076570953, 0.893125, 0.8302446256486287, 0.9796747967479674, 0.8664799253034547, 0.9656203288490284]
 precisions [0.9364406779661016, 0.8865342163355409, 0.916138125440451, 0.7836734693877551, 0.8506453595574678, 0.9608695652173913, 0.7969205160216396, 0.8875, 0.8413639733135656, 0.9861788617886179, 0.9019607843137255, 0.9506726457399103]
 recalls [0.9194915254237288, 0.8874172185430463, 0.8957011980267794, 0.810204081632653, 0.8488014751075599, 0.9521739130434783, 0.7969205160216396, 0.8925, 0.8428465530022239, 0.9772357723577236, 0.8646125116713352, 0.9611360239162929]
 f1scores [0.9393730662152528, 0.8895365865205799, 0.898961688494729, 0.7742783377636426, 0.8356176401731114, 0.9569816949667025, 0.7835999083430291, 0.8950564185844223, 0.802980258792366, 0.9827431262233522, 0.8276319404534845, 0.9578672804521121]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.682 Precision 0.682 Recall 0.682 F1 0.619 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.877 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.868 
=> Acc: 0.714 Precision 0.714 Recall 0.714 F1 0.701 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.864 
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.777 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.891 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.792 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.962 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.863 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.920 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.843 


accs [0.6822033898305084, 0.8763796909492274, 0.8710359408033826, 0.7142857142857143, 0.8666256914566687, 0.9956521739130435, 0.7906783187682064, 0.89, 0.8257968865826538, 0.9626016260162602, 0.880485527544351, 0.9207772795216741, 0.8411910669975186]
 precisions [0.7090395480225988, 0.8887417218543047, 0.8766737138830162, 0.746938775510204, 0.8623232944068838, 0.9956521739130435, 0.7856845609654598, 0.885, 0.843587842846553, 0.9642276422764228, 0.8832866479925303, 0.9192825112107623, 0.8362282878411911]
 recalls [0.6949152542372882, 0.8856512141280353, 0.857646229739253, 0.7489795918367347, 0.8574062692071297, 0.9739130434782609, 0.7819392426133999, 0.890625, 0.8369162342475908, 0.9666666666666667, 0.8720821661998133, 0.9095665171898356, 0.8660049627791563]
 f1scores [0.6313664620553165, 0.897516390872347, 0.8470623866970296, 0.7641175268255148, 0.8634608263490623, 0.9869160372677657, 0.7690534080985202, 0.8926346695781957, 0.8009525375056, 0.9599561721132623, 0.8593744210193972, 0.923220503354818, 0.8096517264248357]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.709 Precision 0.709 Recall 0.709 F1 0.627 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.906 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.899 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.777 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.898 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.797 Precision 0.797 Recall 0.797 F1 0.784 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.922 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.802 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.824 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.727 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.983 


accs [0.7090395480225988, 0.904635761589404, 0.8992248062015504, 0.7816326530612245, 0.8998156115550092, 0.9869565217391304, 0.7965043695380774, 0.92125, 0.8480355819125278, 0.9634146341463414, 0.8356676003734828, 0.9252615844544095, 0.7468982630272953, 0.9838056680161943]
 precisions [0.7146892655367232, 0.9121412803532009, 0.8992248062015504, 0.7244897959183674, 0.8961278426551936, 0.9956521739130435, 0.7811069496462755, 0.92875, 0.8576723498888065, 0.9650406504065041, 0.8412698412698413, 0.9245142002989537, 0.7444168734491315, 0.9959514170040485]
 recalls [0.6751412429378532, 0.8984547461368654, 0.8985200845665962, 0.7795918367346939, 0.9004302397049785, 0.9956521739130435, 0.7906783187682064, 0.931875, 0.8369162342475908, 0.9634146341463414, 0.8431372549019608, 0.9162929745889388, 0.749379652605459, 0.9838056680161943]
 f1scores [0.6505406407938054, 0.9054999206874591, 0.9058002718238919, 0.7436086457017266, 0.8839976476424296, 0.9837001127323708, 0.7906170503711104, 0.9347253323473999, 0.8058881171822645, 0.9614660147371066, 0.8437218855002578, 0.9131737266825288, 0.6845117582321103, 1.0]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.873 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.887 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.888 
=> Acc: 0.710 Precision 0.710 Recall 0.710 F1 0.714 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.830 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.907 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.787 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.966 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.865 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.916 
=> Acc: 0.727 Precision 0.727 Recall 0.727 F1 0.734 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.941 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.831 


accs [0.882768361581921, 0.8887417218543047, 0.8872445384073291, 0.710204081632653, 0.8813767670559312, 0.9869565217391304, 0.8381190178942988, 0.9075, 0.838398813936249, 0.9658536585365853, 0.8739495798319328, 0.9155455904334828, 0.7270471464019851, 0.9433198380566802, 0.8331719909648274]
 precisions [0.8884180790960452, 0.8878587196467991, 0.8752642706131079, 0.7183673469387755, 0.8850645359557467, 0.9608695652173913, 0.8248023304203079, 0.89125, 0.8265381764269829, 0.9642276422764228, 0.8664799253034547, 0.8938714499252616, 0.6898263027295285, 0.9595141700404858, 0.8431752178121975]
 recalls [0.8983050847457628, 0.8772626931567329, 0.86892177589852, 0.7081632653061225, 0.8998156115550092, 0.9695652173913043, 0.8493549729504786, 0.899375, 0.8191252779836916, 0.9691056910569106, 0.869281045751634, 0.9095665171898356, 0.7295285359801489, 0.97165991902834, 0.8422071636011617]
 f1scores [0.8800534850933779, 0.8977759484572673, 0.8704860395404399, 0.7240033548115804, 0.9052217278803557, 0.9600981005285167, 0.8291416971882419, 0.9009456335108611, 0.7730674421441552, 0.9644712487530308, 0.8596568578210434, 0.8937498100407542, 0.7185942053895854, 0.9343660195735616, 0.8443740344413175]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.832 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.875 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.885 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.762 
=> Acc: 0.855 Precision 0.855 Recall 0.855 F1 0.848 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.960 
=> Acc: 0.806 Precision 0.806 Recall 0.806 F1 0.802 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.878 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.827 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.791 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.912 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.804 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.927 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.854 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.919 


accs [0.8531073446327684, 0.8781456953642384, 0.8865398167723749, 0.7857142857142857, 0.8549477566072526, 0.9608695652173913, 0.8064918851435705, 0.87875, 0.8584136397331357, 0.9650406504065041, 0.8048552754435108, 0.9110612855007474, 0.8114143920595533, 0.9230769230769231, 0.8544691836076154, 0.91701244813278]
 precisions [0.8601694915254238, 0.8830022075055187, 0.8935870331219169, 0.753061224489796, 0.8635525507068224, 0.9869565217391304, 0.8135663753641281, 0.865625, 0.8391401037805782, 0.9626016260162602, 0.8338001867413632, 0.9312406576980568, 0.7841191066997518, 0.9271255060728745, 0.856082607292675, 0.9201244813278008]
 recalls [0.8785310734463276, 0.8701986754966887, 0.8851303735024665, 0.7816326530612245, 0.8672403196066379, 0.9695652173913043, 0.8160632542655014, 0.873125, 0.8495181616011861, 0.9682926829268292, 0.8272642390289449, 0.9162929745889388, 0.8089330024813896, 0.9190283400809717, 0.867053888351081, 0.9144190871369294]
 f1scores [0.8525837509066679, 0.8702598337013461, 0.8816257276998757, 0.7681425689104, 0.8688419691781771, 0.9655425604479954, 0.8141399031257819, 0.8695749666444155, 0.798781026981205, 0.9567918067615393, 0.8069626021114493, 0.9102043770327608, 0.7827927578560243, 0.909209285728225, 0.8552355846176374, 0.917426193457063]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.869 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.896 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.869 
=> Acc: 0.718 Precision 0.718 Recall 0.718 F1 0.646 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.832 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.950 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.784 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.834 
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.794 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.835 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.923 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.835 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.927 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.864 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.886 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.973 


accs [0.8785310734463276, 0.897130242825607, 0.8724453840732911, 0.7183673469387755, 0.8432698217578365, 0.9478260869565217, 0.7890137328339576, 0.8375, 0.83765752409192, 0.9601626016260163, 0.8431372549019608, 0.9237668161434978, 0.8362282878411911, 0.9271255060728745, 0.8651177799290094, 0.8890041493775933, 0.9723756906077348]
 precisions [0.8870056497175142, 0.9108167770419426, 0.8773784355179705, 0.6755102040816326, 0.8561770129071912, 0.9826086956521739, 0.7885975863503953, 0.8375, 0.8472942920681986, 0.9560975609756097, 0.834733893557423, 0.9282511210762332, 0.8337468982630273, 0.9230769230769231, 0.8493062278154243, 0.8936721991701245, 0.9861878453038674]
 recalls [0.8940677966101694, 0.8940397350993378, 0.8872445384073291, 0.7163265306122449, 0.8617086662569146, 0.991304347826087, 0.8048272992093217, 0.848125, 0.8265381764269829, 0.9560975609756097, 0.8300653594771242, 0.9230194319880418, 0.8064516129032258, 0.9230769230769231, 0.8525330751855438, 0.8952282157676349, 0.9723756906077348]
 f1scores [0.8909689766991805, 0.9162985965019607, 0.8690114888602685, 0.6422034230980607, 0.8602215358069578, 0.9721153846153847, 0.8034901661561472, 0.823194063334275, 0.8013688362817293, 0.9642265612279923, 0.8123160742990487, 0.9387028259626853, 0.8212276866888752, 0.9167224354497832, 0.8645705812311718, 0.8890537405550456, 0.9805419861406788]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.887 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.907 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.845 
=> Acc: 0.733 Precision 0.733 Recall 0.733 F1 0.713 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.900 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.814 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.870 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.807 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.947 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.843 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.931 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.802 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.913 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.836 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.907 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.927 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.834 


accs [0.8983050847457628, 0.906401766004415, 0.8442565186751233, 0.7326530612244898, 0.9010448678549478, 0.9869565217391304, 0.8156471077819393, 0.87, 0.8406226834692365, 0.948780487804878, 0.8496732026143791, 0.9312406576980568, 0.8039702233250621, 0.9190283400809717, 0.8428525330751856, 0.9107883817427386, 0.925414364640884, 0.8391003460207612]
 precisions [0.9251412429378532, 0.9222958057395143, 0.8597603946441156, 0.7163265306122449, 0.860479409956976, 1.0, 0.7994173949230129, 0.87, 0.83765752409192, 0.9585365853658536, 0.8487394957983193, 0.9439461883408071, 0.7890818858560794, 0.9352226720647774, 0.856727976766699, 0.9061203319502075, 0.9116022099447514, 0.8371230845279288]
 recalls [0.9081920903954802, 0.932008830022075, 0.842847075405215, 0.7653061224489796, 0.8826060233558697, 0.9869565217391304, 0.8168955472326259, 0.8575, 0.8569310600444774, 0.943089430894309, 0.8702147525676938, 0.9230194319880418, 0.8014888337468983, 0.9068825910931174, 0.8647950951919974, 0.908195020746888, 0.930939226519337, 0.8445378151260504]
 f1scores [0.9178916688216445, 0.9123077991216739, 0.8460402079600076, 0.7450627777285839, 0.8962998478086188, 0.9769546243230455, 0.8118086069504405, 0.8689545364646494, 0.8086060936445849, 0.9403668657163546, 0.8337415455407482, 0.9246591908432624, 0.7685113923100847, 0.9205437146585472, 0.8584480248378619, 0.8873097723708969, 0.925840823401799, 0.8224474947185069]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.507 Precision 0.507 Recall 0.507 F1 0.442 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.897 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.871 
=> Acc: 0.714 Precision 0.714 Recall 0.714 F1 0.710 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.862 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.830 
=> Acc: 0.804 Precision 0.804 Recall 0.804 F1 0.800 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.773 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.952 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.845 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.732 Precision 0.732 Recall 0.732 F1 0.730 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.920 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.806 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.881 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.885 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.808 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.861 


accs [0.5070621468926554, 0.8997792494481236, 0.8731501057082452, 0.7142857142857143, 0.8721573448063922, 0.9869565217391304, 0.8335414065751144, 0.804375, 0.8191252779836916, 0.9520325203252032, 0.8646125116713352, 0.9372197309417041, 0.7320099255583127, 0.9190283400809717, 0.803162310422717, 0.8869294605809128, 0.8895027624309392, 0.810182896688087, 0.8678451178451179]
 precisions [0.4985875706214689, 0.8984547461368654, 0.8773784355179705, 0.7244897959183674, 0.8961278426551936, 0.991304347826087, 0.8214731585518102, 0.821875, 0.821349147516679, 0.9471544715447154, 0.834733893557423, 0.92152466367713, 0.7270471464019851, 0.9230769230769231, 0.7841239109390126, 0.8630705394190872, 0.8591160220994475, 0.8044982698961938, 0.8737373737373737]
 recalls [0.4971751412429379, 0.895364238410596, 0.8653981677237491, 0.7163265306122449, 0.8942839582052858, 0.991304347826087, 0.826883062838119, 0.791875, 0.8146775389177169, 0.9479674796747968, 0.8646125116713352, 0.922272047832586, 0.7667493796526055, 0.9352226720647774, 0.7860600193610843, 0.866701244813278, 0.8480662983425414, 0.80548690064261, 0.8737373737373737]
 f1scores [0.4421538801454842, 0.8931499554236442, 0.8640382338964118, 0.7489016545032465, 0.8657302298765932, 1.0, 0.8225575085839436, 0.7870443647130301, 0.7877225422844394, 0.9606197227518374, 0.7957139719905678, 0.9165170412305524, 0.7211533601075834, 0.9374579488312096, 0.7947055741496485, 0.8752358987923664, 0.8849409068183032, 0.8003626183655939, 0.8707547868576458]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.617 Precision 0.617 Recall 0.617 F1 0.571 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.890 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.914 
=> Acc: 0.722 Precision 0.722 Recall 0.722 F1 0.701 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.878 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.936 
=> Acc: 0.740 Precision 0.740 Recall 0.740 F1 0.734 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.815 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.802 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.935 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.816 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.909 
=> Acc: 0.722 Precision 0.722 Recall 0.722 F1 0.724 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.882 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.771 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.868 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.906 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.770 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.846 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.923 


accs [0.617231638418079, 0.8891832229580574, 0.9140239605355884, 0.7224489795918367, 0.883220651505839, 0.9347826086956522, 0.7399084477736163, 0.811875, 0.8257968865826538, 0.9357723577235773, 0.8263305322128851, 0.9080717488789237, 0.7220843672456576, 0.8947368421052632, 0.7760567925137141, 0.8734439834024896, 0.9005524861878453, 0.7738507167572911, 0.8476430976430976, 0.9222365038560412]
 precisions [0.577683615819209, 0.893598233995585, 0.9041578576462297, 0.7163265306122449, 0.8973570989551322, 0.9565217391304348, 0.7145235122763213, 0.84, 0.843587842846553, 0.9447154471544715, 0.8394024276377218, 0.9043348281016442, 0.7220843672456576, 0.8866396761133604, 0.7676669893514037, 0.8625518672199171, 0.8480662983425414, 0.7723677706376668, 0.82996632996633, 0.922879177377892]
 recalls [0.6002824858757062, 0.8874172185430463, 0.9119097956307258, 0.7326530612244898, 0.9010448678549478, 0.9565217391304348, 0.7369954223886808, 0.823125, 0.8554484803558191, 0.9422764227642276, 0.842203548085901, 0.906576980568012, 0.7518610421836228, 0.9149797570850202, 0.7705711519845111, 0.8609958506224067, 0.9033149171270718, 0.7763222936233317, 0.8569023569023569, 0.9177377892030848]
 f1scores [0.5140329743238136, 0.8848009966756637, 0.9110502203258773, 0.7015442455425905, 0.9039288160817364, 0.9564712889362962, 0.7345919190652009, 0.830821165693419, 0.8221746117235964, 0.9462921496765319, 0.8600935979325733, 0.9057315679620895, 0.7491740747262494, 0.8706344194060452, 0.7668602983177564, 0.8489474551127723, 0.9064490188481186, 0.7848989014176365, 0.8235110398883461, 0.9275279355830159]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.971 


accs [0.9723346828609987]
 precisions [0.97165991902834]
 recalls [0.9723346828609987]
 f1scores [0.9699250904712743]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.955 
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 


accs [0.9541160593792173, 0.9986123959296948]
 precisions [0.9568151147098516, 0.9949121184088807]
 recalls [0.9642375168690959, 0.9972247918593895]
 f1scores [0.963330571825197, 0.9981598420510727]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.948 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 


accs [0.9480431848852902, 0.9944495837187789, 0.9809119830328739]
 precisions [0.9520917678812416, 0.9958371877890841, 0.9819724284199364]
 recalls [0.9507422402159245, 0.9967622571692877, 0.9893955461293743]
 f1scores [0.9508756708292714, 0.9964081317550108, 0.988121958012939]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.963 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.964 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.986 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.985 


accs [0.9622132253711201, 0.9648473635522664, 0.985153764581124, 0.9856373429084381]
 precisions [0.9520917678812416, 0.973172987974098, 0.9893955461293743, 0.9820466786355476]
 recalls [0.956140350877193, 0.96577243293247, 0.9936373276776246, 0.9838420107719928]
 f1scores [0.9601729658014966, 0.96787272719131, 0.9887131953501104, 0.9826106594399278]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.760 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.899 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.972 


accs [0.9790823211875843, 0.8052728954671601, 0.968186638388123, 0.9030520646319569, 0.9721969006381039]
 precisions [0.9817813765182186, 0.7987974098057354, 0.9787910922587487, 0.9245960502692998, 0.9731084776663628]
 recalls [0.9838056680161943, 0.8098982423681776, 0.9692470837751855, 0.9120287253141831, 0.9799453053783045]
 f1scores [0.9794536786784601, 0.763387171405642, 0.9665507676948074, 0.918525778644385, 0.9739783460283837]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.957 
=> Acc: 0.805 Precision 0.805 Recall 0.805 F1 0.746 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.956 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.938 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.784 Precision 0.784 Recall 0.784 F1 0.728 


accs [0.9568151147098516, 0.8052728954671601, 0.9544008483563097, 0.9443447037701975, 0.968094804010939, 0.7840593141797961]
 precisions [0.9547908232118758, 0.8094357076780758, 0.9395546129374337, 0.947935368043088, 0.9685505925250684, 0.7961075069508804]
 recalls [0.9581646423751687, 0.7978723404255319, 0.9374337221633086, 0.9281867145421903, 0.968094804010939, 0.7970342910101946]
 f1scores [0.9591207555304109, 0.7434714123724904, 0.9531065097684552, 0.957626137902207, 0.963608079475194, 0.7267909712862629]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.946 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.730 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.935 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.734 Precision 0.734 Recall 0.734 F1 0.705 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.944 


accs [0.9460188933873145, 0.7858464384828863, 0.975609756097561, 0.9353680430879713, 0.9608021877848678, 0.7340129749768304, 0.9483648881239243]
 precisions [0.9473684210526315, 0.7858464384828863, 0.9787910922587487, 0.9551166965888689, 0.9594348222424794, 0.7312326227988879, 0.955249569707401]
 recalls [0.9446693657219973, 0.8038852913968547, 0.9872746553552492, 0.9389587073608617, 0.971285323609845, 0.7303058387395737, 0.9569707401032702]
 f1scores [0.9588805354788137, 0.7382477298092822, 0.9695632787333693, 0.9470163869394405, 0.9639795752041767, 0.7150578972163724, 0.9491978298178216]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.920 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.930 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.924 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.942 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.840 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.797 


accs [0.9230769230769231, 0.9579093432007401, 0.9289501590668081, 0.926391382405745, 0.9443938012762079, 0.8443002780352178, 0.9707401032702238, 0.8404040404040404]
 precisions [0.9311740890688259, 0.9579093432007401, 0.9448568398727466, 0.9425493716337523, 0.9425706472196901, 0.8257645968489342, 0.963855421686747, 0.8235690235690236]
 recalls [0.9325236167341431, 0.9518963922294172, 0.9278897136797455, 0.9371633752244165, 0.9384685505925251, 0.8507877664504171, 0.9655765920826161, 0.826936026936027]
 f1scores [0.9349246142736514, 0.9497344091178442, 0.9384294434519465, 0.9193472254306435, 0.9452509286637779, 0.8296006139397427, 0.9723305859734079, 0.7714076281348348]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.932 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.940 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.917 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.896 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.976 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.834 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.689 


accs [0.9426450742240216, 0.9680851063829787, 0.9310710498409331, 0.9425493716337523, 0.9243391066545124, 0.8906394810009268, 0.9759036144578314, 0.8511784511784511, 0.7290732436472347]
 precisions [0.9460188933873145, 0.9699352451433858, 0.9247083775185578, 0.9245960502692998, 0.9243391066545124, 0.891566265060241, 0.9827882960413081, 0.8491582491582491, 0.7238415545590433]
 recalls [0.946693657219973, 0.9722479185938946, 0.9215270413573701, 0.9389587073608617, 0.9175022789425706, 0.8841519925857275, 0.9759036144578314, 0.8518518518518519, 0.7357997010463379]
 f1scores [0.9531496583367993, 0.9705289827422628, 0.928366023884819, 0.953368445523154, 0.9283668237450906, 0.8856733242973529, 0.9949281182853392, 0.8489871591342737, 0.6840048421059673]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.935 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.887 Precision 0.887 Recall 0.887 F1 0.887 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.909 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.926 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.878 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.963 
=> Acc: 0.836 Precision 0.836 Recall 0.836 F1 0.819 
=> Acc: 0.743 Precision 0.743 Recall 0.743 F1 0.705 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 


accs [0.9352226720647774, 0.9666975023126735, 0.8865323435843054, 0.9066427289048474, 0.9284412032816773, 0.8767377201112141, 0.963855421686747, 0.8356902356902357, 0.7432735426008968, 0.966802860061287]
 precisions [0.9487179487179487, 0.9569842738205365, 0.8939554612937434, 0.9030520646319569, 0.9238833181403828, 0.845227062094532, 0.9518072289156626, 0.8424242424242424, 0.7544843049327354, 0.9683350357507661]
 recalls [0.9520917678812416, 0.96577243293247, 0.9066808059384942, 0.9138240574506283, 0.9238833181403828, 0.865616311399444, 0.9655765920826161, 0.8262626262626263, 0.7346786248131539, 0.9673135852911133]
 f1scores [0.9527748660417285, 0.9616149586149063, 0.9049585053352563, 0.9023830297084248, 0.9275140230288444, 0.8585884457566012, 0.9520501598377464, 0.8161568062752276, 0.7040804922183596, 0.9731805354573554]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.887 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.947 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.863 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.921 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.918 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.860 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.943 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.796 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.712 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.907 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 


accs [0.8927125506072875, 0.9481961147086031, 0.8695652173913043, 0.9210053859964094, 0.9238833181403828, 0.871177015755329, 0.9414802065404475, 0.8101010101010101, 0.7485052316890882, 0.9106230847803881, 0.9767002518891688]
 precisions [0.8832658569500674, 0.9551341350601296, 0.8769883351007424, 0.9174147217235189, 0.9120328167730173, 0.8544949026876738, 0.9466437177280551, 0.806060606060606, 0.7219730941704036, 0.8958120531154239, 0.9767002518891688]
 recalls [0.8927125506072875, 0.9417206290471786, 0.8621420996818664, 0.9120287253141831, 0.9211485870556062, 0.8563484708063022, 0.9328743545611016, 0.7993265993265993, 0.7365470852017937, 0.8983656792645557, 0.9798488664987406]
 f1scores [0.8866730572754914, 0.9411303868147085, 0.8753630516038345, 0.91670408790501, 0.923649781332878, 0.8534944193813356, 0.9326368400498698, 0.8008913631256951, 0.707842074779211, 0.8920280819861146, 0.9812561999934616]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.874 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.931 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.925 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.876 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.920 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.886 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.936 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.779 
=> Acc: 0.713 Precision 0.713 Recall 0.713 F1 0.666 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.894 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.870 


accs [0.8785425101214575, 0.9338575393154487, 0.9257688229056203, 0.8797127468581688, 0.9266180492251596, 0.8850787766450418, 0.9345955249569707, 0.7892255892255893, 0.7133781763826607, 0.8942798774259448, 0.9741813602015114, 0.8720424915499758]
 precisions [0.8670715249662618, 0.9421831637372803, 0.9225874867444327, 0.881508078994614, 0.9156791248860529, 0.8906394810009268, 0.9397590361445783, 0.764983164983165, 0.703662182361734, 0.8912155260469867, 0.9729219143576826, 0.8850796716562047]
 recalls [0.8812415654520918, 0.9329324699352451, 0.9257688229056203, 0.8904847396768402, 0.922060164083865, 0.8999073215940686, 0.9311531841652324, 0.7777777777777778, 0.7059043348281017, 0.9014300306435138, 0.966624685138539, 0.8623853211009175]
 f1scores [0.8690072114745006, 0.9327262445924358, 0.934170586168244, 0.8843647147865882, 0.9054034320127237, 0.9037515153969876, 0.9388463280213297, 0.7887659495876163, 0.6701946224180038, 0.897375518270221, 0.9697668311471457, 0.8701859965143625]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.916 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.929 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.856 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.899 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.861 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.741 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.888 
=> Acc: 0.624 Precision 0.624 Recall 0.624 F1 0.600 
=> Acc: 0.695 Precision 0.695 Recall 0.695 F1 0.626 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.823 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.958 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.809 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.958 


accs [0.9176788124156545, 0.9306197964847364, 0.8621420996818664, 0.9066427289048474, 0.8723792160437557, 0.7488415199258572, 0.8898450946643718, 0.6242424242424243, 0.695067264573991, 0.830949948927477, 0.9596977329974811, 0.8150651859005311, 0.9587955625990491]
 precisions [0.918353576248313, 0.9343200740055504, 0.8547189819724285, 0.8725314183123878, 0.8773928896991796, 0.768303985171455, 0.8760757314974182, 0.6424242424242425, 0.6842301943198804, 0.841164453524004, 0.9596977329974811, 0.8136166103331723, 0.9587955625990491]
 recalls [0.9197031039136302, 0.9380203515263644, 0.8663838812301167, 0.9012567324955116, 0.873746581586144, 0.772937905468026, 0.882960413080895, 0.6080808080808081, 0.6853512705530643, 0.8462717058222676, 0.9603274559193955, 0.8169966199903428, 0.9746434231378764]
 f1scores [0.9238347230976176, 0.926865067084184, 0.8607040659947403, 0.8982129539287864, 0.8670527379322974, 0.7494683146212942, 0.8860488539695254, 0.6120022834711509, 0.6268490451463421, 0.8338353397942934, 0.9577942118650682, 0.8095158580237662, 0.9724343188181402]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.904 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.934 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.906 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.889 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.876 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.830 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.912 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.773 
=> Acc: 0.700 Precision 0.700 Recall 0.700 F1 0.649 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.883 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.955 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.812 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.845 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.875 


accs [0.9048582995951417, 0.9375578168362627, 0.9088016967126193, 0.8940754039497307, 0.8910665451230629, 0.8489341983317887, 0.9139414802065404, 0.7946127946127947, 0.6995515695067265, 0.8861082737487231, 0.9540302267002518, 0.8184451955577016, 0.8510301109350238, 0.8773255813953489]
 precisions [0.9008097165991903, 0.9343200740055504, 0.9172852598091198, 0.8653500897666068, 0.8673655423883319, 0.8322520852641334, 0.9087779690189329, 0.8101010101010101, 0.6999252615844545, 0.8947906026557712, 0.9508816120906801, 0.8145823273780782, 0.8510301109350238, 0.8848837209302326]
 recalls [0.9041835357624831, 0.9468085106382979, 0.9183457051961824, 0.8886894075403949, 0.8846855059252506, 0.8331788693234476, 0.9036144578313253, 0.7905723905723906, 0.726831091180867, 0.8973442288049029, 0.9559193954659949, 0.8261709319169483, 0.8557844690966719, 0.8784883720930232]
 f1scores [0.8996433169072097, 0.9299390043161155, 0.9066627937749466, 0.8659814446883567, 0.8625994839071442, 0.8353489615367659, 0.8934927740612242, 0.7715762208708691, 0.6510569379842346, 0.8909044572547273, 0.9529011009283215, 0.8213591889084393, 0.8436439617830788, 0.886896007514155]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.912 
=> Acc: 0.952 Precision 0.952 Recall 0.952 F1 0.950 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.928 
=> Acc: 0.648 Precision 0.648 Recall 0.648 F1 0.626 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.851 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.826 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.744 
=> Acc: 0.719 Precision 0.719 Recall 0.719 F1 0.685 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.926 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.782 Precision 0.782 Recall 0.782 F1 0.771 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.797 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.873 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.965 


accs [0.9136302294197031, 0.9518963922294172, 0.926829268292683, 0.6481149012567325, 0.8641750227894257, 0.8405931417979611, 0.9328743545611016, 0.7663299663299663, 0.718609865470852, 0.9295199182839632, 0.9534005037783375, 0.7817479478512795, 0.8114104595879557, 0.8813953488372093, 0.9627329192546584]
 precisions [0.9149797570850202, 0.9352451433857539, 0.9416755037115588, 0.644524236983842, 0.8728350045578851, 0.8368860055607044, 0.9225473321858864, 0.7764309764309765, 0.7365470852017937, 0.940755873340143, 0.9527707808564232, 0.785610816030903, 0.8526148969889065, 0.8860465116279069, 0.9596273291925466]
 recalls [0.9041835357624831, 0.9426456984273821, 0.9257688229056203, 0.6283662477558348, 0.8646308113035551, 0.830398517145505, 0.9053356282271945, 0.773063973063973, 0.7257100149476831, 0.924923391215526, 0.9534005037783375, 0.7769193626267503, 0.8351822503961965, 0.8790697674418605, 0.9565217391304348]
 f1scores [0.9152944637706492, 0.9499358863081427, 0.918457199171457, 0.6398341343046354, 0.8563766522929608, 0.8270576093498982, 0.9018775589423192, 0.7276074772394616, 0.6880875342077537, 0.9308488747900349, 0.9423394982781836, 0.7756360681501169, 0.8217213627512688, 0.8862302249244992, 0.97557763313159]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.892 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.921 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.885 
=> Acc: 0.657 Precision 0.657 Recall 0.657 F1 0.633 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.893 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.763 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.916 
=> Acc: 0.768 Precision 0.768 Recall 0.768 F1 0.759 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.679 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.937 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.828 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.809 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.839 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.941 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.963 


accs [0.8947368421052632, 0.9232192414431082, 0.8918345705196182, 0.6570915619389587, 0.9001823154056517, 0.7757182576459685, 0.9156626506024096, 0.7676767676767676, 0.726083707025411, 0.9382022471910112, 0.9534005037783375, 0.8285852245292129, 0.8225039619651348, 0.85, 0.937888198757764, 0.9645390070921985]
 precisions [0.8852901484480432, 0.9264569842738205, 0.8663838812301167, 0.6840215439856373, 0.9120328167730173, 0.7784986098239111, 0.9173838209982789, 0.7723905723905724, 0.7144992526158446, 0.940755873340143, 0.9540302267002518, 0.8266537904394012, 0.8145800316957211, 0.8593023255813953, 0.9409937888198758, 0.958966565349544]
 recalls [0.8792172739541161, 0.9222941720629048, 0.8504772004241782, 0.6804308797127468, 0.9083865086599817, 0.7812789620018535, 0.8984509466437177, 0.7777777777777778, 0.7339312406576981, 0.9244126659856997, 0.9452141057934509, 0.821825205214872, 0.8225039619651348, 0.8523255813953489, 0.9254658385093167, 0.9584599797365755]
 f1scores [0.9030212540371403, 0.9259931894918634, 0.8736331797881401, 0.6254574943570457, 0.907904608150837, 0.7828412594442455, 0.9026112591017152, 0.7593664411306701, 0.6751032986337853, 0.9268788545367037, 0.9491002970434714, 0.8520264725061079, 0.7893834204391241, 0.8476329930980357, 0.951777471745257, 0.9510281826920408]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.905 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.924 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.898 
=> Acc: 0.621 Precision 0.621 Recall 0.621 F1 0.599 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.846 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.857 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.877 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.810 
=> Acc: 0.708 Precision 0.708 Recall 0.708 F1 0.662 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.943 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 
=> Acc: 0.800 Precision 0.800 Recall 0.800 F1 0.791 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.795 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.847 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.899 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.930 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 


accs [0.9082321187584346, 0.92368177613321, 0.9013785790031813, 0.6211849192100538, 0.8623518687329079, 0.8572752548656163, 0.8812392426850258, 0.8195286195286196, 0.7077727952167414, 0.9427987742594485, 0.948992443324937, 0.8000965717044906, 0.8019017432646592, 0.8534883720930233, 0.8944099378881988, 0.9290780141843972, 0.975187265917603]
 precisions [0.9008097165991903, 0.9292321924144311, 0.8960763520678685, 0.6068222621184919, 0.8523245214220602, 0.8591288229842446, 0.8691910499139415, 0.775084175084175, 0.6898355754857997, 0.9412665985699693, 0.9546599496221663, 0.8126508932882666, 0.7939778129952456, 0.8622093023255814, 0.8881987577639752, 0.9336372847011145, 0.9737827715355806]
 recalls [0.8792172739541161, 0.9329324699352451, 0.9109225874867445, 0.6642728904847397, 0.873746581586144, 0.8646895273401297, 0.8864027538726333, 0.7878787878787878, 0.7010463378176383, 0.9290091930541369, 0.9445843828715366, 0.8169966199903428, 0.8288431061806656, 0.8645348837209302, 0.9037267080745341, 0.9295845997973657, 0.974250936329588]
 f1scores [0.8790428349057123, 0.9293682678367945, 0.8789675639098075, 0.6307721124686994, 0.8402488127139233, 0.8707191710520357, 0.8819660632054565, 0.7711175221680933, 0.6567126957513143, 0.9341846957407889, 0.9442752031931583, 0.8033625108381923, 0.7734661828680904, 0.850969318720032, 0.9041672873846609, 0.9361470587718304, 0.9753937507429569]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.877 
=> Acc: 0.911 Precision 0.911 Recall 0.911 F1 0.910 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.913 
=> Acc: 0.664 Precision 0.664 Recall 0.664 F1 0.624 
=> Acc: 0.857 Precision 0.857 Recall 0.857 F1 0.825 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.901 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.857 
=> Acc: 0.776 Precision 0.776 Recall 0.776 F1 0.754 
=> Acc: 0.723 Precision 0.723 Recall 0.723 F1 0.681 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.879 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.979 
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.820 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.809 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.863 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.865 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.934 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.973 


accs [0.8819163292847504, 0.9111933395004626, 0.9162248144220573, 0.6642728904847397, 0.8573381950774841, 0.8999073215940686, 0.8588640275387264, 0.7757575757575758, 0.7227204783258595, 0.8794688457609806, 0.9785894206549118, 0.8271366489618541, 0.8177496038034865, 0.8686046511627907, 0.860248447204969, 0.9336372847011145, 0.9372659176029963, 0.9724137931034482]
 precisions [0.8751686909581646, 0.913968547641073, 0.9172852598091198, 0.6840215439856373, 0.849134001823154, 0.8943466172381835, 0.8623063683304647, 0.7845117845117845, 0.7062780269058296, 0.8855975485188968, 0.9792191435768262, 0.8512795750845003, 0.8320126782884311, 0.8511627906976744, 0.8913043478260869, 0.9316109422492401, 0.9400749063670412, 0.9758620689655172]
 recalls [0.8792172739541161, 0.9250693802035153, 0.9045599151643691, 0.6660682226211849, 0.8354603463992707, 0.8906394810009268, 0.846815834767642, 0.8101010101010101, 0.702914798206278, 0.8825331971399387, 0.9767002518891688, 0.840173829068083, 0.8256735340729001, 0.8546511627906976, 0.8322981366459627, 0.9240121580547113, 0.9424157303370787, 0.993103448275862]
 f1scores [0.8703260296214086, 0.9214907117929101, 0.9017275984514681, 0.6059738679371552, 0.8172674628303879, 0.8914153153029233, 0.8559287007833749, 0.7837473438976754, 0.6603850131851088, 0.8791250150487444, 0.9768928194375871, 0.8396010077704549, 0.8112400531971465, 0.8408237587362303, 0.8883616811610093, 0.9387189822122824, 0.9408415387409821, 0.9675852732052206]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.882 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.923 
=> Acc: 0.723 Precision 0.723 Recall 0.723 F1 0.695 
=> Acc: 0.689 Precision 0.689 Recall 0.689 F1 0.665 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.874 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.877 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.946 
=> Acc: 0.710 Precision 0.710 Recall 0.710 F1 0.700 
=> Acc: 0.747 Precision 0.747 Recall 0.747 F1 0.705 
=> Acc: 0.896 Precision 0.896 Recall 0.896 F1 0.894 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.947 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.835 
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.772 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.845 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.853 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.915 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.917 
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.780 


accs [0.8852901484480432, 0.9213691026827012, 0.7232237539766702, 0.6894075403949731, 0.8792160437556974, 0.8785912882298424, 0.9466437177280551, 0.7104377104377104, 0.7470104633781763, 0.8958120531154239, 0.9477329974811083, 0.8435538387252535, 0.7749603803486529, 0.8488372093023255, 0.8509316770186336, 0.9159067882472138, 0.9391385767790262, 0.9172413793103448, 0.7989864864864865]
 precisions [0.902834008097166, 0.9037927844588344, 0.7200424178154825, 0.6876122082585279, 0.8887876025524157, 0.8860055607043559, 0.9156626506024096, 0.7063973063973064, 0.749626307922272, 0.8810010214504597, 0.9389168765743073, 0.8425881216803477, 0.7622820919175911, 0.8494186046511628, 0.8726708074534162, 0.9219858156028369, 0.9442883895131086, 0.9, 0.8361486486486487]
 recalls [0.8765182186234818, 0.9172062904717854, 0.7327677624602333, 0.703770197486535, 0.8910665451230629, 0.9119555143651529, 0.9139414802065404, 0.6962962962962963, 0.7447683109118086, 0.898876404494382, 0.9452141057934509, 0.840656687590536, 0.7543581616481775, 0.8412790697674418, 0.8975155279503105, 0.9245187436676798, 0.9419475655430711, 0.9379310344827586, 0.8547297297297297]
 f1scores [0.8828023954372334, 0.925144763560121, 0.7070696216736, 0.6389008301356656, 0.8894344192562714, 0.9062978083431604, 0.9274029430052781, 0.6955564420008029, 0.7018383658377783, 0.876750803039625, 0.9566578404670322, 0.836945043585445, 0.7708686390351234, 0.841073879110812, 0.864128182656796, 0.911637790569935, 0.9358607174404122, 0.9190058874686386, 0.8003453511296632]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.827 Precision 0.827 Recall 0.827 F1 0.812 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.909 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.858 
=> Acc: 0.901 Precision 0.901 Recall 0.901 F1 0.900 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.830 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.863 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.886 
=> Acc: 0.597 Precision 0.597 Recall 0.597 F1 0.568 
=> Acc: 0.736 Precision 0.736 Recall 0.736 F1 0.688 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.862 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.943 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.819 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.811 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.854 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.844 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.940 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.937 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.940 
=> Acc: 0.760 Precision 0.760 Recall 0.760 F1 0.739 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 


accs [0.8265856950067476, 0.9084181313598519, 0.8600212089077413, 0.9012567324955116, 0.8486782133090246, 0.8628359592215014, 0.8881239242685026, 0.5966329966329966, 0.7357997010463379, 0.86414708886619, 0.9414357682619647, 0.8338966682761951, 0.8177496038034865, 0.8627906976744186, 0.8478260869565217, 0.9407294832826748, 0.9386704119850188, 0.9413793103448276, 0.7601351351351351, 0.9499527856468366]
 precisions [0.8259109311740891, 0.913968547641073, 0.8833510074231177, 0.8850987432675045, 0.8559708295350957, 0.8758109360518999, 0.8795180722891566, 0.5858585858585859, 0.7286995515695067, 0.8840653728294178, 0.9502518891687658, 0.8411395461129889, 0.8256735340729001, 0.836046511627907, 0.8354037267080745, 0.9376899696048632, 0.9461610486891385, 0.9172413793103448, 0.7702702702702703, 0.9442870632672332]
 recalls [0.8373819163292847, 0.9107308048103607, 0.8854718981972428, 0.8833034111310593, 0.8614402917046491, 0.865616311399444, 0.8846815834767642, 0.6296296296296297, 0.7137518684603886, 0.8733401430030644, 0.9414357682619647, 0.834379526798648, 0.8129952456418383, 0.8447674418604652, 0.860248447204969, 0.9361702127659575, 0.9447565543071161, 0.9448275862068966, 0.7787162162162162, 0.9442870632672332]
 f1scores [0.8075928123747623, 0.9175921809832586, 0.8892341932836867, 0.8653144531730825, 0.8280924741916452, 0.8765715631942855, 0.8796443705693402, 0.55128571277518, 0.6780656156945317, 0.8798242193458691, 0.9421180491130219, 0.8230310993911113, 0.7986031210214936, 0.8299101643673582, 0.8243308833266226, 0.9351998471582377, 0.9410517259660566, 0.9390288324959666, 0.7393048941464105, 0.9398675725498821]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 


accs [1.0]
 precisions [1.0]
 recalls [1.0]
 f1scores [1.0]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 1.000 Precision 1.000 Recall 1.000 F1 1.000 
=> Acc: 0.999 Precision 0.999 Recall 0.999 F1 0.999 


accs [1.0, 0.9991416309012876]
 precisions [1.0, 0.9991416309012876]
 recalls [1.0, 0.9982832618025751]
 f1scores [1.0, 0.9991885279158692]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.988 Precision 0.988 Recall 0.988 F1 0.988 
=> Acc: 0.982 Precision 0.982 Recall 0.982 F1 0.982 


accs [0.9907016060862215, 0.9879828326180258, 0.9815557337610264]
 precisions [0.9957734573119188, 0.984549356223176, 0.9871692060946271]
 recalls [0.9873203719357565, 0.9819742489270387, 0.9887730553327987]
 f1scores [0.9889482863842352, 0.9862819335512876, 0.9854648859193194]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.990 Precision 0.990 Recall 0.990 F1 0.990 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.912 


accs [0.9873203719357565, 0.9896995708154507, 0.9839615076182838, 0.9175506268081003]
 precisions [0.9915469146238377, 0.9879828326180258, 0.9807538091419407, 0.9194792671166827]
 recalls [0.9923922231614539, 0.9854077253218884, 0.9943865276663993, 0.9209257473481196]
 f1scores [0.994148995754417, 0.9931616685625875, 0.9860638685285608, 0.9216191736375373]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.958 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.896 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.972 


accs [0.9602704987320372, 0.9802575107296138, 0.958299919807538, 0.9026036644165863, 0.9728485964104924]
 precisions [0.9459002535925612, 0.9802575107296138, 0.9550922213311949, 0.9050144648023144, 0.9746893695352048]
 recalls [0.9551986475063398, 0.9819742489270387, 0.9591018444266239, 0.90549662487946, 0.9779107225034515]
 f1scores [0.9536870402218213, 0.9811798863836636, 0.961464388734735, 0.8943253512095796, 0.9736968638588792]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.919 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.911 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.954 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.786 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.969 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 


accs [0.9222316145393068, 0.9124463519313305, 0.9534883720930233, 0.7955641272902604, 0.9700874367234238, 0.9839797639123102]
 precisions [0.9061707523245984, 0.9107296137339056, 0.958299919807538, 0.7907425265188043, 0.9737689829728486, 0.9890387858347386]
 recalls [0.9349112426035503, 0.9150214592274678, 0.9486768243785084, 0.7974927675988428, 0.9751495628163829, 0.9881956155143339]
 f1scores [0.9350237474204306, 0.911354268050346, 0.9609216120921606, 0.7748488600645036, 0.972249070460013, 0.9886653258409981]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.695 Precision 0.695 Recall 0.695 F1 0.694 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.856 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.975 
=> Acc: 0.755 Precision 0.755 Recall 0.755 F1 0.739 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.948 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 


accs [0.694843617920541, 0.8626609442060086, 0.9759422614274258, 0.7550626808100289, 0.9498389323515877, 0.9814502529510961, 0.9798994974874372]
 precisions [0.7066779374471682, 0.8515021459227468, 0.9855653568564555, 0.7733847637415622, 0.946617579383341, 0.975548060708263, 0.9798994974874372]
 recalls [0.7472527472527473, 0.8618025751072962, 0.9823576583801122, 0.7685631629701061, 0.9627243442245743, 0.9751264755480608, 0.9798994974874372]
 f1scores [0.7190904006851564, 0.8490692636913841, 0.978257390550078, 0.7292513529252795, 0.9501734446831589, 0.9759919154598362, 0.9731721350761677]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.872 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.849 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.943 
=> Acc: 0.722 Precision 0.722 Recall 0.722 F1 0.696 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.977 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.945 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.909 


accs [0.8740490278951818, 0.8506437768240344, 0.9438652766639936, 0.7222757955641272, 0.9489185457892315, 0.9763912310286678, 0.9472361809045227, 0.9129533678756476]
 precisions [0.8825021132713441, 0.8772532188841202, 0.9470729751403368, 0.7280617164898746, 0.9539806718821905, 0.9721753794266442, 0.9363484087102177, 0.9191709844559586]
 recalls [0.8681318681318682, 0.8575107296137339, 0.9454691259021651, 0.7290260366441659, 0.9516797054763001, 0.9759696458684655, 0.9271356783919598, 0.9077720207253887]
 f1scores [0.8617473433789037, 0.8576876855308173, 0.9455804289983142, 0.7205923192257248, 0.9481699225440025, 0.9727064952995688, 0.9328036638449729, 0.9114743132983454]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.912 
=> Acc: 0.830 Precision 0.830 Recall 0.830 F1 0.827 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.934 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.850 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.927 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.947 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.890 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 


accs [0.9137785291631445, 0.8300429184549356, 0.9342421812349639, 0.8611378977820636, 0.9282098481362172, 0.9620573355817875, 0.9505862646566164, 0.8937823834196891, 0.9833948339483395]
 precisions [0.8985629754860525, 0.8369098712446352, 0.9366479550922213, 0.8596914175506268, 0.9433962264150944, 0.968381112984823, 0.9530988274706867, 0.877720207253886, 0.9760147601476015]
 recalls [0.8884192730346576, 0.8309012875536481, 0.9334402566158782, 0.8649951783992286, 0.9291302346985734, 0.9637436762225969, 0.9489112227805695, 0.8829015544041451, 0.9833948339483395]
 f1scores [0.9203726150202941, 0.8553333389291741, 0.9459416801928926, 0.8420082788216767, 0.925651311620531, 0.9610034658855705, 0.9409169723885116, 0.8894128755667842, 0.9854360445909327]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.744 Precision 0.744 Recall 0.744 F1 0.726 
=> Acc: 0.771 Precision 0.771 Recall 0.771 F1 0.741 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 
=> Acc: 0.731 Precision 0.731 Recall 0.731 F1 0.702 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.975 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.986 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.916 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.873 
=> Acc: 0.825 Precision 0.825 Recall 0.825 F1 0.827 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 


accs [0.7438715131022823, 0.7708154506437769, 0.9775461106655974, 0.7309546769527483, 0.975609756097561, 0.9856661045531198, 0.9179229480737019, 0.8787564766839379, 0.8247232472324724, 0.9804202483285578]
 precisions [0.7616229923922232, 0.769098712446352, 0.9703287890938251, 0.7237222757955641, 0.9746893695352048, 0.9844013490725126, 0.9304857621440537, 0.8715025906735752, 0.8099630996309963, 0.9785100286532952]
 recalls [0.7252747252747253, 0.7733905579399142, 0.9631114675220529, 0.7246865959498554, 0.9783709157846295, 0.9814502529510961, 0.9187604690117253, 0.8699481865284974, 0.8339483394833949, 0.9775549188156638]
 f1scores [0.7032788229936118, 0.736600661983504, 0.9847665074141089, 0.7175733956996133, 0.9719538282747809, 0.982775629764981, 0.907282625349778, 0.864657724548632, 0.833149868869814, 0.9800398349694124]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.733 Precision 0.733 Recall 0.733 F1 0.717 
=> Acc: 0.770 Precision 0.770 Recall 0.770 F1 0.759 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.961 
=> Acc: 0.721 Precision 0.721 Recall 0.721 F1 0.695 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.884 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.882 
=> Acc: 0.815 Precision 0.815 Recall 0.815 F1 0.819 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.942 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.7328825021132713, 0.7699570815450644, 0.9591018444266239, 0.7208293153326905, 0.9733087896916705, 0.9768128161888702, 0.8852596314907872, 0.8891191709844559, 0.8154981549815498, 0.943170964660936, 0.9890350877192983]
 precisions [0.746407438715131, 0.8051502145922746, 0.9478748997594226, 0.7155255544840887, 0.9742291762540267, 0.9827150084317032, 0.8860971524288107, 0.8823834196891192, 0.8154981549815498, 0.9508118433619867, 0.9736842105263158]
 recalls [0.7151310228233305, 0.8042918454935623, 0.9550922213311949, 0.6981677917068466, 0.9687068568798896, 0.9835581787521079, 0.8961474036850922, 0.8896373056994819, 0.8025830258302583, 0.9555873925501432, 0.9868421052631579]
 f1scores [0.72610603653712, 0.7891623090337734, 0.9511294726360087, 0.6922494863711446, 0.9634164858232639, 0.97987334205423, 0.8938442315400124, 0.8756999572855172, 0.812989481130703, 0.9447040293997071, 0.980777809245567]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.785 
=> Acc: 0.676 Precision 0.676 Recall 0.676 F1 0.617 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.952 
=> Acc: 0.732 Precision 0.732 Recall 0.732 F1 0.696 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.896 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.872 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.764 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.957 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.964 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.951 


accs [0.7928994082840237, 0.6755364806866953, 0.9526864474739375, 0.7319189971070396, 0.9788311090658076, 0.9839797639123102, 0.8986599664991625, 0.8756476683937824, 0.8007380073800738, 0.958930276981853, 0.9649122807017544, 0.9503239740820735]
 precisions [0.7971259509721048, 0.6540772532188841, 0.9550922213311949, 0.7377049180327869, 0.980211688909342, 0.9822934232715008, 0.8860971524288107, 0.8673575129533678, 0.7859778597785978, 0.9594078319006686, 0.9802631578947368, 0.9546436285097192]
 recalls [0.8021978021978022, 0.6832618025751073, 0.9542902967121091, 0.7372227579556413, 0.9783709157846295, 0.9818718381112985, 0.9020100502512562, 0.8709844559585492, 0.7822878228782287, 0.9694364851957975, 0.9605263157894737, 0.9481641468682506]
 f1scores [0.8005285693737172, 0.6222710742122204, 0.9581175799896551, 0.7015271255169502, 0.9803260165666717, 0.9862062337593542, 0.8968724384121052, 0.8736394882994418, 0.7736575492739568, 0.9645900481962022, 0.9636636558206522, 0.9503677583751499]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.672 Precision 0.672 Recall 0.672 F1 0.657 
=> Acc: 0.688 Precision 0.688 Recall 0.688 F1 0.648 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.948 
=> Acc: 0.723 Precision 0.723 Recall 0.723 F1 0.678 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.808 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.867 
=> Acc: 0.764 Precision 0.764 Recall 0.764 F1 0.760 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.931 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.975 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.969 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 


accs [0.6720202874049028, 0.688412017167382, 0.95028067361668, 0.7227579556412729, 0.9581224114127934, 0.9831365935919055, 0.8224455611390284, 0.8683937823834197, 0.7638376383763837, 0.9297994269340975, 0.9736842105263158, 0.9676025917926566, 0.9376790830945558]
 precisions [0.6830092983939138, 0.6832618025751073, 0.9695268644747393, 0.7270973963355835, 0.9502991256327658, 0.9822934232715008, 0.8098827470686767, 0.8569948186528498, 0.7859778597785978, 0.9197707736389685, 0.9846491228070176, 0.9654427645788337, 0.9262177650429799]
 recalls [0.6720202874049028, 0.6952789699570815, 0.9631114675220529, 0.7227579556412729, 0.9604233778186838, 0.9776559865092749, 0.8140703517587939, 0.8538860103626943, 0.8044280442804428, 0.9231136580706781, 0.9692982456140351, 0.9654427645788337, 0.9391117478510028]
 f1scores [0.6584119991190066, 0.6368117341375112, 0.9590184887954509, 0.6759901524477663, 0.9546729315406498, 0.9814645988865532, 0.8086776531272719, 0.8573417587442759, 0.7941233966491698, 0.9290015609270481, 0.976696244511108, 0.9784322820037106, 0.9334543838263943]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.838 Precision 0.838 Recall 0.838 F1 0.827 
=> Acc: 0.704 Precision 0.704 Recall 0.704 F1 0.662 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.969 
=> Acc: 0.728 Precision 0.728 Recall 0.728 F1 0.708 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.933 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.893 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.858 
=> Acc: 0.714 Precision 0.714 Recall 0.714 F1 0.686 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.925 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.762 Precision 0.762 Recall 0.762 F1 0.700 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.935 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.937 


accs [0.8377007607776839, 0.703862660944206, 0.9679230152365678, 0.727579556412729, 0.9341923607915325, 0.9725969645868465, 0.8919597989949749, 0.8616580310880829, 0.7140221402214022, 0.9231136580706781, 0.9692982456140351, 0.7624190064794817, 0.9348137535816619, 0.935969868173258]
 precisions [0.8157227387996618, 0.7055793991416309, 0.9679230152365678, 0.7145612343297975, 0.9397146801656696, 0.9704890387858347, 0.8994974874371859, 0.8772020725388601, 0.6808118081180812, 0.9269340974212035, 0.9736842105263158, 0.734341252699784, 0.9247851002865329, 0.9491525423728814]
 recalls [0.8216398985629755, 0.703862660944206, 0.9711307137129109, 0.710221793635487, 0.9438564196962724, 0.968381112984823, 0.9137353433835846, 0.8601036269430051, 0.7084870848708487, 0.9336198662846227, 0.9583333333333334, 0.714902807775378, 0.9183381088825215, 0.9472693032015066]
 f1scores [0.8119233192030102, 0.6411934151410786, 0.9635227464742666, 0.6999737228029144, 0.9381717636034101, 0.9686388650486217, 0.8955099052793152, 0.8669951968159607, 0.7037417778155634, 0.927912294352416, 0.9622380521937448, 0.6755645439239361, 0.9185023211694187, 0.9483707104155306]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.642 Precision 0.642 Recall 0.642 F1 0.615 
=> Acc: 0.729 Precision 0.729 Recall 0.729 F1 0.678 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.940 
=> Acc: 0.706 Precision 0.706 Recall 0.706 F1 0.668 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.957 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.976 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.869 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.877 
=> Acc: 0.777 Precision 0.777 Recall 0.777 F1 0.775 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.939 
=> Acc: 0.961 Precision 0.961 Recall 0.961 F1 0.961 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.950 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.899 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.923 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 


accs [0.6415891800507185, 0.728755364806867, 0.9390537289494787, 0.7058823529411765, 0.9567418315692591, 0.9751264755480608, 0.8676716917922948, 0.8813471502590674, 0.7767527675276753, 0.938872970391595, 0.9605263157894737, 0.9481641468682506, 0.8968481375358166, 0.9190207156308852, 0.9651257096512571]
 precisions [0.6610312764158918, 0.7175965665236052, 0.9470729751403368, 0.6967213114754098, 0.9535204786010124, 0.9637436762225969, 0.8877721943048577, 0.8886010362694301, 0.7767527675276753, 0.940305635148042, 0.9649122807017544, 0.9568034557235421, 0.9126074498567335, 0.9246704331450094, 0.9513381995133819]
 recalls [0.6398985629754861, 0.711587982832618, 0.95028067361668, 0.7044358727097396, 0.9567418315692591, 0.9709106239460371, 0.8701842546063652, 0.8818652849740932, 0.7638376383763837, 0.944603629417383, 0.9671052631578947, 0.9568034557235421, 0.9262177650429799, 0.9209039548022598, 0.9472830494728305]
 f1scores [0.6330737390717385, 0.6954114629890938, 0.9554425647934448, 0.6642045546400775, 0.9541006756305551, 0.9684924829307928, 0.8703189239193817, 0.8709471726247348, 0.7410199991473716, 0.945203444441406, 0.959563424690759, 0.9459413449885214, 0.8967230409555779, 0.9070724005876691, 0.9629126610576554]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.756 Precision 0.756 Recall 0.756 F1 0.757 
=> Acc: 0.724 Precision 0.724 Recall 0.724 F1 0.694 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.696 Precision 0.696 Recall 0.696 F1 0.667 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.962 Precision 0.962 Recall 0.962 F1 0.962 
=> Acc: 0.895 Precision 0.895 Recall 0.895 F1 0.897 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.840 
=> Acc: 0.727 Precision 0.727 Recall 0.727 F1 0.715 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.905 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.959 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.906 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.884 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.911 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.922 


accs [0.7557058326289096, 0.7244635193133048, 0.9631114675220529, 0.6962391513982642, 0.9668660837551771, 0.9624789207419899, 0.8953098827470687, 0.844041450777202, 0.7269372693726938, 0.9087870105062082, 0.9583333333333334, 0.9028077753779697, 0.8846704871060171, 0.943502824858757, 0.9132197891321979, 0.9196581196581196]
 precisions [0.7709213863060017, 0.736480686695279, 0.946271050521251, 0.7251687560270009, 0.9590427979751496, 0.9624789207419899, 0.8944723618090452, 0.8559585492227979, 0.7416974169741697, 0.9102196752626552, 0.9627192982456141, 0.9028077753779697, 0.8861031518624641, 0.9246704331450094, 0.9172749391727494, 0.9358974358974359]
 recalls [0.768385460693153, 0.7184549356223175, 0.9607056936647955, 0.7131147540983607, 0.9687068568798896, 0.9675379426644182, 0.8919597989949749, 0.8398963730569948, 0.7601476014760148, 0.9025787965616046, 0.9451754385964912, 0.9352051835853131, 0.8646131805157593, 0.940677966101695, 0.9091646390916464, 0.9153846153846154]
 f1scores [0.7791508585509656, 0.7065261521499017, 0.9523009373360221, 0.6973119878709624, 0.9643428483006687, 0.9671548074174521, 0.8988324930473682, 0.8379093430761608, 0.7691260535330429, 0.9002512802239873, 0.9730492535278674, 0.9223442823557516, 0.8999721644831485, 0.9280362060657417, 0.9123286152345134, 0.9121445505336034]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.642 Precision 0.642 Recall 0.642 F1 0.610 
=> Acc: 0.697 Precision 0.697 Recall 0.697 F1 0.658 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.957 
=> Acc: 0.677 Precision 0.677 Recall 0.677 F1 0.647 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.982 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.878 
=> Acc: 0.839 Precision 0.839 Recall 0.839 F1 0.829 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.779 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.933 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.878 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.905 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.933 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.916 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.835 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.880 


accs [0.6415891800507185, 0.6969957081545064, 0.9558941459502807, 0.6769527483124397, 0.9668660837551771, 0.9814502529510961, 0.8768844221105527, 0.8393782383419689, 0.7730627306273062, 0.9336198662846227, 0.9649122807017544, 0.8920086393088553, 0.9083094555873925, 0.931261770244821, 0.9172749391727494, 0.8290598290598291, 0.8826907301066448]
 precisions [0.6542688081149619, 0.6901287553648069, 0.9558941459502807, 0.6972034715525555, 0.9668660837551771, 0.9772344013490725, 0.8869346733668342, 0.8606217616580311, 0.8136531365313653, 0.9364851957975168, 0.9320175438596491, 0.8509719222462203, 0.8989971346704871, 0.9340866290018832, 0.902676399026764, 0.8222222222222222, 0.8908941755537325]
 recalls [0.6280642434488588, 0.6746781115879829, 0.9574979951884522, 0.6817743490838959, 0.9696272434422457, 0.978920741989882, 0.8802345058626466, 0.8533678756476684, 0.7896678966789668, 0.9297994269340975, 0.9605263157894737, 0.8682505399568035, 0.8932664756446992, 0.9265536723163842, 0.9083536090835361, 0.8350427350427351, 0.8810500410172273]
 f1scores [0.5956523945763991, 0.6388286989075835, 0.9489418264186866, 0.6644306777019046, 0.9671269603828936, 0.980097257613961, 0.8861572484853205, 0.8382553723422342, 0.7906996156548427, 0.9252175269374471, 0.9662193371881657, 0.8825342144960479, 0.8943948774392855, 0.9255092484065244, 0.9119301001894009, 0.814114661751845, 0.8846651973677536]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.683 Precision 0.683 Recall 0.683 F1 0.651 
=> Acc: 0.683 Precision 0.683 Recall 0.683 F1 0.631 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.769 Precision 0.769 Recall 0.769 F1 0.748 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.859 
=> Acc: 0.803 Precision 0.803 Recall 0.803 F1 0.791 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.777 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.898 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.974 
=> Acc: 0.691 Precision 0.691 Recall 0.691 F1 0.648 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.903 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.892 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.786 
=> Acc: 0.777 Precision 0.777 Recall 0.777 F1 0.748 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.870 


accs [0.6830092983939138, 0.6832618025751073, 0.9374498797113071, 0.7685631629701061, 0.9576622181316152, 0.9810286677908938, 0.8592964824120602, 0.8031088082901554, 0.7730627306273062, 0.897803247373448, 0.9758771929824561, 0.6911447084233261, 0.9032951289398281, 0.891713747645951, 0.9326845093268451, 0.7794871794871795, 0.7768662838392125, 0.8735810113519091]
 precisions [0.6737109044801353, 0.6944206008583691, 0.9326383319967922, 0.7651880424300868, 0.9558214450069029, 0.9780775716694773, 0.8450586264656617, 0.81139896373057, 0.7878228782287823, 0.9044890162368673, 0.9780701754385965, 0.7062634989200864, 0.9312320916905444, 0.8973634651600754, 0.9416058394160584, 0.788034188034188, 0.7793273174733388, 0.8761609907120743]
 recalls [0.6745562130177515, 0.6789699570815451, 0.9366479550922213, 0.7603664416586307, 0.9549010584445468, 0.9873524451939292, 0.8559463986599665, 0.8025906735751296, 0.7712177121771218, 0.9054441260744985, 0.956140350877193, 0.7084233261339092, 0.9140401146131805, 0.9048964218455744, 0.9310624493106245, 0.7769230769230769, 0.7653814602132896, 0.8704850361197111]
 f1scores [0.6516322706648057, 0.6602950738671212, 0.9356481494158528, 0.732897823679415, 0.9522208905558657, 0.9844128852976267, 0.8620949541275017, 0.7905522087672494, 0.8327380367317134, 0.8975217820972979, 0.9781103699266784, 0.6738402005389321, 0.9147823832847036, 0.8965219600916825, 0.9350992901474141, 0.7809296799987854, 0.766312240330904, 0.8900535293568685]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.757 Precision 0.757 Recall 0.757 F1 0.722 
=> Acc: 0.561 Precision 0.561 Recall 0.561 F1 0.541 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.874 
=> Acc: 0.744 Precision 0.744 Recall 0.744 F1 0.716 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.917 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.890 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.852 
=> Acc: 0.745 Precision 0.745 Recall 0.745 F1 0.751 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.886 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.947 
=> Acc: 0.676 Precision 0.676 Recall 0.676 F1 0.638 
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.888 
=> Acc: 0.957 Precision 0.957 Recall 0.957 F1 0.958 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.906 
=> Acc: 0.748 Precision 0.748 Recall 0.748 F1 0.751 
=> Acc: 0.807 Precision 0.807 Recall 0.807 F1 0.798 
=> Acc: 0.821 Precision 0.821 Recall 0.821 F1 0.814 
=> Acc: 0.845 Precision 0.845 Recall 0.845 F1 0.827 


accs [0.757396449704142, 0.5605150214592275, 0.8708901363271853, 0.7439729990356798, 0.9208467556373677, 0.9700674536256324, 0.8927973199329984, 0.8559585492227979, 0.7453874538745388, 0.8939828080229226, 0.9473684210526315, 0.6760259179265659, 0.8875358166189111, 0.9566854990583804, 0.9059205190592052, 0.7478632478632479, 0.8072190319934373, 0.8209494324045408, 0.844541910331384]
 precisions [0.7514792899408284, 0.5639484978540773, 0.8644747393744988, 0.7309546769527483, 0.9360331339162449, 0.9662731871838112, 0.8685092127303182, 0.8569948186528498, 0.7324723247232472, 0.9054441260744985, 0.9649122807017544, 0.7170626349892009, 0.8982808022922636, 0.9548022598870056, 0.8929440389294404, 0.7410256410256411, 0.8318293683347006, 0.8008255933952528, 0.865009746588694]
 recalls [0.7396449704142012, 0.5656652360515021, 0.8732959101844426, 0.7487945998071359, 0.9180855959502991, 0.965008431703204, 0.8785594639865997, 0.8595854922279793, 0.7490774907749077, 0.89207258834766, 0.9649122807017544, 0.734341252699784, 0.8882521489971347, 0.9595103578154426, 0.8880778588807786, 0.7564102564102564, 0.8047579983593109, 0.8194014447884417, 0.8698830409356725]
 f1scores [0.7015990268885779, 0.5365101104149, 0.873469074726323, 0.7249481125259749, 0.9214373344212283, 0.964510076444086, 0.8770805693250164, 0.8580255284127759, 0.7815143226488639, 0.9022668930505026, 0.952699566378282, 0.6467740434835934, 0.9079522353602171, 0.9594072637758693, 0.8979150802442929, 0.765653302197023, 0.7881969962647425, 0.8000231355916607, 0.842883785590552]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.693 Precision 0.693 Recall 0.693 F1 0.660 
=> Acc: 0.765 Precision 0.765 Recall 0.765 F1 0.735 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.936 
=> Acc: 0.767 Precision 0.767 Recall 0.767 F1 0.755 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.972 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.745 
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.842 
=> Acc: 0.766 Precision 0.766 Recall 0.766 F1 0.768 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.865 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.964 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.689 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.887 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.947 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.900 
=> Acc: 0.834 Precision 0.834 Recall 0.834 F1 0.835 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.831 
=> Acc: 0.837 Precision 0.837 Recall 0.837 F1 0.831 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.867 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.909 


accs [0.6931530008453085, 0.7648068669527897, 0.9350441058540497, 0.7671166827386693, 0.9263690750115048, 0.9713322091062394, 0.7914572864321608, 0.850259067357513, 0.7656826568265682, 0.873447946513849, 0.9649122807017544, 0.7494600431965442, 0.8839541547277937, 0.9453860640301318, 0.9002433090024331, 0.8341880341880342, 0.8367514356029533, 0.8369453044375645, 0.8801169590643275, 0.9122807017543859]
 precisions [0.6846999154691462, 0.7742489270386266, 0.9326383319967922, 0.7820636451301832, 0.93235158766682, 0.9679595278246206, 0.8023450586264657, 0.8616580310880829, 0.7822878228782287, 0.8849092645654251, 0.9714912280701754, 0.7300215982721382, 0.8796561604584527, 0.935969868173258, 0.9059205190592052, 0.8307692307692308, 0.8498769483182936, 0.8307533539731682, 0.8840155945419104, 0.9360902255639098]
 recalls [0.705832628909552, 0.759656652360515, 0.9350441058540497, 0.76374156219865, 0.9314312011044639, 0.9666947723440135, 0.8140703517587939, 0.8580310880829015, 0.7933579335793358, 0.8739255014326648, 0.9714912280701754, 0.6997840172786177, 0.8782234957020058, 0.9190207156308852, 0.8896999188969992, 0.8222222222222222, 0.8408531583264971, 0.8348813209494325, 0.8903508771929824, 0.9291979949874687]
 f1scores [0.6452625459577283, 0.7333624412477855, 0.9339945384473427, 0.7486927382208315, 0.9274409227653564, 0.965850576319524, 0.7582048727214539, 0.8416934757828765, 0.7474154092031517, 0.8801034327287034, 0.9741136990026437, 0.6733197562642695, 0.8886125206024863, 0.9229886372514441, 0.9116740217135735, 0.8333700460900928, 0.8442340932361423, 0.8336003861355186, 0.867231407905885, 0.9324017965160263]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.996 


accs [0.9964539007092199]
 precisions [0.9955673758865248]
 recalls [0.9946808510638298]
 f1scores [0.9955054824065275]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.996 Precision 0.996 Recall 0.996 F1 0.995 
=> Acc: 0.986 Precision 0.986 Recall 0.986 F1 0.986 


accs [0.9955673758865248, 0.9863207547169811]
 precisions [0.9893617021276596, 0.9910377358490566]
 recalls [0.9911347517730497, 0.9891509433962264]
 f1scores [0.9893236288079497, 0.98781173417826]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.997 Precision 0.997 Recall 0.997 F1 0.997 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.958 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.979 


accs [0.9973404255319149, 0.9599056603773585, 0.9796716184519155]
 precisions [0.9946808510638298, 0.9693396226415094, 0.9745895230648944]
 recalls [0.9937943262411347, 0.9627358490566038, 0.9738076622361219]
 f1scores [0.9930149473744125, 0.9618846036927634, 0.9713155951269885]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 
=> Acc: 0.943 Precision 0.943 Recall 0.943 F1 0.944 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.973 


accs [0.9804964539007093, 0.9429245283018868, 0.9784988272087568, 0.974739970282318]
 precisions [0.9840425531914894, 0.940566037735849, 0.9827990617670055, 0.974739970282318]
 recalls [0.9840425531914894, 0.9419811320754717, 0.9831899921813917, 0.9821693907875185]
 f1scores [0.9818297301105293, 0.9356080927081007, 0.9862604700160065, 0.9668666021743567]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.991 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.925 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.940 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.980 


accs [0.9911347517730497, 0.9254716981132075, 0.9808444096950742, 0.9420505200594353, 0.9786910197869102]
 precisions [0.9858156028368794, 0.9363207547169812, 0.980453479280688, 0.9420505200594353, 0.9832572298325722]
 recalls [0.9929078014184397, 0.9283018867924528, 0.9816262705238468, 0.9539375928677564, 0.9908675799086758]
 f1scores [0.9927718751972396, 0.9270366369200781, 0.9779046622563072, 0.9341158337863746, 0.992645128850089]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.997 Precision 0.997 Recall 0.997 F1 0.997 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.869 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.946 
=> Acc: 0.976 Precision 0.976 Recall 0.976 F1 0.975 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.968 


accs [0.9973404255319149, 0.8716981132075472, 0.9765441751368257, 0.9465081723625557, 0.9756468797564688, 0.9690506064408198]
 precisions [0.9973404255319149, 0.8726415094339622, 0.982017200938233, 0.9494799405646359, 0.9649923896499238, 0.9677959012965287]
 recalls [0.9964539007092199, 0.8716981132075472, 0.9749804534792806, 0.9420505200594353, 0.9771689497716894, 0.9698870765370138]
 f1scores [0.9991886276203994, 0.8828539123338105, 0.976166731073788, 0.9328246697847724, 0.9809605367939742, 0.9680169366312927]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.864 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.929 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.794 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.936 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.948 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.935 


accs [0.9813829787234043, 0.8726415094339622, 0.9272869429241595, 0.8187221396731055, 0.9375951293759512, 0.9493935591802594, 0.9374389051808406]
 precisions [0.9663120567375887, 0.8735849056603774, 0.9323690383111806, 0.8335809806835067, 0.9497716894977168, 0.9485570890840652, 0.9351580319322255]
 recalls [0.9831560283687943, 0.8702830188679245, 0.9233776387802971, 0.8424962852897474, 0.954337899543379, 0.9594312003345881, 0.9436298468556533]
 f1scores [0.9696492204321701, 0.847937640432858, 0.9345753633241619, 0.7964112608801969, 0.9552475531972888, 0.9536551302943679, 0.9346422471086132]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.929 
=> Acc: 0.840 Precision 0.840 Recall 0.840 F1 0.831 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.879 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.758 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.984 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.941 
=> Acc: 0.935 Precision 0.935 Recall 0.935 F1 0.933 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 


accs [0.9308510638297872, 0.839622641509434, 0.8749022673964034, 0.7949479940564635, 0.984779299847793, 0.9422835633626098, 0.9351580319322255, 0.9501915708812261]
 precisions [0.9308510638297872, 0.8580188679245283, 0.8881939014855356, 0.8157503714710252, 0.9878234398782344, 0.944374738603095, 0.9384164222873901, 0.9486590038314177]
 recalls [0.9361702127659575, 0.85, 0.8846755277560594, 0.7934621099554234, 0.974124809741248, 0.9439565035549979, 0.9296187683284457, 0.9501915708812261]
 f1scores [0.9295711072104688, 0.8303089629123879, 0.8870602370386191, 0.7557581948484622, 0.9699244414264871, 0.9432816326334506, 0.9329375483428638, 0.9484161775344869]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.980 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.885 
=> Acc: 0.879 Precision 0.879 Recall 0.879 F1 0.882 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.780 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.975 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.919 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.901 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.880 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.9804964539007093, 0.8924528301886793, 0.8792025019546521, 0.8202080237741456, 0.974124809741248, 0.9213718109577582, 0.90257412838058, 0.8827586206896552, 0.9890710382513661]
 precisions [0.9813829787234043, 0.8797169811320755, 0.8639562157935887, 0.8157503714710252, 0.9665144596651446, 0.9188624006691761, 0.8999674160964484, 0.8873563218390804, 0.9918032786885246]
 recalls [0.9813829787234043, 0.8933962264150943, 0.8792025019546521, 0.8098068350668648, 0.9832572298325722, 0.9092429945629443, 0.8973607038123167, 0.8666666666666667, 0.9836065573770492]
 f1scores [0.9769330283213332, 0.8793854901937742, 0.8728037386353822, 0.7977349051500835, 0.9728445749542898, 0.9166836358668649, 0.9047508551489386, 0.8806515405352693, 0.980670029533294]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.945 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.833 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.910 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.785 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.953 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.914 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.916 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.913 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.978 


accs [0.9441489361702128, 0.8514150943396226, 0.90852228303362, 0.8187221396731055, 0.9528158295281582, 0.9163529903805939, 0.9201694362984686, 0.9141762452107279, 0.9262295081967213, 0.9781321184510251]
 precisions [0.9512411347517731, 0.8669811320754717, 0.9093041438623924, 0.8068350668647846, 0.9558599695585996, 0.9230447511501464, 0.906158357771261, 0.8919540229885058, 0.9262295081967213, 0.9808656036446469]
 recalls [0.9441489361702128, 0.8693396226415094, 0.9116497263487099, 0.8112927191679049, 0.9604261796042618, 0.9121706398996235, 0.9139784946236559, 0.8919540229885058, 0.9316939890710383, 0.9813211845102505]
 f1scores [0.9368310328091857, 0.8473460400501676, 0.9173305095806311, 0.7860855248842761, 0.9554157542091811, 0.9208305415251854, 0.9189805631834187, 0.9165397504331778, 0.9215310905368337, 0.980686109606037]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.981 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.857 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.914 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.798 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.871 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.910 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.889 
=> Acc: 0.807 Precision 0.807 Recall 0.807 F1 0.765 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.821 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.916 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.980 


accs [0.9804964539007093, 0.8627358490566037, 0.9120406567630962, 0.8231797919762258, 0.8812785388127854, 0.9121706398996235, 0.8927989573150863, 0.8068965517241379, 0.8333333333333334, 0.9170842824601366, 0.9794786466999446]
 precisions [0.975177304964539, 0.8688679245283019, 0.918295543393276, 0.8053491827637445, 0.8873668188736682, 0.9021329987452948, 0.8960573476702509, 0.7923371647509578, 0.8879781420765027, 0.924373576309795, 0.9767054908485857]
 recalls [0.9769503546099291, 0.8683962264150943, 0.9077404222048475, 0.8395245170876672, 0.8949771689497716, 0.9125888749477207, 0.8888888888888888, 0.803831417624521, 0.8333333333333334, 0.9339407744874715, 0.9733777038269551]
 f1scores [0.9740413831326604, 0.8482901000777596, 0.9101523770481093, 0.757201808689814, 0.8803328608361006, 0.9002047651318014, 0.8776414179864777, 0.7648805083690529, 0.8300378400310429, 0.9324321659515272, 0.9788900939095022]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.930 
=> Acc: 0.798 Precision 0.798 Recall 0.798 F1 0.786 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.951 
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.839 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.963 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.940 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.897 
=> Acc: 0.774 Precision 0.774 Recall 0.774 F1 0.755 
=> Acc: 0.811 Precision 0.811 Recall 0.811 F1 0.810 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.941 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.915 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.912 


accs [0.9326241134751773, 0.7981132075471699, 0.9507427677873339, 0.8632986627043091, 0.9649923896499238, 0.9414470932664157, 0.9002932551319648, 0.7739463601532567, 0.8114754098360656, 0.9421412300683372, 0.9173599556295063, 0.9202714164546225]
 precisions [0.9388297872340425, 0.780188679245283, 0.9515246286161063, 0.8514115898959881, 0.9482496194824962, 0.9360100376411543, 0.9068100358422939, 0.7670498084291187, 0.8169398907103825, 0.9466970387243736, 0.915696062118691, 0.9312977099236641]
 recalls [0.9237588652482269, 0.7830188679245284, 0.9538702111024238, 0.8395245170876672, 0.9345509893455098, 0.9381012128816395, 0.9071358748778103, 0.767816091954023, 0.8661202185792349, 0.944874715261959, 0.9168053244592346, 0.917726887192536]
 f1scores [0.9390750286750095, 0.7838932220363733, 0.9625981943613121, 0.8232473608325229, 0.9470463082589369, 0.9378647454509268, 0.9002471961246228, 0.7601257685119919, 0.8340671812106095, 0.9408449590067687, 0.9143192058964976, 0.911668835735802]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.931 
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.767 
=> Acc: 0.965 Precision 0.965 Recall 0.965 F1 0.965 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.802 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.945 
=> Acc: 0.912 Precision 0.912 Recall 0.912 F1 0.910 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.759 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.881 
=> Acc: 0.944 Precision 0.944 Recall 0.944 F1 0.944 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.901 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.926 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.983 


accs [0.9326241134751773, 0.7745283018867924, 0.9652071931196247, 0.8231797919762258, 0.9375951293759512, 0.945629443747386, 0.9123492994460737, 0.7862068965517242, 0.8797814207650273, 0.9439635535307517, 0.9029395452024404, 0.9321458863443596, 0.9825]
 precisions [0.9645390070921985, 0.7783018867924528, 0.965598123534011, 0.8142644873699851, 0.9421613394216134, 0.9544123797574237, 0.9156076898012382, 0.7793103448275862, 0.8333333333333334, 0.9271070615034168, 0.8962839711591791, 0.9304495335029687, 0.965]
 recalls [0.9601063829787234, 0.7759433962264151, 0.9636434714620797, 0.826151560178306, 0.9315068493150684, 0.9498117942283564, 0.9208211143695014, 0.7946360153256705, 0.8715846994535519, 0.9357630979498861, 0.908485856905158, 0.916030534351145, 0.9575]
 f1scores [0.9398192983887128, 0.7739514620678017, 0.9640090607399106, 0.7917435939306445, 0.9275866101819334, 0.9535937301749984, 0.9058988316623686, 0.7574145107437394, 0.8494118302972632, 0.9402546245093021, 0.9106684796954226, 0.9296615866458702, 0.9638341907457288]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.859 Precision 0.859 Recall 0.859 F1 0.857 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.928 
=> Acc: 0.823 Precision 0.823 Recall 0.823 F1 0.783 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.921 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.916 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.884 
=> Acc: 0.779 Precision 0.779 Recall 0.779 F1 0.732 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.965 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.948 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.937 
=> Acc: 0.885 Precision 0.885 Recall 0.885 F1 0.879 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.877 


accs [0.973404255319149, 0.8594339622641509, 0.9268960125097733, 0.8231797919762258, 0.9299847792998478, 0.918444165621079, 0.8895405669599218, 0.7793103448275862, 0.9672131147540983, 0.9494305239179954, 0.9367720465890182, 0.8846480067854113, 0.97, 0.8917609046849758]
 precisions [0.9716312056737588, 0.8603773584905661, 0.9308053166536356, 0.8246656760772659, 0.9315068493150684, 0.9201171058134672, 0.895405669599218, 0.7862068965517242, 0.9371584699453552, 0.9553530751708428, 0.9445368829728231, 0.8710771840542832, 0.9875, 0.8691437802907916]
 recalls [0.9858156028368794, 0.8518867924528302, 0.924941360437842, 0.7904903417533432, 0.91324200913242, 0.9138435800920117, 0.8976865428478332, 0.7731800766283525, 0.9371584699453552, 0.9466970387243736, 0.9389905712701054, 0.8778625954198473, 0.9725, 0.9240710823909531]
 f1scores [0.9713240197352512, 0.8548946686103861, 0.9270215479124182, 0.7831616858941548, 0.8992619379140271, 0.9165893462049046, 0.892448262745215, 0.726474629917358, 0.9091799402018381, 0.9449547283630055, 0.9414516073796655, 0.873161508668516, 0.9679210844492875, 0.9016453930522372]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.808 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.936 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.835 
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.908 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.878 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.803 
=> Acc: 0.877 Precision 0.877 Recall 0.877 F1 0.876 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.921 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.904 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.898 
=> Acc: 0.978 Precision 0.978 Recall 0.978 F1 0.977 
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.901 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.979 


accs [0.9264184397163121, 0.8174528301886792, 0.9343236903831118, 0.8410104011887073, 0.9071537290715372, 0.9330823923044751, 0.8813945910720105, 0.8099616858237548, 0.8770491803278688, 0.9207289293849659, 0.9040488075429839, 0.904156064461408, 0.9775, 0.9030694668820679, 0.9792166266986411]
 precisions [0.9308510638297872, 0.8113207547169812, 0.9319781078967944, 0.8187221396731055, 0.8599695585996956, 0.9268088665830196, 0.8872596937113066, 0.8160919540229885, 0.9180327868852459, 0.9138952164009112, 0.9151414309484193, 0.8939779474130619, 0.97, 0.9063004846526656, 0.9784172661870504]
 recalls [0.9352836879432624, 0.8014150943396227, 0.9401876465989054, 0.8291233283803864, 0.863013698630137, 0.9226265161020494, 0.8810687520364939, 0.8237547892720306, 0.8879781420765027, 0.9070615034168565, 0.9234608985024958, 0.90754877014419, 0.9675, 0.8901453957996769, 0.9696243005595524]
 f1scores [0.9424379513842407, 0.800333507780666, 0.9326605450461335, 0.8385785464800113, 0.872109869468791, 0.9233359352495482, 0.8868988191945599, 0.8177849186869108, 0.9052296876894396, 0.913431564673774, 0.9148219344748781, 0.9100933990086902, 0.9619757969351465, 0.9163015692469643, 0.9798808906549455]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.927 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.873 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.926 
=> Acc: 0.813 Precision 0.813 Recall 0.813 F1 0.754 
=> Acc: 0.886 Precision 0.886 Recall 0.886 F1 0.889 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.912 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.891 
=> Acc: 0.848 Precision 0.848 Recall 0.848 F1 0.842 
=> Acc: 0.719 Precision 0.719 Recall 0.719 F1 0.698 
=> Acc: 0.964 Precision 0.964 Recall 0.964 F1 0.964 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.911 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.908 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.924 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.893 
=> Acc: 0.954 Precision 0.954 Recall 0.954 F1 0.952 
=> Acc: 0.844 Precision 0.844 Recall 0.844 F1 0.824 


accs [0.9264184397163121, 0.8834905660377359, 0.9229867083659109, 0.812778603268945, 0.8858447488584474, 0.9142618151401087, 0.8973607038123167, 0.8482758620689655, 0.7185792349726776, 0.9635535307517085, 0.908485856905158, 0.916030534351145, 0.9225, 0.8933764135702746, 0.9536370903277378, 0.8439450686641697]
 precisions [0.9237588652482269, 0.8919811320754717, 0.9202501954652071, 0.7860326894502229, 0.8873668188736682, 0.9205353408615642, 0.9028999674160965, 0.8352490421455939, 0.7049180327868853, 0.9562642369020501, 0.9046034387132557, 0.9151823579304496, 0.9075, 0.8820678513731826, 0.9456434852118305, 0.8601747815230961]
 recalls [0.9406028368794326, 0.8834905660377359, 0.9284597341673182, 0.7979197622585439, 0.8843226788432268, 0.903387703889586, 0.8924731182795699, 0.8521072796934865, 0.726775956284153, 0.9603644646924829, 0.9262340543538546, 0.8787107718405428, 0.9175, 0.8691437802907916, 0.938449240607514, 0.8420724094881398]
 f1scores [0.93892380658493, 0.8740687544822473, 0.929571599796345, 0.7715510155480613, 0.903230379916856, 0.9031164263623876, 0.8955687528913607, 0.844516098219548, 0.6892538144831722, 0.9615212637127375, 0.9312060847917648, 0.8950790764723925, 0.9131307373573794, 0.9008601636756763, 0.9390406304353796, 0.8357494550526742]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.822 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.896 
=> Acc: 0.854 Precision 0.854 Recall 0.854 F1 0.842 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.845 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.882 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.876 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.753 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.918 
=> Acc: 0.909 Precision 0.909 Recall 0.909 F1 0.909 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.888 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.881 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.953 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.863 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.937 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.802 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.962 


accs [0.9379432624113475, 0.8306603773584905, 0.893666927286943, 0.8543833580980683, 0.852359208523592, 0.8837306566290255, 0.8826979472140762, 0.7731800766283525, 0.9207650273224044, 0.9093394077448748, 0.8907376594564614, 0.8922815945716709, 0.955, 0.8707592891760905, 0.9392486011191047, 0.83270911360799, 0.9626639757820383]
 precisions [0.9565602836879432, 0.8504716981132076, 0.8983580922595777, 0.8454680534918276, 0.852359208523592, 0.8799665411961523, 0.8804170739654611, 0.7647509578544062, 0.8825136612021858, 0.9034168564920273, 0.894065446478092, 0.8863443596268024, 0.965, 0.8739903069466882, 0.947242206235012, 0.8264669163545568, 0.9646821392532795]
 recalls [0.9671985815602837, 0.8547169811320755, 0.9093041438623924, 0.8573551263001485, 0.8447488584474886, 0.8866583019657047, 0.8869338546757901, 0.750191570881226, 0.8688524590163934, 0.8915717539863326, 0.8935108153078203, 0.8804071246819338, 0.965, 0.8723747980613893, 0.9360511590727418, 0.8245942571785269, 0.9606458123107972]
 f1scores [0.9562161864177654, 0.8449305335825865, 0.901628069311206, 0.8162888162242347, 0.866181304830671, 0.8751573373139909, 0.8720170832147669, 0.7565416986292767, 0.8867671181190504, 0.8941453081575746, 0.8828997595456098, 0.8711172458908818, 0.9653790585910051, 0.8514809142867495, 0.9408874217361314, 0.8072048126077098, 0.9724409989480696]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.945 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.831 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.887 
=> Acc: 0.802 Precision 0.802 Recall 0.802 F1 0.784 
=> Acc: 0.900 Precision 0.900 Recall 0.900 F1 0.900 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.875 
=> Acc: 0.873 Precision 0.873 Recall 0.873 F1 0.863 
=> Acc: 0.759 Precision 0.759 Recall 0.759 F1 0.703 
=> Acc: 0.817 Precision 0.817 Recall 0.817 F1 0.789 
=> Acc: 0.902 Precision 0.902 Recall 0.902 F1 0.903 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.886 
=> Acc: 0.866 Precision 0.866 Recall 0.866 F1 0.857 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.869 Precision 0.869 Recall 0.869 F1 0.861 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.854 
=> Acc: 0.780 Precision 0.780 Recall 0.780 F1 0.744 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.936 
=> Acc: 0.884 Precision 0.884 Recall 0.884 F1 0.872 


accs [0.9450354609929078, 0.8424528301886792, 0.8815480844409695, 0.8023774145616642, 0.8995433789954338, 0.876202425763279, 0.873248615184099, 0.7586206896551724, 0.8169398907103825, 0.9015945330296128, 0.8901830282861897, 0.8659881255301103, 0.975, 0.8691437802907916, 0.8601119104716227, 0.7802746566791511, 0.934409687184662, 0.8837944664031621]
 precisions [0.9618794326241135, 0.8325471698113207, 0.8932759968725567, 0.7979197622585439, 0.8706240487062404, 0.8808030112923463, 0.8765070055392636, 0.7402298850574712, 0.8060109289617486, 0.9002277904328019, 0.8785357737104825, 0.8727735368956743, 0.97, 0.8610662358642972, 0.8441247002398081, 0.797752808988764, 0.9323915237134208, 0.8806324110671937]
 recalls [0.9441489361702128, 0.8320754716981132, 0.8811571540265832, 0.8335809806835067, 0.8904109589041096, 0.8803847762442493, 0.8664059954382535, 0.7310344827586207, 0.8169398907103825, 0.882004555808656, 0.8863006100942873, 0.8617472434266328, 0.98, 0.8432956381260097, 0.8521183053557154, 0.8002496878901373, 0.9253279515640767, 0.8790513833992095]
 f1scores [0.9470904192708097, 0.8208027121244366, 0.8916218683706674, 0.7785871457343811, 0.8859046867402827, 0.8623798702513585, 0.8684716825351936, 0.6932531805531594, 0.7359707774033508, 0.8997660872604165, 0.8729237713504375, 0.8608608950156384, 0.9726548347190084, 0.8377991627435113, 0.8305094468491679, 0.7377578691912003, 0.9118440747894303, 0.8572096111036904]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.863 
=> Acc: 0.905 Precision 0.905 Recall 0.905 F1 0.907 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.807 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.929 
=> Acc: 0.842 Precision 0.842 Recall 0.842 F1 0.844 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.851 
=> Acc: 0.723 Precision 0.723 Recall 0.723 F1 0.689 
=> Acc: 0.749 Precision 0.749 Recall 0.749 F1 0.737 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.929 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.877 
=> Acc: 0.847 Precision 0.847 Recall 0.847 F1 0.833 
=> Acc: 0.958 Precision 0.958 Recall 0.958 F1 0.957 
=> Acc: 0.856 Precision 0.856 Recall 0.856 F1 0.850 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.888 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.770 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.938 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.920 
=> Acc: 0.992 Precision 0.992 Recall 0.992 F1 0.992 


accs [0.950354609929078, 0.8721698113207547, 0.9046129788897577, 0.8202080237741456, 0.9299847792998478, 0.8423253868674195, 0.8608667318344738, 0.7233716475095785, 0.7486338797814208, 0.9266514806378132, 0.8796450360510261, 0.8473282442748091, 0.9575, 0.8562197092084006, 0.8928856914468425, 0.7908863920099876, 0.9384460141271443, 0.9233201581027668, 0.9921011058451816]
 precisions [0.9397163120567376, 0.8646226415094339, 0.8909304143862392, 0.8112927191679049, 0.9315068493150684, 0.8544542032622334, 0.8615184099055067, 0.7103448275862069, 0.7431693989071039, 0.910250569476082, 0.8790904048807543, 0.8532654792196777, 0.965, 0.8691437802907916, 0.8920863309352518, 0.8027465667915106, 0.9495459132189707, 0.9407114624505929, 0.981042654028436]
 recalls [0.9592198581560284, 0.8797169811320755, 0.8991399530883503, 0.8142644873699851, 0.928462709284627, 0.849017147636972, 0.8709677419354839, 0.7134099616858237, 0.7349726775956285, 0.9047835990888383, 0.8796450360510261, 0.8303647158608991, 0.95, 0.8739903069466882, 0.8840927258193445, 0.7965043695380774, 0.934409687184662, 0.9304347826086956, 0.9873617693522907]
 f1scores [0.9598785963961909, 0.8564850385612495, 0.8995884096401247, 0.807853604714954, 0.9412480354809556, 0.8479233032698985, 0.8557970164842359, 0.6840313478345947, 0.7235794213903884, 0.9149259833863592, 0.858753179529752, 0.838409661366262, 0.9633224210135868, 0.8494055810289465, 0.9026301412054103, 0.7578045046441673, 0.9458716746272005, 0.9255971189631291, 0.9892099276289545]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.959 
=> Acc: 0.875 Precision 0.875 Recall 0.875 F1 0.869 
=> Acc: 0.871 Precision 0.871 Recall 0.871 F1 0.876 
=> Acc: 0.826 Precision 0.826 Recall 0.826 F1 0.815 
=> Acc: 0.883 Precision 0.883 Recall 0.883 F1 0.883 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.865 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.859 
=> Acc: 0.720 Precision 0.720 Recall 0.720 F1 0.665 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.809 
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.921 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.922 
=> Acc: 0.812 Precision 0.812 Recall 0.812 F1 0.794 
=> Acc: 0.948 Precision 0.948 Recall 0.948 F1 0.945 
=> Acc: 0.801 Precision 0.801 Recall 0.801 F1 0.784 
=> Acc: 0.908 Precision 0.908 Recall 0.908 F1 0.907 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.776 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.894 
=> Acc: 0.983 Precision 0.983 Recall 0.983 F1 0.982 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.937 


accs [0.9601063829787234, 0.8754716981132076, 0.870992963252541, 0.826151560178306, 0.882800608828006, 0.8674194897532413, 0.8670576735092864, 0.7203065134099617, 0.8306010928961749, 0.9202733485193622, 0.9223516361619523, 0.811704834605598, 0.9475, 0.8012924071082391, 0.9080735411670664, 0.8096129837702871, 0.9323915237134208, 0.8988142292490119, 0.9826224328593997, 0.9405267629566695]
 precisions [0.9636524822695035, 0.8589622641509433, 0.8686473807662236, 0.8008915304606241, 0.8964992389649924, 0.8678377248013384, 0.8673835125448028, 0.7095785440613027, 0.7950819672131147, 0.9312072892938497, 0.920687742651137, 0.8091603053435115, 0.96, 0.8368336025848142, 0.8832933653077538, 0.8083645443196005, 0.9253279515640767, 0.8956521739130435, 0.9921011058451816, 0.935429056924384]
 recalls [0.9521276595744681, 0.8561320754716981, 0.8733385457388585, 0.8306092124814265, 0.9010654490106544, 0.8582183186951067, 0.8696643857934181, 0.7318007662835249, 0.8360655737704918, 0.9271070615034168, 0.920687742651137, 0.8176420695504665, 0.95, 0.840064620355412, 0.8920863309352518, 0.7990012484394506, 0.9152371342078708, 0.908300395256917, 0.9842022116903634, 0.9341546304163126]
 f1scores [0.9567027587910605, 0.8467103492852243, 0.882967246439974, 0.7892404930672127, 0.9046288248648224, 0.8720494109094851, 0.8622973206145239, 0.6697425018749321, 0.7811310912650705, 0.9294156020200649, 0.9274359641363542, 0.8169869877525093, 0.9442074098349069, 0.8073789731531267, 0.8924961533946935, 0.771037828025205, 0.926685032661785, 0.9056731753424172, 0.9873412961489076, 0.9395759483162008]
done w/ time
Start w/ time
CUDA is used

Preparing the data...
 Training data X (257023, 2439) Y (257023,)
 Test data X (28559, 2439) Y (28559,)

Parameter-stamp...
 --> task:          AZ_Task20-task
 --> model:         ember_MLP
 --> hyper-params:  i10000-lr0.001-b256-sgd
AZ_Task20-task--ember_MLP--i10000-lr0.001-b256-sgd--

----------------------------------------MAIN MODEL----------------------------------------
Classifier(
  (flatten): Flatten()
  (fcE): AZ_MLP_Net(
    (fc0): Linear(in_features=2439, out_features=2048, bias=True)
    (fc0_bn): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act0): ReLU()
    (fc0_drop): Dropout(p=0.5, inplace=False)
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act1): ReLU()
    (fc1_drop): Dropout(p=0.5, inplace=False)
    (fc2): Linear(in_features=1024, out_features=512, bias=True)
    (fc2_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act2): ReLU()
    (fc2_drop): Dropout(p=0.5, inplace=False)
    (fc3): Linear(in_features=512, out_features=256, bias=True)
    (fc3_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act3): ReLU()
    (fc3_drop): Dropout(p=0.5, inplace=False)
    (fc4): Linear(in_features=256, out_features=128, bias=True)
    (fc4_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (act4): ReLU()
    (fc4_drop): Dropout(p=0.5, inplace=False)
  )
  (classifier): AZ_Classifier(
    (fc_last): Linear(in_features=128, out_features=100, bias=True)
  )
)
------------------------------------------------------------------------------------------
--> this network has 7805156 parameters (~7.8 million)
      of which: - learnable: 7805156 (~7.8 million)
                - fixed: 0 (~0.0 million)
------------------------------------------------------------------------------------------

Training...
task 1 =>> taskLabels [0, 1, 2, 3, 4]
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.980 


accs [0.9806362378976486]
 precisions [0.9746426924850161]
 recalls [0.9797141539880129]
 f1scores [0.9705617905462297]
task 2 =>> taskLabels [5, 6, 7, 8, 9]

np.unique(Y) [0 1 2 3 4] np.unique(Y_train) [0 1 2 3 4]
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.989 Precision 0.989 Recall 0.989 F1 0.989 


accs [0.9677270631627478, 0.989252814738997]
 precisions [0.9617335177501153, 0.9897645854657113]
 recalls [0.9714153988012909, 0.9897645854657113]
 f1scores [0.9694768174380372, 0.9901066780313339]
task 3 =>> taskLabels [10, 11, 12, 13, 14]

np.unique(Y) [0 1 2 3 4 5 6 7 8 9] np.unique(Y_train) [0 1 2 3 4 5 6 7 8 9]
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.929 Precision 0.929 Recall 0.929 F1 0.930 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.941 


accs [0.9746426924850161, 0.9288638689866939, 0.9424870466321243]
 precisions [0.9769479022591055, 0.9257932446264073, 0.9378238341968912]
 recalls [0.9755647763946519, 0.9165813715455476, 0.9373056994818653]
 f1scores [0.9694347977022352, 0.9258568136003034, 0.9417710016581144]
task 4 =>> taskLabels [15, 16, 17, 18, 19]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.955 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.978 
=> Acc: 0.841 Precision 0.841 Recall 0.841 F1 0.824 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.958 


accs [0.9557399723374828, 0.977482088024565, 0.8409326424870466, 0.9589216944801027]
 precisions [0.9557399723374828, 0.9754350051177073, 0.8331606217616581, 0.9653401797175867]
 recalls [0.9455970493314891, 0.9754350051177073, 0.833678756476684, 0.9486521181001284]
 f1scores [0.951319836651755, 0.978800478273623, 0.8178939304528121, 0.9760530300981974]
task 5 =>> taskLabels [20, 21, 22, 23, 24]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.971 
=> Acc: 0.874 Precision 0.874 Recall 0.874 F1 0.858 
=> Acc: 0.919 Precision 0.919 Recall 0.919 F1 0.921 
=> Acc: 0.997 Precision 0.997 Recall 0.997 F1 0.997 


accs [0.950207468879668, 0.970317297850563, 0.8740932642487047, 0.9191270860077022, 0.9968652037617555]
 precisions [0.9557399723374828, 0.9723643807574207, 0.8829015544041451, 0.9152759948652118, 0.9968652037617555]
 recalls [0.9386814200092208, 0.9795291709314228, 0.8699481865284974, 0.9281129653401797, 1.0]
 f1scores [0.9404734765988408, 0.9783101734912678, 0.859656145597314, 0.940752623860163, 0.9972935430389389]
task 6 =>> taskLabels [25, 26, 27, 28, 29]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24]
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.954 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.969 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.894 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.794 
=> Acc: 0.994 Precision 0.994 Recall 0.994 F1 0.994 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 


accs [0.9534347625633933, 0.9692937563971341, 0.8994818652849741, 0.82798459563543, 0.9937304075235109, 0.9499047100462837]
 precisions [0.9474412171507607, 0.9723643807574207, 0.8974093264248705, 0.8549422336328626, 0.987460815047022, 0.9572556493329704]
 recalls [0.9437528815122176, 0.965711361310133, 0.9062176165803109, 0.8356867779204108, 0.9843260188087775, 0.9477266539613395]
 f1scores [0.9469053217546055, 0.968189726910697, 0.8891885438566278, 0.834849652535891, 0.9969587835134053, 0.9535493761274603]
task 7 =>> taskLabels [30, 31, 32, 33, 34]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29]
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.939 
=> Acc: 0.984 Precision 0.984 Recall 0.984 F1 0.984 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.870 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.806 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.980 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.922 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 


accs [0.9405255878284924, 0.9841351074718526, 0.8818652849740932, 0.8189987163029525, 0.9811912225705329, 0.9224067519738633, 0.9852686308492201]
 precisions [0.9230059935454127, 0.9831115660184238, 0.8766839378238342, 0.82798459563543, 0.9843260188087775, 0.9245848080588075, 0.9930675909878682]
 recalls [0.9207007837713231, 0.9861821903787104, 0.8979274611398964, 0.8318356867779204, 0.9749216300940439, 0.9112442145385243, 0.9835355285961872]
 f1scores [0.9388302268098834, 0.982561555957324, 0.8735619434561877, 0.8189514390074499, 0.9848803170652751, 0.9167123456465976, 0.991019832880298]
task 8 =>> taskLabels [35, 36, 37, 38, 39]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34]
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.936 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.899 Precision 0.899 Recall 0.899 F1 0.890 
=> Acc: 0.878 Precision 0.878 Recall 0.878 F1 0.866 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.979 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 
=> Acc: 0.977 Precision 0.977 Recall 0.977 F1 0.977 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 


accs [0.9377593360995851, 0.9754350051177073, 0.8989637305699482, 0.8780487804878049, 0.9811912225705329, 0.9493601960250476, 0.9774696707105719, 0.9846041055718475]
 precisions [0.9303826648224989, 0.973899692937564, 0.8829015544041451, 0.8857509627727856, 0.9905956112852664, 0.9482711679825756, 0.9818024263431543, 0.9970674486803519]
 recalls [0.9363762102351314, 0.9728761514841351, 0.8937823834196891, 0.8664955070603337, 0.9968652037617555, 0.9455485978763953, 0.9835355285961872, 0.9948680351906158]
 f1scores [0.9350833784210565, 0.9751227433776497, 0.8896304406033773, 0.8384789796114891, 0.9908526610644257, 0.9494365165452845, 0.9756330723928024, 0.9913797569635472]
task 9 =>> taskLabels [40, 41, 42, 43, 44]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.948 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.957 
=> Acc: 0.862 Precision 0.862 Recall 0.862 F1 0.852 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.805 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.944 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.985 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.898 


accs [0.950207468879668, 0.9564994882292733, 0.8616580310880829, 0.8202824133504493, 0.9811912225705329, 0.9327525183773482, 0.9410745233968805, 0.9853372434017595, 0.9040959040959041]
 precisions [0.9446749654218534, 0.9600818833162743, 0.8761658031088083, 0.810012836970475, 0.9968652037617555, 0.9327525183773482, 0.938474870017331, 0.9890029325513197, 0.8991008991008991]
 recalls [0.9423697556477639, 0.9580348004094166, 0.8580310880829015, 0.810012836970475, 0.9655172413793104, 0.9313912333242581, 0.9419410745233969, 0.9882697947214076, 0.906093906093906]
 f1scores [0.9492766638739569, 0.96653561353284, 0.8515589059365203, 0.7986367450385545, 0.9969185185185185, 0.9370845108861656, 0.9467354665100235, 0.989282636960322, 0.9096327083325656]
task 10 =>> taskLabels [45, 46, 47, 48, 49]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]
=> Acc: 0.920 Precision 0.920 Recall 0.920 F1 0.920 
=> Acc: 0.987 Precision 0.987 Recall 0.987 F1 0.987 
=> Acc: 0.870 Precision 0.870 Recall 0.870 F1 0.857 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.859 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.973 
=> Acc: 0.927 Precision 0.927 Recall 0.927 F1 0.928 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.923 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.973 
=> Acc: 0.890 Precision 0.890 Recall 0.890 F1 0.889 
=> Acc: 0.972 Precision 0.972 Recall 0.972 F1 0.972 


accs [0.9197786998616874, 0.9872057318321392, 0.8699481865284974, 0.8677792041078306, 0.9749216300940439, 0.9273073781649878, 0.9211438474870017, 0.9736070381231672, 0.8901098901098901, 0.9723837209302325]
 precisions [0.9230059935454127, 0.9749232343909928, 0.877720207253886, 0.834403080872914, 0.9717868338557993, 0.9398312006534169, 0.9428076256499134, 0.9846041055718475, 0.8941058941058941, 0.9854651162790697]
 recalls [0.9147072383586906, 0.9759467758444217, 0.8704663212435233, 0.858793324775353, 0.9811912225705329, 0.9313912333242581, 0.9176776429809359, 0.9802052785923754, 0.8871128871128872, 0.9680232558139535]
 f1scores [0.9142391945546002, 0.9831791513088317, 0.847747764497653, 0.8397687294688243, 0.9611471801965022, 0.9249450820872008, 0.9266158442835823, 0.9698524348725408, 0.8903804075627646, 0.9790821855594076]
task 11 =>> taskLabels [50, 51, 52, 53, 54]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49]
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.910 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.864 Precision 0.864 Recall 0.864 F1 0.850 
=> Acc: 0.819 Precision 0.819 Recall 0.819 F1 0.814 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.941 
=> Acc: 0.955 Precision 0.955 Recall 0.955 F1 0.955 
=> Acc: 0.947 Precision 0.947 Recall 0.947 F1 0.945 
=> Acc: 0.985 Precision 0.985 Recall 0.985 F1 0.984 
=> Acc: 0.868 Precision 0.868 Recall 0.868 F1 0.860 
=> Acc: 0.981 Precision 0.981 Recall 0.981 F1 0.981 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.916 


accs [0.913324112494237, 0.9749232343909928, 0.8637305699481865, 0.8189987163029525, 0.9404388714733543, 0.9548053362374082, 0.9471403812824957, 0.9846041055718475, 0.8681318681318682, 0.9811046511627907, 0.9145496535796767]
 precisions [0.9105578607653296, 0.9779938587512794, 0.8725388601036269, 0.8318356867779204, 0.9498432601880877, 0.9474543969507215, 0.962738301559792, 0.9816715542521994, 0.8741258741258742, 0.9767441860465116, 0.9214780600461894]
 recalls [0.9160903642231443, 0.9749232343909928, 0.8797927461139896, 0.8318356867779204, 0.9278996865203761, 0.9518105091206098, 0.9679376083188909, 0.9890029325513197, 0.8611388611388612, 0.9767441860465116, 0.9260969976905312]
 f1scores [0.9124176984522172, 0.9636866261554584, 0.8688476903978671, 0.8185502459711277, 0.9520837954868749, 0.9522735868383967, 0.9587646141694013, 0.9846407466457606, 0.8603869434248154, 0.9807299241313526, 0.9206288966640581]
task 12 =>> taskLabels [55, 56, 57, 58, 59]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54]
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.918 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 
=> Acc: 0.851 Precision 0.851 Recall 0.851 F1 0.833 
=> Acc: 0.846 Precision 0.846 Recall 0.846 F1 0.832 
=> Acc: 0.787 Precision 0.787 Recall 0.787 F1 0.785 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.936 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.950 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.872 Precision 0.872 Recall 0.872 F1 0.870 
=> Acc: 0.953 Precision 0.953 Recall 0.953 F1 0.955 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.824 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.807 


accs [0.9207007837713231, 0.9733879222108496, 0.8507772020725388, 0.8459563543003851, 0.786833855799373, 0.9365641165260006, 0.949740034662045, 0.9706744868035191, 0.8721278721278721, 0.9534883720930233, 0.8283294842186297, 0.820160750167448]
 precisions [0.9114799446749654, 0.9718526100307062, 0.8487046632124352, 0.82798459563543, 0.8087774294670846, 0.942009256738361, 0.9540727902946274, 0.9655425219941349, 0.8871128871128872, 0.9491279069767442, 0.8437259430331023, 0.8057602143335566]
 recalls [0.9087136929460581, 0.9646878198567042, 0.8569948186528498, 0.8202824133504493, 0.7931034482758621, 0.9417369997277429, 0.949740034662045, 0.9582111436950147, 0.8781218781218781, 0.9636627906976745, 0.8344880677444187, 0.7937039517749498]
 f1scores [0.9092514577335816, 0.9707141898820177, 0.8306551822662392, 0.8050815376278324, 0.8104102356319419, 0.936158376834633, 0.9555020344772462, 0.9634489444946416, 0.8713103355321554, 0.9704472374257505, 0.828194338262278, 0.8064535198079357]
task 13 =>> taskLabels [60, 61, 62, 63, 64]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59]
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.879 
=> Acc: 0.960 Precision 0.960 Recall 0.960 F1 0.960 
=> Acc: 0.820 Precision 0.820 Recall 0.820 F1 0.788 
=> Acc: 0.833 Precision 0.833 Recall 0.833 F1 0.824 
=> Acc: 0.831 Precision 0.831 Recall 0.831 F1 0.806 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.933 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.925 
=> Acc: 0.950 Precision 0.950 Recall 0.950 F1 0.949 
=> Acc: 0.891 Precision 0.891 Recall 0.891 F1 0.886 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.944 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.805 
=> Acc: 0.822 Precision 0.822 Recall 0.822 F1 0.814 
=> Acc: 0.865 Precision 0.865 Recall 0.865 F1 0.866 


accs [0.8805901337021669, 0.9600818833162743, 0.8202072538860103, 0.8331193838254172, 0.8307210031347962, 0.9332970323985843, 0.9263431542461005, 0.9501466275659824, 0.8911088911088911, 0.9447674418604651, 0.8083140877598153, 0.8221701272605493, 0.8652597402597403]
 precisions [0.8704472106961734, 0.9723643807574207, 0.827461139896373, 0.7933247753530167, 0.7931034482758621, 0.9286686632180778, 0.9454072790294628, 0.9560117302052786, 0.8791208791208791, 0.9534883720930233, 0.812933025404157, 0.8338914936369726, 0.8733766233766234]
 recalls [0.8681420009220839, 0.9708290685772774, 0.8253886010362694, 0.8112965340179717, 0.780564263322884, 0.9166893547508849, 0.9393414211438474, 0.9479472140762464, 0.8741258741258742, 0.9593023255813954, 0.8160123171670516, 0.8359008707300737, 0.8668831168831169]
 f1scores [0.8650992233227683, 0.973163409663462, 0.8137013370990935, 0.8284303486125063, 0.7888167044049397, 0.9259598467522249, 0.9492622826760542, 0.9540166028145295, 0.8537081332695792, 0.9596785318227441, 0.8064599910771296, 0.824449331758934, 0.8899382971933507]
task 14 =>> taskLabels [65, 66, 67, 68, 69]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64]
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.862 
=> Acc: 0.970 Precision 0.970 Recall 0.970 F1 0.970 
=> Acc: 0.853 Precision 0.853 Recall 0.853 F1 0.841 
=> Acc: 0.858 Precision 0.858 Recall 0.858 F1 0.860 
=> Acc: 0.969 Precision 0.969 Recall 0.969 F1 0.962 
=> Acc: 0.949 Precision 0.949 Recall 0.949 F1 0.949 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.931 
=> Acc: 0.945 Precision 0.945 Recall 0.945 F1 0.945 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.851 
=> Acc: 0.924 Precision 0.924 Recall 0.924 F1 0.924 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.784 
=> Acc: 0.808 Precision 0.808 Recall 0.808 F1 0.792 
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.884 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.978 


accs [0.8626094974642693, 0.970317297850563, 0.8528497409326425, 0.8575096277278562, 0.9686520376175548, 0.9490879390144297, 0.9298093587521664, 0.9450146627565983, 0.8611388611388612, 0.9244186046511628, 0.7959969207082371, 0.8084393837910248, 0.8798701298701299, 0.9787798408488063]
 precisions [0.8667588750576303, 0.9698055271238485, 0.8471502590673575, 0.8446726572528883, 0.9529780564263323, 0.9450040838551592, 0.9315424610051993, 0.9545454545454546, 0.8621378621378621, 0.9258720930232558, 0.7913779830638953, 0.8107836570663094, 0.8961038961038961, 0.980106100795756]
 recalls [0.8630705394190872, 0.9687819856704196, 0.8409326424870466, 0.8639281129653402, 0.9341692789968652, 0.9482711679825756, 0.9211438474870017, 0.9428152492668622, 0.8671328671328671, 0.936046511627907, 0.8006158583525789, 0.8064300066979236, 0.8766233766233766, 0.9774535809018567]
 f1scores [0.8591904790070679, 0.9568512310972815, 0.8348811655701143, 0.8345819721683776, 0.9530305390460011, 0.9511334306548704, 0.9339542823496911, 0.9474502536149323, 0.8428884249103866, 0.9468119474917017, 0.7937930437347103, 0.7813977372894769, 0.8921914052116877, 0.9784535157512215]
task 15 =>> taskLabels [70, 71, 72, 73, 74]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69]
=> Acc: 0.888 Precision 0.888 Recall 0.888 F1 0.885 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.829 Precision 0.829 Recall 0.829 F1 0.812 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.802 
=> Acc: 0.793 Precision 0.793 Recall 0.793 F1 0.763 
=> Acc: 0.923 Precision 0.923 Recall 0.923 F1 0.922 
=> Acc: 0.951 Precision 0.951 Recall 0.951 F1 0.950 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.938 
=> Acc: 0.889 Precision 0.889 Recall 0.889 F1 0.882 
=> Acc: 0.917 Precision 0.917 Recall 0.917 F1 0.918 
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.797 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.828 
=> Acc: 0.843 Precision 0.843 Recall 0.843 F1 0.829 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.932 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.929 


accs [0.888427846934071, 0.9682702149437052, 0.8290155440414507, 0.8138639281129654, 0.7931034482758621, 0.9226790089844813, 0.951473136915078, 0.9398826979472141, 0.8891108891108891, 0.9171511627906976, 0.7990762124711316, 0.8429336905559277, 0.8425324675324676, 0.9316976127320955, 0.9332113449222323]
 precisions [0.8635315813739051, 0.9662231320368475, 0.844041450777202, 0.8292682926829268, 0.799373040752351, 0.9270351211543697, 0.9376083188908145, 0.9501466275659824, 0.8691308691308691, 0.9229651162790697, 0.8036951501154734, 0.8503014065639651, 0.814935064935065, 0.9263925729442971, 0.9368709972552608]
 recalls [0.8787459658828953, 0.9692937563971341, 0.8367875647668394, 0.8112965340179717, 0.8150470219435737, 0.929213177239314, 0.9471403812824957, 0.9296187683284457, 0.8891108891108891, 0.9156976744186046, 0.7959969207082371, 0.8489618218352311, 0.8344155844155844, 0.9244031830238727, 0.9341262580054894]
 f1scores [0.8815901861141727, 0.9796876580298057, 0.8219325464361968, 0.7985798552920673, 0.7935584604212055, 0.9301618174394131, 0.932433456035961, 0.9485682100724151, 0.8798459080918738, 0.9190011005615544, 0.7894450281418817, 0.8391868860754595, 0.8064698158976104, 0.9280861940160727, 0.9412385840562412]
task 16 =>> taskLabels [75, 76, 77, 78, 79]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74]
=> Acc: 0.880 Precision 0.880 Recall 0.880 F1 0.877 
=> Acc: 0.968 Precision 0.968 Recall 0.968 F1 0.968 
=> Acc: 0.737 Precision 0.737 Recall 0.737 F1 0.711 
=> Acc: 0.775 Precision 0.775 Recall 0.775 F1 0.741 
=> Acc: 0.925 Precision 0.925 Recall 0.925 F1 0.923 
=> Acc: 0.931 Precision 0.931 Recall 0.931 F1 0.931 
=> Acc: 0.934 Precision 0.934 Recall 0.934 F1 0.934 
=> Acc: 0.910 Precision 0.910 Recall 0.910 F1 0.908 
=> Acc: 0.867 Precision 0.867 Recall 0.867 F1 0.858 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.956 
=> Acc: 0.786 Precision 0.786 Recall 0.786 F1 0.786 
=> Acc: 0.789 Precision 0.789 Recall 0.789 F1 0.773 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.767 
=> Acc: 0.946 Precision 0.946 Recall 0.946 F1 0.943 
=> Acc: 0.915 Precision 0.915 Recall 0.915 F1 0.913 
=> Acc: 0.939 Precision 0.939 Recall 0.939 F1 0.938 


accs [0.8796680497925311, 0.9677584442169908, 0.7367875647668394, 0.7753530166880617, 0.9247648902821317, 0.9308467193030221, 0.9341421143847487, 0.9098240469208211, 0.8671328671328671, 0.9563953488372093, 0.7859892224788299, 0.7893503014065639, 0.7905844155844156, 0.9456233421750663, 0.9149130832570905, 0.9391727493917275]
 precisions [0.8773628400184417, 0.9672466734902764, 0.722279792746114, 0.7958921694480102, 0.9059561128526645, 0.9313912333242581, 0.9168110918544194, 0.906158357771261, 0.8421578421578422, 0.9418604651162791, 0.7736720554272517, 0.7983924983255191, 0.8068181818181818, 0.9376657824933687, 0.9011893870082343, 0.9361313868613139]
 recalls [0.8773628400184417, 0.965711361310133, 0.7419689119170985, 0.8138639281129654, 0.9122257053291536, 0.9376531445684726, 0.9194107452339688, 0.9046920821114369, 0.8621378621378621, 0.9491279069767442, 0.7782909930715936, 0.790020093770931, 0.8198051948051948, 0.9310344827586207, 0.8975297346752058, 0.9330900243309003]
 f1scores [0.8617734548455772, 0.9682570691623382, 0.7128396004064896, 0.7655333341135322, 0.932242181052392, 0.9291245520071009, 0.931832072266171, 0.9149041585880683, 0.8426724386052686, 0.9466860665274786, 0.7689047535184306, 0.7755786813676209, 0.7571044750931287, 0.9361734022562246, 0.8929859804971482, 0.9403346359285386]
task 17 =>> taskLabels [80, 81, 82, 83, 84]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79]
=> Acc: 0.907 Precision 0.907 Recall 0.907 F1 0.904 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.967 
=> Acc: 0.796 Precision 0.796 Recall 0.796 F1 0.777 
=> Acc: 0.720 Precision 0.720 Recall 0.720 F1 0.706 
=> Acc: 0.966 Precision 0.966 Recall 0.966 F1 0.967 
=> Acc: 0.956 Precision 0.956 Recall 0.956 F1 0.957 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.895 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.906 
=> Acc: 0.852 Precision 0.852 Recall 0.852 F1 0.832 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.919 
=> Acc: 0.814 Precision 0.814 Recall 0.814 F1 0.816 
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.780 
=> Acc: 0.763 Precision 0.763 Recall 0.763 F1 0.737 
=> Acc: 0.922 Precision 0.922 Recall 0.922 F1 0.919 
=> Acc: 0.933 Precision 0.933 Recall 0.933 F1 0.932 
=> Acc: 0.930 Precision 0.930 Recall 0.930 F1 0.930 
=> Acc: 0.940 Precision 0.940 Recall 0.940 F1 0.940 


accs [0.9073305670816044, 0.9667349027635619, 0.7963730569948186, 0.7201540436456996, 0.9655172413793104, 0.9564388783011163, 0.8968804159445407, 0.9039589442815249, 0.8521478521478522, 0.9215116279069767, 0.8144726712856043, 0.7990622906898861, 0.762987012987013, 0.9217506631299734, 0.9332113449222323, 0.9300486618004866, 0.9404542664211173]
 precisions [0.9036422314430613, 0.9651995905834186, 0.7994818652849741, 0.7317073170731707, 0.9561128526645768, 0.9518105091206098, 0.8890814558058926, 0.9178885630498533, 0.8471528471528471, 0.9156976744186046, 0.806774441878368, 0.8010716677829873, 0.7532467532467533, 0.9330238726790451, 0.929551692589204, 0.9306569343065694, 0.9429097605893186]
 recalls [0.9068695251267865, 0.9600818833162743, 0.78860103626943, 0.7188703465982028, 0.9749216300940439, 0.9578001633542064, 0.8856152512998267, 0.9252199413489736, 0.8621378621378621, 0.9171511627906976, 0.8121632024634334, 0.8077695914266577, 0.7824675324675324, 0.9257294429708223, 0.9451052150045746, 0.920316301703163, 0.941682013505218]
 f1scores [0.9073361888059205, 0.9650322555513767, 0.7697741989868774, 0.724998472165795, 0.9651669558611026, 0.9537131848769921, 0.8967731340518943, 0.9191362367440856, 0.8142187299832464, 0.9295436454743358, 0.7959903389173365, 0.7815939587106907, 0.7105722203376643, 0.9219645376837644, 0.9310434371512624, 0.9286388122097395, 0.9421211358654193]
task 18 =>> taskLabels [85, 86, 87, 88, 89]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84]
=> Acc: 0.850 Precision 0.850 Recall 0.850 F1 0.843 
=> Acc: 0.974 Precision 0.974 Recall 0.974 F1 0.974 
=> Acc: 0.816 Precision 0.816 Recall 0.816 F1 0.793 
=> Acc: 0.861 Precision 0.861 Recall 0.861 F1 0.853 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.975 
=> Acc: 0.904 Precision 0.904 Recall 0.904 F1 0.902 
=> Acc: 0.897 Precision 0.897 Recall 0.897 F1 0.897 
=> Acc: 0.914 Precision 0.914 Recall 0.914 F1 0.913 
=> Acc: 0.876 Precision 0.876 Recall 0.876 F1 0.873 
=> Acc: 0.967 Precision 0.967 Recall 0.967 F1 0.966 
=> Acc: 0.828 Precision 0.828 Recall 0.828 F1 0.824 
=> Acc: 0.809 Precision 0.809 Recall 0.809 F1 0.794 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.850 
=> Acc: 0.893 Precision 0.893 Recall 0.893 F1 0.894 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.897 
=> Acc: 0.926 Precision 0.926 Recall 0.926 F1 0.926 
=> Acc: 0.898 Precision 0.898 Recall 0.898 F1 0.891 
=> Acc: 0.973 Precision 0.973 Recall 0.973 F1 0.973 


accs [0.8497003227293684, 0.973899692937564, 0.8160621761658031, 0.8613607188703466, 0.9749216300940439, 0.9038932752518377, 0.8968804159445407, 0.9142228739002932, 0.8761238761238761, 0.9665697674418605, 0.8283294842186297, 0.8091091761553918, 0.849025974025974, 0.8932360742705571, 0.898444647758463, 0.9263990267639902, 0.898096992019644, 0.9734513274336283]
 precisions [0.8570769940064545, 0.9713408393039918, 0.8072538860103627, 0.8318356867779204, 0.9843260188087775, 0.918867410835829, 0.8942807625649913, 0.9178885630498533, 0.8591408591408591, 0.9563953488372093, 0.8344880677444187, 0.825184192900201, 0.8425324675324676, 0.8846153846153846, 0.9075937785910339, 0.9282238442822385, 0.9079189686924494, 0.9823008849557522]
 recalls [0.8616874135546335, 0.9687819856704196, 0.8119170984455959, 0.8318356867779204, 0.9749216300940439, 0.9180506398039749, 0.8968804159445407, 0.9215542521994134, 0.8761238761238761, 0.9433139534883721, 0.8521939953810623, 0.8308774279973208, 0.8652597402597403, 0.896551724137931, 0.9021043000914913, 0.927007299270073, 0.8956414978514426, 0.9690265486725663]
 f1scores [0.8647624359273312, 0.9685517061119168, 0.7926364395058276, 0.8451804684757217, 0.9747630850901512, 0.9126215383304798, 0.8863762054016663, 0.9304757620523032, 0.8486839655185552, 0.9488290553313752, 0.8286078446622398, 0.7956623959663505, 0.8677522245674215, 0.8944527573295156, 0.8781874861924323, 0.928828688255962, 0.9003962940615141, 0.9668367038951665]
task 19 =>> taskLabels [90, 91, 92, 93, 94]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89]
=> Acc: 0.903 Precision 0.903 Recall 0.903 F1 0.901 
=> Acc: 0.975 Precision 0.975 Recall 0.975 F1 0.976 
=> Acc: 0.773 Precision 0.773 Recall 0.773 F1 0.752 
=> Acc: 0.795 Precision 0.795 Recall 0.795 F1 0.781 
=> Acc: 0.818 Precision 0.818 Recall 0.818 F1 0.795 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.915 
=> Acc: 0.942 Precision 0.942 Recall 0.942 F1 0.943 
=> Acc: 0.928 Precision 0.928 Recall 0.928 F1 0.927 
=> Acc: 0.849 Precision 0.849 Recall 0.849 F1 0.846 
=> Acc: 0.980 Precision 0.980 Recall 0.980 F1 0.981 
=> Acc: 0.701 Precision 0.701 Recall 0.701 F1 0.700 
=> Acc: 0.799 Precision 0.799 Recall 0.799 F1 0.776 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.799 
=> Acc: 0.921 Precision 0.921 Recall 0.921 F1 0.922 
=> Acc: 0.882 Precision 0.882 Recall 0.882 F1 0.882 
=> Acc: 0.906 Precision 0.906 Recall 0.906 F1 0.905 
=> Acc: 0.941 Precision 0.941 Recall 0.941 F1 0.939 
=> Acc: 0.916 Precision 0.916 Recall 0.916 F1 0.912 
=> Acc: 0.979 Precision 0.979 Recall 0.979 F1 0.979 


accs [0.9031811894882434, 0.9754350051177073, 0.7725388601036269, 0.7946084724005135, 0.8181818181818182, 0.9156003267084127, 0.9419410745233969, 0.9281524926686217, 0.8491508491508492, 0.9796511627906976, 0.7013086989992302, 0.7987273945077026, 0.810064935064935, 0.9210875331564987, 0.8819762122598354, 0.9057177615571776, 0.9410681399631676, 0.915929203539823, 0.9788732394366197]
 precisions [0.9096357768556939, 0.9779938587512794, 0.7435233160621761, 0.7933247753530167, 0.8620689655172413, 0.9077048734004901, 0.9350086655112652, 0.9274193548387096, 0.8591408591408591, 0.9607558139534884, 0.7020785219399538, 0.7923643670462157, 0.8165584415584416, 0.9091511936339522, 0.8847209515096066, 0.8838199513381995, 0.9275629220380601, 0.8805309734513275, 0.9823943661971831]
 recalls [0.9174734900875979, 0.9779938587512794, 0.7699481865284974, 0.7958921694480102, 0.786833855799373, 0.9126054995916145, 0.9454072790294628, 0.9274193548387096, 0.8701298701298701, 0.9723837209302325, 0.7421093148575828, 0.7973878097789685, 0.7905844155844156, 0.9190981432360743, 0.8911253430924062, 0.9063260340632603, 0.9337016574585635, 0.8915929203539823, 0.9797535211267606]
 f1scores [0.9038894062332261, 0.9724744761119007, 0.764297026417369, 0.7755106874839065, 0.7665868151254802, 0.9115136491185375, 0.9405511698368064, 0.925636302547937, 0.8320415197074376, 0.9687571556829507, 0.712027968929408, 0.7744624544357075, 0.7512212719529793, 0.8979456089471778, 0.8749661781517641, 0.8911961267673988, 0.9361843379490968, 0.8732760698083748, 0.9839800974865348]
task 20 =>> taskLabels [95, 96, 97, 98, 99]

np.unique(Y) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94] np.unique(Y_train) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]
=> Acc: 0.863 Precision 0.863 Recall 0.863 F1 0.858 
=> Acc: 0.971 Precision 0.971 Recall 0.971 F1 0.971 
=> Acc: 0.791 Precision 0.791 Recall 0.791 F1 0.760 
=> Acc: 0.777 Precision 0.777 Recall 0.777 F1 0.752 
=> Acc: 0.959 Precision 0.959 Recall 0.959 F1 0.959 
=> Acc: 0.932 Precision 0.932 Recall 0.932 F1 0.931 
=> Acc: 0.892 Precision 0.892 Recall 0.892 F1 0.893 
=> Acc: 0.913 Precision 0.913 Recall 0.913 F1 0.911 
=> Acc: 0.860 Precision 0.860 Recall 0.860 F1 0.850 
=> Acc: 0.938 Precision 0.938 Recall 0.938 F1 0.935 
=> Acc: 0.726 Precision 0.726 Recall 0.726 F1 0.723 
=> Acc: 0.792 Precision 0.792 Recall 0.792 F1 0.768 
=> Acc: 0.810 Precision 0.810 Recall 0.810 F1 0.802 
=> Acc: 0.936 Precision 0.936 Recall 0.936 F1 0.934 
=> Acc: 0.937 Precision 0.937 Recall 0.937 F1 0.934 
=> Acc: 0.881 Precision 0.881 Recall 0.881 F1 0.881 
=> Acc: 0.918 Precision 0.918 Recall 0.918 F1 0.917 
=> Acc: 0.894 Precision 0.894 Recall 0.894 F1 0.893 
=> Acc: 0.963 Precision 0.963 Recall 0.963 F1 0.963 
=> Acc: 0.991 Precision 0.991 Recall 0.991 F1 0.992 


accs [0.8630705394190872, 0.9708290685772774, 0.7906735751295336, 0.7766367137355584, 0.9592476489028213, 0.9322080043561122, 0.891681109185442, 0.9134897360703812, 0.8601398601398601, 0.9375, 0.7259430331023865, 0.7916945746818487, 0.810064935064935, 0.9356763925729443, 0.9368709972552608, 0.8813868613138686, 0.9177409453652547, 0.8938053097345132, 0.9630281690140845, 0.9914163090128756]
 precisions [0.8653757491931766, 0.9723643807574207, 0.7922279792746114, 0.8138639281129654, 0.9561128526645768, 0.9275796351756058, 0.8812824956672444, 0.9039589442815249, 0.8641358641358642, 0.9375, 0.7321016166281755, 0.7940388479571333, 0.7905844155844156, 0.9350132625994695, 0.9204025617566332, 0.8959854014598541, 0.9263351749539595, 0.9026548672566371, 0.965669014084507, 0.9957081545064378]
 recalls [0.8626094974642693, 0.9646878198567042, 0.7854922279792746, 0.803594351732991, 0.9310344827586207, 0.9273073781649878, 0.8500866551126517, 0.9105571847507331, 0.8841158841158842, 0.9316860465116279, 0.7313317936874519, 0.8027461486939049, 0.801948051948052, 0.9323607427055703, 0.9121683440073193, 0.8819951338199513, 0.9238796807857581, 0.9070796460176991, 0.9524647887323944, 0.9879828326180258]
 f1scores [0.8418823827622687, 0.9734975733096544, 0.7758723200396511, 0.8004412335982674, 0.9668568263638881, 0.9328178718231184, 0.8852733518100621, 0.9017187805448451, 0.8551433399935393, 0.9347587333924953, 0.7422088317870019, 0.7751046980732149, 0.8272572870482149, 0.9254130271356825, 0.9251643697863592, 0.8915575116531798, 0.9308321538203664, 0.9155097951581925, 0.964417444033019, 0.9869024139597388]
done w/ time
All done
