{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import ConcatDataset, Dataset\n",
    "import torch\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 23 74 19 61 71 36 35 92  5 87 79 64 57 80  9 84 77 49 63 10 13  1 26\n",
      " 31 67 72 51 32 65 15 70 11 60  0 62 82 58 66 45 73 25 52 59 20  3 99 30\n",
      " 48 97 37 24 16 94 76 83 75 81 53 17 55 14 38 40 33 44 54 27 56 41 12 21\n",
      " 68 85 39  7 88 43 78  8 34 28 69 29 47 89 18 98 91 96  2 95 93 86 50 22\n",
      " 90 42  6  4]\n",
      " Training data X (303331, 2381) Y (303331,)\n",
      " Test data X (33704, 2381) Y (33704,)\n",
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], [50, 51, 52, 53, 54], [55, 56, 57, 58, 59], [60, 61, 62, 63, 64], [65, 66, 67, 68, 69], [70, 71, 72, 73, 74], [75, 76, 77, 78, 79], [80, 81, 82, 83, 84], [85, 86, 87, 88, 89], [90, 91, 92, 93, 94], [95, 96, 97, 98, 99]]\n"
     ]
    }
   ],
   "source": [
    "def get_selected_classes(target_classes):\n",
    "    classes_Y = [i for i in range(100)]\n",
    "    #print(classes_Y)\n",
    "    selected_classes = np.random.choice(classes_Y, target_classes,replace=False)\n",
    "    #print(selected_classes)\n",
    "    \n",
    "    return selected_classes\n",
    "\n",
    "def V2_get_continual_ember_class_data(data_dir, train=True):\n",
    "    \n",
    "    if train:\n",
    "        data_dir = data_dir + '/'\n",
    "        XY_train = np.load(data_dir + 'XY_train.npz')\n",
    "        X_tr, Y_tr = XY_train['X_train'], XY_train['Y_train']\n",
    "\n",
    "        return X_tr, Y_tr\n",
    "    else:\n",
    "        data_dir = data_dir + '/'\n",
    "        XY_test = np.load(data_dir + 'XY_test.npz')\n",
    "        X_test, Y_test = XY_test['X_test'], XY_test['Y_test']\n",
    "\n",
    "        return X_test, Y_test \n",
    "\n",
    "\n",
    "def get_ember_selected_class_data(data_dir, selected_classes, train=True):\n",
    "    \n",
    "    \n",
    "    if train:\n",
    "        all_X, all_Y = V2_get_continual_ember_class_data(data_dir, train=True)\n",
    "    else:\n",
    "        all_X, all_Y = V2_get_continual_ember_class_data(data_dir, train=False)\n",
    "    \n",
    "    X_ = []\n",
    "    Y_ = []\n",
    "\n",
    "    for ind, cls in enumerate(selected_classes):\n",
    "        get_ind_cls = np.where(all_Y == cls)\n",
    "        cls_X = all_X[get_ind_cls]\n",
    "        #cls_Y = all_Y[get_ind_cls]\n",
    "\n",
    "        #assert len(cls_Y) == len(cls_X)\n",
    "\n",
    "        for j in range(len(cls_X)):\n",
    "            X_.append(cls_X[j])\n",
    "            Y_.append(ind)\n",
    "\n",
    "    #from sklearn.utils import shuffle        \n",
    "    X_ = np.float32(np.array(X_))\n",
    "    Y_ = np.array(Y_, dtype=np.int64)\n",
    "    X_, Y_ = shuffle(X_, Y_)\n",
    "\n",
    "    if train:\n",
    "        print(f' Training data X {X_.shape} Y {Y_.shape}')\n",
    "    else:\n",
    "        print(f' Test data X {X_.shape} Y {Y_.shape}')\n",
    "    \n",
    "    return X_, Y_\n",
    "\n",
    "\n",
    "class malwareSubDataset(Dataset):\n",
    "    '''To sub-sample a dataset, taking only those samples with label in [sub_labels].\n",
    "\n",
    "    After this selection of samples has been made, it is possible to transform the target-labels,\n",
    "    which can be useful when doing continual learning with fixed number of output units.'''\n",
    "    \n",
    "    def __init__(self, original_dataset, orig_length_features,\\\n",
    "                 target_length_features, sub_labels):\n",
    "        super().__init__()\n",
    "        #print(target_transform)\n",
    "        self.dataset, self.origlabels = original_dataset\n",
    "        self.orig_length_features = orig_length_features\n",
    "        self.target_length_features = target_length_features\n",
    "        \n",
    "        self.sub_indeces = []\n",
    "        for index in range(len(self.dataset)):\n",
    "            label = self.origlabels[index]\n",
    "            \n",
    "            if label in sub_labels:\n",
    "                self.sub_indeces.append(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sub_indeces)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        self.padded_features = np.zeros(self.target_length_features - self.orig_length_features, dtype=np.float32)\n",
    "        sample = np.concatenate((self.dataset[self.sub_indeces[index]],self.padded_features))\n",
    "        target = self.origlabels[self.sub_indeces[index]]\n",
    "        \n",
    "        return (sample, target)  \n",
    "\n",
    "\n",
    "def get_malware_multitask_experiment(target_classes,\\\n",
    "                                     orig_feats_length, target_feats_length,\\\n",
    "                                     scenario, tasks,\\\n",
    "                                     data_dir=\"../../../ember2018/top_class_bases/top_classes_100\"):\n",
    "    \n",
    "    num_class = target_classes\n",
    "\n",
    "    classes_per_task = 5\n",
    "\n",
    "    selected_classes = get_selected_classes(target_classes)\n",
    "\n",
    "    print(selected_classes)\n",
    "\n",
    "    X_train, Y_train = get_ember_selected_class_data(data_dir, selected_classes, train=True)\n",
    "    X_test, Y_test = get_ember_selected_class_data(data_dir, selected_classes, train=False)\n",
    "\n",
    "    \n",
    "    standardization = StandardScaler()\n",
    "    standard_scaler = standardization.fit(X_train)\n",
    "    X_train = standard_scaler.transform(X_train)\n",
    "    X_test = standard_scaler.transform(X_test)  \n",
    "\n",
    "    ember_train, ember_test = (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "\n",
    "    first_task = list(range(50)) #[0, 1, .., 49]\n",
    "\n",
    "    labels_per_task = list([first_task]) + [ \n",
    "        list(np.array(range(classes_per_task)) + classes_per_task * task_id) for task_id in range(10,20)]\n",
    "\n",
    "    print(labels_per_task)\n",
    "\n",
    "#     # split them up into sub-tasks\n",
    "#     train_datasets = []\n",
    "#     test_datasets = []\n",
    "#     for labels in labels_per_task:\n",
    "#         train_datasets.append(malwareSubDataset(ember_train, orig_feats_length,\\\n",
    "#                                                 target_feats_length, labels))\n",
    "#         test_datasets.append(malwareSubDataset(ember_test, orig_feats_length,\\\n",
    "#                                                target_feats_length, labels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Return tuple of train-, validation- and test-dataset, and number of classes per task\n",
    "    #return ((train_datasets, test_datasets), classes_per_task, labels_per_task)\n",
    "    return (ember_train, ember_test, classes_per_task)\n",
    "\n",
    "\n",
    "target_classes = 100\n",
    "scenario = 'class'\n",
    "orig_feats_length, target_feats_length = 2381, 2381\n",
    "tasks = 11\n",
    "\n",
    "# (train_datasets, test_datasets), classes_per_task, (ember_test, labels_per_task) = get_malware_multitask_experiment(\n",
    "#         target_classes=target_classes, scenario=scenario,\\\n",
    "#         orig_feats_length=orig_feats_length,\\\n",
    "#         target_feats_length=target_feats_length, tasks=tasks\n",
    "#     )\n",
    "\n",
    "\n",
    "ember_train, ember_test, classes_per_task  = get_malware_multitask_experiment(\n",
    "        target_classes=target_classes, scenario=scenario,\\\n",
    "        orig_feats_length=orig_feats_length,\\\n",
    "        target_feats_length=target_feats_length, tasks=tasks\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_data(X, Y, replay_portion):\n",
    "    indx = [i for i in range(len(Y))]\n",
    "    random.shuffle(indx)\n",
    "\n",
    "    replay_data_size = int(len(indx)*replay_portion)\n",
    "    replay_index = indx[:replay_data_size]\n",
    "\n",
    "    X_train = X[replay_index]\n",
    "    Y_train = Y[replay_index]\n",
    "    \n",
    "    return X_train, Y_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_class_grs(PreviousTasksData, PreviousTasksLabels,\\\n",
    "                  replay_portion=0.5):\n",
    "    #replay_portion = 0.5\n",
    "    \n",
    "    X, Y = PreviousTasksData\n",
    "    \n",
    "    all_replay_X = []\n",
    "    all_replay_Y = []\n",
    "    for previousTask, CurrentTaskLabels in enumerate(PreviousTasksLabels):\n",
    "        for task_Y in CurrentTaskLabels:\n",
    "            Y_task_ind = np.where(Y == task_Y)\n",
    "\n",
    "            task_samples = X[Y_task_ind]\n",
    "            task_labels = Y[Y_task_ind]\n",
    "\n",
    "            for ind, l in enumerate(task_labels):\n",
    "                all_replay_X.append(task_samples[ind])\n",
    "                all_replay_Y.append(l)\n",
    "\n",
    "\n",
    "    all_replay_X, all_replay_Y = np.array(all_replay_X), np.array(all_replay_Y)\n",
    "    unique_labels = np.unique(all_replay_Y)\n",
    "    \n",
    "    #print(f'all_replay_X {all_replay_X.shape} all_replay_Y {all_replay_Y.shape}')\n",
    "    all_replay_X, all_replay_Y = get_partial_data(all_replay_X, all_replay_Y, replay_portion)\n",
    "    #print(f'all_replay_X {all_replay_X.shape} all_replay_Y {all_replay_Y.shape}')\n",
    "\n",
    "    #print(unique_labels)\n",
    "    \n",
    "    return all_replay_X, all_replay_Y\n",
    "\n",
    "def get_current_task_data(CurrentTaskData, CurrentTaskLabels):\n",
    "    \n",
    "    X, Y = CurrentTaskData\n",
    "    \n",
    "    X_task_samples = []\n",
    "    Y_task_labels = []\n",
    "    \n",
    "    for task_Y in CurrentTaskLabels:\n",
    "        Y_task_ind = np.where(Y == task_Y)\n",
    "        \n",
    "        task_samples = X[Y_task_ind]\n",
    "        task_labels = Y[Y_task_ind]\n",
    "        \n",
    "        for ind, l in enumerate(task_labels):\n",
    "            X_task_samples.append(task_samples[ind])\n",
    "            Y_task_labels.append(l)\n",
    "        \n",
    "    X_task_samples, Y_task_labels = np.array(X_task_samples),\\\n",
    "                                    np.array(Y_task_labels)\n",
    "    \n",
    "    return X_task_samples, Y_task_labels\n",
    "\n",
    "\n",
    "\n",
    "class malwareTrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.samples, self.labels = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        sample = self.samples[index]\n",
    "        target = self.labels[index]\n",
    "        \n",
    "        return (sample, target) \n",
    "    \n",
    "\n",
    "    \n",
    "diversity_mode = 'grs' #'ifs' #ahrs \n",
    "\n",
    "\n",
    "first_task = list(range(50)) #[0, 1, .., 49]\n",
    "\n",
    "labels_per_task = list([first_task]) + [ \n",
    "    list(np.array(range(classes_per_task)) + classes_per_task * task_id) for task_id in range(10,20)]\n",
    "\n",
    "#print(labels_per_task)\n",
    "    \n",
    "# ember_train, ember_test    \n",
    "    \n",
    "# all_current_X, all_current_Y = get_current_task_data(ember_train, labels_per_task[4])\n",
    "\n",
    "all_replay_X, all_replay_Y = get_class_grs(ember_train, labels_per_task[2:3])\n",
    "\n",
    "\n",
    "# all_X = np.concatenate((all_current_X, all_replay_X))\n",
    "# all_Y = np.concatenate((all_current_Y, all_replay_Y))\n",
    "\n",
    "# print(np.unique(all_Y))\n",
    "\n",
    "# task_train_dataset = malwareTrainDataset((all_X, all_Y))\n",
    "\n",
    "\n",
    "# cnt = 0\n",
    "# labels_ = []\n",
    "# for a, b in task_train_dataset:\n",
    "    \n",
    "#     cnt += 1\n",
    "    \n",
    "#     #print(a)\n",
    "#     labels_.append(b)\n",
    "# #     if cnt == 10:\n",
    "# #         break\n",
    "# print(np.unique(labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_replay_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_data(X, Y, replay_portion):\n",
    "    indx = [i for i in range(len(Y))]\n",
    "    random.shuffle(indx)\n",
    "\n",
    "    replay_data_size = int(len(indx)*replay_portion)\n",
    "    replay_index = indx[:replay_data_size]\n",
    "\n",
    "    X_train = X[replay_index]\n",
    "    Y_train = Y[replay_index]\n",
    "    \n",
    "    return X_train, Y_train\n",
    "\n",
    "def get_class_grs(PreviousTasksData, PreviousTasksLabels,\\\n",
    "                  replay_portion=0.5):\n",
    "    #replay_portion = 0.5\n",
    "    \n",
    "    X, Y = PreviousTasksData\n",
    "    \n",
    "    all_replay_X = []\n",
    "    all_replay_Y = []\n",
    "    for previousTask, CurrentTaskLabels in enumerate(PreviousTasksLabels):\n",
    "        for task_Y in CurrentTaskLabels:\n",
    "            Y_task_ind = np.where(Y == task_Y)\n",
    "\n",
    "            task_samples = X[Y_task_ind]\n",
    "            task_labels = Y[Y_task_ind]\n",
    "\n",
    "            for ind, l in enumerate(task_labels):\n",
    "                all_replay_X.append(task_samples[ind])\n",
    "                all_replay_Y.append(l)\n",
    "\n",
    "\n",
    "    all_replay_X, all_replay_Y = np.array(all_replay_X), np.array(all_replay_Y)\n",
    "    unique_labels = np.unique(all_replay_Y)\n",
    "    \n",
    "    #print(f'all_replay_X {all_replay_X.shape} all_replay_Y {all_replay_Y.shape}')\n",
    "    all_replay_X, all_replay_Y = get_partial_data(all_replay_X, all_replay_Y, replay_portion)\n",
    "    #print(f'all_replay_X {all_replay_X.shape} all_replay_Y {all_replay_Y.shape}')\n",
    "\n",
    "    #print(unique_labels)\n",
    "    print(f'all_replay_X {all_replay_X.shape} all_replay_Y {all_replay_Y.shape}')\n",
    "    \n",
    "    return all_replay_X, all_replay_Y\n",
    "\n",
    "\n",
    "\n",
    "all_replay_X, all_replay_Y = get_class_grs(ember_train, labels_per_task[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "def get_data_loader(dataset, batch_size, cuda=False, collate_fn=None, drop_last=False, augment=False):\n",
    "    '''Return <DataLoader>-object for the provided <DataSet>-object [dataset].'''\n",
    "    \n",
    "    \n",
    "    dataset_ = copy.deepcopy(dataset)\n",
    "        \n",
    "        \n",
    "    lbls = []\n",
    "    for ind, i in dataset_:\n",
    "        #print(i)\n",
    "        lbls.append(i)\n",
    "    #print(np.unique(lbls))\n",
    "    y = np.array(lbls,dtype=int)\n",
    "    class_sample_count = np.array([len(np.where(y == t)[0]) for t in np.unique(y)])\n",
    "    \n",
    "    weight = 1. / class_sample_count\n",
    "    \n",
    "    #print(class_sample_count, weight)\n",
    "        \n",
    "    new_samples_weight = []\n",
    "    unique_labels = np.unique(y)\n",
    "    \n",
    "    for lbl in y:\n",
    "        for ul_ind, ul in enumerate(unique_labels):\n",
    "            if lbl == ul:\n",
    "                new_samples_weight.append(weight[ul_ind])\n",
    "    samples_weight = np.array(new_samples_weight)\n",
    "\n",
    "    #print(weight, np.unique(samples_weight), samples_weight[:5], y[:5])\n",
    "\n",
    "    samples_weight = torch.from_numpy(samples_weight).float()\n",
    "    sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "        \n",
    "        \n",
    "    # Create and return the <DataLoader>-object\n",
    "    return DataLoader(\n",
    "        dataset_, batch_size=batch_size, shuffle=False,\n",
    "        collate_fn=(collate_fn or default_collate), drop_last=drop_last, sampler=sampler,\n",
    "        **({'num_workers': 0, 'pin_memory': True} if cuda else {})\n",
    "    )\n",
    "\n",
    "all_current_X, all_current_Y = get_current_task_data(ember_train, labels_per_task[0])\n",
    "task_train_dataset = malwareTrainDataset((all_current_X, all_current_Y))\n",
    "data_loader = iter(get_data_loader(task_train_dataset, 128, drop_last=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "first_task = list(range(50)) #[0, 1, .., 49]\n",
    "\n",
    "labels_per_task = list([first_task]) + [ \n",
    "    list(np.array(range(classes_per_task)) + classes_per_task * task_id) for task_id in range(10,20)]\n",
    "\n",
    "for task, per_task in enumerate(labels_per_task, 1):\n",
    "    if task != 1:\n",
    "        print(f'replay {task-2} previous tasks, {labels_per_task[task-2:task-1]}')\n",
    "        print(f'current task {task} {labels_per_task[task-1]}')\n",
    "        print()\n",
    "    else:\n",
    "        print(task, labels_per_task[task-1])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "first_task = list(range(50)) #[0, 1, .., 49]\n",
    "\n",
    "labels_per_task = list([first_task]) + [ \n",
    "    list(np.array(range(classes_per_task)) + classes_per_task * task_id) for task_id in range(10,20)]\n",
    "\n",
    "#print(labels_per_task)\n",
    "    \n",
    "# ember_train, ember_test    \n",
    "    \n",
    "all_current_X, all_current_Y = get_current_task_data(ember_train, labels_per_task[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_current_X.shape, all_current_Y.shape, np.unique(all_current_Y)==labels_per_task[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partial_data(X, Y, replay_portion):\n",
    "    indx = [i for i in range(len(Y))]\n",
    "    random.shuffle(indx)\n",
    "\n",
    "    replay_data_size = int(len(indx)*replay_portion)\n",
    "    replay_index = indx[:replay_data_size]\n",
    "\n",
    "    X_train = X[replay_index]\n",
    "    Y_train = Y[replay_index]\n",
    "    \n",
    "    return X_train, Y_train\n",
    "\n",
    "\n",
    "num_samples_per_class = 200\n",
    "\n",
    "diversity_mode = 'random' #'ifs' #ahrs \n",
    "#family_based == None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for task, train_data in enumerate(train_datasets, 1):\n",
    "    print(f'task {task}')\n",
    "    cnt = 0\n",
    "    #print(task, train_data)\n",
    "    Ys = []\n",
    "    Xs = []\n",
    "    for x, y in train_data:\n",
    "        #print(type(xy))\n",
    "        Ys.append(y)\n",
    "        Xs.append(x)\n",
    "        \n",
    "    #print(len(np.unique(Ys)), len(Xs))\n",
    "    \n",
    "    Xs, Ys = np.array(Xs), np.array(Ys)\n",
    "    unique_labels = np.unique(Ys)\n",
    "    #print(type(Ys), type(Xs))\n",
    "#     if diversity_mode == 'random' and not family_based:\n",
    "#         for dY in unique_labels:\n",
    "#             dY_ind = np.where(Ys == dY)\n",
    "#             #print(len(dYs[0]))\n",
    "#             #print(Ys)\n",
    "#             #print(type(dY_ind), dY_ind)\n",
    "#             dYs = Ys[dY_ind]\n",
    "#             dXs = Xs[dY_ind]\n",
    "#             #print(len(dYs) == len(dXs))\n",
    "            \n",
    "            \n",
    "            \n",
    "#         pass\n",
    "    \n",
    "    #print(unique_labels)\n",
    "    \n",
    "    \n",
    "#         if cnt == 10:\n",
    "#             break\n",
    "#         cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import random\n",
    "\n",
    "def get_IFBased_samples(family_name, family_data,\\\n",
    "                        contamination,\\\n",
    "                        num_samples_per_malware_family):\n",
    "    \n",
    "    data_X = np.array(family_data)\n",
    "    \n",
    "    if len(data_X) > num_samples_per_malware_family:\n",
    "        \n",
    "        # fit the model\n",
    "        clf = IsolationForest(max_samples=len(data_X), contamination=contamination)\n",
    "        clf.fit(data_X)\n",
    "        #scores_prediction = clf.decision_function(data_X)\n",
    "        y_pred = clf.predict(data_X)\n",
    "\n",
    "\n",
    "        anomalous_idx = np.where(y_pred == -1.0)\n",
    "        similar_idx = np.where(y_pred == 1.0)\n",
    "\n",
    "        #print(f'{family_name}: all-{len(y_pred)} anomalous-{len(anomalous_idx[0])} similar-{len(similar_idx[0])}')\n",
    "        assert len(anomalous_idx[0]) + len(similar_idx[0]) == len(y_pred)\n",
    "\n",
    "        anomalous_samples = data_X[anomalous_idx]\n",
    "        \n",
    "        if len(anomalous_samples) >= num_samples_per_malware_family:\n",
    "            anomalous_samples_pool = list(anomalous_samples)\n",
    "            remaining_samples_to_pick = int(num_samples_per_malware_family/2)\n",
    "            anomalous_samples = random.sample(anomalous_samples_pool, remaining_samples_to_pick)\n",
    "\n",
    "        else:\n",
    "            remaining_samples_to_pick = num_samples_per_malware_family - len(anomalous_samples)\n",
    "            \n",
    "        \n",
    "        if remaining_samples_to_pick <= len(similar_idx):\n",
    "            similar_samples = data_X[similar_idx]\n",
    "        else:\n",
    "            similar_samples_pool = list(data_X[similar_idx])\n",
    "            \n",
    "            print(f'similar_samples_pool {len(similar_samples_pool)} remaining_samples_to_pick {remaining_samples_to_pick}')\n",
    "            similar_samples = random.sample(similar_samples_pool, remaining_samples_to_pick)\n",
    "            \n",
    "        print(f'anomalous_samples {len(anomalous_samples)} similar_samples {len(similar_samples)}')\n",
    "        replay_samples = np.concatenate((anomalous_samples, similar_samples))\n",
    "    else:\n",
    "        replay_samples = data_X\n",
    "        \n",
    "    print(f'Num replay samples {len(replay_samples)}')\n",
    "    return replay_samples\n",
    "\n",
    "\n",
    "\n",
    "def get_class_grs(PreviousTasksData, PreviousTasksLabels, replay_config = 'ifs'):\n",
    "    #replay_portion = 0.5\n",
    "    \n",
    "    replay_portion = 0.5 #args.replay_portion\n",
    "    \n",
    "    \n",
    "    X, Y = PreviousTasksData\n",
    "    \n",
    "    if replay_config == 'frs':\n",
    "        all_replay_X = []\n",
    "        all_replay_Y = []\n",
    "        for previousTask, CurrentTaskLabels in enumerate(PreviousTasksLabels):\n",
    "            for task_Y in CurrentTaskLabels:\n",
    "                Y_task_ind = np.where(Y == task_Y)\n",
    "\n",
    "                task_samples = X[Y_task_ind]\n",
    "                task_labels = Y[Y_task_ind]\n",
    "                \n",
    "                for ind, l in enumerate(task_labels):\n",
    "                    all_replay_X.append(task_samples[ind])\n",
    "                    all_replay_Y.append(l)\n",
    "\n",
    "\n",
    "        all_replay_X, all_replay_Y = np.array(all_replay_X), np.array(all_replay_Y)\n",
    "        unique_labels = np.unique(all_replay_Y)\n",
    "        \n",
    "    elif replay_config == 'ifs':\n",
    "        all_replay_X = []\n",
    "        all_replay_Y = []\n",
    "        for previousTask, CurrentTaskLabels in enumerate(PreviousTasksLabels):\n",
    "            for task_Y in CurrentTaskLabels:\n",
    "                Y_task_ind = np.where(Y == task_Y)\n",
    "\n",
    "                task_samples = X[Y_task_ind]\n",
    "                task_labels = Y[Y_task_ind]\n",
    "                \n",
    "                task_samples = get_IFBased_samples(task_Y, task_samples,\\\n",
    "                        0.1,\\\n",
    "                        200)\n",
    "                \n",
    "                \n",
    "                for ind, ifs_sample in enumerate(task_samples):\n",
    "                    all_replay_X.append(ifs_sample)\n",
    "                    all_replay_Y.append(task_Y)\n",
    "\n",
    "\n",
    "        all_replay_X, all_replay_Y = np.array(all_replay_X), np.array(all_replay_Y)\n",
    "        unique_labels = np.unique(all_replay_Y)\n",
    "        \n",
    "        return all_replay_X, all_replay_Y\n",
    "    else:\n",
    "        all_replay_X = []\n",
    "        all_replay_Y = []\n",
    "        for previousTask, CurrentTaskLabels in enumerate(PreviousTasksLabels):\n",
    "            for task_Y in CurrentTaskLabels:\n",
    "                Y_task_ind = np.where(Y == task_Y)\n",
    "\n",
    "                task_samples = X[Y_task_ind]\n",
    "                task_labels = Y[Y_task_ind]\n",
    "\n",
    "                for ind, l in enumerate(task_labels):\n",
    "                    all_replay_X.append(task_samples[ind])\n",
    "                    all_replay_Y.append(l)\n",
    "\n",
    "\n",
    "        all_replay_X, all_replay_Y = np.array(all_replay_X), np.array(all_replay_Y)\n",
    "        unique_labels = np.unique(all_replay_Y)\n",
    "    \n",
    "        if replay_portion == 1.0:\n",
    "            return all_replay_X, all_replay_Y\n",
    "        else:\n",
    "            all_replay_X, all_replay_Y = get_partial_data(all_replay_X, all_replay_Y, replay_portion)\n",
    "            #print(f'all_replay_X {all_replay_X.shape} all_replay_Y {all_replay_Y.shape}')\n",
    "            #print(unique_labels)\n",
    "            return all_replay_X, all_replay_Y\n",
    "        \n",
    "\n",
    "        \n",
    "def get_current_task_test_data(X, Y, CurrentTaskLabels):\n",
    "    \n",
    "    X_task_samples = []\n",
    "    Y_task_labels = []\n",
    "    \n",
    "    for task_Y in CurrentTaskLabels:\n",
    "        Y_task_ind = np.where(Y == task_Y)\n",
    "        \n",
    "        task_samples = X[Y_task_ind]\n",
    "        task_labels = Y[Y_task_ind]\n",
    "        \n",
    "        for ind, l in enumerate(task_labels):\n",
    "            X_task_samples.append(task_samples[ind])\n",
    "            Y_task_labels.append(l)\n",
    "        \n",
    "    X_task_samples, Y_task_labels = np.array(X_task_samples),\\\n",
    "                                    np.array(Y_task_labels)\n",
    "    \n",
    "    return X_task_samples, Y_task_label        \n",
    "        \n",
    "init_classes = 50\n",
    "target_classes = 100\n",
    "num_class = target_classes\n",
    "\n",
    "scenario = 'class'\n",
    "\n",
    "if scenario == 'class':\n",
    "    initial_task_num_classes = init_classes\n",
    "    if initial_task_num_classes > target_classes:\n",
    "        raise ValueError(f\"Initial Number of Classes cannot be more than {target_classes} classes!\")\n",
    "    left_tasks = 11 - 1 \n",
    "    classes_per_task_except_first_task = int((num_class - initial_task_num_classes) / left_tasks)\n",
    "\n",
    "    #print(selected_classes)\n",
    "    first_task = list(range(initial_task_num_classes))\n",
    "\n",
    "    labels_per_task = [first_task] + [list(initial_task_num_classes +\\\n",
    "                                       np.array(range(classes_per_task_except_first_task)) +\\\n",
    "                                       classes_per_task_except_first_task * task_id)\\\n",
    "                                      for task_id in range(left_tasks)]\n",
    "    classes_per_task = classes_per_task_except_first_task\n",
    "\n",
    "else:\n",
    "    classes_per_task = int(np.floor(num_class / tasks))\n",
    "\n",
    "    labels_per_task = [list(np.array(range(classes_per_task)) +\\\n",
    "                        classes_per_task * task_id) for task_id in range(tasks)]    \n",
    "\n",
    "labels_per_task = labels_per_task[:2]\n",
    "# Loop over all tasks.\n",
    "for task, per_task in enumerate(labels_per_task, 1):\n",
    "\n",
    "    if task != 1:\n",
    "            all_replay_X, all_replay_Y = get_class_grs(ember_train, labels_per_task[:task-1])\n",
    "            all_current_X, all_current_Y = get_current_task_data(ember_train, labels_per_task[task-1])\n",
    "            print(f'all_current_X {all_current_X.shape} all_replay_X {all_replay_X.shape}')\n",
    "            all_X = np.concatenate((all_current_X, all_replay_X))\n",
    "            all_Y = np.concatenate((all_current_Y, all_replay_Y))\n",
    "    else:\n",
    "        all_X, all_Y = get_current_task_data(ember_train, labels_per_task[task-1])\n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"../../../ember2018/top_class_bases/top_classes_100/\"\n",
    "XY_train = np.load(data_dir + 'XY_train.npz')\n",
    "Y_tr = XY_train['Y_train']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys = np.unique(Y_tr)\n",
    "\n",
    "numS = []\n",
    "\n",
    "for Yi in Ys:\n",
    "    YiN = len(np.where(Y_tr == Yi)[0])\n",
    "    numS.append(YiN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.array(numS) >= 1000)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_task_rest_data(X, Y, CurrentTaskLabels):\n",
    "    \n",
    "    X_task_samples = []\n",
    "    Y_task_labels = []\n",
    "    \n",
    "    for task_Y in CurrentTaskLabels:\n",
    "        Y_task_ind = np.where(Y == task_Y)\n",
    "        \n",
    "        task_samples = X[Y_task_ind]\n",
    "        task_labels = Y[Y_task_ind]\n",
    "        \n",
    "        for ind, l in enumerate(task_labels):\n",
    "            X_task_samples.append(task_samples[ind])\n",
    "            Y_task_labels.append(l)\n",
    "        \n",
    "    X_task_samples, Y_task_labels = np.array(X_task_samples),\\\n",
    "                                    np.array(Y_task_labels)\n",
    "    \n",
    "    return X_task_samples, Y_task_labels \n",
    "\n",
    "def get_rest_task_data(RestTasksData, RestTasksLabels):\n",
    "    \n",
    "    X, Y = RestTasksData\n",
    "    \n",
    "    all_rest_X = []\n",
    "    all_rest_Y = []\n",
    "    for restTask, restCurrentTaskLabels in enumerate(RestTasksLabels):\n",
    "        for task_Y in restCurrentTaskLabels:\n",
    "            Y_task_ind = np.where(Y == task_Y)\n",
    "\n",
    "            task_samples = X[Y_task_ind]\n",
    "            task_labels = Y[Y_task_ind]\n",
    "\n",
    "            for ind, l in enumerate(task_labels):\n",
    "                all_rest_X.append(task_samples[ind])\n",
    "                all_rest_Y.append(l)\n",
    "\n",
    "\n",
    "    all_rest_X, all_rest_Y = np.array(all_rest_X), np.array(all_rest_Y)\n",
    "    #unique_labels = np.unique(all_rest_Y)\n",
    "\n",
    "    return all_rest_X, all_rest_Y\n",
    "\n",
    "\n",
    "tasks = 20\n",
    "classes_per_task = int(np.floor(num_class / tasks))\n",
    "\n",
    "labels_per_task = [list(np.array(range(classes_per_task)) +\\\n",
    "                    classes_per_task * task_id) for task_id in range(tasks)] \n",
    "\n",
    "#print(labels_per_task)\n",
    "\n",
    "replay_mode =\"offline\"\n",
    "scenario = \"task\"\n",
    "#task = 1\n",
    "\n",
    "all_replay_X, all_replay_Y = [], []\n",
    "\n",
    "for task in range(1,6):\n",
    "    if replay_mode==\"offline\" and scenario == \"task\":\n",
    "        print(f'current task {task}')\n",
    "        \n",
    "        if task == 1:\n",
    "            current_X, current_Y = get_current_task_data(ember_train, labels_per_task[task-1])\n",
    "\n",
    "            print(f'current task labels {labels_per_task[task-1]}')\n",
    "            print(f'rest task labels {labels_per_task[task:]}')\n",
    "            rest_X, rest_Y = get_rest_task_data(ember_train, labels_per_task[task:])\n",
    "            all_rest_X = rest_X\n",
    "            all_rest_Y = rest_Y\n",
    "\n",
    "        else:\n",
    "            current_X, current_Y = get_current_task_data(ember_train, labels_per_task[task-1])\n",
    "\n",
    "            prev_replay_X, prev_replay_Y = get_class_grs(ember_train, labels_per_task[task-2:task-1])\n",
    "            print(f'prev_replay_Y {prev_replay_Y.shape} {np.unique(prev_replay_Y)}')\n",
    "            \n",
    "            if task > 2:\n",
    "                all_replay_X, all_replay_Y = np.concatenate((all_replay_X, prev_replay_X)),\\\n",
    "                                                     np.concatenate((all_replay_Y, prev_replay_Y))\n",
    "            else:\n",
    "                all_replay_X, all_replay_Y = prev_replay_X, prev_replay_Y\n",
    "                \n",
    "            print(f'all_replay_Y {np.unique(all_replay_Y)}')\n",
    "            \n",
    "            \n",
    "            if task != tasks:\n",
    "                rest_X, rest_Y = get_rest_task_data(ember_train, labels_per_task[task:])\n",
    "\n",
    "                all_rest_X = np.concatenate((all_replay_X, rest_X))\n",
    "                all_rest_Y = np.concatenate((all_replay_Y, rest_Y))\n",
    "\n",
    "            else:\n",
    "                all_rest_X = all_replay_X\n",
    "                all_rest_Y = all_replay_Y\n",
    "\n",
    "        print()\n",
    "        print(f'\\n current_Y {len(current_Y)}')\n",
    "        print(f'\\n all_rest_Y {len(all_rest_Y)}\\n')\n",
    "    #     standard_scaler = standardization.partial_fit(current_X)\n",
    "\n",
    "    #     current_X = standard_scaler.transform(current_X)\n",
    "    #     all_rest_X = standard_scaler.transform(all_rest_X)\n",
    "\n",
    "        x_test, y_test = ember_test\n",
    "    #     x_test = standard_scaler.transform(x_test)\n",
    "\n",
    "\n",
    "        train_datasets = [None]*tasks\n",
    "        for ct, labels in enumerate(labels_per_task):\n",
    "            if ct == task:\n",
    "                train_dataset = malwareTrainDataset((current_X, current_Y))\n",
    "                training_dataset = train_dataset\n",
    "                train_datasets[ct] = train_dataset\n",
    "            else:\n",
    "                rest_task_X, rest_task_Y = get_current_task_rest_data(all_rest_X, all_rest_Y, labels)\n",
    "                train_datasets[ct] = malwareTrainDataset((rest_task_X, rest_task_Y))\n",
    "\n",
    "\n",
    "    previous_datasets = train_datasets\n",
    "    iter(get_data_loader(previous_datasets[task], 512, drop_last=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter(get_data_loader(previous_datasets[task], 512, drop_last=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(all_rest_Y), np.unique(prev_replay_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_loader(previous_datasets[1], 512, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(previous_datasets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "if scenario==\"task\":\n",
    "\n",
    "    up_to_task = task\n",
    "    \n",
    "    batch_size_replay = int(np.ceil(batch_size/up_to_task)) if (up_to_task>1) else batch_size\n",
    "    \n",
    "    # -in Task-IL scenario, need separate replay for each task\n",
    "    for task_id in range(up_to_task):\n",
    "        batch_size_to_use = min(batch_size_replay, len(previous_datasets[task_id]))\n",
    "        \n",
    "        iters_left_previous[task_id] -= 1\n",
    "        \n",
    "        if iters_left_previous[task_id] == 0:\n",
    "            data_loader_previous[task_id] = iter(utils.get_data_loader(\n",
    "                previous_datasets[task_id], batch_size_to_use, cuda=cuda, drop_last=True\n",
    "            ))\n",
    "            iters_left_previous[task_id] = len(data_loader_previous[task_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
