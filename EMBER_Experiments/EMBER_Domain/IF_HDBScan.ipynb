{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import hdbscan\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from ember_utils import *\n",
    "from ember_model import *\n",
    "from ember_pjr_utils import *\n",
    "\n",
    "\n",
    "\n",
    "def get_HDBScanBased_similar_samples(ifbased_similar_samples):\n",
    "    \n",
    "    similar_malware_samples = []\n",
    "    \n",
    "    clf_hdbscan = hdbscan.HDBSCAN()\n",
    "    clf_fit_hdbscan = clf_hdbscan.fit(ifbased_similar_samples)\n",
    "    unique_hdbscan_labels = np.unique(clf_fit_hdbscan.labels_)\n",
    "\n",
    "    if len(unique_hdbscan_labels) == 1:\n",
    "        similar_malware_samples = ifbased_similar_samples\n",
    "    else:\n",
    "        exemplars = clf_fit_hdbscan.exemplars_\n",
    "\n",
    "        #print(selected_family_samples)\n",
    "        for cluster in exemplars:\n",
    "            for sample in cluster:\n",
    "                similar_malware_samples.append(sample)\n",
    "\n",
    "\n",
    "    return similar_malware_samples\n",
    "\n",
    "\n",
    "\n",
    "def get_IFBased_samples(family_name, family_data, num_samples_per_malware_family):\n",
    "    data_X = np.array(family_data)\n",
    "    \n",
    "    if len(data_X) > 1:\n",
    "        \n",
    "        # fit the model\n",
    "        clf = IsolationForest(max_samples=len(data_X))\n",
    "        clf.fit(data_X)\n",
    "        #scores_prediction = clf.decision_function(data_X)\n",
    "        y_pred = clf.predict(data_X)\n",
    "\n",
    "\n",
    "        anomalous_idx = np.where(y_pred == -1.0)\n",
    "        similar_idx = np.where(y_pred == 1.0)\n",
    "\n",
    "        #print(f'{family_name}: all-{len(y_pred)} anomalous-{len(anomalous_idx[0])} similar-{len(similar_idx[0])}')\n",
    "        assert len(anomalous_idx[0]) + len(similar_idx[0]) == len(y_pred)\n",
    "\n",
    "        anomalous_samples = data_X[anomalous_idx]\n",
    "        \n",
    "        similar_samples = get_HDBScanBased_similar_samples(data_X[similar_idx])\n",
    "        \n",
    "        replay_samples = np.concatenate((anomalous_samples, similar_samples))\n",
    "    else:\n",
    "        replay_samples = data_X\n",
    "    \n",
    "    return replay_samples\n",
    "\n",
    "\n",
    "\n",
    "def get_replay_samples_IF_HDBScan_Based(global_family_dict, num_samples_per_malware_family):\n",
    "    \n",
    "    pre_malware_samples = []\n",
    "\n",
    "    cnt = 0\n",
    "    for k, v in global_family_dict.items():\n",
    "        if k != 'goodware':\n",
    "            cnt += 1\n",
    "            selected_family_samples = get_IFBased_samples(k, v, num_samples_per_malware_family)\n",
    "            \n",
    "            #print(selected_family_samples)\n",
    "            for sample in selected_family_samples:\n",
    "                pre_malware_samples.append(sample)\n",
    "                \n",
    "    if len(global_family_dict['goodware']) < len(pre_malware_samples):\n",
    "        pre_goodware_samples = random.sample(global_family_dict['goodware'], len(global_family_dict['goodware']))\n",
    "    else:\n",
    "        pre_goodware_samples = random.sample(global_family_dict['goodware'], len(pre_malware_samples))\n",
    "    \n",
    "    \n",
    "    samples_to_replay = np.concatenate((np.array(pre_goodware_samples), np.array(pre_malware_samples)))\n",
    "    labels_to_replay = np.concatenate((np.zeros(len(pre_goodware_samples)), np.ones(len(pre_malware_samples))))\n",
    "\n",
    "\n",
    "    #print(f'X_replay {samples_to_replay.shape} Y_replay {labels_to_replay.shape}')\n",
    "    #print(f'Replay {len(pre_malware_samples)} malware samples of {len(global_family_dict.keys()) -1} families')\n",
    "    #print(f'and Replay {len(pre_goodware_samples)} goodware samples')\n",
    "    \n",
    "    \n",
    "    return samples_to_replay, labels_to_replay\n",
    "\n",
    "all_task_months = ['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',\n",
    "                   '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12']\n",
    "\n",
    "data_dir = '../../month_based_processing_with_family_labels/'\n",
    "\n",
    "\n",
    "\n",
    "patience = 5\n",
    "replay_type = 'PJR_IF_HDBSCAN'\n",
    "\n",
    "\n",
    "\n",
    "num_exps = 2 #args.num_exps\n",
    "#task_month = args.task_month\n",
    "num_epoch = 500 #args.num_epoch\n",
    "batch_size = 6000 #args.batch_size\n",
    "#replay_portion = args.replay_portion\n",
    "num_samples_per_malware_family = 500\n",
    "\n",
    "exp_type = 'if_hdbscan_' #{'', 'last', 'random', 'ifbased'}\n",
    "\n",
    "exp_seeds = [random.randint(1, 99999) for i in range(num_exps)]\n",
    "\n",
    "\n",
    "allexps_acc = {}\n",
    "allexps_rocauc = {}\n",
    "allexps_training_time = {}\n",
    "all_exps_best_epoch = {}\n",
    "\n",
    "mistaken_stats = {}\n",
    "\n",
    "cnt =  1    \n",
    "for exp in exp_seeds:\n",
    "    start_time = time.time()\n",
    "    use_cuda = True\n",
    "    print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "    use_cuda = use_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    torch.manual_seed(exp)\n",
    "\n",
    "    model = Ember_MLP_Net()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.000001)\n",
    "       \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(f'Model has {count_parameters(model)/1000000}m parameters')    \n",
    "    criterion = nn.BCELoss()    \n",
    "\n",
    "    \n",
    "    \n",
    "    stored_global_family_dict = defaultdict(list)\n",
    "    \n",
    "    standardization = StandardScaler()\n",
    "    standard_scaler = None\n",
    "    for task_month in range(len(all_task_months)):\n",
    "                \n",
    "        print(f'\\n{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Round {cnt} ...')\n",
    "        task_start = time.time()\n",
    "        \n",
    "        #task_month = task_month\n",
    "        current_task = all_task_months[task_month]\n",
    "        task_months = all_task_months[:task_month+1]\n",
    "        print(f'Current Task {current_task} w/ {num_samples_per_malware_family} samples to Replay per Malware family.')\n",
    "\n",
    "\n",
    "        model_save_dir = '../IFBased_pjr_saved_model_' +\\\n",
    "                    str(exp_type) + '/IFBased_PJR_replay_' +\\\n",
    "                    str(num_samples_per_malware_family) + '/' + str(current_task) + '/'\n",
    "        create_parent_folder(model_save_dir)\n",
    "        \n",
    "        opt_save_path = '../IFBased_pjr_saved_optimizer_' +\\\n",
    "                    str(exp_type) + '/IFBased_PJR_replay_' +\\\n",
    "                    str(num_samples_per_malware_family) + '/' + str(current_task) + '/'\n",
    "        create_parent_folder(opt_save_path)\n",
    "        \n",
    "        \n",
    "        results_save_dir = './IFBased_saved_results_' +\\\n",
    "                    str(exp_type) + '/IFBased_PJR_replay_' +\\\n",
    "                    str(num_samples_per_malware_family) + '/' \n",
    "        create_parent_folder(results_save_dir)\n",
    "\n",
    "        \n",
    "        X_train, Y_train, Y_train_family = get_family_labeled_month_data(data_dir, current_task)\n",
    "        X_test, Y_test, Y_test_family = get_family_labeled_task_test_data(data_dir, task_months, mlp_net=True)\n",
    "        \n",
    "        \n",
    "        # to debug\n",
    "        #X_train, Y_train, Y_train_family = X_train[:500], Y_train [:500], Y_train_family[:500]\n",
    "        #X_test, Y_test, Y_test_family = X_test[:50], Y_test[:50], Y_test_family[:50]\n",
    "        \n",
    "\n",
    "        if current_task == all_task_months[0]:\n",
    "            num_replay_samples = 0\n",
    "            stored_global_family_dict = make_family_based_dict(X_train, Y_train, Y_train_family,\\\n",
    "                                                                   current_task, stored_global_family_dict)\n",
    "        else:\n",
    "            \n",
    "            stored_global_family_dict = make_family_based_dict(X_train, Y_train, Y_train_family,\\\n",
    "                                                                   current_task, stored_global_family_dict)\n",
    "            X_train, Y_train =\\\n",
    "                get_replay_samples_IF_HDBScan_Based(stored_global_family_dict, num_samples_per_malware_family)\n",
    "            \n",
    "        print()\n",
    "        print(f'X_train {X_train.shape} Y_train {Y_train.shape}')\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Standardizing ...')\n",
    "        standard_scaler = standardization.partial_fit(X_train)\n",
    "\n",
    "        X_train = standard_scaler.transform(X_train)\n",
    "        X_test = standard_scaler.transform(X_test)\n",
    "\n",
    "        X_train, Y_train = np.array(X_train, np.float32), np.array(Y_train, np.int32)\n",
    "        X_test, Y_test = np.array(X_test, np.float32), np.array(Y_test, np.int32)        \n",
    "                \n",
    "        \n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Training ...')\n",
    "        task_training_time, epoch_ran, training_loss, validation_loss  =\\\n",
    "                                training_early_stopping(model, model_save_dir, opt_save_path,\\\n",
    "                                X_train, Y_train, X_test, Y_test, patience,\\\n",
    "                                batch_size, device, optimizer, num_epoch,\\\n",
    "                                 criterion, replay_type, current_task, exp, earlystopping=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        model = Ember_MLP_Net()\n",
    "        model = model.to(device)\n",
    "        #load the best model for this task\n",
    "        best_model_path = model_save_dir + os.listdir(model_save_dir)[0]\n",
    "        print(f'loading best model {best_model_path}')\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "        \n",
    "        \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.000001)\n",
    "        best_optimizer = opt_save_path + os.listdir(opt_save_path)[0]\n",
    "        print(f'loading best optimizer {best_optimizer}')\n",
    "        optimizer.load_state_dict(torch.load(best_optimizer))\n",
    "        \n",
    "        acc, rocauc = testing_aucscore(model, X_test, Y_test, batch_size, device)\n",
    "           \n",
    "\n",
    "        task_end = time.time()\n",
    "        \n",
    "        print(f'Task Elapsed time {(task_end - task_start)/60} mins.')    \n",
    "        \n",
    "        \n",
    "        results_f = open(os.path.join(results_save_dir + 'if_hdbscan_results_accumulated_replay_' + str(num_samples_per_malware_family) + '_results.txt'), 'a')\n",
    "        result_string = '{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t\\n'.format(current_task,epoch_ran, task_training_time, acc, rocauc, num_replay_samples)\n",
    "        results_f.write(result_string)\n",
    "        results_f.flush()\n",
    "        results_f.close()\n",
    "        \n",
    "    \n",
    "    end_time = time.time()\n",
    "    cnt += 1\n",
    "    print(f'Elapsed time {(end_time - start_time)/60} mins.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
