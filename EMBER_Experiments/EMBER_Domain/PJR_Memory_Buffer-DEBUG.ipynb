{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a49f34d2",
   "metadata": {},
   "source": [
    "mal_samples = np.array([32491, 31222, 20152, 26892, 22193, 25116, 26622, 21791, 37062,\n",
    "        56459, 50000, 50000])\n",
    "good_samples = np.array([29423, 22915, 21373, 25190, 23719, 23285, 24799, 23634, 25707,\n",
    "        29955, 50000, 50000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8799695b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Task 2018-01 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-02 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-03 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-04 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-05 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-06 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-07 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-08 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-09 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-10 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-11 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "Current Task 2018-12 w/ 1 samples to Replay per Malware family.\n",
      "*****************   *****************   *****************\n",
      "\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from ember_utils import *\n",
    "from ember_model import *\n",
    "from ember_pjr_utils import *\n",
    "\n",
    "\n",
    "\n",
    "def create_parent_folder(file_path):\n",
    "    if not os.path.exists(os.path.dirname(file_path)):\n",
    "        os.makedirs(os.path.dirname(file_path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_family_labeled_month_data(data_dir, month, train=True):\n",
    "    \n",
    "    if train:\n",
    "        data_dir = data_dir + str(month) + '/'\n",
    "        XY_train = np.load(data_dir + 'XY_train.npz')\n",
    "        X_tr, Y_tr, Y_tr_family = XY_train['X_train'], XY_train['Y_train'], XY_train['Y_family_train']\n",
    "\n",
    "        #print(f'X_train {X_tr.shape} Y_train {Y_tr.shape} Y_tr_family {Y_tr_family.shape}')\n",
    "        \n",
    "        return X_tr, Y_tr, Y_tr_family\n",
    "    else:\n",
    "        data_dir = data_dir + str(month) + '/'\n",
    "        XY_test = np.load(data_dir + 'XY_test.npz')\n",
    "        X_test, Y_test, Y_test_family = XY_test['X_test'], XY_test['Y_test'], XY_test['Y_family_test']\n",
    "\n",
    "        return X_test, Y_test, Y_test_family\n",
    "\n",
    "    \n",
    "    \n",
    "def get_family_labeled_task_test_data(data_dir, task_months, mlp_net=False):\n",
    "    \n",
    "    X_te, Y_te, Y_te_family = get_family_labeled_month_data(data_dir, task_months[-1], train=False)\n",
    "    \n",
    "    for month in task_months[:-1]:\n",
    "        pre_X_te, pre_Y_te, pre_Y_te_family = get_family_labeled_month_data(data_dir, month, train=False)\n",
    "        X_te, Y_te, Y_te_family = np.concatenate((X_te, pre_X_te)), np.concatenate((Y_te, pre_Y_te)),\\\n",
    "                                np.concatenate((Y_te_family, pre_Y_te_family))\n",
    "        \n",
    "\n",
    "    X_test, Y_test, Y_test_family = X_te, Y_te, Y_te_family\n",
    "    #print(f'X_test {X_test.shape} Y_test {Y_test.shape} Y_te_family {Y_te_family.shape}')\n",
    "    \n",
    "    return X_test, Y_test, Y_test_family\n",
    "\n",
    "\n",
    "def make_family_based_dict(X_train, Y_train, Y_train_family, task_month, global_family_dict):\n",
    "    count = 0\n",
    "    for x_ind, x_sample in enumerate(X_train):\n",
    "        count += 1\n",
    "        #print(x_ind, Y_train[x_ind])\n",
    "\n",
    "        if Y_train[x_ind] == 0:\n",
    "            global_family_dict[\"goodware\"].append(x_sample)\n",
    "        if Y_train[x_ind] == 1:\n",
    "            if Y_train_family[x_ind] == '':\n",
    "                global_family_dict[\"others_family\"].append(x_sample)\n",
    "            else:\n",
    "                global_family_dict[Y_train_family[x_ind]].append(x_sample)\n",
    "\n",
    "    print(f'Task {task_month} and #-of new samples stored {count}')\n",
    "    \n",
    "    return global_family_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_replay_samples(global_family_dict, num_samples_per_malware_family):\n",
    "    pre_malware_samples = []\n",
    "\n",
    "    cnt = 0\n",
    "    for k in global_family_dict.keys():\n",
    "        if k != 'goodware':\n",
    "            cnt += 1\n",
    "            if num_samples_per_malware_family > len(global_family_dict[k]):\n",
    "                selected_family_samples = random.sample(global_family_dict[k], len(global_family_dict[k]))\n",
    "            else:\n",
    "                selected_family_samples = random.sample(global_family_dict[k], num_samples_per_malware_family)\n",
    "\n",
    "            #print(selected_family_samples)\n",
    "            for sample in selected_family_samples:\n",
    "                pre_malware_samples.append(sample)\n",
    "                \n",
    "    if len(global_family_dict['goodware']) < len(pre_malware_samples):\n",
    "        pre_goodware_samples = random.sample(global_family_dict['goodware'], len(global_family_dict['goodware']))\n",
    "    else:\n",
    "        pre_goodware_samples = random.sample(global_family_dict['goodware'], len(pre_malware_samples))\n",
    "\n",
    "    samples_to_replay = np.concatenate((np.array(pre_goodware_samples), np.array(pre_malware_samples)))\n",
    "    labels_to_replay = np.concatenate((np.zeros(len(pre_goodware_samples)), np.ones(len(pre_malware_samples))))\n",
    "\n",
    "\n",
    "    print(f'X_replay {samples_to_replay.shape} Y_replay {labels_to_replay.shape}')\n",
    "    #print(f'Replay {len(pre_malware_samples)} malware samples of {len(global_family_dict.keys()) -1} families')\n",
    "    #print(f'and Replay {len(pre_goodware_samples)} goodware samples')\n",
    "    \n",
    "    \n",
    "    return samples_to_replay, labels_to_replay\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_task_months = ['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',\n",
    "                   '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12']\n",
    "\n",
    "data_dir = '../../month_based_processing_with_family_labels/'\n",
    "num_samples_per_malware_family = 1\n",
    "\n",
    "\n",
    "replay_samples_count = []\n",
    "num_new_samples_per_task = []\n",
    "\n",
    "stored_global_family_dict = defaultdict(list)\n",
    "for task_month in range(len(all_task_months)):\n",
    "\n",
    "    #print(f'\\n{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Round {cnt} ...')\n",
    "    task_start = time.time()\n",
    "\n",
    "    current_task = all_task_months[task_month]\n",
    "    task_months = all_task_months[:task_month+1]\n",
    "    print(f'Current Task {current_task} w/ {num_samples_per_malware_family} samples to Replay per Malware family.')\n",
    "\n",
    "\n",
    "    X_train, Y_train, Y_train_family = get_family_labeled_month_data(data_dir, current_task)\n",
    "    X_test, Y_test, Y_test_family = get_family_labeled_task_test_data(data_dir, task_months, mlp_net=True)\n",
    "    \n",
    "    num_new_samples_per_task.append(len(Y_train))\n",
    "    \n",
    "    #if current_task == all_task_months[0]:\n",
    "    #        stored_global_family_dict = make_family_based_dict(X_train, Y_train, Y_train_family,\\\n",
    "    #                                                           current_task, stored_global_family_dict)\n",
    "    #else:\n",
    "    #        X_replay, Y_replay = get_replay_samples(stored_global_family_dict, num_samples_per_malware_family)\n",
    "    #        replay_samples_count.append(len(Y_replay))\n",
    "    #        stored_global_family_dict = make_family_based_dict(X_train, Y_train, Y_train_family,\\\n",
    "    #                                                           current_task, stored_global_family_dict)\n",
    "            \n",
    "    print(f'*****************   *****************   *****************')\n",
    "    print()\n",
    "    \n",
    "\n",
    "print()\n",
    "print(f'{replay_samples_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbabbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_new_samples_per_task = np.array(num_new_samples_per_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36df14b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fer\n",
      "her\n",
      "ser\n",
      "ser\n",
      "ser\n",
      "ser\n",
      "ser\n",
      "ser\n",
      "ser\n",
      "ser\n",
      "ser\n",
      "ser\n",
      "[     0.  55722.  93094. 139967. 181287. 224847. 271125. 312007. 368499.\n",
      " 446271. 536271. 626271.]\n",
      "[     0.   11144.4  18618.8  27993.4  36257.4  44969.4  54225.   62401.4\n",
      "  73699.8  89254.2 107254.2 125254.2]\n",
      "[     0.   27861.   46547.   69983.5  90643.5 112423.5 135562.5 156003.5\n",
      " 184249.5 223135.5 268135.5 313135.5]\n"
     ]
    }
   ],
   "source": [
    "joint_rep = np.zeros(12)\n",
    "\n",
    "for indx, x in enumerate(num_new_samples_per_task):\n",
    "    #print(indx)\n",
    "    if indx == 0:\n",
    "        print('fer')\n",
    "        joint_rep[indx] = 0.0\n",
    "    elif indx == 1:\n",
    "        print('her')\n",
    "        joint_rep[indx] = num_new_samples_per_task[indx - 1]\n",
    "    else:\n",
    "        print('ser')\n",
    "        joint_rep[indx] = joint_rep[indx - 1] + x\n",
    "        \n",
    "print(joint_rep)\n",
    "print(joint_rep*.20)\n",
    "print(joint_rep*.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f8f6d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 1.6.0 CUDA 10.2\n",
      "Model has 3.132161m parameters\n",
      "\n",
      "2022-09-20 10:38:01 Round 1 ...\n",
      "Current Task 2018-01 w/ 5000 samples to Replay per Malware family.\n",
      "X_train (55722, 2381) Y_train (55722,) Y_tr_family (55722,)\n",
      "X_test (6192, 2381) Y_test (6192,) Y_te_family (6192,)\n",
      "2022-09-20 10:38:02 Standardizing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2018-01 and #-of new samples stored 55722\n",
      "Initial Task 2018-01 X_train (55722, 2381) Y_train (55722,)\n",
      "************** ************** **************\n",
      "\n",
      "2022-09-20 10:38:05 Training ...\n",
      "Epoch 1 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  6.09it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7039, Train Acc: 53.01\n",
      "Val Loss: 0.6807, Val Acc: 69.41\n",
      "Validation loss decreased (inf --> 0.680662).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_1.pt\n",
      "Epoch 2 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.09it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.34it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6592, Train Acc: 61.92\n",
      "Val Loss: 0.6331, Val Acc: 75.55\n",
      "Validation loss decreased (0.680662 --> 0.633099).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_2.pt\n",
      "Epoch 3 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.38it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.30it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6085, Train Acc: 68.45\n",
      "Val Loss: 0.5747, Val Acc: 77.15\n",
      "Validation loss decreased (0.633099 --> 0.574686).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_3.pt\n",
      "Epoch 4 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.47it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.47it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5556, Train Acc: 72.58\n",
      "Val Loss: 0.4838, Val Acc: 81.76\n",
      "Validation loss decreased (0.574686 --> 0.483850).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_4.pt\n",
      "Epoch 5 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.49it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.36it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4987, Train Acc: 76.02\n",
      "Val Loss: 0.4500, Val Acc: 78.71\n",
      "Validation loss decreased (0.483850 --> 0.450000).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_5.pt\n",
      "Epoch 6 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.20it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.51it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4605, Train Acc: 78.01\n",
      "Val Loss: 0.3819, Val Acc: 82.65\n",
      "Validation loss decreased (0.450000 --> 0.381923).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_6.pt\n",
      "Epoch 7 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.48it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.35it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4232, Train Acc: 79.93\n",
      "Val Loss: 0.3538, Val Acc: 84.62\n",
      "Validation loss decreased (0.381923 --> 0.353795).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_7.pt\n",
      "Epoch 8 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.37it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.45it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3855, Train Acc: 82.16\n",
      "Val Loss: 0.3322, Val Acc: 87.19\n",
      "Validation loss decreased (0.353795 --> 0.332237).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_8.pt\n",
      "Epoch 9 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.37it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.26it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3584, Train Acc: 83.99\n",
      "Val Loss: 0.2824, Val Acc: 89.75\n",
      "Validation loss decreased (0.332237 --> 0.282358).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_9.pt\n",
      "Epoch 10 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.28it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3314, Train Acc: 85.44\n",
      "Val Loss: 0.2788, Val Acc: 88.47\n",
      "Validation loss decreased (0.282358 --> 0.278834).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_10.pt\n",
      "Epoch 11 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.64it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.25it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3076, Train Acc: 86.64\n",
      "Val Loss: 0.2815, Val Acc: 88.26\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 12 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.30it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2893, Train Acc: 87.54\n",
      "Val Loss: 0.2788, Val Acc: 87.04\n",
      "Validation loss decreased (0.278834 --> 0.278775).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_12.pt\n",
      "Epoch 13 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.59it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.28it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2728, Train Acc: 88.40\n",
      "Val Loss: 0.2366, Val Acc: 90.05\n",
      "Validation loss decreased (0.278775 --> 0.236636).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_13.pt\n",
      "Epoch 14 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.49it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2601, Train Acc: 89.14\n",
      "Val Loss: 0.2015, Val Acc: 91.70\n",
      "Validation loss decreased (0.236636 --> 0.201539).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_14.pt\n",
      "Epoch 15 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.42it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2471, Train Acc: 89.52\n",
      "Val Loss: 0.2338, Val Acc: 90.24\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 16 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.27it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2403, Train Acc: 89.99\n",
      "Val Loss: 0.2075, Val Acc: 91.37\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 17 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.28it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2331, Train Acc: 90.37\n",
      "Val Loss: 0.1934, Val Acc: 91.79\n",
      "Validation loss decreased (0.201539 --> 0.193431).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_17.pt\n",
      "Epoch 18 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.29it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2250, Train Acc: 90.87\n",
      "Val Loss: 0.2167, Val Acc: 90.62\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 19 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.52it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.32it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2165, Train Acc: 91.20\n",
      "Val Loss: 0.1775, Val Acc: 92.67\n",
      "Validation loss decreased (0.193431 --> 0.177496).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_19.pt\n",
      "Epoch 20 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.50it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.33it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2068, Train Acc: 91.70\n",
      "Val Loss: 0.1719, Val Acc: 92.32\n",
      "Validation loss decreased (0.177496 --> 0.171850).  Saving model ...\n",
      "../pjr_saved_model/PJR_replay_5000/2018-01/best_model_epoch_20.pt\n",
      "Epoch 21 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.19it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.44it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2037, Train Acc: 91.86\n",
      "Val Loss: 0.2051, Val Acc: 92.25\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 22 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.50it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2008, Train Acc: 91.93\n",
      "Val Loss: 0.1983, Val Acc: 91.88\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 23 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.34it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1939, Train Acc: 92.38\n",
      "Val Loss: 0.1889, Val Acc: 92.66\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 24 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.39it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.46it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1933, Train Acc: 92.27\n",
      "Val Loss: 0.1821, Val Acc: 92.51\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 25 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  5.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.23it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1857, Train Acc: 92.61\n",
      "Val Loss: 0.2000, Val Acc: 92.14\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Training time: 0.773 minutes\n",
      "0.9278100775193798 0.9818103702095049\n",
      "Elapsed time 0.8428683559099833 mins.\n",
      "\n",
      "2022-09-20 10:38:51 Round 1 ...\n",
      "Current Task 2018-02 w/ 5000 samples to Replay per Malware family.\n",
      "X_train (48723, 2381) Y_train (48723,) Y_tr_family (48723,)\n",
      "X_test (11606, 2381) Y_test (11606,) Y_te_family (11606,)\n",
      "2022-09-20 10:38:52 Standardizing ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7ee5e52aa806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m                                                                current_task, stored_global_family_dict)\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mX_replay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_replay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_replay_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstored_global_family_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples_per_malware_family\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             stored_global_family_dict = make_family_based_dict(X_train, Y_train, Y_train_family,\\\n\u001b[1;32m     98\u001b[0m                                                                current_task, stored_global_family_dict)\n",
      "\u001b[0;32m<ipython-input-3-542140246318>\u001b[0m in \u001b[0;36mget_replay_samples\u001b[0;34m(global_family_dict, num_samples_per_malware_family)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mpre_malware_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mpre_goodware_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_family_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'goodware'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_malware_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0msamples_to_replay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_goodware_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_malware_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/PyTorch/lib/python3.7/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "all_task_months = ['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',\n",
    "                   '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12']\n",
    "\n",
    "data_dir = '../../month_based_processing_with_family_labels/'\n",
    "\n",
    "\n",
    "patience = 5\n",
    "replay_type = 'partial_joint_replay'\n",
    "\n",
    "\n",
    "num_exps = 1 #args.num_exps\n",
    "#task_month = args.task_month\n",
    "num_epoch = 500 #args.num_epoch\n",
    "batch_size = 6000 #args.batch_size\n",
    "#replay_portion = args.replay_portion\n",
    "num_samples_per_malware_family = 5000\n",
    "\n",
    "exp_seeds = [random.randint(1, 99999) for i in range(num_exps)]\n",
    "\n",
    "\n",
    "allexps_acc = {}\n",
    "allexps_rocauc = {}\n",
    "allexps_training_time = {}\n",
    "all_exps_best_epoch = {}\n",
    "\n",
    "\n",
    "\n",
    "cnt =  1    \n",
    "for exp in exp_seeds:\n",
    "    start_time = time.time()\n",
    "    use_cuda = True\n",
    "    print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "    use_cuda = use_cuda and torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    torch.manual_seed(exp)\n",
    "\n",
    "    model = Ember_MLP_Net()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.000001)\n",
    "       \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(f'Model has {count_parameters(model)/1000000}m parameters')    \n",
    "    criterion = nn.BCELoss()    \n",
    "\n",
    "    \n",
    "    \n",
    "    stored_global_family_dict = defaultdict(list)\n",
    "    \n",
    "    standardization = StandardScaler()\n",
    "    standard_scaler = None\n",
    "    for task_month in range(len(all_task_months)):\n",
    "                \n",
    "        print(f'\\n{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Round {cnt} ...')\n",
    "        task_start = time.time()\n",
    "        \n",
    "        current_task = all_task_months[task_month]\n",
    "        task_months = all_task_months[:task_month+1]\n",
    "        print(f'Current Task {current_task} w/ {num_samples_per_malware_family} samples to Replay per Malware family.')\n",
    "\n",
    "\n",
    "        model_save_dir = '../pjr_saved_model/PJR_replay_' + str(num_samples_per_malware_family) + '/' + str(current_task) + '/'\n",
    "        create_parent_folder(model_save_dir)\n",
    "        \n",
    "        results_save_dir = './saved_results/PJR_replay_' + str(num_samples_per_malware_family) + '/' \n",
    "        create_parent_folder(results_save_dir)\n",
    "\n",
    "        \n",
    "        X_train, Y_train, Y_train_family = get_family_labeled_month_data(data_dir, current_task)\n",
    "        X_test, Y_test, Y_test_family = get_family_labeled_task_test_data(data_dir, task_months, mlp_net=True)\n",
    "        \n",
    "        # to debug\n",
    "        #X_train, Y_train, Y_train_family = X_train[:500], Y_train [:500], Y_train_family[:500]\n",
    "        #X_test, Y_test, Y_test_family = X_test[:50], Y_test[:50], Y_test_family[:50]\n",
    "        \n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Standardizing ...')\n",
    "        \n",
    "        standard_scaler = standardization.partial_fit(X_train)\n",
    "\n",
    "        X_train = standard_scaler.transform(X_train)\n",
    "        X_test = standard_scaler.transform(X_test)\n",
    "\n",
    "        X_train, Y_train = np.array(X_train, np.float32), np.array(Y_train, np.int32)\n",
    "        X_test, Y_test = np.array(X_test, np.float32), np.array(Y_test, np.int32)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if current_task == all_task_months[0]:\n",
    "            stored_global_family_dict = make_family_based_dict(X_train, Y_train, Y_train_family,\\\n",
    "                                                               current_task, stored_global_family_dict)\n",
    "        else:\n",
    "            X_replay, Y_replay = get_replay_samples(stored_global_family_dict, num_samples_per_malware_family)\n",
    "            stored_global_family_dict = make_family_based_dict(X_train, Y_train, Y_train_family,\\\n",
    "                                                               current_task, stored_global_family_dict)\n",
    "        \n",
    "        \n",
    "        if current_task == all_task_months[0]:\n",
    "            print(f'Initial Task {current_task} X_train {X_train.shape} Y_train {Y_train.shape}')\n",
    "            print(f'************** ************** **************')\n",
    "            print()\n",
    "        else:\n",
    "            print(f'W/O replay samples \\n X_train {X_train.shape} Y_train {Y_train.shape}')\n",
    "            X_train, Y_train = np.concatenate((X_train, X_replay)), np.concatenate((Y_train, Y_replay))\n",
    "            print(f'With replay samples \\n X_train {X_train.shape} Y_train {Y_train.shape}')\n",
    "            print(f'************** ************** **************')\n",
    "            print()\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(f'{datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")} Training ...')\n",
    "        task_training_time, epoch_ran, training_loss, validation_loss  = training_early_stopping(model, model_save_dir,\\\n",
    "                                X_train, Y_train, X_test, Y_test, patience,\\\n",
    "                                batch_size, device, optimizer, num_epoch,\\\n",
    "                                 criterion, replay_type, current_task, exp, earlystopping=True)\n",
    "\n",
    "        acc, rocauc = testing_aucscore(model, X_test, Y_test, batch_size, device)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f'Elapsed time {(end_time - start_time)/60} mins.')    \n",
    "\n",
    "\n",
    "        task_end = time.time()\n",
    "        task_run_time = (task_end - task_start)/60\n",
    "        \n",
    "        try:\n",
    "            allexps_acc[str(current_task)].append(acc)\n",
    "            allexps_rocauc[str(current_task)].append(rocauc)\n",
    "            allexps_training_time[str(current_task)].append(task_run_time)\n",
    "            all_exps_best_epoch[str(current_task)].append(epoch_ran)\n",
    "        except:\n",
    "            allexps_acc[str(current_task)] = [acc]\n",
    "            allexps_rocauc[str(current_task)] = [rocauc]\n",
    "            allexps_training_time[str(current_task)] = [task_run_time]\n",
    "            all_exps_best_epoch[str(current_task)] = [epoch_ran]\n",
    "        \n",
    "        \n",
    "        \n",
    "        results_f = open(os.path.join(results_save_dir + 'results_accumulated_replay_' + str(num_samples_per_malware_family) + '_results.txt'), 'a')\n",
    "        result_string = '{}\\t{}\\t{}\\t{}\\t{}\\t\\n'.format(current_task,epoch_ran, task_training_time, acc, rocauc)\n",
    "        results_f.write(result_string)\n",
    "        results_f.flush()\n",
    "        results_f.close()\n",
    "\n",
    "        \n",
    "        wf = open(os.path.join(results_save_dir + 'Results_' + str(current_task) + '_' + str(num_epoch) + '_replay_' + str(num_samples_per_malware_family) + '_results.txt'), 'a')\n",
    "        task_exp_string = '\\n\\nSeed\\t{}\\t\\tRun time\\t{}\\tAcc:\\t{}\\t\\tROC_AUC:\\t{}\\n\\tepoch_ran\\t{}\\t\\n\\ntraining_loss\\t{}\\n\\nValid_loss\\t{}\\n\\n'.format(exp,task_training_time, acc, rocauc, epoch_ran, training_loss, validation_loss)\n",
    "        \n",
    "        wf.write('\\n ########################### ########################### ###########################\\n')\n",
    "        wf.write(str(model))\n",
    "        wf.write(task_exp_string)\n",
    "        \n",
    "        wf.flush()\n",
    "        wf.close()\n",
    "\n",
    "    end_time = time.time()\n",
    "    cnt += 1\n",
    "    print(f'Elapsed time {(end_time - start_time)/60} mins.')\n",
    "    \n",
    "results_save_dir = './saved_results/PJR_replay_' + str(num_samples_per_malware_family) + '/' \n",
    "create_parent_folder(results_save_dir)\n",
    "\n",
    "all_results_save_file = results_save_dir + 'PJR_acc_rocauc_tr_time_best_epoch_' + str(args.num_run) + '.npz'\n",
    "\n",
    "np.savez_compressed(all_results_save_file,\n",
    "                        accuracy = allexps_acc, rocauc = allexps_rocauc, tr_time = allexps_training_time, best_epochs = all_exps_best_epoch)\n",
    "print(f'all results saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178cbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
