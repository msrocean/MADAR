{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time, random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsample.torchsample.modules import ModuleTrainer\n",
    "from ember_utils import *\n",
    "from ember_model import *\n",
    "#from ember_utils import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        #self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        #self.current_epoch = epoch\n",
    "    def __call__(self, path, epoch, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(path, epoch, val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(path, epoch, val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, path, epoch, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        self.delete_previous_saved_model(path)\n",
    "        path = path + 'best_model_epoch_' + str(epoch) + '.pt'\n",
    "        torch.save(model.state_dict(), path)\n",
    "        self.val_loss_min = val_loss\n",
    "        \n",
    "    def delete_previous_saved_model(self, path):\n",
    "        saved_models = os.listdir(path)\n",
    "        for prev_model in saved_models:\n",
    "            prev_model = path + prev_model\n",
    "            print(prev_model)\n",
    "            if os.path.isfile(prev_model):\n",
    "                os.remove(prev_model)\n",
    "            else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_early_stopping(model, X_train, y_train, X_valid, y_valid,\\\n",
    "                            patience, batch_size, device, optimizer, num_epoch,\\\n",
    "             criterion, replay_type, current_task, save_dir, exp, earlystopping=True):\n",
    " \n",
    "    \n",
    "    \n",
    "    trainloader = get_dataloader(X_train, y_train, batch_size, train_data=True)\n",
    "    validloader = get_dataloader(X_valid, y_valid, batch_size, train_data=False)\n",
    "    \n",
    "    \n",
    "    train_loss, train_acc = [], []\n",
    "    valid_loss, valid_acc = [], []\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    \n",
    "    start_train = time.time()\n",
    "    for epoch in range(1,num_epoch+1):\n",
    "        print(f\"Epoch {epoch} of {num_epoch}\")\n",
    "        epoch_train_loss, epoch_train_acc = epoch_training(model, trainloader, batch_size, criterion, optimizer, device)\n",
    "        epoch_valid_loss, epoch_valid_acc = validation(model, validloader, batch_size, criterion, device)\n",
    "        \n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_acc.append(epoch_train_acc)\n",
    "        valid_loss.append(epoch_valid_loss)\n",
    "        valid_acc.append(epoch_valid_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}\")\n",
    "        print(f'Val Loss: {epoch_valid_loss:.4f}, Val Acc: {epoch_valid_acc:.2f}')\n",
    "\n",
    "        \n",
    "        save_path = './dummy_test/' + str(exp) + '/'\n",
    "        create_parent_folder(save_path)\n",
    "        #lr_scheduler(epoch_valid_loss)\n",
    "        if earlystopping:\n",
    "            early_stopping(save_path, epoch, epoch_valid_loss, model)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "                \n",
    "    end = time.time()\n",
    "    print(f\"Training time: {(end-start_train)/60:.3f} minutes\")\n",
    "    \n",
    "    best_model = os.listdir(save_path)\n",
    "    best_epoch = int(saved_models[0].split('_')[3].split('.')[0])\n",
    "    return (end-start_train)/60, best_epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch 1.6.0 CUDA 10.2\n",
      "Model has 9.210305m parameters\n",
      "Current Task 2018-01 with Replay 0.0%\n",
      "Current Task month 2018-01 data X (50149, 2381) Y (50149,)\n",
      "X_train (50149, 1, 49, 49) Y_train (50149,)\n",
      "\n",
      "X_valid (5573, 1, 49, 49) Y_valid (5573,)\n",
      "\n",
      "X_test (6192, 1, 49, 49) Y_test (6192,)\n",
      "Epoch 1 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:18,  2.55it/s]\n",
      "6it [00:01,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7124, Train Acc: 51.04\n",
      "Val Loss: 0.6930, Val Acc: 51.61\n",
      "Validation loss decreased (inf --> 0.692952).  Saving model ...\n",
      "./dummy_test/11/best_model_epoch_5.pt\n",
      "Epoch 2 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [00:19,  2.50it/s]\n",
      "6it [00:01,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6997, Train Acc: 50.90\n",
      "Val Loss: 0.6971, Val Acc: 49.95\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 3 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [00:19,  2.45it/s]\n",
      "6it [00:01,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6947, Train Acc: 50.94\n",
      "Val Loss: 0.6966, Val Acc: 49.64\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 4 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [00:19,  2.41it/s]\n",
      "6it [00:01,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6927, Train Acc: 51.23\n",
      "Val Loss: 0.6957, Val Acc: 50.16\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 5 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [00:20,  2.39it/s]\n",
      "6it [00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6918, Train Acc: 51.54\n",
      "Val Loss: 0.6984, Val Acc: 49.37\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 6 of 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "48it [00:20,  2.38it/s]\n",
      "6it [00:01,  5.84it/s]\n",
      " 14%|█▍        | 1/7 [00:00<00:01,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6911, Train Acc: 51.21\n",
      "Val Loss: 0.6987, Val Acc: 49.70\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "Training time: 2.204 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.204322302341461 5\n",
      "0.5243863049095607 0.5128695963079182\n",
      "Elapsed time 2.27274866104126 mins.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
    "use_cuda = use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n",
    "torch.manual_seed(1);\n",
    "\n",
    "\n",
    "batch_size = 1024\n",
    "num_epoch = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "replay_type = 'joint'\n",
    "\n",
    "result_save_dir = '../../ember2018_exps_store/month_based_partial/'\n",
    "\n",
    "model = Ember_Net()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model = model.to(device)\n",
    "print(f'Model has {count_parameters(model)/1000000}m parameters')    \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()\n",
    "patience = 5\n",
    "\n",
    "#lr_scheduler = LRScheduler(optimizer, patience)\n",
    "\n",
    "\n",
    "all_task_months = ['2018-01', '2018-02', '2018-03', '2018-04', '2018-05', '2018-06',\n",
    "                   '2018-07', '2018-08', '2018-09', '2018-10', '2018-11', '2018-12']\n",
    "\n",
    "data_dir = '../../ember2018/month_based_processing/'\n",
    "\n",
    "\n",
    "replay_portion = 0.00\n",
    "\n",
    "\n",
    "for task in range(len(all_task_months[:1])):\n",
    "    start_time = time.time()\n",
    "    current_task = all_task_months[task]\n",
    "    task_months = all_task_months[:task+1]\n",
    "    print(f'Current Task {current_task} with Replay {replay_portion*100}%')\n",
    "\n",
    "    X_train, Y_train, X_valid, Y_valid = get_task_partial_joint_training_data(data_dir, task_months, replay_portion)\n",
    "    X_test, Y_test = get_task_test_data(data_dir, task_months)\n",
    "    \n",
    "    model_save_dir = '../../ember2018_exps_store/month_based_partial/' + '/partial_joint_replay_' + str(replay_portion) + '/'\n",
    "    results_save_dir = './ember2018_store_results/' + '/replay_' + str(replay_portion) + '/' \n",
    "    \n",
    "    tr_time, best_epoch = training_early_stopping(model, X_train, Y_train, X_valid, Y_valid, patience, batch_size, device, optimizer, num_epoch,\\\n",
    "                 criterion, replay_type, current_task, save_dir, 11, earlystopping=True)\n",
    "\n",
    "    acc, rocauc = testing_aucscore(model, X_test, Y_test, batch_size, device)\n",
    "    \n",
    "    print(tr_time, best_epoch)\n",
    "    print(acc, rocauc)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f'Elapsed time {(end_time - start_time)/60} mins.')    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
